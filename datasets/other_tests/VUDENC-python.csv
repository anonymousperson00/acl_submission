function,label
"[""def FUNC_8(self, VAR_10=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_10:\n"", ""VAR_25 = Win.objects.inactive()\n"", ""VAR_25 = Win.objects.all()\n"", ""if VAR_10:\n"", ""VAR_25 = VAR_25.exclude(user__email__in=settings.IGNORE_USERS)\n"", ""VAR_25 = VAR_25.values()\n"", ""for VAR_5 in VAR_25:\n"", ""yield self._get_win_data(VAR_5)\n""]",0
"[""@login_required...\n"", ""VAR_5 = {}\n"", ""if not VAR_0.user.is_authenticated:\n"", ""return invalid_permission_redirect(VAR_0)\n"", ""VAR_20 = VAR_2.get('transaction_code', None)\n"", ""VAR_4 = get_object_or_404(Transaction, code=transaction_code)\n"", ""VAR_5['transaction'] = VAR_4\n"", ""if VAR_4.closed:\n"", ""return redirect('message', message=gettext('Transaction Closed'))\n"", ""if VAR_0.method == 'POST':\n"", ""VAR_26 = TransactionPayForm(VAR_0.POST, instance=transaction)\n"", ""VAR_26 = TransactionPayForm(instance=transaction)\n"", ""VAR_33 = VAR_26.is_valid()\n"", ""VAR_5['form'] = VAR_26\n"", ""if VAR_26.data['cancel_button'] == 'True':\n"", ""return render(VAR_0, 'transactions/transaction_pay.html', VAR_5)\n"", ""VAR_4.delete()\n"", ""if VAR_33:\n"", ""return redirect('index')\n"", ""if VAR_26.cleaned_data['confirm_button']:\n"", ""VAR_5['form'] = VAR_26\n"", ""VAR_4.closed = True\n"", ""if VAR_26.cleaned_data['save_button']:\n"", ""return render(VAR_0, 'transactions/transaction_pay.html', VAR_5)\n"", ""VAR_4.closed_date = timezone.datetime.now()\n"", ""VAR_4.save()\n"", ""VAR_4.save()\n"", ""return redirect('transaction_detail', VAR_20=transaction.code)\n"", ""return redirect('transaction_detail', VAR_20=transaction.code)\n""]",0
"[""def FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10):...\n"", ""if VAR_11 == 'POST':\n"", ""return CLASS_0.session.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=\n    _HEADERS, VAR_10=timeout)\n"", ""if VAR_11 == 'GET':\n"", ""return CLASS_0.session.get(FUNC_2(VAR_7), headers=_HEADERS, VAR_10=timeout)\n""]",1
"[""@wraps(VAR_7)...\n"", ""if not app.config.get('USE_AUTH'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""FUNC_0()\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""logging.warning('require_logout(): calling log_out()')\n"", ""VAR_16 = VAR_1.log_out()\n"", ""if VAR_16.headers.get('Location') == url_for('goodbye'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""return VAR_16\n""]",0
"[""def FUNC_6(self, VAR_11, VAR_12=None, VAR_13=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.query = VAR_11\n"", ""if not VAR_12 or not VAR_13:\n"", ""VAR_12, VAR_13 = self.model.rowCount() + 1, self.model.rowCount(\n    ) + self.model.item_load_batch\n"", ""VAR_19, VAR_20 = self._get_sort_parameters()\n"", ""VAR_23 = {'filter': FUNC_1(VAR_11), 'first': VAR_12 if VAR_12 else '',\n    'last': VAR_13 if VAR_13 else '', 'sort_by': VAR_19 if VAR_19 else '',\n    'sort_asc': VAR_20, 'hide_xxx': self.model.hide_xxx, 'metadata_type': \n    self.model.type_filter if self.model.type_filter else ''}\n"", ""self.request_mgr = TriblerRequestManager()\n"", ""self.request_mgr.perform_request('search', self.on_search_results, VAR_23=\n    url_params)\n""]",0
"[""def FUNC_11(self, VAR_20=None, VAR_18=None, **VAR_3):...\n"", ""VAR_34 = VAR_3.pop('cache', False)\n"", ""VAR_20 = self.__prepare(VAR_20, VAR_18)\n"", ""return self._unload(VAR_20, VAR_3, VAR_34=cache)\n""]",0
"[""def __init__(self, VAR_5, VAR_6):...\n"", ""tk.Frame.__init__(self, VAR_5)\n"", ""self.controller = VAR_6\n"", ""VAR_22, VAR_23, VAR_24, VAR_25 = VAR_6.get_result()\n"", ""VAR_26 = Image.open(VAR_25)\n"", ""VAR_27 = ImageTk.PhotoImage(VAR_26)\n"", ""VAR_28 = tk.Label(self, image=render)\n"", ""VAR_28.image = VAR_27\n"", ""VAR_28.pack(side='right')\n"", ""VAR_29 = tk.Label(self, text='Product: ' + name, font=controller.titleFont)\n"", ""VAR_29.pack(pady=10, padx=10, anchor='nw')\n"", ""VAR_30 = tk.Label(self, text='UPC: ' + UPC, font=controller.itemFont)\n"", ""VAR_30.pack(pady=10, padx=10, anchor='nw')\n"", ""VAR_31 = tk.Button(self, text='New Search', font=controller.itemFont,\n    command=lambda : self.new_search())\n"", ""VAR_31.pack(side='left', pady=10, padx=10, anchor='sw')\n"", ""VAR_32 = tk.Button(self, text='Quit', font=controller.itemFont, command=lambda\n    : sys.exit(0))\n"", ""VAR_32.pack(side='left', pady=10, padx=10, anchor='sw')\n""]",1
"[""def FUNC_19(VAR_32, VAR_33, VAR_5=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_52 = {}\n"", ""VAR_61 = {}\n"", ""def FUNC_31(VAR_62):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_84 = 0\n"", ""while VAR_62[VAR_84].isdigit():\n"", ""VAR_84 += 1\n"", ""if VAR_84 > 0:\n"", ""return int(VAR_62[:VAR_84])\n"", ""return 0\n""]",0
"[""from __future__ import absolute_import\n"", ""from __future__ import division\n"", ""from __future__ import print_function\n"", ""import threading\n"", ""import traceback\n"", ""import redis\n"", ""import ray\n"", ""from ray import ray_constants\n"", ""from ray import cloudpickle as pickle\n"", ""from ray import profiling\n"", ""from ray import utils\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0, VAR_1):...\n"", ""self.worker = VAR_0\n"", ""self.mode = VAR_1\n"", ""self.redis_client = VAR_0.redis_client\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = threading.Thread(target=self._run, name='ray_import_thread')\n"", ""VAR_3.daemon = True\n"", ""VAR_3.start()\n"", ""def FUNC_1(self):...\n"", ""VAR_4 = self.redis_client.pubsub()\n"", ""VAR_4.subscribe('__keyspace@0__:Exports')\n"", ""VAR_5 = 0\n"", ""VAR_9 = self.redis_client.lrange('Exports', 0, -1)\n"", ""for VAR_2 in VAR_9:\n"", ""VAR_5 += 1\n"", ""for msg in VAR_4.listen():\n"", ""def FUNC_2(self, VAR_2):...\n"", ""self._process_key(VAR_2)\n"", ""if msg['type'] == 'subscribe':\n"", ""\""\""\""docstring\""\""\""\n"", ""assert msg['data'] == b'rpush'\n"", ""if self.mode != ray.WORKER_MODE:\n"", ""VAR_12 = self.redis_client.llen('Exports')\n"", ""if VAR_2.startswith(b'FunctionsToRun'):\n"", ""if VAR_2.startswith(b'RemoteFunction'):\n"", ""assert VAR_12 >= VAR_5\n"", ""self.fetch_and_execute_function_to_run(VAR_2)\n"", ""return\n"", ""self.worker.function_actor_manager.fetch_and_register_remote_function(VAR_2)\n"", ""if VAR_2.startswith(b'FunctionsToRun'):\n"", ""for i in range(VAR_5, VAR_12):\n"", ""def FUNC_3(self, VAR_2):...\n"", ""self.fetch_and_execute_function_to_run(VAR_2)\n"", ""if VAR_2.startswith(b'ActorClass'):\n"", ""VAR_5 += 1\n"", ""\""\""\""docstring\""\""\""\n"", ""self.worker.function_actor_manager.imported_actor_classes.add(VAR_2)\n"", ""VAR_2 = self.redis_client.lindex('Exports', i)\n"", ""VAR_6, VAR_7, VAR_8 = self.redis_client.hmget(VAR_2, ['driver_id',\n    'function', 'run_on_other_drivers'])\n"", ""self._process_key(VAR_2)\n"", ""if utils.decode(VAR_8\n"", ""return\n"", ""VAR_10 = pickle.loads(VAR_7)\n"", ""VAR_11 = traceback.format_exc()\n"", ""VAR_10({'worker': self.worker})\n"", ""utils.push_error_to_driver(self.worker, ray_constants.\n    FUNCTION_TO_RUN_PUSH_ERROR, VAR_11, VAR_6=ray.DriverID(driver_id))\n""]",1
"[""def FUNC_9(VAR_6):...\n"", ""if VAR_6.is_redirect:\n"", ""return False\n"", ""return True\n""]",0
"[""def FUNC_10(self):...\n"", ""VAR_2 = 'response'\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndRaise(urllib2.HTTPError('url', 500, 'error message',\n    None, None))\n"", ""time.sleep(mox.IgnoreArg())\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(VAR_2, url_helper.UrlOpen('url', max_tries=10))\n"", ""self._mox.VerifyAll()\n""]",1
"[""def FUNC_7(self):...\n"", ""self.assertFalse(DatabaseQuery('DocType').execute(filters={'name': ['in',\n    None]}))\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['not in', None]}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertTrue(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['in', 'DocType,DocField']}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertFalse(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['not in', 'DocType,DocField']}))\n""]",0
"[""def FUNC_7(self, VAR_21, VAR_23=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_21 == '/':\n"", ""return self.fs\n"", ""VAR_55 = VAR_21.strip('/').split('/')\n"", ""VAR_22 = ''\n"", ""VAR_57 = self.fs\n"", ""for VAR_66 in VAR_55:\n"", ""if VAR_66 not in [x[VAR_1] for x in VAR_57[VAR_8]]:\n"", ""return VAR_57\n"", ""return False\n"", ""for x in VAR_57[VAR_8]:\n"", ""if x[VAR_1] == VAR_66:\n"", ""VAR_22 = '/'.join((VAR_22, VAR_66))\n"", ""if VAR_66 == VAR_55[-1] and VAR_23 == False:\n"", ""VAR_57 = x\n"", ""if x[VAR_2] == VAR_11:\n"", ""if x[VAR_9][0] == '/':\n"", ""VAR_57 = x\n"", ""VAR_57 = self.getfile(x[VAR_9], VAR_23=follow_symlinks)\n"", ""VAR_57 = self.getfile('/'.join((VAR_22, x[VAR_9])), VAR_23=follow_symlinks)\n"", ""if VAR_57 == False:\n"", ""return False\n""]",1
"[""def FUNC_1(VAR_4):...\n"", ""get_executing_test().addCleanup(require_io_loop_executor().stop)\n"", ""require_io_loop_executor().execute(VAR_4=timeout)\n"", ""get_executing_test().error = traceback.format_exc()\n""]",0
"[""def FUNC_0(self):...\n"", ""if not GenericRequest.test_success(self):\n"", ""return False\n"", ""self.get_submission_info()\n"", ""return False\n"", ""return True\n""]",0
"[""import os\n"", ""import six\n"", ""import testtools\n"", ""from bandit.core import config as b_config\n"", ""from bandit.core import constants as C\n"", ""from bandit.core import manager as b_manager\n"", ""from bandit.core import metrics\n"", ""from bandit.core import test_set as b_test_set\n"", ""\""\""\""string\""\""\""\n"", ""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""VAR_3 = os.path.join(os.getcwd(), 'bandit', 'plugins')\n"", ""VAR_4 = b_config.BanditConfig()\n"", ""self.b_mgr = b_manager.BanditManager(VAR_4, 'file')\n"", ""self.b_mgr.b_conf._settings['plugins_dir'] = VAR_3\n"", ""self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n"", ""def FUNC_1(self, VAR_0, VAR_1=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = os.path.join(os.getcwd(), 'examples', VAR_0)\n"", ""self.b_mgr.ignore_nosec = VAR_1\n"", ""self.b_mgr.discover_files([VAR_3], True)\n"", ""self.b_mgr.run_tests()\n"", ""def FUNC_2(self, VAR_0, VAR_2, VAR_1=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.b_mgr.scores = []\n"", ""self.run_example(VAR_0, VAR_1=ignore_nosec)\n"", ""VAR_5 = 0\n"", ""VAR_6 = 0\n"", ""for test_scores in self.b_mgr.scores:\n"", ""for score_type in test_scores:\n"", ""self.assertEqual(VAR_5, VAR_6)\n"", ""self.assertIn(score_type, VAR_2)\n"", ""def FUNC_3(self, VAR_0, VAR_2):...\n"", ""for rating in VAR_2[score_type]:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 += VAR_2[score_type][rating] * C.RANKING_VALUES[rating]\n"", ""VAR_6 += sum(test_scores[score_type])\n"", ""self.b_mgr.metrics = metrics.Metrics()\n"", ""self.b_mgr.scores = []\n"", ""self.run_example(VAR_0)\n"", ""VAR_7 = self.b_mgr.metrics.data\n"", ""for k in VAR_2:\n"", ""if k != 'issues':\n"", ""if 'issues' in VAR_2:\n"", ""self.assertEqual(VAR_2[k], VAR_7['_totals'][k])\n"", ""for criteria, default in C.CRITERIA:\n"", ""def FUNC_4(self):...\n"", ""for rank in C.RANKING:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_15 = '{0}.{1}'.format(criteria, rank)\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n"", ""VAR_5 = 0\n"", ""self.check_example('binding.py', VAR_2)\n"", ""if VAR_2['issues'].get(criteria, None).get(rank, None):\n"", ""def FUNC_5(self):...\n"", ""VAR_5 = VAR_2['issues'][criteria][rank]\n"", ""self.assertEqual(VAR_5, VAR_7['_totals'][VAR_15])\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('crypto-md5.py', VAR_2)\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 13}, 'CONFIDENCE': {'HIGH': 13}}\n"", ""self.check_example('ciphers.py', VAR_2)\n"", ""def FUNC_7(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('cipher-modes.py', VAR_2)\n"", ""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('eval.py', VAR_2)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('mark_safe.py', VAR_2)\n"", ""def FUNC_10(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = 'exec-{}.py'\n"", ""if six.PY2:\n"", ""VAR_8 = VAR_8.format('py2')\n"", ""VAR_8 = VAR_8.format('py3')\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example(VAR_8, VAR_2)\n"", ""def FUNC_11(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n"", ""self.check_example('exec-as-root.py', VAR_2)\n"", ""def FUNC_12(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n"", ""self.check_example('hardcoded-passwords.py', VAR_2)\n"", ""def FUNC_13(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('hardcoded-tmp.py', VAR_2)\n"", ""def FUNC_14(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('httplib_https.py', VAR_2)\n"", ""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0}, 'CONFIDENCE': {\n    'HIGH': 9}}\n"", ""self.check_example('imports-aliases.py', VAR_2)\n"", ""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('imports-from.py', VAR_2)\n"", ""def FUNC_17(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('imports-function.py', VAR_2)\n"", ""def FUNC_18(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('telnetlib.py', VAR_2)\n"", ""def FUNC_19(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('ftplib.py', VAR_2)\n"", ""def FUNC_20(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('imports.py', VAR_2)\n"", ""def FUNC_21(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n"", ""self.check_example('mktemp.py', VAR_2)\n"", ""def FUNC_22(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.run_example('nonsense.py')\n"", ""self.assertEqual(1, len(self.b_mgr.skipped))\n"", ""def FUNC_23(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {}, 'CONFIDENCE': {}}\n"", ""self.check_example('okay.py', VAR_2)\n"", ""def FUNC_24(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = 'os-chmod-{}.py'\n"", ""if six.PY2:\n"", ""VAR_8 = VAR_8.format('py2')\n"", ""VAR_8 = VAR_8.format('py3')\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2, 'HIGH': 8}, 'CONFIDENCE': {'MEDIUM': 1,\n    'HIGH': 9}}\n"", ""self.check_example(VAR_8, VAR_2)\n"", ""def FUNC_25(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n"", ""self.check_example('os-exec.py', VAR_2)\n"", ""def FUNC_26(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1}, 'CONFIDENCE': {\n    'HIGH': 9}}\n"", ""self.check_example('os-popen.py', VAR_2)\n"", ""def FUNC_27(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n"", ""self.check_example('os-spawn.py', VAR_2)\n"", ""def FUNC_28(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('os-startfile.py', VAR_2)\n"", ""def FUNC_29(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('os_system.py', VAR_2)\n"", ""def FUNC_30(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'MEDIUM': 6}, 'CONFIDENCE': {'HIGH': 8}}\n"", ""self.check_example('pickle_deserialize.py', VAR_2)\n"", ""def FUNC_31(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('popen_wrappers.py', VAR_2)\n"", ""def FUNC_32(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n"", ""self.check_example('random_module.py', VAR_2)\n"", ""def FUNC_33(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('requests-ssl-verify-disabled.py', VAR_2)\n"", ""def FUNC_34(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n"", ""self.check_example('skip.py', VAR_2)\n"", ""def FUNC_35(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('skip.py', VAR_2, VAR_1=True)\n"", ""def FUNC_36(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 12}, 'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}\n"", ""self.check_example('sql_statements.py', VAR_2)\n"", ""def FUNC_37(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7}, 'CONFIDENCE': {\n    'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}}\n"", ""self.check_example('ssl-insecure-version.py', VAR_2)\n"", ""def FUNC_38(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14}, 'CONFIDENCE': {\n    'HIGH': 17, 'LOW': 1}}\n"", ""self.check_example('subprocess_shell.py', VAR_2)\n"", ""def FUNC_39(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n"", ""self.check_example('urlopen.py', VAR_2)\n"", ""def FUNC_40(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n"", ""self.check_example('utils-shell.py', VAR_2)\n"", ""def FUNC_41(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10}, 'CONFIDENCE': {\n    'MEDIUM': 5, 'HIGH': 9}}\n"", ""self.check_example('wildcard-injection.py', VAR_2)\n"", ""def FUNC_42(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('yaml_load.py', VAR_2)\n"", ""def FUNC_43(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 4}, 'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n"", ""self.check_example('jinja2_templating.py', VAR_2)\n"", ""def FUNC_44(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'MEDIUM': 2}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('secret-config-option.py', VAR_2)\n"", ""def FUNC_45(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('mako_templating.py', VAR_2)\n"", ""def FUNC_46(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 4}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 4}}\n"", ""self.check_example('xml_etree_celementtree.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_expatbuilder.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3, 'HIGH': 1}, 'CONFIDENCE': {'HIGH': 3,\n    'MEDIUM': 1}}\n"", ""self.check_example('xml_lxml.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_pulldom.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('xml_xmlrpc.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 4}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 4}}\n"", ""self.check_example('xml_etree_elementtree.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 1}}\n"", ""self.check_example('xml_expatreader.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_minidom.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 6}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 6}}\n"", ""self.check_example('xml_sax.py', VAR_2)\n"", ""def FUNC_47(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('httpoxy_cgihandler.py', VAR_2)\n"", ""self.check_example('httpoxy_twisted_script.py', VAR_2)\n"", ""self.check_example('httpoxy_twisted_directory.py', VAR_2)\n"", ""def FUNC_48(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('assert.py', VAR_2)\n"", ""def FUNC_49(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'MEDIUM': 2}}\n"", ""self.check_example('paramiko_injection.py', VAR_2)\n"", ""def FUNC_50(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('partial_path_process.py', VAR_2)\n"", ""def FUNC_51(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = next(x for x in self.b_mgr.b_ts.tests['ExceptHandler'] if x.\n    __name__ == 'try_except_continue')\n"", ""VAR_9._config = {'check_typed_exception': True}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('try_except_continue.py', VAR_2)\n"", ""VAR_9._config = {'check_typed_exception': False}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('try_except_continue.py', VAR_2)\n"", ""def FUNC_52(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = next(x for x in self.b_mgr.b_ts.tests['ExceptHandler'] if x.\n    __name__ == 'try_except_pass')\n"", ""VAR_9._config = {'check_typed_exception': True}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('try_except_pass.py', VAR_2)\n"", ""VAR_9._config = {'check_typed_exception': False}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('try_except_pass.py', VAR_2)\n"", ""def FUNC_53(self):...\n"", ""VAR_2 = {'nosec': 2, 'loc': 7, 'issues': {'CONFIDENCE': {'HIGH': 5},\n    'SEVERITY': {'LOW': 5}}}\n"", ""self.check_metrics('skip.py', VAR_2)\n"", ""VAR_2 = {'nosec': 0, 'loc': 4, 'issues': {'CONFIDENCE': {'HIGH': 2},\n    'SEVERITY': {'LOW': 2}}}\n"", ""self.check_metrics('imports.py', VAR_2)\n"", ""def FUNC_54(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 8, 'HIGH': 6}, 'CONFIDENCE': {'HIGH': 14}}\n"", ""self.check_example('weak_cryptographic_key_sizes.py', VAR_2)\n"", ""def FUNC_55(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.run_example('multiline_statement.py')\n"", ""self.assertEqual(0, len(self.b_mgr.skipped))\n"", ""self.assertEqual(1, len(self.b_mgr.files_list))\n"", ""self.assertTrue(self.b_mgr.files_list[0].endswith('multiline_statement.py'))\n"", ""VAR_10 = self.b_mgr.get_issue_list()\n"", ""self.assertEqual(2, len(VAR_10))\n"", ""self.assertTrue(VAR_10[0].fname.endswith('examples/multiline_statement.py'))\n"", ""self.assertEqual(1, VAR_10[0].lineno)\n"", ""self.assertEqual(list(range(1, 3)), VAR_10[0].linerange)\n"", ""self.assertIn('subprocess', VAR_10[0].get_code())\n"", ""self.assertEqual(5, VAR_10[1].lineno)\n"", ""self.assertEqual(list(range(3, 6 + 1)), VAR_10[1].linerange)\n"", ""self.assertIn('shell=True', VAR_10[1].get_code())\n"", ""def FUNC_56(self):...\n"", ""self.run_example('binding.py')\n"", ""VAR_10 = self.b_mgr.get_issue_list()\n"", ""VAR_11 = VAR_10[0].get_code().splitlines()\n"", ""VAR_12 = VAR_10[0].lineno\n"", ""self.assertEqual('%i ' % (VAR_12 - 1), VAR_11[0][:2])\n"", ""self.assertEqual('%i ' % VAR_12, VAR_11[1][:2])\n"", ""self.assertEqual('%i ' % (VAR_12 + 1), VAR_11[2][:2])\n"", ""def FUNC_57(self):...\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n"", ""self.check_example('flask_debug.py', VAR_2)\n"", ""def FUNC_58(self):...\n"", ""VAR_2 = {'SEVERITY': {}, 'CONFIDENCE': {}}\n"", ""self.check_example('nosec.py', VAR_2)\n"", ""def FUNC_59(self):...\n"", ""VAR_13 = 'string'\n"", ""VAR_14 = 'string' % (os.getcwd(), VAR_13)\n"", ""self.b_mgr.populate_baseline(VAR_14)\n"", ""self.run_example('flask_debug.py')\n"", ""self.assertEqual(1, len(self.b_mgr.baseline))\n"", ""self.assertEqual({}, self.b_mgr.get_issue_list())\n"", ""def FUNC_60(self):...\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('input.py', VAR_2)\n""]",1
"[""def FUNC_29(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('os_system.py', VAR_2)\n""]",0
"[""def FUNC_34(VAR_16, VAR_22, VAR_28, VAR_23):...\n"", ""VAR_90 = FUNC_33(VAR_16, VAR_22, VAR_23)\n"", ""if FUNC_13(VAR_16, VAR_28, VAR_18=tournaments):\n"", ""return True\n"", ""return False\n""]",1
"[""from __future__ import unicode_literals\n"", ""import frappe\n"", ""from frappe import _\n"", ""from frappe.website.website_generator import WebsiteGenerator\n"", ""from frappe.website.render import clear_cache\n"", ""from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n"", ""from frappe.website.utils import find_first_image, get_comment_list\n"", ""VAR_8 = frappe._dict(VAR_7='published_on desc')\n"", ""def FUNC_5(self):...\n"", ""if not self.route:\n"", ""return frappe.db.get_value('Blog Category', self.blog_category, 'route'\n    ) + '/' + self.scrub(self.title)\n"", ""def FUNC_6(self):...\n"", ""return self.title\n""]",1
"[""@staticmethod...\n"", ""if not isinstance(VAR_1, int):\n"", ""VAR_9 = {}\n"", ""VAR_10 = VAR_0.view_task(VAR_1, details=True)\n"", ""if VAR_10:\n"", ""VAR_19 = VAR_10.to_dict()\n"", ""return Exception('Task not found')\n"", ""VAR_19['guest'] = {}\n"", ""if VAR_10.guest:\n"", ""VAR_19['guest'] = VAR_10.guest.to_dict()\n"", ""VAR_19['errors'] = []\n"", ""for error in VAR_10.errors:\n"", ""VAR_19['errors'].append(error.message)\n"", ""VAR_19['sample'] = {}\n"", ""if VAR_10.sample_id:\n"", ""VAR_26 = VAR_0.view_sample(VAR_10.sample_id)\n"", ""VAR_9['task'] = VAR_19\n"", ""VAR_19['sample'] = VAR_26.to_dict()\n"", ""return VAR_9\n""]",1
"[""def __init__(self, VAR_0, VAR_1, VAR_2=False, VAR_3=True):...\n"", ""self.address = VAR_0.strip()\n"", ""self.local = False\n"", ""self.hostname = None\n"", ""self.config = VAR_1\n"", ""self.sos_path = None\n"", ""self.retrieved = False\n"", ""self.hash_retrieved = False\n"", ""self.sos_info = {'version': None, 'enabled': [], 'disabled': [], 'options':\n    [], 'presets': []}\n"", ""VAR_28 = ['localhost', '127.0.0.1', self.config['hostname']]\n"", ""self.logger = logging.getLogger('sos_collector')\n"", ""self.console = logging.getLogger('sos_collector_console')\n"", ""if self.address not in VAR_28 or VAR_2:\n"", ""self.connected = self.open_ssh_session()\n"", ""self.connected = True\n"", ""self.sftp = self.client.open_sftp()\n"", ""self.local = True\n"", ""if self.connected and VAR_3:\n"", ""self.host = self.determine_host()\n"", ""self._set_sos_prefix(self.host.set_sos_prefix())\n"", ""if not self.host:\n"", ""self.connected = False\n"", ""self.log_debug('Host facts found to be %s' % self.host.report_facts())\n"", ""self.close_ssh_session()\n"", ""self.get_hostname()\n"", ""return None\n"", ""self._load_sos_info()\n""]",0
"[""def __str__(self):...\n"", ""return f'<RoamPathException: {self.path.description()}>'\n""]",0
"[""def FUNC_38(self, VAR_84):...\n"", ""return [VAR_82 for job in VAR_84.jobs for VAR_82 in job.subworkflow_input if\n    job.subworkflow_input[VAR_82] is self]\n""]",0
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_2=('PUT',))\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', {'xsrf_token': VAR_17})\n"", ""VAR_7.put('/request', {'xsrf_token': VAR_17})\n"", ""self.assertEqual([('POST', True), ('PUT', True)], VAR_12)\n"", ""self.assertEqual(200, VAR_7.post('/request').status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', expect_errors=True).status_int)\n"", ""VAR_18 = {'xsrf_token': 'boo'}\n"", ""self.assertEqual(403, VAR_7.post('/request', VAR_18, expect_errors=True).\n    status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', VAR_18, expect_errors=True).\n    status_int)\n""]",1
"[""def FUNC_0(self, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return database_utilities.execute_query(\n    f\""select * from users where user_id = '{VAR_1}'\"")\n""]",1
"[""def FUNC_24(self, VAR_6, VAR_7=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return cryptolib.load_private_key_pem_as_bare_base64(VAR_6, VAR_7=password)\n""]",0
"[""def FUNC_15(self):...\n"", """"]",0
"[""def FUNC_3(VAR_5):...\n"", """"]",0
"[""from django.db.models.signals import post_save, post_delete\n"", ""from lib.cache import CachedAbstract\n"", ""from .models import Notification\n"", ""VAR_3 = 'notifications'\n"", ""def __init__(self, VAR_4):...\n"", ""super().__init__(VAR_4)\n"", ""def FUNC_1(self, VAR_4, VAR_5=None):...\n"", ""if not VAR_4 or not VAR_4.is_authenticated():\n"", ""return {'count': 0, 'notifications': []}\n"", ""def FUNC_4(VAR_6):...\n"", ""VAR_8 = VAR_6.submission.exercise if VAR_6.submission else None\n"", ""return {'id': VAR_6.id, 'submission_id': VAR_6.submission.id if VAR_6.\n    submission else 0, 'name': '{} {}, {}'.format(VAR_6.course_instance.\n    course.code, str(VAR_8.parent) if VAR_8 and VAR_8.parent else VAR_6.\n    course_instance.instance_name, str(VAR_8) if VAR_8 else VAR_6.subject),\n    'link': VAR_6.get_display_url()}\n""]",1
"[""def FUNC_6(self):...\n"", ""return True\n""]",0
"[""def FUNC_17(VAR_10, VAR_3, VAR_7):...\n"", ""VAR_21 = VAR_3 + '-' + VAR_7\n"", ""VAR_18 = 'SELECT \""count\"" FROM {table} WHERE \""name_option\"" = \\'{key}\\''.format(\n    table=CFG('options_table_name'), VAR_21=key)\n"", ""VAR_12 = FUNC_3(VAR_10, VAR_18)\n"", ""if VAR_12 == None:\n"", ""return VAR_12\n""]",1
"[""@VAR_0.route('/login', methods=['GET', 'POST'])...\n"", ""VAR_11 = loginForm(request.form)\n"", ""if request.method == 'POST' and VAR_11.validate():\n"", ""VAR_8 = VAR_3.connection\n"", ""return render_template('login.html', VAR_11=form)\n"", ""VAR_9 = VAR_8.cursor()\n"", ""VAR_9.execute('SELECT id, password FROM users WHERE username=\""%s\"" ' % str(\n    VAR_11.username.data))\n"", ""VAR_10 = VAR_9.fetchall()\n"", ""if sha256_crypt.verify(VAR_11.password.data, str(VAR_10[0]['password'])):\n"", ""VAR_23 = CLASS_0(VAR_10[0]['id'])\n"", ""return 'Wrong password'\n"", ""VAR_23.authenticate(VAR_11.username.data)\n"", ""login_user(VAR_23)\n"", ""flash('Logged in successfully.')\n"", ""VAR_22 = request.args.get('next')\n"", ""if not FUNC_10(VAR_22):\n"", ""return abort(400)\n"", ""return redirect(VAR_22 or url_for('home'))\n""]",1
"[""def FUNC_31():...\n"", ""VAR_24 = vim.eval('tagfiles()')\n"", ""VAR_25 = VAR_0.getcwd()\n"", ""return [VAR_0.path.join(VAR_25, x) for x in VAR_24]\n""]",0
"[""def FUNC_39(VAR_101):...\n"", ""VAR_101.shellcmd = VAR_81\n"", ""return VAR_101\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import re\n"", ""from lib.core.data import conf\n"", ""from lib.core.settings import MATCH_RATIO\n"", ""def FUNC_0(VAR_0, VAR_1=None, VAR_2=False):...\n"", ""VAR_3 = None\n"", ""if conf.eString and conf.eString in VAR_0:\n"", ""VAR_4 = VAR_0.index(conf.eString)\n"", ""if conf.eRegexp:\n"", ""VAR_5 = len(conf.eString)\n"", ""VAR_3 = re.findall(conf.eRegexp, VAR_0, re.I | re.M)\n"", ""if conf.string:\n"", ""VAR_6 = VAR_0[:VAR_4]\n"", ""if VAR_3:\n"", ""if conf.string in VAR_0:\n"", ""if conf.regexp:\n"", ""VAR_6 += VAR_0[VAR_4 + VAR_5:]\n"", ""for regExpResult in VAR_3:\n"", ""return True\n"", ""return False\n"", ""if re.search(conf.regexp, VAR_0, re.I | re.M):\n"", ""conf.seqMatcher.set_seq2(VAR_0)\n"", ""VAR_0 = VAR_6\n"", ""VAR_4 = VAR_0.index(regExpResult)\n"", ""return True\n"", ""return False\n"", ""if VAR_2:\n"", ""VAR_5 = len(regExpResult)\n"", ""return round(conf.seqMatcher.ratio(), 5)\n"", ""if round(conf.seqMatcher.ratio(), 5) >= MATCH_RATIO:\n"", ""VAR_7 = VAR_0[:VAR_4]\n"", ""return True\n"", ""return False\n"", ""VAR_7 += VAR_0[VAR_4 + VAR_5:]\n"", ""VAR_0 = VAR_7\n""]",1
"[""def FUNC_7(self):...\n"", ""self.__use_lb_name = 'katotest-lb-' + self.test_id\n"", ""self.__use_lb_hc_name = '%s-hc' % self.__use_lb_name\n"", ""self.__use_lb_tp_name = '%s-tp' % self.__use_lb_name\n"", ""self.__use_lb_target = '{0}/targetPools/{1}'.format(self.bindings[\n    'TEST_GCE_REGION'], self.__use_lb_tp_name)\n"", ""VAR_25 = 123\n"", ""VAR_26 = 4\n"", ""VAR_27 = 5\n"", ""VAR_28 = 78\n"", ""VAR_29 = '/' + self.__use_lb_target\n"", ""VAR_31 = {'checkIntervalSec': VAR_25, 'healthyThreshold': VAR_26,\n    'unhealthyThreshold': VAR_27, 'timeoutSec': VAR_28, 'requestPath': VAR_29}\n"", ""VAR_21 = self.agent.type_to_payload('upsertGoogleLoadBalancerDescription',\n    {'healthCheck': VAR_31, 'region': self.bindings['TEST_GCE_REGION'],\n    'credentials': self.bindings['GCE_CREDENTIALS'], 'loadBalancerName':\n    self.__use_lb_name})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Forwarding Rules Added', retryable_for_secs=30\n    ).list_resources('forwarding-rules').contains_path_value('name', self.\n    __use_lb_name).contains_path_value('target', self.__use_lb_target)\n"", ""VAR_20.new_clause_builder('Target Pool Added', retryable_for_secs=15\n    ).list_resources('target-pools').contains_path_value('name', self.\n    __use_lb_tp_name)\n"", ""VAR_20.new_clause_builder('Health Check Added', retryable_for_secs=15\n    ).list_resources('http-health-checks').contains_pred_list([jc.\n    PathContainsPredicate('name', self.__use_lb_hc_name), jc.\n    PathContainsPredicate(None, VAR_31)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer', data=payload, VAR_29='ops'), contract=builder.\n    build())\n""]",1
"[""def FUNC_1(self):...\n"", ""return str(VAR_23.uuid4())\n""]",0
"[""def FUNC_10(VAR_32, VAR_34):...\n"", ""logging.info('Got signal %s', VAR_32)\n""]",0
"[""def FUNC_2(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""VAR_1 = {'name': self.volume_name, 'size': 1}\n"", ""self.driver._eql_execute('volume', 'create', VAR_1['name'], '%sG' % VAR_1[\n    'size'], 'pool', self.configuration.eqlx_pool, 'thin-provision').AndReturn(\n    ['iSCSI target name is %s.' % self.fake_iqn])\n"", ""self.mox.ReplayAll()\n"", ""VAR_2 = self.driver.create_volume(VAR_1)\n"", ""self.assertEqual(VAR_2, self._model_update)\n""]",0
"[""\""\""\""A helper script for wrapping url calls.\""\""\""\n"", ""import hashlib\n"", ""import httplib\n"", ""import logging\n"", ""import math\n"", ""import os\n"", ""import random\n"", ""import socket\n"", ""import time\n"", ""import urllib\n"", ""import urllib2\n"", ""import urlparse\n"", ""from common import swarm_constants\n"", ""VAR_0 = 4\n"", ""VAR_1 = 5 * 60\n"", ""def FUNC_0(VAR_2, VAR_3=None, VAR_4=None, VAR_5=5, VAR_6=None, VAR_7='POST'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 <= 0:\n"", ""logging.error('UrlOpen(%s): Invalid number of tries: %d', VAR_2, VAR_5)\n"", ""if VAR_6 and VAR_6 < 0:\n"", ""return None\n"", ""logging.error('UrlOpen(%s): Invalid wait duration: %d', VAR_2, VAR_6)\n"", ""VAR_3 = VAR_3 or {}\n"", ""return None\n"", ""if VAR_17.COUNT_KEY in VAR_3:\n"", ""logging.error(\""UrlOpen(%s): key '%s' is duplicate.\"", VAR_2, VAR_17.COUNT_KEY)\n"", ""VAR_11 = None\n"", ""return None\n"", ""for attempt in range(VAR_5):\n"", ""VAR_3[VAR_17.COUNT_KEY] = attempt\n"", ""logging.error('UrlOpen(%s): Unable to open after %d attempts', VAR_2, VAR_5)\n"", ""for VAR_18, VAR_9 in VAR_3.iteritems():\n"", ""if e.code >= 500:\n"", ""if VAR_11 is not None:\n"", ""return None\n"", ""if isinstance(VAR_9, basestring):\n"", ""VAR_20 = urllib.urlencode(VAR_3)\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s ', VAR_2, attempt, e)\n"", ""logging.exception('UrlOpen(%s): %s', VAR_2, e)\n"", ""logging.info('UrlOpen(%s) got %d bytes.', VAR_2, len(VAR_11))\n"", ""if attempt != VAR_5 - 1:\n"", ""VAR_3[VAR_18] = VAR_9.encode('utf-8', 'xmlcharrefreplace')\n"", ""if VAR_7 == 'POSTFORM':\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s', VAR_2, attempt, e)\n"", ""return None\n"", ""return VAR_11\n"", ""if VAR_6 is None:\n"", ""VAR_16, VAR_15 = FUNC_3(VAR_10=data.iteritems(), VAR_4=files)\n"", ""if VAR_7 == 'POST':\n"", ""VAR_23 = random.random() * 3 + math.pow(1.5, attempt + 1)\n"", ""VAR_23 = VAR_6\n"", ""VAR_15 = VAR_15 or ''\n"", ""VAR_11 = urllib2.urlopen(VAR_2, VAR_20, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_22 = list(urlparse.urlparse(VAR_2))\n"", ""VAR_23 = min(10, max(0.1, VAR_23))\n"", ""time.sleep(VAR_23)\n"", ""VAR_21 = urllib2.Request(VAR_2, VAR_3=body)\n"", ""VAR_22[VAR_0] = VAR_20\n"", ""VAR_21.add_header('Content-Type', VAR_16)\n"", ""VAR_2 = urlparse.urlunparse(VAR_22)\n"", ""VAR_21.add_header('Content-Length', len(VAR_15))\n"", ""VAR_11 = urllib2.urlopen(VAR_2, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_11 = urllib2.urlopen(VAR_21, timeout=URL_OPEN_TIMEOUT).read()\n""]",1
"[""from dal import autocomplete\n"", ""from django.shortcuts import render, redirect, get_object_or_404, HttpResponseRedirect\n"", ""from django.utils.translation import ugettext_lazy as _\n"", ""from django.contrib.auth.decorators import login_required\n"", ""from dashboard.models import *\n"", ""from dashboard.forms import HabitsPUCForm, create_detail_formset\n"", ""@login_required()...\n"", ""VAR_3 = get_object_or_404(DataDocument, VAR_1=pk)\n"", ""VAR_4 = Script.objects.get(title='Manual (dummy)', script_type='EX')\n"", ""VAR_5, VAR_6 = ExtractedText.objects.get_or_create(data_document=doc,\n    extraction_script=script)\n"", ""if VAR_6:\n"", ""VAR_5.doc_date = 'please add...'\n"", ""VAR_7, VAR_8 = create_detail_formset(VAR_3)\n"", ""VAR_9 = VAR_7(VAR_0.POST or None, instance=extext)\n"", ""VAR_10 = VAR_8(VAR_0.POST or None, instance=extext, prefix='habits')\n"", ""if VAR_0.method == 'POST' and 'save' in VAR_0.POST:\n"", ""if VAR_10.is_valid() and VAR_9.is_valid():\n"", ""VAR_11 = {'doc': VAR_3, 'ext_form': VAR_9, 'hp_formset': VAR_10}\n"", ""if not VAR_3.extracted:\n"", ""return render(VAR_0, VAR_2, VAR_11)\n"", ""VAR_3.extracted = True\n"", ""VAR_10.save()\n"", ""VAR_3.save()\n"", ""VAR_9.save()\n"", ""return HttpResponseRedirect(f'/habitsandpractices/{VAR_3.pk}')\n""]",1
"[""def FUNC_3(VAR_5, VAR_6=''):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_18 = urllib2.Request(VAR_5)\n"", ""if VAR_6:\n"", ""VAR_18.add_header('User-Agent', VAR_6)\n"", ""VAR_20 = VAR_8(VAR_18)\n"", ""VAR_0.error('Unable to read from URL %s.' % VAR_5)\n"", ""VAR_11 = FUNC_1(VAR_21, VAR_3=True)\n"", ""VAR_21 = tempfile.mkstemp(prefix='bibclassify.')[1]\n"", ""return None\n"", ""os.remove(VAR_21)\n"", ""VAR_22 = open(VAR_21, 'w')\n"", ""VAR_12 = len(VAR_11)\n"", ""VAR_22.write(VAR_20.read())\n"", ""VAR_13 = 0\n"", ""VAR_22.close()\n"", ""for line in VAR_11:\n"", ""VAR_13 += len(re.findall('\\\\S+', line))\n"", ""VAR_0.info('Remote file has %d lines and %d words.' % (VAR_12, VAR_13))\n"", ""return VAR_11\n""]",1
"[""def FUNC_8():...\n"", ""VAR_29 = VAR_11.read(VAR_8)\n"", ""VAR_6.set_result(VAR_29)\n""]",0
"[""def FUNC_4(self, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = \""SELECT tag FROM tid_tag WHERE tid = '\"" + str(VAR_4) + \""'\""\n"", ""self.query(VAR_9)\n"", ""return [i[0] for i in self.c.fetchall()]\n""]",1
"[""@jwt_required...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = f'insert into users values (%s);'\n"", ""VAR_3 = request.get_json()\n"", ""VAR_4 = VAR_3['user_id'],\n"", ""database_utilities.execute_query(VAR_2, VAR_4)\n""]",1
"[""import sqlite3\n"", ""from Client import Client\n"", ""import create_database\n"", ""def __init__(self, VAR_0):...\n"", ""self.__conn = VAR_0\n"", ""def FUNC_0(self, VAR_1, VAR_2):...\n"", ""VAR_6 = 'string'.format(VAR_1, VAR_2.get_client_id())\n"", ""VAR_7 = self.__conn.cursor()\n"", ""VAR_7.execute(VAR_6)\n"", ""self.__conn.commit()\n"", ""VAR_2.set_message(VAR_1)\n"", ""def FUNC_1(self, VAR_3, VAR_2):...\n"", ""VAR_6 = 'string'.format(VAR_3, VAR_2.get_client_id())\n"", ""VAR_7 = self.__conn.cursor()\n"", ""VAR_7.execute(VAR_6)\n"", ""self.__conn.commit()\n"", ""def FUNC_2(self, VAR_4, VAR_5):...\n"", ""VAR_8 = (\n    \""\""\""\n            INSERT INTO Clients (username, password)\n            VALUES ('{}', '{}')\n        \""\""\""\n    .format(VAR_4, VAR_5))\n"", ""VAR_7 = self.__conn.cursor()\n"", ""VAR_7.execute(VAR_8)\n"", ""self.__conn.commit()\n"", ""def FUNC_3(self, VAR_4, VAR_5):...\n"", ""VAR_9 = 'string'.format(VAR_4, VAR_5)\n"", ""VAR_7 = self.__conn.cursor()\n"", ""VAR_7.execute(VAR_9)\n"", ""VAR_10 = VAR_7.fetchone()\n"", ""if VAR_10:\n"", ""return Client(VAR_10[0], VAR_10[1], VAR_10[2], VAR_10[3])\n"", ""return False\n""]",1
"[""@frappe.whitelist(allow_guest=True)...\n"", ""from frappe.www.contact import send_message as website_send_message\n"", ""VAR_4 = VAR_5 = None\n"", ""website_send_message(VAR_0, VAR_1, VAR_2)\n"", ""VAR_5 = frappe.db.sql('string'.format(email_id=sender))\n"", ""if not VAR_5:\n"", ""VAR_4 = frappe.db.get_value('Lead', dict(email_id=sender))\n"", ""VAR_6 = frappe.get_doc(dict(doctype='Opportunity', enquiry_from='Customer' if\n    customer else 'Lead', VAR_3='Open', title=subject, contact_email=sender,\n    to_discuss=message))\n"", ""if not VAR_4:\n"", ""if VAR_5:\n"", ""VAR_8 = frappe.get_doc(dict(doctype='Lead', email_id=sender, lead_name=\n    sender.split('@')[0].title())).insert(ignore_permissions=True)\n"", ""VAR_6.customer = VAR_5[0][0]\n"", ""if VAR_4:\n"", ""VAR_6.insert(ignore_permissions=True)\n"", ""VAR_6.lead = VAR_4\n"", ""VAR_6.lead = VAR_8.name\n"", ""VAR_7 = frappe.get_doc({'doctype': 'Communication', 'subject': VAR_0,\n    'content': VAR_1, 'sender': VAR_2, 'sent_or_received': 'Received',\n    'reference_doctype': 'Opportunity', 'reference_name': VAR_6.name})\n"", ""VAR_7.insert(ignore_permissions=True)\n"", ""return 'okay'\n""]",1
"[""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", """"]",0
"[""def FUNC_1(self):...\n"", ""self.client.login(username=self.user.username, password='testing')\n"", ""VAR_1 = self.client.get(reverse('iframe-navigation'))\n"", ""self.assertContains(VAR_1, urlencode({'people': self.user.email}))\n"", ""self.assertContains(VAR_1, urlencode({'author__email__startswith': self.\n    user.email}))\n""]",0
"[""def FUNC_5(self, *VAR_4, **VAR_5):...\n"", ""VAR_11 = self.REQUEST\n"", ""VAR_16 = VAR_11.RESPONSE\n"", ""VAR_17 = VAR_11.SESSION\n"", ""self._zmi_page_request()\n"", ""VAR_16.setHeader('Expires', DateTime(VAR_11['ZMI_TIME'] - 10000).toZone(\n    'GMT+1').rfc822())\n"", ""VAR_16.setHeader('Cache-Control', 'no-cache')\n"", ""VAR_16.setHeader('Pragma', 'no-cache')\n"", ""VAR_16.setHeader('Content-Type', 'text/html;charset=%s' % VAR_11['ZMS_CHARSET']\n    )\n"", ""if not VAR_11.get('preview'):\n"", ""VAR_11.set('preview', 'preview')\n"", ""VAR_18 = self.getLanguages(VAR_11)\n"", ""if VAR_11.get('lang') not in VAR_18:\n"", ""VAR_11.set('lang', VAR_18[0])\n"", ""if VAR_11.get('manage_lang') not in self.getLocale().get_manage_langs():\n"", ""VAR_11.set('manage_lang', self.get_manage_lang())\n"", ""if not VAR_11.get('manage_tabs_message'):\n"", ""VAR_11.set('manage_tabs_message', self.getConfProperty(\n    'ZMS.manage_tabs_message', ''))\n"", ""if VAR_11.form.has_key('zmi-manage-system'):\n"", ""VAR_11.SESSION.set('zmi-manage-system', int(VAR_11.get('zmi-manage-system')))\n"", ""VAR_19 = self.getPhysicalPath()\n"", ""VAR_20 = VAR_11['URL0'][len(VAR_11['BASE0']):].split('/')\n"", ""VAR_21 = VAR_20[:-1]\n"", ""if len(filter(lambda x: x.find('.') > 0 or x.startswith('manage_'), VAR_21)\n"", ""for VAR_25 in range(len(VAR_21)):\n"", ""if VAR_21[:-(VAR_25 + 1)] != VAR_19[:-(VAR_25 + 1)]:\n"", ""VAR_23 = VAR_21 + [VAR_20[-1]]\n"", ""VAR_21[:-(VAR_25 + 1)] = VAR_19[:-(VAR_25 + 1)]\n"", ""if VAR_20 != VAR_23:\n"", ""VAR_11.RESPONSE.redirect('/'.join(VAR_23))\n""]",1
"[""def FUNC_3(VAR_0, VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_17 = db.engine.execute(\n    \""SELECT data_type from information_schema.columns where table_name = '{0}' and column_name = '{1}';\""\n    .format(VAR_0, VAR_3)).fetchall()[0][0]\n"", ""if VAR_4 == 'INTEGER':\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE BIGINT USING \""{1}\""::bigint'.\n    format(VAR_0, VAR_3))\n"", ""if VAR_4 == 'DOUBLE':\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE DOUBLE PRECISION USING \""{1}\""::double precision'\n    .format(VAR_0, VAR_3))\n"", ""if VAR_4 == 'TEXT':\n"", ""if VAR_17 == 'date':\n"", ""if VAR_4 == 'DATE':\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE TEXT USING to_char(\""{1}\"", \\'DD/MM/YYYY\\')'\n    .format(VAR_0, VAR_3))\n"", ""if VAR_17 == 'timestamp with time zone':\n"", ""if VAR_17 == 'timestamp with time zone':\n"", ""if VAR_4 == 'TIMESTAMP':\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE TEXT USING to_char(\""{1}\"", \\'DD/MM/YYYY HH24:MI:SS\\')'\n    .format(VAR_0, VAR_3))\n"", ""db.engine.execute('ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE TEXT'.format(\n    VAR_0, VAR_3))\n"", ""db.engine.execute('ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE DATE'.format(\n    VAR_0, VAR_3))\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE DATE USING to_date(\""{1}\"", \\'DD/MM/YYYY\\')'\n    .format(VAR_0, VAR_3))\n"", ""if VAR_17 == 'date':\n"", ""db.engine.execute(\n    'ALTER TABLE {0} ALTER COLUMN \""{1}\"" TYPE TIMESTAMP WITH TIME ZONE'.\n    format(VAR_0, VAR_3))\n"", ""db.engine.execute('string'.format(VAR_0, VAR_3))\n""]",1
"[""@receiver(VAR_5, **decorator_kwargs)...\n"", ""if settings.SUSPEND_SIGNALS:\n"", ""return\n"", ""return VAR_17(VAR_23, **kwargs)\n""]",0
"[""from soscollector.clusters import Cluster\n"", ""VAR_0 = 'kubernetes-master',\n"", ""VAR_1 = ['kubernetes']\n"", ""VAR_2 = {'kubernetes.all': 'on'}\n"", ""VAR_3 = 'kubectl'\n"", ""VAR_4 = [('label', '', 'Filter node list to those with matching label'), (\n    'role', '', 'Filter node list to those with matching role')]\n"", ""def FUNC_0(self):...\n"", ""self.cmd += ' get nodes'\n"", ""if self.get_option('label'):\n"", ""self.cmd += ' -l %s ' % self.get_option('label')\n"", ""VAR_6 = self.exec_master_cmd(self.cmd)\n"", ""if VAR_6['status'] == 0:\n"", ""VAR_7 = []\n"", ""VAR_0 = 'atomic-openshift',\n"", ""VAR_8 = [x for x in self.get_option('role').split(',') if x]\n"", ""VAR_5 = 'ocp'\n"", ""for nodeln in VAR_6['stdout'].splitlines()[1:]:\n"", ""VAR_3 = 'oc'\n"", ""VAR_9 = nodeln.split()\n"", ""return VAR_7\n"", ""if not VAR_8:\n"", ""VAR_7.append(VAR_9[0])\n"", ""if VAR_9[2] in VAR_8:\n"", ""VAR_7.append(VAR_9[0])\n""]",1
"[""def __sinit__(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.log = logging.getLogger(self.name)\n"", ""self.running = threading.Event()\n"", ""self.sleep_ticker = Ticker()\n"", ""self.poller = zmq.Poller()\n"", ""VAR_27 = self.ctx.socket(zmq.SUB)\n"", ""self.poller.register(VAR_27, zmq.POLLIN)\n"", ""VAR_27.setsockopt(zmq.IPV6, True)\n"", ""VAR_27.connect(self.sig_addr)\n"", ""VAR_27.setsockopt(zmq.SUBSCRIBE, b'GLOBAL')\n"", ""VAR_27.setsockopt(zmq.SUBSCRIBE, b'WZWorker')\n"", ""VAR_27.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8'))\n"", ""self.sig_sock = VAR_27\n"", ""VAR_27 = self.ctx.socket(zmq.DEALER)\n"", ""self.poller.register(VAR_27, zmq.POLLIN)\n"", ""VAR_27.setsockopt(zmq.IPV6, True)\n"", ""self.wz_sock = VAR_27\n"", ""self.wz = WZHandler()\n"", ""def FUNC_21(VAR_10, VAR_11, VAR_12):...\n"", ""self.log.info('Termination signal %s recieved', repr((VAR_10, VAR_11, VAR_12)))\n"", ""self.term()\n"", ""self.wz.set_sig_handler(b'WZWorker', b'terminate', FUNC_21)\n"", ""def FUNC_22(VAR_10, VAR_11, VAR_12):...\n"", ""self.log.info('Resume signal %s recieved', repr((VAR_10, VAR_11, VAR_12)))\n"", ""self.wz.set_sig_handler(b'WZWorker', b'resume', FUNC_21)\n"", ""self.running.set()\n""]",1
"[""import mimetypes\n"", ""import os\n"", ""from django.contrib.gis.db.models import GeometryField\n"", ""from django.contrib.gis.db.models.functions import Envelope\n"", ""from django.core.exceptions import ObjectDoesNotExist\n"", ""from django.db.models.functions import Cast\n"", ""from django.http import HttpResponse\n"", ""from wsgiref.util import FileWrapper\n"", ""from rest_framework import status, serializers, viewsets, filters, exceptions, permissions, parsers\n"", ""from rest_framework.response import Response\n"", ""from rest_framework.decorators import detail_route\n"", ""from rest_framework.views import APIView\n"", ""from .common import get_and_check_project, get_tile_json\n"", ""from app import models, scheduler, pending_actions\n"", ""from nodeodm.models import ProcessingNode\n"", ""def FUNC_0(self, VAR_0):...\n"", ""return VAR_0.id\n""]",1
"[""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""self.mock(logging, 'error', lambda *_: None)\n"", ""self.mock(logging, 'exception', lambda *_: None)\n"", ""self.mock(logging, 'info', lambda *_: None)\n"", ""self.mock(logging, 'warning', lambda *_: None)\n"", ""self.mock(time, 'sleep', lambda _: None)\n""]",1
"[""def FUNC_7(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""VAR_3 = {'name': 'fakesnap', 'volume_name': 'fakevolume_name'}\n"", ""VAR_1 = {'name': self.volume_name}\n"", ""self.driver._eql_execute('volume', 'select', VAR_3['volume_name'],\n    'snapshot', 'select', VAR_3['name'], 'clone', VAR_1['name']).AndReturn([\n    'iSCSI target name is %s.' % self.fake_iqn])\n"", ""self.mox.ReplayAll()\n"", ""VAR_2 = self.driver.create_volume_from_snapshot(VAR_1, VAR_3)\n"", ""self.assertEqual(VAR_2, self._model_update)\n""]",0
"[""def FUNC_7(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/keys'\n"", ""VAR_5 = {'id': 'autotest', 'public': 'string'}\n"", ""VAR_6 = self.client.post(VAR_4, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""VAR_8 = Key.objects.get(uuid=response.data['uuid'])\n"", ""self.assertEqual(str(VAR_8),\n    'ssh-rsa AAAAB3NzaC.../HJDw9QckTS0vN autotest@deis.io')\n""]",0
"[""def FUNC_8(VAR_15, VAR_16=None, VAR_17=None):...\n"", ""VAR_34 = FUNC_0()\n"", ""return VAR_34.do_request(VAR_6 + VAR_15, VAR_16, VAR_17)\n""]",1
"[""from lxml import html\n"", ""from django.test import Client\n"", ""from django.urls import reverse\n"", ""from django.test import TestCase, override_settings\n"", ""from django.core.exceptions import ObjectDoesNotExist\n"", ""from dashboard.forms import *\n"", ""from factotum.settings import EXTRA\n"", ""from dashboard.tests.loader import *\n"", ""VAR_0 = fixtures_standard\n"", ""def FUNC_0(self):...\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""def FUNC_1(self):...\n"", ""for VAR_13 in DataDocument.objects.all():\n"", ""VAR_11 = VAR_13.id\n"", ""def FUNC_2(self):...\n"", ""VAR_12 = self.client.get('/datadocument/%s/' % VAR_11)\n"", ""VAR_1 = DataDocument.objects.first()\n"", ""self.assertEqual(VAR_12.status_code, 200,\n    'The page must return a 200 status code')\n"", ""VAR_2 = self.client.get(f'/datadocument/179486/')\n"", ""VAR_20 = ExtractedText.objects.get(data_document=dd)\n"", ""self.assertContains(VAR_12, 'No Extracted Text exists for this Data Document')\n"", ""self.assertContains(VAR_12, '<h4>Extracted Text')\n"", ""self.assertIn('Download Script', VAR_2.content.decode('utf-8'))\n"", ""self.assertIn('Extraction Script', VAR_2.content.decode('utf-8'))\n"", ""def FUNC_3(self):...\n"", ""VAR_2 = self.client.get('/datadocument/179486/')\n"", ""VAR_3 = VAR_2.content.decode('utf-8')\n"", ""VAR_4 = VAR_3.index('<h4>Extracted Text')\n"", ""VAR_5 = VAR_3.index('<h4 class=\""d-inline\"">Products')\n"", ""self.assertTrue(VAR_5 > VAR_4,\n    'Product card should come after Extracted Text card')\n"", ""def FUNC_4(self):...\n"", ""VAR_2 = self.client.get('/datadocument/167497/')\n"", ""self.assertContains(VAR_2, '/link_product_form/167497/')\n"", ""VAR_6 = {'title': ['New Product'], 'upc': ['stub_1860'], 'document_type': [\n    1], 'return_url': ['/datadocument/167497/']}\n"", ""VAR_2 = self.client.post('/link_product_form/167497/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/167497/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""self.assertContains(VAR_2, 'New Product')\n"", ""def FUNC_5(self):...\n"", ""VAR_2 = self.client.get('/datadocument/245401/')\n"", ""self.assertContains(VAR_2, '/link_product_form/245401/')\n"", ""VAR_6 = {'title': ['Product Title'], 'upc': ['stub_9100'], 'document_type':\n    [1], 'return_url': ['/datadocument/245401/']}\n"", ""VAR_2 = self.client.post('/link_product_form/245401/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/245401/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""VAR_7 = Product.objects.get(upc='stub_9100')\n"", ""self.assertContains(VAR_2, f'product/%s' % VAR_7.id)\n"", ""VAR_6 = {'title': ['Product Title'], 'upc': ['stub_9101'], 'document_type':\n    [1], 'return_url': ['/datadocument/245401/']}\n"", ""VAR_2 = self.client.post('/link_product_form/245401/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/245401/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""VAR_7 = Product.objects.get(upc='stub_9101')\n"", ""self.assertContains(VAR_2, f'product/%s' % VAR_7.id)\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = DataDocument.objects.get(pk=354784)\n"", ""self.assertFalse(VAR_1.extracted, 'This document is matched but not extracted')\n"", ""VAR_6 = {'hhe_report_number': ['47']}\n"", ""VAR_2 = self.client.post('/extractedtext/edit/354784/', VAR_6=data, follow=True\n    )\n"", ""VAR_1 = DataDocument.objects.get(pk=354784)\n"", ""self.assertTrue(VAR_1.extracted, 'This document is not extracted ')\n"", ""VAR_8 = VAR_3.fromstring(VAR_2.content)\n"", ""VAR_9 = VAR_8.xpath('//dd[contains(@class, \""hh-report-no\"")]')[0].text\n"", ""self.assertIn('47', VAR_9)\n"", ""VAR_0 = fixtures_standard\n"", ""def FUNC_0(self):...\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""def FUNC_7(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for et in ExtractedText.objects.all():\n"", ""for ex_child in et.fetch_extracted_records():\n"", ""def FUNC_8(self):...\n"", ""VAR_21 = ex_child.__class__\n"", ""\""\""\""docstring\""\""\""\n"", ""self.assertEqual(et.pk, VAR_21.objects.get(pk=ex_child.pk).extracted_text.\n    pk, 'string')\n"", ""for VAR_1 in DataDocument.objects.all():\n"", ""def FUNC_9(self):...\n"", ""VAR_22 = ExtractedText.objects.get_subclass(data_document=doc)\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.data_group.group_type.code == 'CP':\n"", ""for et in ExtractedText.objects.all():\n"", ""self.assertEqual(type(VAR_22), ExtractedCPCat)\n"", ""if VAR_1.data_group.group_type.code == 'HH':\n"", ""VAR_13 = et.data_document\n"", ""def FUNC_10(self):...\n"", ""self.assertEqual(type(VAR_22), ExtractedHHDoc)\n"", ""self.assertEqual(type(VAR_22), ExtractedText)\n"", ""VAR_14, VAR_15 = create_detail_formset(VAR_13, EXTRA)\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_14(instance=et)\n"", ""for et in ExtractedText.objects.all():\n"", ""VAR_17 = VAR_15(instance=et)\n"", ""VAR_13 = et.data_document\n"", ""def FUNC_11(self):...\n"", ""VAR_18 = get_extracted_models(VAR_13.data_group.group_type.code)[1]\n"", ""VAR_14, VAR_15 = create_detail_formset(VAR_13)\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = VAR_17.__dict__.get('queryset').__dict__.get('model')\n"", ""VAR_17 = VAR_15(instance=et)\n"", ""VAR_10 = {'CO': ExtractedChemical, 'FU': ExtractedFunctionalUse, 'HP':\n    ExtractedHabitsAndPractices, 'CP': ExtractedListPresence, 'HH':\n    ExtractedHHRec}\n"", ""self.assertEqual(VAR_18, VAR_19)\n"", ""for form in VAR_17.forms:\n"", ""for code, model in VAR_10.items():\n"", ""if VAR_13.data_group.type in ['CO', 'UN']:\n"", ""if DataDocument.objects.filter(document_type__group_type__code=code,\n"", ""VAR_25 = form.instance\n"", ""self.assertFalse('true_cas' in form.fields)\n"", ""VAR_1 = DataDocument.objects.filter(document_type__group_type__code=code,\n    extractedtext__isnull=False).first()\n"", ""if VAR_25.dsstox is not None:\n"", ""VAR_2 = self.client.get(reverse('data_document', kwargs={'pk': doc.pk}))\n"", ""self.assertTrue('true_cas' in form.fields)\n"", ""self.assertFalse('true_cas' in form.fields)\n"", ""VAR_23 = VAR_2.context['detail_formset'].total_form_count()\n"", ""self.assertTrue('SID' in form.fields)\n"", ""self.assertFalse('SID' in form.fields)\n"", ""VAR_24 = model.objects.filter(VAR_20=doc.extractedtext).count()\n"", ""if VAR_1.detail_page_editable:\n"", ""VAR_26 = f'{model.__module__} should have one more forms than instances'\n"", ""VAR_26 = (\n    f'{model.__module__} should have the same number of forms as instances')\n"", ""self.assertEqual(VAR_23, VAR_24 + 1, VAR_26)\n"", ""self.assertEqual(VAR_23, VAR_24, VAR_26)\n""]",1
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_10 = []\n"", ""for dim in VAR_1.split(':')[0].split('x'):\n"", ""VAR_10.append(int(dim))\n"", ""return VAR_10[0], VAR_10[1]\n""]",0
"[""def FUNC_14(self):...\n"", ""return self._get_ancestors().values()\n""]",1
"[""def FUNC_1(VAR_1, VAR_3):...\n"", """"]",0
"[""def FUNC_8(VAR_15):...\n"", ""VAR_32 = VAR_15.to_dict()\n"", ""VAR_32['tags'] = AnnTag.get_ann_tags(VAR_15.id, self.sql_session)\n"", ""return VAR_32\n""]",0
"[""\""\""\""Unit tests for phobos.dss\""\""\""\n"", ""import sys\n"", ""import unittest\n"", ""import os\n"", ""from random import randint\n"", ""from phobos.core.dss import Client\n"", ""from phobos.core.ffi import MediaInfo, DevInfo\n"", ""from phobos.core.const import dev_family2str, PHO_DEV_DIR\n"", ""\""\""\""\n    This test case issue requests to the DSS to stress the python bindings.\n    \""\""\""\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0 = Client()\n"", ""VAR_0.connect()\n"", ""VAR_0.disconnect()\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0 = Client()\n"", ""VAR_1 = VAR_2.environ['PHOBOS_DSS_connect_string']\n"", ""VAR_2.environ['PHOBOS_DSS_connect_string'\n    ] = \""dbname='tata', user='titi', password='toto'\""\n"", ""self.assertRaises(EnvironmentError, VAR_0.connect)\n"", ""VAR_2.environ['PHOBOS_DSS_connect_string'] = VAR_1\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for fam in ('tape', 'disk', 'dir'):\n"", ""for VAR_6 in client.devices.get(family=fam):\n"", ""def FUNC_3(self):...\n"", ""self.assertEqual(dev_family2str(VAR_6.family), fam)\n"", ""\""\""\""docstring\""\""\""\n"", ""for mda in client.media.get():\n"", ""self.assertTrue(isinstance(mda, MediaInfo))\n"", ""def FUNC_4(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = []\n"", ""for i in range(10):\n"", ""VAR_6 = DevInfo()\n"", ""client.devices.insert(VAR_3)\n"", ""VAR_6.family = PHO_DEV_DIR\n"", ""for VAR_6 in VAR_3:\n"", ""VAR_6.model = ''\n"", ""VAR_7 = client.devices.get(serial=dev.serial)\n"", ""client.devices.delete(VAR_7)\n"", ""VAR_6.path = '/tmp/test_%d' % randint(0, 1000000)\n"", ""for retrieved_dev in VAR_7:\n"", ""def FUNC_5(self):...\n"", ""VAR_6.host = 'localhost'\n"", ""self.assertTrue(isinstance(retrieved_dev, VAR_6.__class__))\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6.serial = '__TEST_MAGIC_%d' % randint(0, 1000000)\n"", ""self.assertEqual(retrieved_dev.serial, VAR_6.serial)\n"", ""client.devices.insert([])\n"", ""VAR_3.append(VAR_6)\n"", ""client.devices.insert(None)\n"", ""client.devices.delete([])\n"", ""client.devices.delete(None)\n"", ""client.media.insert([])\n"", ""client.media.insert(None)\n"", ""client.media.delete([])\n"", ""client.media.delete(None)\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/some/path_%d' % randint(0, 1000000)\n"", ""client.media.add(PHO_DEV_DIR, 'POSIX', None, VAR_4, locked=False)\n"", ""VAR_5 = client.media.get(id=label)[0]\n"", ""self.assertFalse(VAR_5.is_locked())\n"", ""client.media.lock([VAR_5])\n"", ""client.media.lock([VAR_5])\n"", ""VAR_5 = client.media.get(id=label)[0]\n"", ""self.assertTrue(VAR_5.is_locked())\n"", ""client.media.unlock([VAR_5])\n"", ""client.media.unlock([VAR_5])\n"", ""VAR_5 = client.media.get(id=label)[0]\n"", ""self.assertFalse(VAR_5.is_locked())\n"", ""if __name__ == '__main__':\n"", ""unittest.main()\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.translation import gettext as _, gettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""@gallery.route('/gallery/benwa/<int:post_id>/comment/add', methods=['POST'])...\n"", ""VAR_6 = CommentForm()\n"", ""if VAR_6.validate_on_submit():\n"", ""VAR_5 = Post.query.get(VAR_1)\n"", ""return redirect(url_for('gallery.show_post', VAR_1=post_id))\n"", ""VAR_8 = Comment(content=form.content.data, VAR_14=datetime.utcnow(), user=\n    current_user, VAR_5=post)\n"", ""db.session.add(VAR_8)\n"", ""db.session.commit()\n""]",0
"[""import six\n"", ""def FUNC_0(VAR_0):...\n"", ""if '[' in VAR_0:\n"", ""VAR_7, VAR_8, VAR_9 = VAR_0.rstrip(']').partition('[')\n"", ""if '{' in VAR_0:\n"", ""return VAR_9, CLASS_0, VAR_7\n"", ""VAR_7, VAR_8, VAR_12 = VAR_0.rstrip('}').partition('{')\n"", ""return CLASS_0, CLASS_0, VAR_0\n"", ""VAR_13, VAR_8, VAR_14 = VAR_12.partition('=')\n"", ""return VAR_14, VAR_13, VAR_7\n""]",0
"[""def FUNC_16(VAR_16):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = VAR_19(VAR_16, 'dynamic')\n"", ""VAR_31 = [VAR_30] if FUNC_10(VAR_30) else VAR_30\n"", ""for VAR_3 in VAR_31:\n"", ""VAR_52 = list(VAR_5.finditer(VAR_3))\n"", ""return VAR_30\n"", ""for VAR_29 in VAR_52:\n"", ""if VAR_29.group('constraint'):\n""]",1
"[""def FUNC_31(self):...\n"", ""VAR_22 = 3\n"", ""VAR_0 = [SleepCheckPollFail(10) for i in range(VAR_22)]\n"", ""VAR_21 = len(VAR_0)\n"", ""self.set_max_jobs(1)\n"", ""self.runall(VAR_0)\n"", ""VAR_15 = self.runner.stats\n"", ""self.assertEqual(VAR_22, VAR_15.num_cases())\n"", ""self.assertEqual(VAR_22, len(VAR_15.failures()))\n""]",0
"[""def FUNC_23(self, VAR_12=False):...\n"", ""if self.DiagnosticsForCurrentFileReady():\n"", ""VAR_22 = self._latest_file_parse_request.Response()\n"", ""return []\n"", ""self._latest_file_parse_request = None\n"", ""if VAR_12:\n"", ""return vimsupport.ConvertDiagnosticsToQfList(VAR_22)\n"", ""return VAR_22\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import hashlib\n"", ""import json\n"", ""import logging\n"", ""import os\n"", ""import StringIO\n"", ""import zipfile\n"", ""VAR_0 = ('__main__.py', 'api/__init__.py', 'api/bot.py', 'api/parallel.py',\n    'api/os_utilities.py', 'api/platforms/__init__.py',\n    'api/platforms/android.py', 'api/platforms/common.py',\n    'api/platforms/gce.py', 'api/platforms/linux.py',\n    'api/platforms/osx.py', 'api/platforms/posix.py',\n    'api/platforms/win.py', 'bot_code/__init__.py', 'bot_code/bot_main.py',\n    'bot_code/common.py', 'bot_code/singleton.py',\n    'bot_code/task_runner.py', 'bot_code/xsrf_client.py', 'client/auth.py',\n    'client/isolated_format.py', 'client/isolateserver.py',\n    'client/run_isolated.py', 'config/__init__.py',\n    'third_party/__init__.py', 'third_party/colorama/__init__.py',\n    'third_party/colorama/ansi.py', 'third_party/colorama/ansitowin32.py',\n    'third_party/colorama/initialise.py', 'third_party/colorama/win32.py',\n    'third_party/colorama/winterm.py',\n    'third_party/depot_tools/__init__.py',\n    'third_party/depot_tools/fix_encoding.py',\n    'third_party/depot_tools/subcommand.py',\n    'third_party/httplib2/__init__.py', 'third_party/httplib2/cacerts.txt',\n    'third_party/httplib2/iri2uri.py', 'third_party/httplib2/socks.py',\n    'third_party/oauth2client/__init__.py',\n    'third_party/oauth2client/_helpers.py',\n    'third_party/oauth2client/_openssl_crypt.py',\n    'third_party/oauth2client/_pycrypto_crypt.py',\n    'third_party/oauth2client/client.py',\n    'third_party/oauth2client/clientsecrets.py',\n    'third_party/oauth2client/crypt.py', 'third_party/oauth2client/file.py',\n    'third_party/oauth2client/gce.py',\n    'third_party/oauth2client/keyring_storage.py',\n    'third_party/oauth2client/locked_file.py',\n    'third_party/oauth2client/multistore_file.py',\n    'third_party/oauth2client/service_account.py',\n    'third_party/oauth2client/tools.py', 'third_party/oauth2client/util.py',\n    'third_party/oauth2client/xsrfutil.py',\n    'third_party/pyasn1/pyasn1/__init__.py',\n    'third_party/pyasn1/pyasn1/codec/__init__.py',\n    'third_party/pyasn1/pyasn1/codec/ber/__init__.py',\n    'third_party/pyasn1/pyasn1/codec/ber/decoder.py',\n    'third_party/pyasn1/pyasn1/codec/ber/encoder.py',\n    'third_party/pyasn1/pyasn1/codec/ber/eoo.py',\n    'third_party/pyasn1/pyasn1/codec/cer/__init__.py',\n    'third_party/pyasn1/pyasn1/codec/cer/decoder.py',\n    'third_party/pyasn1/pyasn1/codec/cer/encoder.py',\n    'third_party/pyasn1/pyasn1/codec/der/__init__.py',\n    'third_party/pyasn1/pyasn1/codec/der/decoder.py',\n    'third_party/pyasn1/pyasn1/codec/der/encoder.py',\n    'third_party/pyasn1/pyasn1/compat/__init__.py',\n    'third_party/pyasn1/pyasn1/compat/binary.py',\n    'third_party/pyasn1/pyasn1/compat/octets.py',\n    'third_party/pyasn1/pyasn1/debug.py',\n    'third_party/pyasn1/pyasn1/error.py',\n    'third_party/pyasn1/pyasn1/type/__init__.py',\n    'third_party/pyasn1/pyasn1/type/base.py',\n    'third_party/pyasn1/pyasn1/type/char.py',\n    'third_party/pyasn1/pyasn1/type/constraint.py',\n    'third_party/pyasn1/pyasn1/type/error.py',\n    'third_party/pyasn1/pyasn1/type/namedtype.py',\n    'third_party/pyasn1/pyasn1/type/namedval.py',\n    'third_party/pyasn1/pyasn1/type/tag.py',\n    'third_party/pyasn1/pyasn1/type/tagmap.py',\n    'third_party/pyasn1/pyasn1/type/univ.py',\n    'third_party/pyasn1/pyasn1/type/useful.py',\n    'third_party/requests/__init__.py', 'third_party/requests/adapters.py',\n    'third_party/requests/api.py', 'third_party/requests/auth.py',\n    'third_party/requests/certs.py', 'third_party/requests/compat.py',\n    'third_party/requests/cookies.py', 'third_party/requests/exceptions.py',\n    'third_party/requests/hooks.py', 'third_party/requests/models.py',\n    'third_party/requests/packages/__init__.py',\n    'third_party/requests/packages/urllib3/__init__.py',\n    'third_party/requests/packages/urllib3/_collections.py',\n    'third_party/requests/packages/urllib3/connection.py',\n    'third_party/requests/packages/urllib3/connectionpool.py',\n    'third_party/requests/packages/urllib3/contrib/__init__.py',\n    'third_party/requests/packages/urllib3/contrib/ntlmpool.py',\n    'third_party/requests/packages/urllib3/contrib/pyopenssl.py',\n    'third_party/requests/packages/urllib3/exceptions.py',\n    'third_party/requests/packages/urllib3/fields.py',\n    'third_party/requests/packages/urllib3/filepost.py',\n    'third_party/requests/packages/urllib3/packages/__init__.py',\n    'third_party/requests/packages/urllib3/packages/ordered_dict.py',\n    'third_party/requests/packages/urllib3/packages/six.py',\n    'third_party/requests/packages/urllib3/packages/ssl_match_hostname/__init__.py'\n    ,\n    'third_party/requests/packages/urllib3/packages/ssl_match_hostname/_implementation.py'\n    , 'third_party/requests/packages/urllib3/poolmanager.py',\n    'third_party/requests/packages/urllib3/request.py',\n    'third_party/requests/packages/urllib3/response.py',\n    'third_party/requests/packages/urllib3/util/__init__.py',\n    'third_party/requests/packages/urllib3/util/connection.py',\n    'third_party/requests/packages/urllib3/util/request.py',\n    'third_party/requests/packages/urllib3/util/response.py',\n    'third_party/requests/packages/urllib3/util/retry.py',\n    'third_party/requests/packages/urllib3/util/ssl_.py',\n    'third_party/requests/packages/urllib3/util/timeout.py',\n    'third_party/requests/packages/urllib3/util/url.py',\n    'third_party/requests/sessions.py',\n    'third_party/requests/status_codes.py',\n    'third_party/requests/structures.py', 'third_party/requests/utils.py',\n    'third_party/rsa/rsa/__init__.py', 'third_party/rsa/rsa/_compat.py',\n    'third_party/rsa/rsa/_version133.py',\n    'third_party/rsa/rsa/_version200.py', 'third_party/rsa/rsa/asn1.py',\n    'third_party/rsa/rsa/bigfile.py', 'third_party/rsa/rsa/cli.py',\n    'third_party/rsa/rsa/common.py', 'third_party/rsa/rsa/core.py',\n    'third_party/rsa/rsa/key.py', 'third_party/rsa/rsa/parallel.py',\n    'third_party/rsa/rsa/pem.py', 'third_party/rsa/rsa/pkcs1.py',\n    'third_party/rsa/rsa/prime.py', 'third_party/rsa/rsa/randnum.py',\n    'third_party/rsa/rsa/transform.py', 'third_party/rsa/rsa/util.py',\n    'third_party/rsa/rsa/varblock.py', 'third_party/six/__init__.py',\n    'utils/__init__.py', 'utils/cacert.pem', 'utils/file_path.py',\n    'utils/fs.py', 'utils/large.py', 'utils/logging_utils.py',\n    'utils/lru.py', 'utils/net.py', 'utils/oauth.py', 'utils/on_error.py',\n    'utils/subprocess42.py', 'utils/threading_utils.py', 'utils/tools.py',\n    'utils/zip_package.py', 'adb/__init__.py', 'adb/adb_commands.py',\n    'adb/adb_protocol.py', 'adb/common.py', 'adb/contrib/__init__.py',\n    'adb/contrib/adb_commands_safe.py', 'adb/contrib/high.py',\n    'adb/contrib/parallel.py', 'adb/fastboot.py',\n    'adb/filesync_protocol.py', 'adb/sign_pythonrsa.py',\n    'adb/usb_exceptions.py', 'python_libusb1/__init__.py',\n    'python_libusb1/libusb1.py', 'python_libusb1/usb1.py')\n"", ""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return os.__file__[0] != '/'\n""]",1
"[""def FUNC_28(VAR_24):...\n"", ""VAR_33.append(VAR_24)\n"", ""return 23\n""]",0
"[""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n""]",1
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = '/api/apps'\n"", ""VAR_3 = self.client.post(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 201)\n"", ""VAR_4 = VAR_3.data['id']\n"", ""self.assertIn('id', VAR_3.data)\n"", ""self.assertIn('url', VAR_3.data)\n"", ""self.assertEqual(VAR_3.data['url'], '{app_id}.deisapp.local'.format(**locals())\n    )\n"", ""VAR_3 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""self.assertEqual(len(VAR_3.data['results']), 1)\n"", ""VAR_2 = '/api/apps/{app_id}'.format(**locals())\n"", ""VAR_3 = self.client.get(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""VAR_5 = {'id': 'new'}\n"", ""VAR_3 = self.client.patch(VAR_2, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_3.status_code, 405)\n"", ""VAR_3 = self.client.delete(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 204)\n""]",1
"[""from django.conf.urls import url, include\n"", ""from .projects import ProjectViewSet\n"", ""from .tasks import TaskViewSet, TaskTiles, TaskTilesJson, TaskAssets\n"", ""from .processingnodes import ProcessingNodeViewSet\n"", ""from rest_framework_nested import routers\n"", ""VAR_0 = routers.DefaultRouter()\n"", ""VAR_0.register('projects', ProjectViewSet)\n"", ""VAR_0.register('processingnodes', ProcessingNodeViewSet)\n"", ""VAR_1 = routers.NestedSimpleRouter(VAR_0, 'projects', lookup='project')\n"", ""VAR_1.register('tasks', TaskViewSet, base_name='projects-tasks')\n"", ""VAR_2 = [url('^', include(VAR_0.urls)), url('^', include(VAR_1.urls)), url(\n    'string', TaskTiles.as_view()), url(\n    'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/tiles\\\\.json$',\n    TaskTilesJson.as_view()), url(\n    'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/download/(?P<asset>[^/.]+)/$'\n    , TaskAssets.as_view()), url('^auth/', include('rest_framework.urls'))]\n""]",1
"[""@app.route('/api/events')...\n"", ""return Response(controller.sse.subscribe().feed(), mimetype='text/event-stream'\n    )\n""]",0
"[""def FUNC_9(self, VAR_9: Message) ->CLASS_0:...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = self.users.get(VAR_9.chat.id, None)\n"", ""if VAR_7:\n"", ""return VAR_7\n"", ""log.debug(\""Looking up the user in the database as it doesn't appear in cache\"")\n"", ""VAR_10 = (\n    f'SELECT first_name, nickname, last_name, language FROM users WHERE chat_id={VAR_9.chat.id}'\n    )\n"", ""VAR_19 = db.execute_query(VAR_10)\n"", ""log.error('Cannot lookup the user with chat_id %d in database', VAR_9.chat.id)\n"", ""if not VAR_19.rowcount:\n"", ""VAR_17 = VAR_9.from_user\n"", ""log.info('Adding totally new user to the system...')\n"", ""log.debug('User %d has been found in the database', VAR_9.chat.id)\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, VAR_17.first_name, VAR_17.last_name,\n    VAR_17.username, VAR_4='en-US', VAR_8=False)\n"", ""VAR_17 = VAR_9.from_user\n"", ""VAR_21 = VAR_19.fetchall()[0]\n"", ""return VAR_7\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, VAR_17.first_name, VAR_17.last_name,\n    VAR_17.username, VAR_4='en-US')\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, *VAR_21, VAR_8=False)\n"", ""bot.send_message(config.MY_TELEGRAM, text=f'You have a new user! {user}')\n"", ""return VAR_7\n"", ""log.info('You have a new user! Welcome %s', VAR_7)\n""]",1
"[""def FUNC_16(VAR_12):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_12 is None:\n"", ""return ''\n"", ""return VAR_12.strftime(VAR_0)\n""]",0
"[""@mock.patch('requests.post', FUNC_0)...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.client.login(username='autotest2', password='password')\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""self.client.login(username='autotest', password='password')\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_7 = {'image': 'autotest/example'}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_13 = Build.objects.get(uuid=response.data['uuid'])\n"", ""self.assertEqual(str(VAR_13), '{}-{}'.format(VAR_5.data['app'], VAR_5.data[\n    'uuid'][:7]))\n""]",1
"[""@VAR_0.route('/message/send')...\n"", ""if request.method == 'PUT':\n"", ""return db_sendMessage(request.get_json())\n""]",1
"[""def FUNC_15(self, VAR_14):...\n"", ""VAR_23 = '*'\n"", ""VAR_24 = ''\n"", ""if VAR_14._joins:\n"", ""for VAR_41 in VAR_14._joins:\n"", ""VAR_22 = ''\n"", ""VAR_33 = VAR_41.joint_type\n"", ""if VAR_14._where:\n"", ""if VAR_33 == self.JOIN:\n"", ""VAR_27 = 0\n"", ""VAR_25 = ';'\n"", ""VAR_33 = self.JOIN\n"", ""VAR_33 = self.LEFT_JOIN\n"", ""if isinstance(VAR_14._where, VAR_39):\n"", ""if VAR_14._delete:\n"", ""if VAR_41.dest in VAR_41.src._meta.rel_class and VAR_41.src.isForeignKey(VAR_41\n"", ""VAR_22 = 'WHERE {0}'.format(VAR_14._where)\n"", ""VAR_22 = VAR_14._where.parse()\n"", ""VAR_29 = 'DELETE'\n"", ""VAR_29 = 'SELECT {0}'.format(','.join(VAR_23))\n"", ""VAR_36 = '%s.%s' % (VAR_41.src._meta.table_name, VAR_41.src._meta.rel_class\n    [VAR_41.dest].name)\n"", ""if VAR_41.src in VAR_41.dest._meta.rel_class and VAR_41.dest.isForeignKey(\n"", ""VAR_22 = 'WHERE {0}'.format(VAR_22)\n"", ""if VAR_14.model_class._meta.primary_key:\n"", ""VAR_7 = '{0} FROM {1} {2} {3}{4}'.format(VAR_29, VAR_14.model_class._meta.\n    table_name, VAR_24, VAR_22, VAR_25)\n"", ""VAR_37 = '%s.%s' % (VAR_41.dest._meta.table_name, VAR_41.src._meta.\n    rel_class[VAR_41.dest].reference.name)\n"", ""VAR_36 = '%s.%s' % (VAR_41.src._meta.table_name, VAR_41.dest._meta.\n    rel_class[VAR_41.src].reference.name)\n"", ""VAR_24 += '%s %s on (%s = %s) ' % (VAR_33, VAR_41.dest._meta.table_name,\n    VAR_36, VAR_37)\n"", ""VAR_25 = ' RETURNING id;'\n"", ""return VAR_7\n"", ""VAR_37 = '%s.%s' % (VAR_41.dest._meta.table_name, VAR_41.dest._meta.\n    rel_class[VAR_41.src].name)\n""]",0
"[""def FUNC_6(self, VAR_0):...\n"", """"]",0
"[""def FUNC_2(self):...\n"", ""self.client.get(f'/qa/extractionscript/{self.objects.exscript.pk}/')\n"", ""VAR_0 = self.objects.extext.pk\n"", ""VAR_1 = self.client.post(f'/qa/extractedtext/{VAR_0}/', {'approve': [47]})\n"", ""self.assertEqual(VAR_1.url, '/qa/extractionscript/',\n    'User should be redirected to QA homepage after last extext is approved.')\n""]",1
"[""def __init__(self, VAR_1: neko.NekoBot):...\n"", ""self.bot = VAR_1\n"", ""self.running_lock = asyncio.Lock()\n""]",0
"[""def FUNC_2(self, VAR_1):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = \""INSERT INTO crimes (description) VALUES ('{}');\"".format(VAR_1)\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",1
"[""def FUNC_11(self, VAR_9, *VAR_13, **VAR_14):...\n"", ""VAR_14['partial'] = True\n"", ""return self.update(VAR_9, *VAR_13, **kwargs)\n""]",0
"[""@utils.synchronized('3par', external=True)...\n"", """"]",0
"[""import json\n"", ""import logging\n"", ""from orm_cloud.configuration import Configuration\n"", ""from orm_cloud.database_adapters.database_factory import DatabaseFactory\n"", ""from orm_cloud.database_adapters.ms_sql_adapter import MsSqlAdapter\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""def __init__(self, VAR_1, **VAR_2):...\n"", ""self._type = VAR_1\n"", ""self._db_params = VAR_2\n"", ""def FUNC_0(self, VAR_3, VAR_4, VAR_5, VAR_6=None, VAR_7=None, VAR_8=None,...\n"", ""VAR_10 = Configuration()\n"", ""VAR_11 = VAR_10.db_info\n"", ""VAR_12 = json.loads(VAR_11)\n"", ""self.log.debug('Creating {} database adapter...'.format(self._type))\n"", ""if self._type == 'pymssql':\n"", ""VAR_18 = MsSqlAdapter()\n"", ""VAR_13 = VAR_18.get_sql(VAR_3, VAR_4, VAR_5, VAR_6, VAR_7, VAR_8)\n"", ""self.log.debug('SQL is [{}].'.format(VAR_13))\n"", ""VAR_14 = DatabaseFactory(self._type, hostname=db_info_json['host'], user=\n    db_info_json['username'], password=db_info_json['password'], database=\n    db_info_json['dbInstanceIdentifier'])\n"", ""VAR_15 = VAR_14.get_connection()\n"", ""VAR_16 = VAR_15.cursor()\n"", ""VAR_16.execute(VAR_13, None)\n"", ""VAR_17 = [dict((VAR_16.description[i][0], value) for i, value in enumerate(\n    row)) for row in VAR_16.fetchall()]\n"", ""return (VAR_17[0] if VAR_17 else None) if VAR_9 else VAR_17\n""]",1
"[""def FUNC_48(self, VAR_22, VAR_6=None):...\n"", ""if VAR_6:\n"", ""VAR_5 = VAR_5 = self.session.query(self.obj)\n"", ""return self.session.query(self.obj).get(VAR_22)\n"", ""VAR_35 = VAR_6.copy()\n"", ""VAR_35.add_filter(self.get_pk_name(), self.FilterEqual, VAR_22)\n"", ""VAR_5 = self._get_base_query(VAR_5=query, VAR_6=_filters)\n"", ""return VAR_5.first()\n""]",0
"[""def __call__(self, VAR_2, VAR_3, VAR_4=None):...\n"", ""if VAR_3.strip():\n"", ""return\n"", ""VAR_45 = subprocess.Popen(['uptime'], VAR_66=subprocess.PIPE)\n"", ""VAR_46, VAR_47 = VAR_45.communicate()\n"", ""VAR_46 = VAR_46.decode().strip()\n"", ""if not self._show_users:\n"", ""VAR_46 = re.sub('[0-9]+ users, ', '', VAR_46)\n"", ""self.reply(VAR_2, VAR_46)\n""]",0
"[""import time\n"", ""import sys\n"", ""import citest.gcp_testing as gcp\n"", ""import citest.json_contract as jc\n"", ""import citest.service_testing as st\n"", ""import spinnaker_testing as sk\n"", ""import spinnaker_testing.gate as gate\n"", ""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""return gate.new_agent(VAR_1)\n""]",1
"[""def FUNC_4(VAR_2, VAR_4):...\n"", ""if VAR_4.status == 'failed':\n"", ""VAR_8 = str(uuid.uuid4())\n"", ""os.chdir('screenshots')\n"", ""VAR_2.browser.save_screenshot('failed ' + str(VAR_4.name) + '_' + VAR_8 +\n    '.png')\n"", ""FUNC_7(VAR_2, 'failed ' + str(VAR_4.name) + '_' + VAR_8 + '.html')\n"", ""os.chdir('../')\n""]",0
"[""def FUNC_18(self, VAR_10, VAR_1=None, VAR_65=None):...\n"", ""VAR_100 = CLASS_2(self, VAR_10, VAR_1, VAR_65)\n"", ""self._subworkflows[VAR_10] = VAR_100\n"", ""self.globals[VAR_10] = VAR_100.target\n""]",0
"[""import undead\n"", ""import unittest\n"", ""def FUNC_0(self):...\n"", ""VAR_0 = 'string'\n"", ""VAR_1 = VAR_0.split('#')[-1]\n"", ""VAR_2 = Board(VAR_1)\n"", ""def FUNC_1(self):...\n"", ""VAR_3 = Walker()\n"", ""VAR_4 = 3\n"", ""VAR_5 = 0\n"", ""VAR_3.walk(VAR_2, VAR_4, VAR_5, 'east')\n"", ""if __name__ == '__main__':\n"", ""unittest.main()\n""]",1
"[""def FUNC_40(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return list(self.list_properties.keys())\n""]",0
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps', HTTP_X_DEIS_VERSION='1234.5678')\n"", ""self.assertEqual(VAR_1.status_code, 405)\n""]",1
"[""def FUNC_16(self, VAR_16, VAR_19):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_46 = self.configuration.volume_name_template % VAR_19['id']\n"", ""VAR_0.error(_('Failed to create clone of volume %s'), VAR_16['name'])\n"", ""VAR_25 = self._eql_execute('volume', 'select', VAR_46, 'clone', VAR_16['name'])\n"", ""return self._get_volume_data(VAR_25)\n""]",0
"[""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n""]",1
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import django.utils.timezone\n"", ""VAR_0 = [('exercise', '0004_auto_20150617_1033')]\n"", ""VAR_1 = [migrations.AlterField(model_name='coursemodule', name=\n    'closing_time', field=models.DateTimeField(default=django.utils.\n    timezone.now), preserve_default=True), migrations.AlterField(model_name\n    ='coursemodule', name='late_submission_deadline', field=models.\n    DateTimeField(default=django.utils.timezone.now), preserve_default=True\n    ), migrations.AlterField(model_name='coursemodule', name='opening_time',\n    field=models.DateTimeField(default=django.utils.timezone.now),\n    preserve_default=True), migrations.AlterField(model_name=\n    'deadlineruledeviation', name='exercise', field=models.ForeignKey(to=\n    'exercise.BaseExercise'), preserve_default=True), migrations.AlterField\n    (model_name='maxsubmissionsruledeviation', name='exercise', field=\n    models.ForeignKey(to='exercise.BaseExercise'), preserve_default=True)]\n""]",1
"[""def __init__(self, VAR_3, VAR_4):...\n"", ""self.email = VAR_3\n"", ""self.password = VAR_4\n""]",1
"[""def FUNC_5(self):...\n"", ""VAR_1 = self.client.get(url_for('oauthclient.login', remote_app='test'))\n"", ""self.assertStatus(VAR_1, 302)\n"", ""self.assertEqual(VAR_1.location, \n    'https://foo.bar/oauth/authorize?response_type=code&client_id=testid&redirect_uri=%s'\n     % quote_plus(url_for('oauthclient.authorized', remote_app='test',\n    _external=True)))\n"", ""VAR_1 = self.client.get(url_for('oauthclient.login', remote_app='invalid'))\n"", ""self.assertStatus(VAR_1, 404)\n""]",1
"[""def FUNC_0(self):...\n"", ""VAR_1 = db.GqlQuery('SELECT * FROM Item ORDER BY created_at DESC')\n"", ""VAR_2 = database.users.is_current_user_admin()\n"", ""database.render_template(self, 'items/index.html', {'items': VAR_1})\n""]",0
"[""def __init__(self, VAR_4, VAR_5=False, VAR_6=None, VAR_7=False):...\n"", ""self.skip_checks = VAR_7\n"", ""self.target_dir = VAR_6 if VAR_6 else CONFIG['TARGET_DIR']\n"", ""self.source = VAR_4\n"", ""if VAR_5:\n"", ""set_log_level_to_debug()\n"", ""if not self.target_dir or not os.path.isdir(self.target_dir):\n"", ""VAR_3.debug('Using %s as target dir' % self.target_dir)\n"", ""VAR_3.debug('Using URL: %s' % self.source)\n"", ""VAR_3.debug(\n    'MonitoringConfigGenerator start: reading from %s, writing to %s' % (\n    self.source, self.target_dir))\n""]",0
"[""def __init__(self, VAR_1, VAR_2=False, VAR_3=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.all_processes = {}\n"", ""VAR_1.update_if_absent(node_ip_address=ray.services.get_node_ip_address(),\n    include_log_monitor=True, resources={}, include_webui=False,\n    worker_path=os.path.join(os.path.dirname(os.path.abspath(__file__)),\n    'workers/default_worker.py'))\n"", ""if VAR_2:\n"", ""VAR_1.update_if_absent(num_redis_shards=1, include_webui=True)\n"", ""VAR_18 = ray.services.create_redis_client(VAR_1.redis_address, VAR_1.\n    redis_password)\n"", ""self._ray_params = VAR_1\n"", ""VAR_1.include_java = ray.services.include_java_from_redis(VAR_18)\n"", ""self._config = json.loads(VAR_1._internal_config\n    ) if VAR_1._internal_config else None\n"", ""self._node_ip_address = VAR_1.node_ip_address\n"", ""self._redis_address = VAR_1.redis_address\n"", ""self._plasma_store_socket_name = None\n"", ""self._raylet_socket_name = None\n"", ""self._webui_url = None\n"", ""self.start_ray_processes()\n"", ""if VAR_3:\n"", ""atexit.register(lambda : self.kill_all_processes(VAR_9=False, VAR_8=True))\n""]",0
"[""def FUNC_14(VAR_10, VAR_18, VAR_19, VAR_20, VAR_21=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_44 = FUNC_0(VAR_10['project'])\n"", ""VAR_45 = VAR_44[0] if VAR_44 else 0\n"", ""VAR_21 = VAR_21 or {}\n"", ""VAR_46, VAR_47, VAR_48, VAR_49, VAR_50 = state.get_configs([(\n    'global_per_second_limit', 1000), ('global_concurrent_limit', 1000), (\n    'project_per_second_limit', 1000), ('project_concurrent_limit', 1000),\n    ('use_cache', 0)])\n"", ""VAR_48, VAR_49 = state.get_configs([('project_per_second_limit_{}'.format(\n    VAR_45), VAR_48), ('project_concurrent_limit_{}'.format(VAR_45), VAR_49)])\n"", ""VAR_51 = six.iteritems(state.get_all_configs())\n"", ""VAR_52 = {k.split('/', 1)[1]: v for k, v in VAR_51 if k.startswith(\n    'query_settings/')}\n"", ""VAR_20.mark('get_configs')\n"", ""VAR_53 = md5(FUNC_19(VAR_18)).hexdigest()\n"", ""VAR_20.mark('dedupe_wait')\n"", ""VAR_54 = state.get_result(VAR_53) if VAR_50 else None\n"", ""VAR_20.mark('cache_get')\n"", ""VAR_21.update({'is_duplicate': is_dupe, 'query_id': VAR_53, 'use_cache':\n    bool(VAR_50), 'cache_hit': bool(VAR_54)}),\n"", ""if VAR_54:\n"", ""VAR_75 = 200\n"", ""VAR_32.gauge('query.global_concurrent', g_concurr)\n"", ""VAR_21.update(VAR_52)\n"", ""VAR_21.update({'global_rate': g_rate, 'global_concurrent': g_concurr})\n"", ""state.record_query({'request': VAR_10, 'sql': VAR_18, 'timing': VAR_20,\n    'stats': VAR_21, 'status': VAR_75})\n"", ""VAR_21.update({'project_rate': p_rate, 'project_concurrent': p_concurr})\n"", ""if settings.RECORD_QUERIES:\n"", ""VAR_20.mark('rate_limit')\n"", ""VAR_20.send_metrics_to(VAR_32)\n"", ""VAR_54['timing'] = VAR_20\n"", ""if g_allowed and p_allowed:\n"", ""if settings.STATS_IN_RESPONSE or VAR_10.get('debug', False):\n"", ""if 'max_threads' in VAR_52 and p_concurr > 1:\n"", ""VAR_75 = 429\n"", ""VAR_54['stats'] = VAR_21\n"", ""return VAR_54, VAR_75\n"", ""VAR_83 = VAR_52['max_threads']\n"", ""VAR_22, VAR_23 = VAR_19.execute(VAR_18, with_column_types=True, settings=\n    query_settings, VAR_53=query_id)\n"", ""VAR_85 = six.text_type(ex)\n"", ""VAR_54 = {'error': {'type': 'ratelimit', 'message': 'rate limit exceeded'}}\n"", ""VAR_54['sql'] = VAR_18\n"", ""VAR_52['max_threads'] = max(1, VAR_83 - p_concurr + 1)\n"", ""VAR_22, VAR_23 = FUNC_15(VAR_22, VAR_23)\n"", ""VAR_75 = 500\n"", ""VAR_75 = 200\n"", ""VAR_0.error(\""\""\""Error running query: %s\n%s\""\""\"", VAR_18, VAR_85)\n"", ""if VAR_10.get('totals', False):\n"", ""if isinstance(ex, ClickHouseError):\n"", ""assert len(VAR_22) > 0\n"", ""VAR_54 = {'data': VAR_22, 'meta': VAR_23}\n"", ""VAR_54 = {'error': {'type': 'clickhouse', 'code': ex.code, 'message': VAR_85}}\n"", ""VAR_54 = {'error': {'type': 'unknown', 'message': VAR_85}}\n"", ""VAR_22, VAR_84 = VAR_22[:-1], VAR_22[-1]\n"", ""VAR_0.debug(VAR_18)\n"", ""VAR_54 = {'data': VAR_22, 'meta': VAR_23, 'totals': VAR_84}\n"", ""VAR_20.mark('execute')\n"", ""VAR_21.update({'result_rows': len(VAR_22), 'result_cols': len(VAR_23)})\n"", ""if VAR_50:\n"", ""state.set_result(VAR_53, VAR_54)\n"", ""VAR_20.mark('cache_set')\n""]",0
"[""def FUNC_0(VAR_0):...\n"", ""VAR_3 = VAR_0.add_argument_group('Common parameters')\n"", ""VAR_3.add_argument('--debug', action='store_true', default=False, help=\n    'Show debug messages')\n"", ""VAR_3.add_argument('--repos', action='store_true', default=False, help=\n    'List repositories which the command operates on')\n"", ""VAR_3.add_argument('path', nargs='?', default=os.curdir, help=\n    'Base path to look for repositories')\n""]",1
"[""def FUNC_3(self):...\n"", ""VAR_14 = db_interac.delete_users()\n"", ""return {}, 204\n""]",0
"[""def FUNC_3(VAR_3):...\n"", """"]",0
"[""def __init__(self, VAR_1, VAR_5, VAR_4=None):...\n"", ""GenericRequest.__init__(self, VAR_1, VAR_4)\n"", ""self.url = '%stasks/%s/description' % (self.base_url, VAR_5)\n"", ""self.task_id = VAR_5\n""]",1
"[""@VAR_0.route('/login', methods=['GET', 'POST'])...\n"", ""if request.method == 'POST':\n"", ""VAR_42 = request.form['username']\n"", ""return render_template('login.html')\n"", ""VAR_52 = request.form['password']\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('SELECT * FROM Users WHERE username = %s', [VAR_42])\n"", ""if VAR_29 > 0:\n"", ""VAR_54 = VAR_28.fetchone()\n"", ""VAR_55 = 'Username not found'\n"", ""VAR_44 = VAR_54['password']\n"", ""return render_template('login.html', VAR_55=error)\n"", ""if sha256_crypt.verify(VAR_52, VAR_44):\n"", ""VAR_10['logged_in'] = True\n"", ""VAR_55 = 'Invalid login'\n"", ""VAR_10['username'] = VAR_42\n"", ""return render_template('login.html', VAR_55=error)\n"", ""flash('You are now logged in', 'success')\n"", ""return redirect(url_for('index'))\n""]",1
"[""import numpy as np\n"", ""import matplotlib.pyplot as plt\n"", ""import pandas as pd\n"", ""VAR_0 = pd.read_csv('Churn_Modelling.csv')\n"", ""VAR_1 = VAR_0.iloc[:, 3:13].values\n"", ""VAR_2 = VAR_0.iloc[:, (13)].values\n"", ""from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"", ""VAR_3 = LabelEncoder()\n"", ""VAR_1[:, (1)] = VAR_3.fit_transform(VAR_1[:, (1)])\n"", ""VAR_4 = LabelEncoder()\n"", ""VAR_1[:, (2)] = VAR_4.fit_transform(VAR_1[:, (2)])\n"", ""VAR_5 = OneHotEncoder(categorical_features=[1])\n"", ""VAR_1 = VAR_5.fit_transform(VAR_1).toarray()\n"", ""VAR_1 = VAR_1[:, 1:]\n"", ""from sklearn.model_selection import train_test_split\n"", ""VAR_6, VAR_7, VAR_8, VAR_9 = train_test_split(VAR_1, VAR_2, test_size=0.2,\n    random_state=0)\n"", ""from sklearn.preprocessing import StandardScaler\n"", ""VAR_10 = StandardScaler()\n"", ""VAR_6 = VAR_10.fit_transform(VAR_6)\n"", ""VAR_7 = VAR_10.transform(VAR_7)\n"", ""import keras\n"", ""from keras.models import Sequential\n"", ""from keras.layers import Dense\n"", ""VAR_11 = Sequential()\n"", ""VAR_11.add(Dense(units=6, kernel_initializer='uniform', activation='relu',\n    input_dim=11))\n"", ""VAR_11.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n"", ""VAR_11.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n"", ""VAR_11.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\n    'accuracy'])\n"", ""VAR_11.fit(VAR_6, VAR_8, batch_size=10, epochs=100)\n"", ""VAR_12 = VAR_11.predict(VAR_7)\n"", ""VAR_12 = VAR_12 > 0.5\n"", ""from sklearn.metrics import confusion_matrix\n"", ""VAR_13 = confusion_matrix(VAR_9, VAR_12)\n""]",1
"[""@require_http_methods(['GET'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_next_url_for_login_page(VAR_3)\n"", ""if VAR_3.user.is_authenticated():\n"", ""return redirect(VAR_7)\n"", ""VAR_13 = FUNC_6(VAR_3)\n"", ""VAR_14 = None\n"", ""if '?' in VAR_7:\n"", ""if is_request_in_themed_site() and not configuration_helpers.get_value(\n"", ""VAR_43 = urlparse.parse_qs(urlparse.urlparse(VAR_7).query)\n"", ""if VAR_4 == 'login':\n"", ""VAR_15 = FUNC_8(VAR_3, VAR_4)\n"", ""VAR_44 = VAR_43['tpa_hint'][0]\n"", ""return old_login_view(VAR_3)\n"", ""if VAR_4 == 'register':\n"", ""if VAR_15 is not None:\n"", ""VAR_45 = third_party_auth.provider.Registry.get(VAR_44=provider_id)\n"", ""return old_register_view(VAR_3)\n"", ""return VAR_15\n"", ""VAR_16 = [{'message': message.message, 'tags': message.tags} for message in\n    messages.get_messages(VAR_3) if 'account-activation' in message.tags]\n"", ""if VAR_45:\n"", ""VAR_5 = {'data': {'login_redirect_url': VAR_7, 'initial_mode': VAR_4,\n    'third_party_auth': FUNC_5(VAR_3, VAR_7, VAR_14),\n    'third_party_auth_hint': VAR_14 or '', 'platform_name':\n    configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME\n    ), 'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK',\n    settings.SUPPORT_SITE_LINK), 'password_reset_support_link': \n    configuration_helpers.get_value('PASSWORD_RESET_SUPPORT_LINK', settings\n    .PASSWORD_RESET_SUPPORT_LINK) or settings.SUPPORT_SITE_LINK,\n    'account_activation_messages': VAR_16, 'login_form_desc': json.loads(\n    VAR_13['login']), 'registration_form_desc': json.loads(VAR_13[\n    'registration']), 'password_reset_form_desc': json.loads(VAR_13[\n    'password_reset']), 'account_creation_allowed': configuration_helpers.\n    get_value('ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get(\n    'ALLOW_PUBLIC_ACCOUNT_CREATION', True))}, 'login_redirect_url': VAR_7,\n    'responsive': True, 'allow_iframing': True, 'disable_courseware_js': \n    True, 'combined_login_and_register': True, 'disable_footer': not\n    configuration_helpers.get_value(\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER', settings.FEATURES[\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER'])}\n"", ""if VAR_45.skip_hinted_login_dialog:\n"", ""VAR_5 = FUNC_2(VAR_3, VAR_5)\n"", ""return redirect(pipeline.get_login_url(VAR_44, pipeline.AUTH_ENTRY_LOGIN,\n    redirect_url=redirect_to))\n"", ""VAR_14 = VAR_44\n"", ""return render_to_response('student_account/login_and_register.html', VAR_5)\n"", ""VAR_4 = 'hinted_login'\n""]",1
"[""def FUNC_6(self, VAR_13=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._create_command('node', VAR_13)\n""]",1
"[""def FUNC_10(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return block.path_to_kname(VAR_1).startswith('dm') and FUNC_1(VAR_1\n    ).startswith('LVM')\n""]",0
"[""def FUNC_2(self):...\n"", ""VAR_1 = 'INVALID'\n"", ""self.assertEqual(escape_path_argument('/home/usr/a-file', VAR_1),\n    '/home/usr/a-file')\n"", ""self.assertEqual(escape_path_argument('/home/us r/a-file with spaces.bla',\n    VAR_1), '/home/us r/a-file with spaces.bla')\n"", ""self.assertEqual(escape_path_argument('|home|us r|a*dir with spaces|x|',\n    VAR_1), '|home|us r|a*dir with spaces|x|')\n"", ""self.assertEqual(escape_path_argument('system|a|b|c?d', VAR_1),\n    'system|a|b|c?d')\n""]",0
"[""def FUNC_2(self, VAR_2, VAR_12, VAR_4=None):...\n"", ""VAR_53 = ['ping6' if VAR_12.ipv6 else 'ping']\n"", ""if VAR_12.alot:\n"", ""VAR_15 = 20\n"", ""VAR_15 = 5\n"", ""VAR_53.append('-c{0:d}'.format(VAR_15))\n"", ""VAR_45 = subprocess.Popen(VAR_53 + self.pingargs + [VAR_12.host], stderr=\n    subprocess.PIPE, VAR_66=subprocess.PIPE)\n"", ""VAR_54, VAR_55 = VAR_45.communicate()\n"", ""if VAR_45.wait() != 0:\n"", ""VAR_96 = VAR_55.decode().strip()\n"", ""VAR_97 = VAR_54.decode().strip().split('\\n')\n"", ""if not VAR_96:\n"", ""VAR_98 = self.packetline.match(VAR_97[3])\n"", ""self.reply(VAR_2, 'unknown error, timeout/blocked?')\n"", ""self.reply(VAR_2, 'error: {0}'.format(VAR_96))\n"", ""VAR_99 = self.rttline.match(VAR_97[4])\n"", ""if not VAR_98 or not VAR_99:\n"", ""self.reply(VAR_2,\n    'unknown error, unable to parse ping output, dumping to stdout')\n"", ""VAR_98 = VAR_98.groups()\n"", ""print(VAR_54.decode())\n"", ""VAR_99 = VAR_99.group(1).split('/')\n"", ""VAR_96 = 'string'.format(VAR_11=args.host, sent=int(packetinfo[0]), recv=\n    int(packetinfo[1]), loss=int(packetinfo[3]), rttmin=rttinfo[0], rttavg=\n    rttinfo[1], rttmax=rttinfo[2], rttmdev=rttinfo[3], time=int(packetinfo[4]))\n"", ""self.reply(VAR_2, 'malformatted ping output, dumping to stdout')\n"", ""self.reply(VAR_2, VAR_96)\n"", ""print(VAR_54.decode())\n"", ""return\n""]",1
"[""@VAR_0.inclusion_tag('exercise/_user_toc.html', takes_context=True)...\n"", ""return FUNC_2(VAR_1, VAR_2)\n""]",0
"[""def FUNC_1():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = {}\n"", ""for arg in request.args:\n"", ""VAR_8 = re.findall('page_(.*)', arg)\n"", ""return VAR_5\n"", ""if VAR_8:\n"", ""VAR_5[VAR_8[0]] = int(request.args.get(arg))\n""]",0
"[""def FUNC_9(self, VAR_9, VAR_11=None):...\n"", ""VAR_1 = get_and_check_project(VAR_9, VAR_11, ('change_project',))\n"", ""VAR_27 = [VAR_35 for filesList in map(lambda key: VAR_9.FILES.getlist(key),\n    [keys for keys in VAR_9.FILES]) for VAR_35 in filesList]\n"", ""VAR_28 = models.Task.create_from_images(VAR_27, VAR_1)\n"", ""if VAR_28 is not None:\n"", ""return Response({'id': VAR_28.id}, status=status.HTTP_201_CREATED)\n""]",0
"[""def FUNC_34(self, VAR_64):...\n"", ""return CLASS_1(VAR_64)\n""]",0
"[""def FUNC_6(self, VAR_2):...\n"", ""VAR_7 = self._decompose(VAR_2)\n"", ""if len(VAR_7) > 1:\n"", ""self.cmdqueue.extend(VAR_7[1:])\n"", ""return VAR_7[0]\n""]",1
"[""def FUNC_2(VAR_87):...\n"", ""return map(self._rules.__getitem__, filter(self.is_rule, VAR_87))\n""]",0
"[""def FUNC_4(self):...\n"", ""VAR_1 = self.c.get('/find/?q=terro')\n"", ""self.assertNotContains(VAR_1, '<table')\n"", ""self.assertContains(VAR_1, '<div class=\""results-wrapper\"">')\n""]",0
"[""def FUNC_1(VAR_3, VAR_4, VAR_5):...\n"", ""return {'tilejson': '2.1.0', 'name': VAR_3, 'version': '1.0.0', 'scheme':\n    'tms', 'tiles': VAR_4, 'minzoom': 0, 'maxzoom': 22, 'bounds': VAR_5}\n""]",0
"[""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.stderr_interceptor.read_all()\n"", ""return ''\n""]",1
"[""@rest_utils.ajax(data_required=True)...\n"", ""\""\""\""docstring\""\""\""\n"", ""if 'public_key' in VAR_1.DATA:\n"", ""VAR_22 = api.nova.keypair_import(VAR_1, VAR_1.DATA['name'], VAR_1.DATA[\n    'public_key'])\n"", ""VAR_22 = api.nova.keypair_create(VAR_1, VAR_1.DATA['name'])\n"", ""return rest_utils.CreatedResponse('/api/nova/keypairs/%s' % utils_http.\n    urlquote(VAR_22.name), VAR_22.to_dict())\n""]",0
"[""def FUNC_3(VAR_0):...\n"", ""VAR_2 = []\n"", ""VAR_5 = {}\n"", ""VAR_6 = 's.transaction_date' if VAR_0['based_on'\n    ] == 'Sales Order' else 's.posting_date'\n"", ""VAR_7 = frappe.db.sql('string'.format(VAR_6=date_field, doctype=filters[\n    'based_on']), as_dict=1)\n"", ""for d in VAR_7:\n"", ""VAR_5.setdefault(d.item_name, d)\n"", ""return VAR_5\n""]",1
"[""@VAR_0.route('/fill_null', methods=['POST'])...\n"", ""VAR_1 = get_dataset_with_id(request.args.get('dataset_id'))\n"", ""VAR_17 = request.form['column']\n"", ""VAR_18 = VAR_17[:VAR_17.find(' ')]\n"", ""VAR_19 = VAR_17[VAR_17.find('(') + 1:VAR_17.rfind(')')]\n"", ""VAR_20 = request.form['fill_value']\n"", ""if VAR_20 == '~option-average~':\n"", ""flash('An unexpected error occured while performing the operation', 'danger')\n"", ""flash('Fill operation completed successfully', 'success')\n"", ""if VAR_19 not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n"", ""if VAR_20 == '~option-median~':\n"", ""return redirect(request.referrer)\n"", ""flash('Operation not supported for this column type.', 'danger')\n"", ""fill_null_with_average(VAR_1.working_copy, VAR_18)\n"", ""if VAR_19 not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n"", ""VAR_25 = VAR_19 in ['TEXT', 'VARCHAR(10)', 'VARCHAR(25)', 'VARCHAR(255)']\n"", ""create_action('Filled null values in {0} with average'.format(VAR_18),\n    VAR_1.id, current_user.id)\n"", ""flash('Operation not supported for this column type.', 'danger')\n"", ""fill_null_with_median(VAR_1.working_copy, VAR_18)\n"", ""fill_null_with(VAR_1.working_copy, VAR_18, VAR_20, VAR_25)\n"", ""create_action('Filled null values in {0} with median'.format(VAR_18), VAR_1\n    .id, current_user.id)\n"", ""create_action('Filled null values in {0} with {1}'.format(VAR_18, VAR_20),\n    VAR_1.id, current_user.id)\n""]",0
"[""import datetime\n"", ""from django.core.exceptions import FieldDoesNotExist\n"", ""from django.db.models import BooleanField, ForeignKey\n"", ""from django.utils.formats import localize\n"", ""from django.utils.html import format_html, escape\n"", ""from django.utils.http import urlencode\n"", ""from django.utils.translation import gettext_lazy as _\n"", ""from typing import List\n"", ""from smart_lists.exceptions import SmartListException\n"", ""from smart_lists.filters import SmartListFilter\n"", ""def FUNC_0(self):...\n"", ""if self.label:\n"", ""return self.label\n"", ""if self.model_field:\n"", ""return self.model_field.verbose_name.title()\n"", ""if self.field_name == '__str__':\n"", ""return self.model._meta.verbose_name.title()\n"", ""VAR_10 = getattr(self.model, self.field_name)\n"", ""return self.field_name.title()\n"", ""if callable(VAR_10) and getattr(VAR_10, 'short_description', False):\n"", ""return VAR_10.short_description\n"", ""return self.field_name.replace('_', ' ').title()\n""]",0
"[""def FUNC_3(self, VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = sqlite3.connect(self.filename)\n"", ""VAR_15 = VAR_14.execute(VAR_7)\n"", ""VAR_4 = [i for i in VAR_15]\n"", ""VAR_14.commit()\n"", ""VAR_14.close()\n"", ""return VAR_4\n""]",1
"[""def FUNC_1(self):...\n"", ""self.assertTrue(self.client.login(VAR_8='autotest', VAR_9='password'))\n""]",1
"[""import os\n"", ""import six\n"", ""import testtools\n"", ""from bandit.core import config as b_config\n"", ""from bandit.core import constants as C\n"", ""from bandit.core import manager as b_manager\n"", ""from bandit.core import metrics\n"", ""from bandit.core import test_set as b_test_set\n"", ""\""\""\""string\""\""\""\n"", ""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""VAR_3 = os.path.join(os.getcwd(), 'bandit', 'plugins')\n"", ""VAR_4 = b_config.BanditConfig()\n"", ""self.b_mgr = b_manager.BanditManager(VAR_4, 'file')\n"", ""self.b_mgr.b_conf._settings['plugins_dir'] = VAR_3\n"", ""self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n"", ""def FUNC_1(self, VAR_0, VAR_1=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = os.path.join(os.getcwd(), 'examples', VAR_0)\n"", ""self.b_mgr.ignore_nosec = VAR_1\n"", ""self.b_mgr.discover_files([VAR_3], True)\n"", ""self.b_mgr.run_tests()\n"", ""def FUNC_2(self, VAR_0, VAR_2, VAR_1=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.b_mgr.scores = []\n"", ""self.run_example(VAR_0, VAR_1=ignore_nosec)\n"", ""VAR_5 = 0\n"", ""VAR_6 = 0\n"", ""for test_scores in self.b_mgr.scores:\n"", ""for score_type in test_scores:\n"", ""self.assertEqual(VAR_5, VAR_6)\n"", ""self.assertIn(score_type, VAR_2)\n"", ""def FUNC_3(self, VAR_0, VAR_2):...\n"", ""for rating in VAR_2[score_type]:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 += VAR_2[score_type][rating] * C.RANKING_VALUES[rating]\n"", ""VAR_6 += sum(test_scores[score_type])\n"", ""self.b_mgr.metrics = metrics.Metrics()\n"", ""self.b_mgr.scores = []\n"", ""self.run_example(VAR_0)\n"", ""VAR_7 = self.b_mgr.metrics.data\n"", ""for k in VAR_2:\n"", ""if k != 'issues':\n"", ""if 'issues' in VAR_2:\n"", ""self.assertEqual(VAR_2[k], VAR_7['_totals'][k])\n"", ""for criteria, default in C.CRITERIA:\n"", ""def FUNC_4(self):...\n"", ""for rank in C.RANKING:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_15 = '{0}.{1}'.format(criteria, rank)\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n"", ""VAR_5 = 0\n"", ""self.check_example('binding.py', VAR_2)\n"", ""if VAR_2['issues'].get(criteria, None).get(rank, None):\n"", ""def FUNC_5(self):...\n"", ""VAR_5 = VAR_2['issues'][criteria][rank]\n"", ""self.assertEqual(VAR_5, VAR_7['_totals'][VAR_15])\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('crypto-md5.py', VAR_2)\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 13}, 'CONFIDENCE': {'HIGH': 13}}\n"", ""self.check_example('ciphers.py', VAR_2)\n"", ""def FUNC_7(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('cipher-modes.py', VAR_2)\n"", ""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('eval.py', VAR_2)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('mark_safe.py', VAR_2)\n"", ""def FUNC_10(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = 'exec-{}.py'\n"", ""if six.PY2:\n"", ""VAR_8 = VAR_8.format('py2')\n"", ""VAR_8 = VAR_8.format('py3')\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example(VAR_8, VAR_2)\n"", ""def FUNC_11(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n"", ""self.check_example('exec-as-root.py', VAR_2)\n"", ""def FUNC_12(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n"", ""self.check_example('hardcoded-passwords.py', VAR_2)\n"", ""def FUNC_13(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('hardcoded-tmp.py', VAR_2)\n"", ""def FUNC_14(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('httplib_https.py', VAR_2)\n"", ""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0}, 'CONFIDENCE': {\n    'HIGH': 9}}\n"", ""self.check_example('imports-aliases.py', VAR_2)\n"", ""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('imports-from.py', VAR_2)\n"", ""def FUNC_17(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('imports-function.py', VAR_2)\n"", ""def FUNC_18(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('telnetlib.py', VAR_2)\n"", ""def FUNC_19(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('ftplib.py', VAR_2)\n"", ""def FUNC_20(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('imports.py', VAR_2)\n"", ""def FUNC_21(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n"", ""self.check_example('mktemp.py', VAR_2)\n"", ""def FUNC_22(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.run_example('nonsense.py')\n"", ""self.assertEqual(1, len(self.b_mgr.skipped))\n"", ""def FUNC_23(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {}, 'CONFIDENCE': {}}\n"", ""self.check_example('okay.py', VAR_2)\n"", ""def FUNC_24(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = 'os-chmod-{}.py'\n"", ""if six.PY2:\n"", ""VAR_8 = VAR_8.format('py2')\n"", ""VAR_8 = VAR_8.format('py3')\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2, 'HIGH': 8}, 'CONFIDENCE': {'MEDIUM': 1,\n    'HIGH': 9}}\n"", ""self.check_example(VAR_8, VAR_2)\n"", ""def FUNC_25(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n"", ""self.check_example('os-exec.py', VAR_2)\n"", ""def FUNC_26(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1}, 'CONFIDENCE': {\n    'HIGH': 9}}\n"", ""self.check_example('os-popen.py', VAR_2)\n"", ""def FUNC_27(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n"", ""self.check_example('os-spawn.py', VAR_2)\n"", ""def FUNC_28(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('os-startfile.py', VAR_2)\n"", ""def FUNC_29(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('os_system.py', VAR_2)\n"", ""def FUNC_30(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'MEDIUM': 6}, 'CONFIDENCE': {'HIGH': 8}}\n"", ""self.check_example('pickle_deserialize.py', VAR_2)\n"", ""def FUNC_31(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('popen_wrappers.py', VAR_2)\n"", ""def FUNC_32(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n"", ""self.check_example('random_module.py', VAR_2)\n"", ""def FUNC_33(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('requests-ssl-verify-disabled.py', VAR_2)\n"", ""def FUNC_34(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n"", ""self.check_example('skip.py', VAR_2)\n"", ""def FUNC_35(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n"", ""self.check_example('skip.py', VAR_2, VAR_1=True)\n"", ""def FUNC_36(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 12}, 'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}\n"", ""self.check_example('sql_statements.py', VAR_2)\n"", ""def FUNC_37(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7}, 'CONFIDENCE': {\n    'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}}\n"", ""self.check_example('ssl-insecure-version.py', VAR_2)\n"", ""def FUNC_38(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14}, 'CONFIDENCE': {\n    'HIGH': 17, 'LOW': 1}}\n"", ""self.check_example('subprocess_shell.py', VAR_2)\n"", ""def FUNC_39(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n"", ""self.check_example('urlopen.py', VAR_2)\n"", ""def FUNC_40(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n"", ""self.check_example('utils-shell.py', VAR_2)\n"", ""def FUNC_41(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10}, 'CONFIDENCE': {\n    'MEDIUM': 5, 'HIGH': 9}}\n"", ""self.check_example('wildcard-injection.py', VAR_2)\n"", ""def FUNC_42(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('yaml_load.py', VAR_2)\n"", ""def FUNC_43(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 4}, 'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n"", ""self.check_example('jinja2_templating.py', VAR_2)\n"", ""def FUNC_44(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'MEDIUM': 2}, 'CONFIDENCE': {'MEDIUM': 3}}\n"", ""self.check_example('secret-config-option.py', VAR_2)\n"", ""def FUNC_45(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('mako_templating.py', VAR_2)\n"", ""def FUNC_46(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 4}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 4}}\n"", ""self.check_example('xml_etree_celementtree.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_expatbuilder.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3, 'HIGH': 1}, 'CONFIDENCE': {'HIGH': 3,\n    'MEDIUM': 1}}\n"", ""self.check_example('xml_lxml.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_pulldom.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('xml_xmlrpc.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 4}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 4}}\n"", ""self.check_example('xml_etree_elementtree.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1, 'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1,\n    'MEDIUM': 1}}\n"", ""self.check_example('xml_expatreader.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 2}}\n"", ""self.check_example('xml_minidom.py', VAR_2)\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2, 'HIGH': 6}, 'CONFIDENCE': {'HIGH': 2,\n    'MEDIUM': 6}}\n"", ""self.check_example('xml_sax.py', VAR_2)\n"", ""def FUNC_47(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('httpoxy_cgihandler.py', VAR_2)\n"", ""self.check_example('httpoxy_twisted_script.py', VAR_2)\n"", ""self.check_example('httpoxy_twisted_directory.py', VAR_2)\n"", ""def FUNC_48(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('assert.py', VAR_2)\n"", ""def FUNC_49(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'MEDIUM': 2}}\n"", ""self.check_example('paramiko_injection.py', VAR_2)\n"", ""def FUNC_50(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('partial_path_process.py', VAR_2)\n"", ""def FUNC_51(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = next(x for x in self.b_mgr.b_ts.tests['ExceptHandler'] if x.\n    __name__ == 'try_except_continue')\n"", ""VAR_9._config = {'check_typed_exception': True}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('try_except_continue.py', VAR_2)\n"", ""VAR_9._config = {'check_typed_exception': False}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('try_except_continue.py', VAR_2)\n"", ""def FUNC_52(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = next(x for x in self.b_mgr.b_ts.tests['ExceptHandler'] if x.\n    __name__ == 'try_except_pass')\n"", ""VAR_9._config = {'check_typed_exception': True}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n"", ""self.check_example('try_except_pass.py', VAR_2)\n"", ""VAR_9._config = {'check_typed_exception': False}\n"", ""VAR_2 = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('try_except_pass.py', VAR_2)\n"", ""def FUNC_53(self):...\n"", ""VAR_2 = {'nosec': 2, 'loc': 7, 'issues': {'CONFIDENCE': {'HIGH': 5},\n    'SEVERITY': {'LOW': 5}}}\n"", ""self.check_metrics('skip.py', VAR_2)\n"", ""VAR_2 = {'nosec': 0, 'loc': 4, 'issues': {'CONFIDENCE': {'HIGH': 2},\n    'SEVERITY': {'LOW': 2}}}\n"", ""self.check_metrics('imports.py', VAR_2)\n"", ""def FUNC_54(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 8, 'HIGH': 6}, 'CONFIDENCE': {'HIGH': 14}}\n"", ""self.check_example('weak_cryptographic_key_sizes.py', VAR_2)\n"", ""def FUNC_55(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.run_example('multiline_statement.py')\n"", ""self.assertEqual(0, len(self.b_mgr.skipped))\n"", ""self.assertEqual(1, len(self.b_mgr.files_list))\n"", ""self.assertTrue(self.b_mgr.files_list[0].endswith('multiline_statement.py'))\n"", ""VAR_10 = self.b_mgr.get_issue_list()\n"", ""self.assertEqual(2, len(VAR_10))\n"", ""self.assertTrue(VAR_10[0].fname.endswith('examples/multiline_statement.py'))\n"", ""self.assertEqual(1, VAR_10[0].lineno)\n"", ""self.assertEqual(list(range(1, 3)), VAR_10[0].linerange)\n"", ""self.assertIn('subprocess', VAR_10[0].get_code())\n"", ""self.assertEqual(5, VAR_10[1].lineno)\n"", ""self.assertEqual(list(range(3, 6 + 1)), VAR_10[1].linerange)\n"", ""self.assertIn('shell=True', VAR_10[1].get_code())\n"", ""def FUNC_56(self):...\n"", ""self.run_example('binding.py')\n"", ""VAR_10 = self.b_mgr.get_issue_list()\n"", ""VAR_11 = VAR_10[0].get_code().splitlines()\n"", ""VAR_12 = VAR_10[0].lineno\n"", ""self.assertEqual('%i ' % (VAR_12 - 1), VAR_11[0][:2])\n"", ""self.assertEqual('%i ' % VAR_12, VAR_11[1][:2])\n"", ""self.assertEqual('%i ' % (VAR_12 + 1), VAR_11[2][:2])\n"", ""def FUNC_57(self):...\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n"", ""self.check_example('flask_debug.py', VAR_2)\n"", ""def FUNC_58(self):...\n"", ""VAR_2 = {'SEVERITY': {}, 'CONFIDENCE': {}}\n"", ""self.check_example('nosec.py', VAR_2)\n"", ""def FUNC_59(self):...\n"", ""VAR_13 = 'string'\n"", ""VAR_14 = 'string' % (os.getcwd(), VAR_13)\n"", ""self.b_mgr.populate_baseline(VAR_14)\n"", ""self.run_example('flask_debug.py')\n"", ""self.assertEqual(1, len(self.b_mgr.baseline))\n"", ""self.assertEqual({}, self.b_mgr.get_issue_list())\n"", ""def FUNC_60(self):...\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('input.py', VAR_2)\n""]",1
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._device_class\n""]",0
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return CLASS_1(self.nodes[:])\n""]",1
"[""@app.route('/players/<int:player_id>/achievements')...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = db.connection.cursor(db.pymysql.cursors.DictCursor)\n"", ""VAR_11.execute('string' % VAR_2)\n"", ""return flask.jsonify(items=cursor.fetchall())\n""]",1
"[""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps', HTTP_X_DEIS_VERSION=__version__.rsplit\n    ('.', 1)[0])\n"", ""self.assertEqual(VAR_1.status_code, 200)\n""]",1
"[""def FUNC_1(VAR_1):...\n"", ""VAR_6 = VAR_5.mogrify(\n    'SELECT * FROM articles WHERE index IN %s ORDER BY last_submitted DESC',\n    (tuple(VAR_1),))\n"", ""VAR_5.execute(VAR_6)\n"", ""VAR_19 = VAR_5.fetchall()\n"", ""return VAR_19\n""]",0
"[""from odoo import models\n"", ""from odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins\n"", ""\""\""\""string\""\""\""\n"", ""VAR_0 = 'crapo.business.object'\n"", ""VAR_1 = ['mail.thread', 'mail.activity.mixin']\n"", ""VAR_2 = \""\""\""\n    An object on which to  in a workflow, specific to a given model\n    \""\""\""\n"", ""VAR_3 = ''\n""]",1
"[""@VAR_2.route('/')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_5 = request.args.get('tag', default='christmasmike')\n"", ""VAR_7 = get_web(VAR_0=db)\n"", ""return render_template('libraries/html/web.html', VAR_7=data, VAR_5=tag)\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.translation import gettext as _, gettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def __init__(self, VAR_25, VAR_10):...\n"", ""self.flag = VAR_25\n"", ""def FUNC_2():...\n"", ""super(CLASS_6, self).__init__(slideParser.parse(VAR_10, slideLexer))\n"", ""CLASS_2.parsingQ.insert(0, FUNC_2)\n""]",1
"[""def __bool__(self):...\n"", ""return bool(self.updated_input or self.missing_output or self.forced or\n    self.updated_input_run or self.noio or self.nooutput)\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_28, VAR_27 in zip(self.output, self.rule.output):\n"", ""if VAR_28 in self.dynamic_output:\n"", ""VAR_29 = self.expand_dynamic(VAR_27, VAR_13=self.wildcards, VAR_14=_IOFile.\n    dynamic_fill)\n"", ""yield VAR_28\n"", ""if not VAR_29:\n"", ""yield VAR_27\n"", ""for VAR_28, _ in VAR_29:\n"", ""yield IOFile(VAR_28, self.rule)\n""]",1
"[""def __init__(self, VAR_23, VAR_24):...\n"", ""self.base = VAR_23\n"", ""self.redirections = VAR_24\n""]",0
"[""@VAR_0.route('/css/<path:filename>')...\n"", ""return send_from_directory('css', VAR_5)\n""]",1
"[""def FUNC_12():...\n"", ""VAR_18 = requests.get(FUNC_2('healthy'))\n"", ""VAR_18.raise_for_status()\n"", ""return VAR_18.json()\n""]",1
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""def FUNC_0(self, VAR_0, VAR_1, VAR_2, VAR_3):...\n"", ""if not hasattr(VAR_0, 'kbsite'):\n"", ""return None\n"", ""VAR_7 = VAR_0.kbsite\n"", ""if VAR_7.is_active:\n"", ""return None\n"", ""if self._path_allowed(VAR_0.path):\n"", ""return None\n"", ""if VAR_0.user.is_staff or VAR_0.user.is_superuser:\n"", ""return None\n"", ""return HttpResponse('Site temporarily unavailable', status=503)\n""]",1
"[""def FUNC_13(self, VAR_11, VAR_12, VAR_13, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_31 = 'createhost -iscsi -persona %s -domain %s %s %s' % (VAR_14, VAR_13,\n    VAR_11, VAR_12)\n"", ""VAR_32 = self.common._cli_run(VAR_31, None)\n"", ""if VAR_32 and len(VAR_32) > 1:\n"", ""return self.common.parse_create_host_error(VAR_11, VAR_32)\n"", ""return VAR_11\n""]",1
"[""def FUNC_12(self):...\n"", ""VAR_20 = open(VAR_2, 'r')\n"", ""VAR_22 = VAR_20.read()\n"", ""VAR_20.close()\n"", ""return VAR_22\n""]",0
"[""def FUNC_17(self, VAR_20=None, VAR_21=None, VAR_1=None, VAR_22=0, VAR_23=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = FUNC_0(VAR_1)\n"", ""VAR_59 = ''\n"", ""if VAR_23:\n"", ""VAR_23 = [('*' if c == 'Default' else c) for c in VAR_23]\n"", ""if VAR_22:\n"", ""VAR_59 = \"" AND (CATEGORY = '\""\n"", ""VAR_59 += ' AND STATUS = \""Failed\""'\n"", ""VAR_60 = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n"", ""VAR_59 += \""' OR CATEGORY = '\"".join(VAR_23)\n"", ""VAR_61 = self.execute(VAR_60 + VAR_59, (VAR_1,))\n"", ""VAR_59 += \""' )\""\n"", ""VAR_62 = -1\n"", ""if VAR_61:\n"", ""if not VAR_20:\n"", ""VAR_62 = self.c.fetchone().get('COUNT(*)')\n"", ""VAR_20 = 0\n"", ""if not VAR_21:\n"", ""VAR_21 = VAR_62\n"", ""VAR_58 = VAR_1, VAR_20, VAR_21\n"", ""VAR_60 = 'SELECT * FROM history WHERE name LIKE ?'\n"", ""VAR_57 = self.execute(VAR_60 + VAR_59 +\n    ' ORDER BY completed desc LIMIT ?, ?', VAR_58)\n"", ""if VAR_57:\n"", ""VAR_64 = self.c.fetchall()\n"", ""VAR_64 = []\n"", ""VAR_63 = len(VAR_64)\n"", ""VAR_64 = [FUNC_3(VAR_11) for VAR_11 in VAR_64]\n"", ""return VAR_64, VAR_63, VAR_62\n""]",1
"[""def FUNC_4(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = jc.Contract()\n"", ""return st.OperationContract(self.agent.make_delete_app_operation(VAR_1=self\n    .bindings, application=self.TEST_APP), VAR_5=contract)\n""]",0
"[""def FUNC_10(self, VAR_16):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = ['volume', 'select', VAR_16['name'], 'show']\n"", ""self._eql_execute(*VAR_11)\n"", ""if err.stdout.find('does not exist.\\n') > -1:\n"", ""VAR_0.debug(_('Volume %s does not exist, it may have already been deleted'),\n    VAR_16['name'])\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_1 = self.c.get('/find/?q=diatom')\n"", ""self.assertContains(VAR_1, 'Filter by Group Type')\n"", ""VAR_1 = self.c.get('/find/?q=diatom&group_type=Unidentified')\n"", ""self.assertContains(VAR_1, 'Showing 1 - 20 of')\n"", ""VAR_1 = self.c.get('/find/?q=diatom&group_type=BadGroupName')\n"", ""self.assertContains(VAR_1, 'Sorry, no result found')\n""]",1
"[""def FUNC_35(VAR_29):...\n"", ""VAR_40 = VAR_29.group('name')\n"", ""VAR_16 = VAR_11[VAR_40]\n"", ""if VAR_15:\n"", ""if VAR_13 and VAR_16 == VAR_14:\n"", ""return '{{{}}}'.format(VAR_40)\n"", ""if VAR_12:\n"", ""return str(VAR_16)\n"", ""return VAR_14\n""]",0
"[""import json\n"", ""from django.http import JsonResponse\n"", ""from django.shortcuts import redirect\n"", ""from django.views.decorators.csrf import csrf_exempt\n"", ""from django.views.decorators.http import require_http_methods\n"", ""from cuckoo.common.config import config\n"", ""from cuckoo.core.submit import SubmitManager\n"", ""from cuckoo.web.bin.utils import api_post, JsonSerialize, json_error_response\n"", ""VAR_0 = SubmitManager()\n"", ""def FUNC_0():...\n"", ""VAR_1 = config('cuckoo:cuckoo:machinery')\n"", ""if config('routing:vpn:enabled'):\n"", ""VAR_4 = config('routing:vpn:vpns')\n"", ""VAR_4 = []\n"", ""return {'machine': config('%s:%s:machines' % (VAR_1, VAR_1)), 'package':\n    None, 'priority': 2, 'timeout': config('cuckoo:timeouts:default'),\n    'routing': {'route': config('routing:routing:route'), 'inetsim': config\n    ('routing:inetsim:enabled'), 'tor': config('routing:tor:enabled'),\n    'vpns': VAR_4}, 'options': {'enable-services': False, 'enforce-timeout':\n    False, 'full-memory-dump': config('cuckoo:cuckoo:memory_dump'),\n    'no-injection': False, 'process-memory-dump': True,\n    'simulated-human-interaction': True}}\n""]",0
"[""@VAR_1.route('/new_franchise/<lat>/<lng>')...\n"", """"]",0
"[""from __future__ import absolute_import\n"", ""from __future__ import division\n"", ""from __future__ import print_function\n"", ""import argparse\n"", ""import logging\n"", ""import os\n"", ""import redis\n"", ""import time\n"", ""import ray.ray_constants as ray_constants\n"", ""from ray.services import get_ip_address\n"", ""from ray.services import get_port\n"", ""import ray.utils\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.node_ip_address = VAR_3\n"", ""self.redis_client = redis.StrictRedis(host=redis_ip_address, port=\n    redis_port, password=redis_password)\n"", ""self.log_files = {}\n"", ""self.log_file_handles = {}\n"", ""self.files_to_ignore = set()\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = len(self.log_files)\n"", ""VAR_9 = self.redis_client.lrange('LOG_FILENAMES:{}'.format(self.\n    node_ip_address), VAR_8, -1)\n"", ""for VAR_10 in VAR_9:\n"", ""VAR_0.info('Beginning to track file {}'.format(VAR_10))\n"", ""def FUNC_1(self):...\n"", ""assert VAR_10 not in self.log_files\n"", ""\""\""\""docstring\""\""\""\n"", ""self.log_files[VAR_10] = []\n"", ""for VAR_10 in self.log_files:\n"", ""if VAR_10 in self.log_file_handles:\n"", ""def FUNC_2(self):...\n"", ""VAR_11 = []\n"", ""if VAR_10 in self.files_to_ignore:\n"", ""\""\""\""docstring\""\""\""\n"", ""while True:\n"", ""self.log_file_handles[VAR_10] = open(VAR_10, 'r')\n"", ""if e.errno == os.errno.EMFILE:\n"", ""while True:\n"", ""VAR_12 = self.log_file_handles[VAR_10].tell()\n"", ""VAR_0.warning('Warning: Ignoring {} because there are too many open files.'\n    .format(VAR_10))\n"", ""if e.errno == os.errno.ENOENT:\n"", ""self.update_log_filenames()\n"", ""VAR_13 = self.log_file_handles[VAR_10].readline()\n"", ""self.files_to_ignore.add(VAR_10)\n"", ""VAR_0.warning('Warning: The file {} was not found.'.format(VAR_10))\n"", ""self.check_log_files_and_push_updates()\n"", ""if VAR_13 != '':\n"", ""time.sleep(1)\n"", ""VAR_11.append(VAR_13)\n"", ""self.log_file_handles[VAR_10].seek(VAR_12)\n"", ""if len(VAR_11) > 0:\n"", ""self.log_files[VAR_10] += VAR_11\n"", ""VAR_14 = 'LOGFILE:{}:{}'.format(self.node_ip_address, ray.utils.decode(VAR_10))\n"", ""self.redis_client.rpush(VAR_14, *VAR_11)\n""]",1
"[""def __str__(self):...\n"", ""return 'Could not post ad.\\n' + super().__str__()\n""]",1
"[""def FUNC_3(self, VAR_8, VAR_9, VAR_10, VAR_11):...\n"", ""VAR_14 = ('string' + VAR_8 + \""', '\"" + VAR_9 + \""', '\"" + VAR_10 + \""', '\"" +\n    VAR_11 + \""', '0', '0')\"")\n"", ""self.cursor.execute(VAR_14)\n"", ""self.connection.commit()\n""]",1
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = jc.Contract()\n"", ""return st.OperationContract(self.agent.make_create_app_operation(VAR_1=self\n    .bindings, application=self.TEST_APP), VAR_6=contract)\n""]",0
"[""def FUNC_15(VAR_1, VAR_2, VAR_13, VAR_14, VAR_15):...\n"", ""\""\""\""docstring\""\""\""\n"", ""flash('Authorization with remote service failed.')\n"", ""return redirect('/')\n""]",0
"[""def FUNC_15(self, VAR_0, VAR_1, VAR_10, VAR_3=None):...\n"", ""if not VAR_3:\n"", ""VAR_3 = self.make_reqid()\n"", ""VAR_8 = [VAR_0, VAR_1, make_auth_hash(VAR_0, VAR_1, VAR_3, VAR_10)]\n"", ""return b'Router', b'auth-request', VAR_8, VAR_3\n""]",0
"[""def FUNC_0(self, VAR_49, VAR_48=None, VAR_50=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_43 = None\n"", ""VAR_57 = None\n"", ""VAR_55 = None\n"", ""if VAR_49 in self.conf:\n"", ""if 'playbook' in self.conf[VAR_49]:\n"", ""if VAR_43 is None:\n"", ""VAR_43 = self.conf[VAR_49]['playbook']\n"", ""if 'log_file' in self.conf[VAR_49]:\n"", ""VAR_43 = self.conf['playbook']\n"", ""if VAR_55 is None and VAR_55 in self.conf:\n"", ""VAR_57 = self.conf[VAR_49]['log_file']\n"", ""if 'template' in self.conf[VAR_49]:\n"", ""VAR_55 = self.conf['template']\n"", ""if VAR_57 is None:\n"", ""VAR_55 = self.conf[VAR_49]['template']\n"", ""if 'log_file' in self.conf:\n"", ""if VAR_55:\n"", ""VAR_57 = self.conf['log_file']\n"", ""VAR_57 = open(os.devnull, 'w')\n"", ""open(VAR_43, 'w').write(self.generate_ansible_playbook_from_template(VAR_55,\n    VAR_48))\n"", ""VAR_58 = CLASS_1(VAR_43=playbook, VAR_1=0)\n"", ""VAR_59 = VAR_58.run(VAR_45=context.last_job_id)\n""]",0
"[""def __init__(self):...\n"", ""self.content = VAR_2\n""]",0
"[""def FUNC_4(self, VAR_1, VAR_4, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.cursor.execute('UPDATE {0} SET {1} WHERE {2}'.format(VAR_1, VAR_4, VAR_3))\n"", ""print('Erro: {}'.format(error))\n"", ""self.__connection.commit()\n"", ""return self.cursor\n""]",1
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""def FUNC_0(*VAR_0, **VAR_1):...\n"", ""def FUNC_5(VAR_12):...\n"", ""def FUNC_9(self, *VAR_15, **VAR_75):...\n"", ""for validator in VAR_0:\n"", ""if VAR_102.method == 'POST' and hasattr(self, 'ajax_login_redirect'):\n"", ""return FUNC_9\n"", ""validator(VAR_75)\n"", ""VAR_16 = self.build_arg_list(VAR_12, VAR_75)\n"", ""return self.ajax_login_redirect('/')\n"", ""return self.intermediate_redirect('/login')\n"", ""for VAR_110, validator in VAR_1.iteritems():\n"", ""VAR_16[VAR_110] = validator(VAR_75)\n"", ""return VAR_12(self, *VAR_15, **kw)\n""]",0
"[""def FUNC_4():...\n"", ""VAR_15 = argparse.ArgumentParser(description=\n    'Grade student code against given test cases. Results will be written over stdout in JSON'\n    )\n"", ""VAR_15.add_argument('-n', '--name', required=True, help=\n    'The name of the function the student was supposed to implement')\n"", ""VAR_15.add_argument('-p', '--points', type=int, default=0, help=\n    'The number of points this question is worth. This argument is only used when -c is passed, and defaults to 0'\n    )\n"", ""VAR_15.add_argument('-c', '--code', help=\n    \""The student's code submission. Make sure to carefully escape this argument as a single string. If this argument is ommitted then this program just checks the validity of the test cases. The exit status indicates the validity of the cases\""\n    )\n"", ""VAR_15.add_argument('-t', '--test_case', required=True, action='append',\n    help=\n    \""The test cases to run the students code against. Each test case must take the form of of a function call without the function name followed by a comparison to a return value. For example ``(1, 2) == 3'' or ``(1, 2, (3, 4), *[5, 6], last=8) == None''\""\n    )\n"", ""VAR_15.add_argument('-v', '--verbose', action='count', default=0, help=\n    'Specifies verbositiy level. Each time this flag is specified, the count goes up by one. Level 1 or greater outputs additional information about exceptions that occur'\n    )\n"", ""VAR_16 = VAR_15.parse_args()\n"", ""VAR_10 = VAR_16.verbose\n"", ""VAR_8 = VAR_16.name\n"", ""if not VAR_8.isidentifier() or keyword.iskeyword(VAR_8):\n"", ""VAR_9 = []\n"", ""for i, VAR_19 in enumerate(VAR_16.test_case):\n"", ""VAR_19 = VAR_8 + VAR_19\n"", ""VAR_5 = VAR_16.code\n"", ""VAR_22 = ast.parse(VAR_19, mode='eval')\n"", ""if VAR_10 >= 1:\n"", ""if not VAR_22:\n"", ""if not VAR_5:\n"", ""print(repr(e), file=sys.stderr)\n"", ""VAR_22 = None\n"", ""VAR_18 = False\n"", ""return\n"", ""VAR_3 = []\n"", ""if type(VAR_22) == ast.Expression:\n"", ""VAR_17 = None\n"", ""VAR_23 = VAR_22.body\n"", ""if not VAR_18:\n"", ""while not VAR_17:\n"", ""if type(VAR_23) == ast.Compare and len(VAR_23.ops) == len(VAR_23.comparators\n"", ""VAR_24 = compile(VAR_22, '<unknown>', 'eval')\n"", ""if VAR_10 >= 1:\n"", ""if not VAR_24:\n"", ""if not VAR_17:\n"", ""VAR_17 = ast.parse(VAR_5)\n"", ""VAR_28 = FUNC_2(VAR_5, se)\n"", ""VAR_25 = VAR_23.left\n"", ""print(repr(e), file=sys.stderr)\n"", ""VAR_24 = None\n"", ""VAR_9.append(VAR_24)\n"", ""FUNC_0(VAR_16.points, VAR_3)\n"", ""VAR_18 = False\n"", ""if not VAR_28:\n"", ""VAR_26 = VAR_23.comparators[0]\n"", ""return\n"", ""if type(VAR_17) == ast.Module and len(VAR_17.body) == 1:\n"", ""if VAR_10 >= 1:\n"", ""VAR_5 = VAR_28\n"", ""VAR_27 = False\n"", ""VAR_20 = VAR_17.body[0]\n"", ""if not VAR_18:\n"", ""print(repr(se), file=sys.stderr)\n"", ""FUNC_1(VAR_3, VAR_16.points, 'syntax error')\n"", ""if VAR_10 >= 1:\n"", ""if type(VAR_25) == ast.Call:\n"", ""if type(VAR_20) in [ast.FunctionDef, ast.AsyncFunctionDef]:\n"", ""FUNC_1(VAR_3, VAR_16.points, 'not just a single function definition')\n"", ""VAR_7 = compile(VAR_17, '<unknown>', 'exec')\n"", ""if VAR_10 >= 1:\n"", ""if not VAR_7:\n"", ""print(repr(e), file=sys.stderr)\n"", ""FUNC_1(VAR_3, VAR_16.points, 'failed to parse code')\n"", ""if type(VAR_25.func) == ast.Name and VAR_25.func.id == VAR_8:\n"", ""if VAR_27:\n"", ""if VAR_20.name != VAR_8:\n"", ""FUNC_0(VAR_16.points, VAR_3)\n"", ""print(repr(e), file=sys.stderr)\n"", ""VAR_7 = None\n"", ""FUNC_1(VAR_3, VAR_16.points, 'failed to compile code')\n"", ""VAR_3 += FUNC_3(VAR_7, VAR_8, VAR_16.points, VAR_9, VAR_10)\n"", ""VAR_27 = True\n"", ""if type(VAR_26) in [ast.Num, ast.Str, ast.Bytes, ast.NameConstant, ast.Dict,\n"", ""VAR_20.name = VAR_8\n"", ""VAR_18 = True\n"", ""return\n"", ""FUNC_0(VAR_16.points, VAR_3)\n"", ""FUNC_0(VAR_16.points, VAR_3)\n"", ""VAR_18 = True\n"", ""FUNC_1(VAR_3, 1, 'misnamed function')\n"", ""return\n""]",0
"[""@pytest.mark.skip(reason='not handled yet')...\n"", ""FUNC_2(VAR_2)\n"", ""FUNC_3(VAR_2, 'DYMOND', VAR_7='1')\n"", ""FUNC_5(VAR_4, VAR_5, VAR_11='DIAMOND', VAR_10=[{'name': 'DYMOND'}])\n""]",0
"[""def FUNC_2(VAR_6, VAR_7):...\n"", ""VAR_8 = VAR_1 and VAR_2\n"", ""VAR_9 = 'SELECT COALESCE(COUNT(' + VAR_0 + '.' + VAR_3 + '), 0) FROM ' + VAR_0\n"", ""if VAR_8:\n"", ""VAR_9 += ' LEFT JOIN ' + VAR_1\n"", ""VAR_9 += ' WHERE (' + VAR_0 + '.' + VAR_3 + ' = :x'\n"", ""if VAR_8:\n"", ""VAR_9 += ' AND ' + VAR_1 + '.id = ' + str(VAR_6[VAR_2].data)\n"", ""VAR_9 += ');'\n"", ""VAR_10 = text(VAR_9)\n"", ""VAR_11 = db.engine.execute(VAR_10, x=field.data)\n"", ""for row in VAR_11:\n"", ""if row[0] > 0:\n""]",1
"[""def FUNC_2():...\n"", ""super(CLASS_8, self).__init__(slideParser.parse(VAR_10, slideLexer),\n    '\\\\footnote[frame]{', '}')\n""]",1
"[""def FUNC_4(VAR_9):...\n"", ""VAR_9.cmd('send-keys', '', 'C-c')\n"", ""VAR_9.kill_window()\n""]",0
"[""def __init__(self, VAR_10, VAR_11):...\n"", ""self.__class__.count += 1\n"", ""self.__class__.todo.append(self)\n"", ""from beamr.interpreters import Config\n"", ""VAR_21 = ''\n"", ""VAR_22 = self.__class__.count\n"", ""while VAR_22:\n"", ""VAR_21 += chr(64 + VAR_22 % 27)\n"", ""self.insertCmd = VAR_31.get('vbtmCmds', 'insertion')(VAR_21)\n"", ""VAR_22 //= 27\n"", ""self.head = VAR_10\n"", ""self.body = VAR_11\n"", ""super(CLASS_10, self).__init__(self.insertCmd)\n""]",1
"[""def FUNC_9(self, VAR_10):...\n"", ""self.path = Urtext.get_path(self.view.window())\n"", ""self.errors = []\n"", ""self.visited_files = []\n"", ""self.backward_visited_files = []\n"", ""self.tree = Node(self.view.file_name())\n"", ""VAR_28 = Urtext.UrtextFile(os.path.join(self.path, self.view.file_name()))\n"", ""VAR_29 = CLASS_1(os.path.join(self.path, VAR_28.filename))\n"", ""self.build_node_tree(VAR_29.get_tag('title')[0] + ' -> ' + VAR_28.filename)\n"", ""self.build_backward_node_tree(VAR_29.get_tag('title')[0] + ' -> ' + VAR_28.\n    filename)\n"", ""VAR_23 = self.view.window()\n"", ""VAR_23.focus_group(0)\n"", ""VAR_24 = self.view.window().new_file()\n"", ""VAR_22 = ''\n"", ""for pre, fill, node in RenderTree(self.backward_tree):\n"", ""VAR_22 += '%s%s' % (pre, node.name) + '\\n'\n"", ""VAR_22 = VAR_22.replace('', '')\n"", ""VAR_22 = VAR_22.split('\\n')\n"", ""VAR_22 = VAR_22[1:]\n"", ""VAR_30 = ''\n"", ""for index in range(len(VAR_22)):\n"", ""VAR_30 += VAR_22[len(VAR_22) - 1 - index] + '\\n'\n"", ""VAR_30 = ''.join(VAR_30)\n"", ""VAR_24.run_command('insert_snippet', {'contents': VAR_30})\n"", ""VAR_24.run_command('insert_snippet', {'contents': '\\n'.join(self.errors)})\n"", ""VAR_22 = ''\n"", ""for pre, fill, node in RenderTree(self.tree):\n"", ""VAR_22 += '%s%s' % (pre, node.name) + '\\n'\n"", ""VAR_24.run_command('insert_snippet', {'contents': VAR_22})\n"", ""VAR_24.run_command('insert_snippet', {'contents': '\\n'.join(self.errors)})\n"", ""VAR_24.set_scratch(True)\n""]",1
"[""def FUNC_16():...\n"", ""VAR_19.join(timeout=self._connecttimeout)\n"", ""if VAR_19.is_alive():\n"", ""warnings.warn('timed out waiting for connection')\n"", ""if self._session is None:\n"", ""VAR_22 = 'unable to connect after {} secs'.format(self._connecttimeout)\n"", ""if self._run_server_ex is None:\n"", ""VAR_22 = VAR_22 + os.linesep + self._run_server_ex\n""]",0
"[""__author__ = 'Johannes Kster'\n"", ""__copyright__ = 'Copyright 2015, Johannes Kster'\n"", ""__email__ = 'koester@jimmy.harvard.edu'\n"", ""__license__ = 'MIT'\n"", ""import re\n"", ""import os\n"", ""import sys\n"", ""import signal\n"", ""import json\n"", ""import urllib\n"", ""from collections import OrderedDict\n"", ""from itertools import filterfalse, chain\n"", ""from functools import partial\n"", ""from operator import attrgetter\n"", ""from snakemake.logging import logger, format_resources, format_resource_names\n"", ""from snakemake.rules import Rule, Ruleorder\n"", ""from snakemake.exceptions import RuleException, CreateRuleException, UnknownRuleException, NoRulesException, print_exception, WorkflowError\n"", ""from snakemake.shell import shell\n"", ""from snakemake.dag import DAG\n"", ""from snakemake.scheduler import JobScheduler\n"", ""from snakemake.parser import parse\n"", ""import snakemake.io\n"", ""from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch\n"", ""from snakemake.persistence import Persistence\n"", ""from snakemake.utils import update_config\n"", ""def __init__(self, VAR_1=None, VAR_2=None, VAR_3=None, VAR_4=None, VAR_5=...\n"", ""\""\""\""docstring\""\""\""\n"", ""self._rules = OrderedDict()\n"", ""self.first_rule = None\n"", ""self._workdir = None\n"", ""self.overwrite_workdir = VAR_6\n"", ""self.workdir_init = os.path.abspath(os.curdir)\n"", ""self._ruleorder = Ruleorder()\n"", ""self._localrules = set()\n"", ""self.linemaps = dict()\n"", ""self.rule_count = 0\n"", ""self.basedir = os.path.dirname(VAR_1)\n"", ""self.snakefile = os.path.abspath(VAR_1)\n"", ""self.snakemakepath = VAR_2\n"", ""self.included = []\n"", ""self.included_stack = []\n"", ""self.jobscript = VAR_3\n"", ""self.persistence = None\n"", ""self.global_resources = None\n"", ""self.globals = globals()\n"", ""self._subworkflows = dict()\n"", ""self.overwrite_shellcmd = VAR_4\n"", ""self.overwrite_config = VAR_5\n"", ""self.overwrite_configfile = VAR_7\n"", ""self.config_args = VAR_8\n"", ""self._onsuccess = lambda log: None\n"", ""self._onerror = lambda log: None\n"", ""self.debug = VAR_9\n"", ""VAR_85 = dict()\n"", ""VAR_85.update(self.overwrite_config)\n"", ""VAR_86 = CLASS_3()\n"", ""@property...\n"", ""return self._subworkflows.values()\n""]",1
"[""def FUNC_2(VAR_0, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = 'string'.format(VAR_3)\n"", ""VAR_6 = FUNC_3(VAR_0, VAR_4)\n"", ""if VAR_6 is not None:\n"", ""VAR_8 = open('error_report.txt', 'w')\n"", ""return False\n"", ""for row in VAR_6:\n"", ""VAR_8.write('{} - {}% errors \\n'.format(row[0], row[1]))\n"", ""VAR_8.close()\n"", ""return True\n""]",1
"[""def FUNC_15():...\n"", ""if VAR_14 not in self._timers:\n"", ""return\n"", ""self._timers.remove(VAR_14)\n"", ""VAR_10()\n"", ""logging.exception('Timer callback failed')\n""]",0
"[""@property...\n"", ""if self._hosts is None:\n"", ""self._hosts = set(self.hosts)\n"", ""return self._hosts\n""]",0
"[""def FUNC_24(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_17 = []\n"", ""for VAR_7, VAR_12 in self.all_processes.items():\n"", ""for VAR_16 in VAR_12:\n"", ""return VAR_17\n"", ""if VAR_16.process.poll() is not None:\n"", ""VAR_17.append((VAR_7, VAR_16.process))\n""]",0
"[""@staticmethod...\n"", ""return users.create_login_url(VAR_23)\n""]",0
"[""def FUNC_7(self):...\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndRaise(urllib2.URLError('url'))\n"", ""time.sleep(mox.IgnoreArg())\n"", ""VAR_2 = 'True'\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(url_helper.UrlOpen('url', max_tries=2), VAR_2)\n"", ""self._mox.VerifyAll()\n""]",1
"[""def FUNC_4(VAR_9, VAR_2):...\n"", ""return VAR_9 not in VAR_10 and helpers.convert(VAR_2[VAR_9][0])[0\n    ] == 'JUMPDEST'\n""]",0
"[""from __future__ import unicode_literals\n"", ""import frappe, json\n"", ""from frappe.utils import cstr, unique\n"", ""from frappe import _\n"", ""from six import string_types\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_12 = ['select', 'delete', 'drop', 'update', 'case', 'and', 'or', 'like']\n"", ""def FUNC_6():...\n"", ""VAR_13.throw(_('Invalid Search Field'), VAR_13.DataError)\n"", ""if len(VAR_0) >= 3:\n"", ""if '=' in VAR_0:\n"", ""@VAR_13.whitelist()...\n"", ""FUNC_6()\n"", ""if ' --' in VAR_0:\n"", ""FUNC_2(VAR_1, VAR_2, VAR_3, VAR_0=searchfield, VAR_5=page_length, VAR_4=filters\n    )\n"", ""FUNC_6()\n"", ""if any(' {0} '.format(keyword) in VAR_0.split() for keyword in VAR_12):\n"", ""VAR_13.response['results'] = FUNC_4(VAR_13.response['values'])\n"", ""FUNC_6()\n"", ""if any(keyword in VAR_0.split() for keyword in VAR_12):\n"", ""@VAR_13.whitelist()...\n"", ""FUNC_6()\n"", ""if isinstance(VAR_4, string_types):\n"", ""VAR_4 = json.loads(VAR_4)\n"", ""VAR_9 = VAR_13.get_meta(VAR_1)\n"", ""if VAR_0:\n"", ""FUNC_0(VAR_0)\n"", ""if not VAR_0:\n"", ""VAR_0 = 'name'\n"", ""VAR_14 = VAR_13.get_hooks().standard_queries or {}\n"", ""if VAR_3 and VAR_3.split()[0].lower() != 'select':\n"", ""VAR_13.response['values'] = VAR_13.call(VAR_3, VAR_1, VAR_2, VAR_0, VAR_6,\n    VAR_5, VAR_4, VAR_8=as_dict)\n"", ""if not VAR_3 and VAR_1 in VAR_14:\n"", ""def FUNC_3(VAR_9, VAR_10):...\n"", ""FUNC_2(VAR_1, VAR_2, VAR_14[VAR_1][0], VAR_0, VAR_6, VAR_5, VAR_4)\n"", ""if VAR_3:\n"", ""VAR_15 = VAR_9.search_fields and VAR_9.search_fields.split(',') or []\n"", ""VAR_13.throw(_('This query style is discontinued'))\n"", ""if isinstance(VAR_4, dict):\n"", ""VAR_16 = [VAR_9.title_field\n    ] if VAR_9.title_field and VAR_9.title_field not in VAR_15 else []\n"", ""VAR_25 = VAR_4.items()\n"", ""if VAR_4 == None:\n"", ""VAR_15 = ['name'] + VAR_15 + VAR_16\n"", ""VAR_4 = []\n"", ""VAR_4 = []\n"", ""VAR_19 = []\n"", ""if not VAR_10 in VAR_15:\n"", ""for f in VAR_25:\n"", ""if VAR_2:\n"", ""VAR_15 = VAR_15 + [VAR_10]\n"", ""return VAR_15\n"", ""if isinstance(f[1], (list, tuple)):\n"", ""VAR_26 = ['name']\n"", ""if VAR_9.get('fields', {'fieldname': 'enabled', 'fieldtype': 'Check'}):\n"", ""VAR_4.append([VAR_1, f[0], f[1][0], f[1][1]])\n"", ""VAR_4.append([VAR_1, f[0], '=', f[1]])\n"", ""if VAR_9.title_field:\n"", ""VAR_4.append([VAR_1, 'enabled', '=', 1])\n"", ""if VAR_9.get('fields', {'fieldname': 'disabled', 'fieldtype': 'Check'}):\n"", ""VAR_26.append(VAR_9.title_field)\n"", ""if VAR_9.search_fields:\n"", ""VAR_4.append([VAR_1, 'disabled', '!=', 1])\n"", ""VAR_20 = FUNC_3(VAR_9, VAR_0 or 'name')\n"", ""VAR_26.extend(VAR_9.get_search_fields())\n"", ""for f in VAR_26:\n"", ""if VAR_7:\n"", ""VAR_27 = VAR_9.get_field(f.strip())\n"", ""VAR_20 = list(set(VAR_20 + json.loads(VAR_7)))\n"", ""VAR_21 = [('`tab%s`.`%s`' % (VAR_9.name, f.strip())) for f in VAR_20]\n"", ""if f == 'name' or VAR_27 and VAR_27.fieldtype in ['Data', 'Text',\n"", ""VAR_21.append('locate(\""{_txt}\"", `tab{doctype}`.`name`) as `_relevance`'.\n    format(_txt=frappe.db.escape((txt or '').replace('%', '')), VAR_1=\n    frappe.db.escape(doctype)))\n"", ""VAR_19.append([VAR_1, f.strip(), 'like', '%{0}%'.format(VAR_2)])\n"", ""from frappe.model.db_query import get_order_by\n"", ""VAR_22 = get_order_by(VAR_1, VAR_9)\n"", ""VAR_23 = 'if(_relevance, _relevance, 99999), `tab{0}`.idx desc, {1}'.format(\n    VAR_1, VAR_22)\n"", ""VAR_24 = VAR_13.get_list(VAR_1, VAR_4=filters, VAR_20=formatted_fields,\n    VAR_19=or_filters, limit_start=start, limit_page_length=page_length,\n    VAR_23=order_by, ignore_permissions=True if doctype == 'DocType' else \n    False, as_list=not as_dict)\n"", ""if VAR_8:\n"", ""for r in VAR_24:\n"", ""VAR_13.response['values'] = [r[:-1] for r in VAR_24]\n"", ""r.pop('_relevance')\n"", ""VAR_13.response['values'] = VAR_24\n""]",1
"[""def FUNC_10(VAR_6, VAR_7, VAR_9):...\n"", ""VAR_12 = f\""\""\""\n            UPDATE {VAR_1}\n            SET quantity = {VAR_9}\n            WHERE user_id = {VAR_6} AND product_id = {VAR_7};\n            \""\""\""\n"", ""VAR_14 = create_connection()\n"", ""VAR_14.close()\n"", ""VAR_15 = VAR_14.cursor()\n"", ""VAR_15.execute(VAR_12)\n"", ""VAR_14.commit()\n"", ""return 'Ok'\n""]",1
"[""@VAR_0.route('/about')...\n"", ""return render_template('about.html')\n""]",0
"[""def FUNC_17(self, *VAR_67):...\n"", ""self._ruleorder.add(*VAR_67)\n""]",0
"[""def FUNC_15(self, VAR_14):...\n"", """"]",0
"[""def FUNC_12(self, VAR_1, VAR_62=False, VAR_63=False, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not urllib.parse.urlparse(VAR_1).scheme:\n"", ""if not os.path.isabs(VAR_1) and self.included_stack:\n"", ""if VAR_1 in self.included:\n"", ""VAR_108 = os.path.dirname(self.included_stack[-1])\n"", ""VAR_1 = os.path.abspath(VAR_1)\n"", ""logger.info('Multiple include of {} ignored'.format(VAR_1))\n"", ""self.included.append(VAR_1)\n"", ""VAR_1 = os.path.join(VAR_108, VAR_1)\n"", ""return\n"", ""self.included_stack.append(VAR_1)\n"", ""VAR_83 = self\n"", ""VAR_96 = self.first_rule\n"", ""VAR_97, VAR_98 = parse(VAR_1, VAR_4=self.overwrite_shellcmd)\n"", ""if VAR_63:\n"", ""print(VAR_97)\n"", ""sys.path.insert(0, os.path.dirname(VAR_1))\n"", ""self.linemaps[VAR_1] = VAR_98\n"", ""exec(compile(VAR_97, VAR_1, 'exec'), self.globals)\n"", ""if not VAR_62:\n"", ""self.first_rule = VAR_96\n"", ""self.included_stack.pop()\n""]",0
"[""@rest_utils.ajax()...\n"", ""\""\""\""docstring\""\""\""\n"", ""return api.nova.flavor_get_extras(VAR_1, VAR_5, raw=True)\n""]",0
"[""def FUNC_6(self, VAR_9, VAR_10=[]):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = []\n"", ""VAR_21 = 'https://www.kijiji.ca/p-upload-image.html'\n"", ""for img_file in VAR_10:\n"", ""for i in range(0, 3):\n"", ""return [image for image in VAR_20 if image is not None]\n"", ""VAR_32 = {'file': img_file}\n"", ""VAR_33 = self.session.post(VAR_21, VAR_32=files, headers={\n    'x-ebay-box-token': token})\n"", ""if VAR_33.status_code != 200:\n"", ""print(VAR_33.status_code)\n"", ""VAR_34 = json.loads(VAR_33.text)\n"", ""print('Image Upload failed on try #{}'.format(i + 1))\n"", ""VAR_35 = VAR_34['thumbnailUrl']\n"", ""print('Image Upload success on try #{}'.format(i + 1))\n"", ""VAR_20.append(VAR_35)\n""]",1
"[""@app.route('/api/uploads/<sid>/logs')...\n"", ""if '/' not in VAR_0:\n"", ""VAR_4 = os.path.join(app.config['UPLOAD_FOLDER'], VAR_0)\n"", ""abort(403)\n"", ""if os.path.isfile(os.path.join(VAR_4, app.config['LOG_FILE'])):\n"", ""return send_from_directory(directory=path, filename=app.config['LOG_FILE'])\n"", ""abort(404)\n""]",1
"[""def FUNC_6(self, VAR_5):...\n"", ""VAR_14 = ('select name,password,email,country from users where userid=%d;' %\n    VAR_5)\n"", ""VAR_16 = sql.queryDB(self.conn, VAR_14)\n"", ""return VAR_16\n""]",1
"[""def FUNC_12(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""VAR_1 = {'name': self.volume_name}\n"", ""self.driver._eql_execute('volume', 'select', VAR_1['name'], 'access',\n    'delete', '1')\n"", ""self.mox.ReplayAll()\n"", ""self.driver.terminate_connection(VAR_1, self.connector)\n""]",0
"[""def FUNC_1(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n""]",1
"[""def FUNC_6():...\n"", ""if not request.method in VAR_0:\n"", ""return True\n"", ""if not request.environ.get('AUTH_TYPE') == 'cookie':\n"", ""return True\n"", ""if config.get('skip_authentication'):\n"", ""return True\n"", ""if request.environ.get('HTTP_REFERER'):\n"", ""VAR_7 = urlparse(request.environ.get('HTTP_REFERER'))\n"", ""if request.method == 'GET' and FUNC_4():\n"", ""VAR_8 = VAR_7.hostname\n"", ""return True\n"", ""return False\n"", ""if VAR_7.port:\n"", ""VAR_8 += ':' + str(VAR_7.port)\n"", ""if VAR_8.endswith(request.environ['adhocracy.domain']):\n"", ""if request.method != 'GET':\n"", ""return True\n""]",1
"[""def FUNC_0(self):...\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('2', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput(None, '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput(None, None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput('a', '1', '100'))\n""]",0
"[""def FUNC_33(self):...\n"", ""self.assertEqual(self.cursor.rowcount, -1)\n"", ""self.cursor.execute('create table t1(i int)')\n"", ""VAR_26 = 4\n"", ""for i in range(VAR_26):\n"", ""self.cursor.execute('insert into t1 values (?)', i)\n"", ""self.cursor.execute('delete from t1')\n"", ""self.assertEqual(self.cursor.rowcount, VAR_26)\n""]",0
"[""def FUNC_0(self, VAR_0, VAR_1, VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = CLASS_0(VAR_0, VAR_1, VAR_2)\n"", ""self.nodes.append(VAR_4)\n""]",1
"[""def FUNC_1(VAR_8):...\n"", ""VAR_9 = FUNC_2()\n"", ""VAR_10 = VAR_9.cursor()\n"", ""VAR_10.execute(\n    \""INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\"".\n    format(VAR_8=name))\n"", ""VAR_9.commit()\n"", ""VAR_9.close()\n""]",1
"[""def FUNC_0(VAR_4):...\n"", ""VAR_10 = (VAR_4['page'] - 1) * VAR_4['perPage']\n"", ""VAR_11 = f\""\""\""string{VAR_0} AS p INNER JOIN {VAR_1} AS pt ON\n            p.product_type_id=pt.id\n            WHERE p.rating >= {VAR_4['rating']}\n            ORDER BY p.id LIMIT {VAR_10}, {VAR_4['perPage']}\n            \""\""\""\n"", ""VAR_12 = create_connection()\n"", ""VAR_12.close()\n"", ""VAR_13 = VAR_12.cursor()\n"", ""VAR_13.execute(VAR_11)\n"", ""return VAR_13.fetchall()\n""]",1
"[""@VAR_2.route('/data/platform/')...\n"", ""VAR_38 = request.args.get('platform')\n"", ""VAR_39 = request.args.get('build_system_type')\n"", ""VAR_24, VAR_23 = FUNC_4(request.args)\n"", ""VAR_40 = 'platform: %s startDate: %s endDate: %s' % (VAR_38, VAR_24.\n    strftime('%Y-%m-%d'), VAR_23.strftime('%Y-%m-%d'))\n"", ""VAR_2.logger.debug(VAR_40)\n"", ""VAR_28 = FUNC_0()\n"", ""VAR_32 = VAR_28.cursor()\n"", ""VAR_41 = 'string' % (VAR_38, VAR_24, VAR_23, VAR_39)\n"", ""VAR_32.execute(VAR_41)\n"", ""VAR_42 = VAR_32.fetchall()\n"", ""VAR_43 = []\n"", ""VAR_44 = {}\n"", ""VAR_6 = []\n"", ""VAR_34 = 'green orange blue red'.split()\n"", ""VAR_35 = {VAR_26: (0) for VAR_26 in VAR_34}\n"", ""for cset in VAR_42:\n"", ""VAR_17 = cset[0]\n"", ""VAR_32.close()\n"", ""VAR_68 = CLASS_0(VAR_17)\n"", ""VAR_28.close()\n"", ""VAR_41 = 'string' % (VAR_38, VAR_17, VAR_39)\n"", ""VAR_45 = sorted(VAR_44.keys())\n"", ""VAR_32.execute(VAR_41)\n"", ""VAR_45 += ['total', 'percentage']\n"", ""VAR_69 = VAR_32.fetchall()\n"", ""VAR_46 = Counter()\n"", ""for res, testtype, VAR_52 in VAR_69:\n"", ""VAR_47 = {}\n"", ""VAR_84 = VAR_44.setdefault(testtype, VAR_35.copy())\n"", ""VAR_43.append(VAR_68)\n"", ""for test in VAR_44:\n"", ""if res == 'success':\n"", ""VAR_46.update(VAR_44[test])\n"", ""VAR_48 = sum(VAR_46.values())\n"", ""VAR_68.green[testtype] += 1\n"", ""if res == 'testfailed':\n"", ""for VAR_70 in VAR_46:\n"", ""VAR_84['green'] += 1\n"", ""VAR_68.orange[testtype] += 1\n"", ""if res == 'retry':\n"", ""VAR_47[VAR_70] = round(100.0 * VAR_46[VAR_70] / VAR_48, 2)\n"", ""VAR_49 = FUNC_6(VAR_10=total['green'], VAR_11=total['blue'], VAR_12=test_count)\n"", ""VAR_6.append(VAR_52)\n"", ""VAR_84['orange'] += 1\n"", ""VAR_68.blue[testtype] += 1\n"", ""if res == 'exception' or res == 'busted':\n"", ""VAR_44['total'] = VAR_46\n"", ""VAR_84['blue'] += 1\n"", ""VAR_68.red[testtype] += 1\n"", ""if res == 'usercancel':\n"", ""VAR_44['percentage'] = VAR_47\n"", ""VAR_84['red'] += 1\n"", ""VAR_2.logger.debug('usercancel')\n"", ""VAR_2.logger.debug('UNRECOGNIZED RESULT: %s' % res)\n"", ""return {'testTypes': VAR_45, 'byRevision': VAR_43, 'byTest': VAR_44,\n    'failRates': VAR_49, 'dates': FUNC_3(VAR_6)}\n""]",1
"[""def FUNC_4(self, VAR_2):...\n"", ""if self == VAR_2:\n"", ""if VAR_2 not in self.child_groups:\n"", ""self.child_groups.append(VAR_2)\n"", ""VAR_2.depth = max([self.depth + 1, VAR_2.depth])\n"", ""VAR_2._check_children_depth()\n"", ""if self.name not in [VAR_12.name for VAR_12 in VAR_2.parent_groups]:\n"", ""VAR_2.parent_groups.append(self)\n"", ""self.clear_hosts_cache()\n"", ""for h in VAR_2.get_hosts():\n"", ""h.populate_ancestors()\n""]",1
"[""\""\""\""\nDjango settings for the Deis project.\n\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""import os.path\n"", ""import sys\n"", ""import tempfile\n"", ""VAR_0 = os.path.normpath(os.path.join(os.path.dirname(__file__), '..'))\n"", ""VAR_1 = False\n"", ""VAR_2 = VAR_1\n"", ""VAR_3 = ()\n"", ""VAR_4 = VAR_3\n"", ""VAR_5 = 60 * 3\n"", ""VAR_6 = ['localhost']\n"", ""VAR_7 = 'America/Denver'\n"", ""VAR_8 = 'en-us'\n"", ""VAR_9 = 1\n"", ""VAR_10 = True\n"", ""VAR_11 = True\n"", ""VAR_12 = True\n"", ""VAR_13 = ''\n"", ""VAR_14 = ''\n"", ""VAR_15 = os.path.abspath(os.path.join(__file__, '..', '..', 'static'))\n"", ""VAR_16 = '/static/'\n"", ""VAR_17 = ()\n"", ""VAR_18 = ('django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder')\n"", ""VAR_19 = None\n"", ""VAR_20 = ('django.template.loaders.filesystem.Loader',\n    'django.template.loaders.app_directories.Loader')\n"", ""VAR_21 = ('django.contrib.auth.context_processors.auth',\n    'django.core.context_processors.debug',\n    'django.core.context_processors.i18n',\n    'django.core.context_processors.media',\n    'django.core.context_processors.request',\n    'django.core.context_processors.static',\n    'django.core.context_processors.tz',\n    'django.contrib.messages.context_processors.messages',\n    'deis.context_processors.site')\n"", ""VAR_22 = ('django.middleware.common.CommonMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'api.middleware.VersionMiddleware')\n"", ""VAR_23 = 'deis.urls'\n"", ""VAR_24 = 'deis.wsgi.application'\n"", ""VAR_25 = VAR_0 + '/web/templates',\n"", ""VAR_26 = ('django.contrib.admin', 'django.contrib.auth',\n    'django.contrib.contenttypes', 'django.contrib.humanize',\n    'django.contrib.messages', 'django.contrib.sessions',\n    'django.contrib.sites', 'django.contrib.staticfiles', 'django_fsm',\n    'guardian', 'json_field', 'gunicorn', 'rest_framework', 'south', 'api',\n    'web')\n"", ""VAR_27 = ('django.contrib.auth.backends.ModelBackend',\n    'guardian.backends.ObjectPermissionBackend')\n"", ""VAR_28 = -1\n"", ""VAR_29 = True\n"", ""VAR_30 = 'none'\n"", ""VAR_31 = True\n"", ""VAR_32 = ['system']\n"", ""VAR_33 = '/api/auth/login/'\n"", ""VAR_34 = '/'\n"", ""VAR_35 = False\n"", ""VAR_36 = {'DEFAULT_MODEL_SERIALIZER_CLASS':\n    'rest_framework.serializers.ModelSerializer',\n    'DEFAULT_PERMISSION_CLASSES': (\n    'rest_framework.permissions.IsAuthenticated',),\n    'DEFAULT_AUTHENTICATION_CLASSES': (\n    'rest_framework.authentication.SessionAuthentication',), 'PAGINATE_BY': 100\n    }\n"", ""VAR_37 = False\n"", ""if os.path.exists('/dev/log'):\n"", ""VAR_62 = '/dev/log'\n"", ""if os.path.exists('/var/log/syslog'):\n"", ""VAR_38 = {'version': 1, 'disable_existing_loggers': False, 'formatters': {\n    'verbose': {'format':\n    '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'\n    }, 'simple': {'format': '%(levelname)s %(message)s'}}, 'filters': {\n    'require_debug_false': {'()': 'django.utils.log.RequireDebugFalse'}},\n    'handlers': {'null': {'level': 'DEBUG', 'class': 'logging.NullHandler'},\n    'console': {'level': 'DEBUG', 'class': 'logging.StreamHandler',\n    'formatter': 'simple'}, 'mail_admins': {'level': 'ERROR', 'filters': [\n    'require_debug_false'], 'class': 'django.utils.log.AdminEmailHandler'},\n    'rsyslog': {'class': 'logging.handlers.SysLogHandler', 'address':\n    VAR_62, 'facility': 'local0'}}, 'loggers': {'django': {'handlers': [\n    'null'], 'level': 'INFO', 'propagate': True}, 'django.request': {\n    'handlers': ['console', 'mail_admins'], 'level': 'WARNING', 'propagate':\n    True}, 'api': {'handlers': ['console', 'mail_admins', 'rsyslog'],\n    'level': 'INFO', 'propagate': True}}}\n"", ""VAR_62 = '/var/log/syslog'\n"", ""VAR_62 = 'localhost', 514\n"", ""VAR_39 = 'api.tests.SilentDjangoTestSuiteRunner'\n"", ""VAR_40, VAR_41 = os.environ.get('ETCD', '127.0.0.1:4001').split(',')[0].split(\n    ':')\n"", ""VAR_42 = os.path.abspath(os.path.join(__file__, '..', '..', 'logs'))\n"", ""VAR_43 = 1000\n"", ""VAR_44 = tempfile.mkdtemp(prefix='deis')\n"", ""VAR_45 = 'deis/helloworld'\n"", ""VAR_46 = 'deisapp.local'\n"", ""VAR_47 = 'mock'\n"", ""VAR_48 = ''\n"", ""VAR_49 = ''\n"", ""VAR_50 = {}\n"", ""VAR_51 = ''\n"", ""VAR_19 = os.environ.get('DEIS_SECRET_KEY',\n    'CHANGEME_sapm$s%upvsw5l_zuy_&29rkywd^78ff(qi')\n"", ""VAR_52 = os.environ.get('DEIS_BUILDER_KEY',\n    'CHANGEME_sapm$s%upvsw5l_zuy_&29rkywd^78ff(qi')\n"", ""VAR_53 = 'registry.mock'\n"", ""VAR_54 = 'http://localhost:5000'\n"", ""VAR_55 = 'localhost'\n"", ""VAR_56 = 5000\n"", ""VAR_57 = True\n"", ""VAR_58 = False\n"", ""VAR_59 = {'default': {'ENGINE': 'django.db.backends.' + os.environ.get(\n    'DATABASE_ENGINE', 'postgresql_psycopg2'), 'NAME': os.environ.get(\n    'DATABASE_NAME', 'deis')}}\n"", ""VAR_60 = '[a-z0-9-]+'\n"", ""VAR_6 = ['*']\n"", ""VAR_61 = 'HTTP_X_FORWARDED_PROTO', 'https'\n"", ""from .local_settings import *\n"", ""if os.path.exists('/templates/confd_settings.py'):\n"", ""sys.path.append('/templates')\n"", ""from confd_settings import *\n""]",1
"[""def FUNC_16(self, VAR_12):...\n"", ""VAR_32 = []\n"", ""print(VAR_12)\n"", ""VAR_27 = VAR_12.name.split('->')[1].strip()\n"", ""print(VAR_27)\n"", ""VAR_31 = self.get_links_to_file(VAR_27)\n"", ""for VAR_39 in VAR_31:\n"", ""print(VAR_39)\n"", ""if VAR_39 in self.visited_files:\n"", ""VAR_40 = CLASS_1(os.path.join(self.path, VAR_39))\n"", ""self.backward_visited_files.append(VAR_39)\n"", ""VAR_41 = Node(' ... ' + VAR_40.get_tag('title')[0] + ' -> ' + VAR_39,\n    VAR_12=parent)\n"", ""self.visited_files.append(VAR_39)\n"", ""VAR_39 = VAR_39.split('/')[-1]\n"", ""VAR_40 = CLASS_1(os.path.join(self.path, VAR_39))\n"", ""VAR_41 = Node(VAR_40.get_tag('title')[0] + ' -> ' + VAR_39, VAR_12=parent)\n"", ""self.add_backward_children(VAR_41)\n""]",1
"[""@VAR_0.route('/log/<filename>')...\n"", ""return send_from_directory(VAR_1, VAR_4)\n""]",0
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import lib.models\n"", ""import colorfield.fields\n"", ""VAR_0 = [('userprofile', '0003_auto_20160728_1139'), ('course',\n    '0028_auto_20160825_0601')]\n"", ""VAR_1 = [migrations.CreateModel(name='UserTag', fields=[('id', models.\n    AutoField(auto_created=True, serialize=False, primary_key=True,\n    verbose_name='ID')), ('name', models.CharField(max_length=200)), (\n    'description', models.CharField(blank=True, max_length=164, help_text=\n    'Describe the usage or meaning of this usertag')), (\n    'visible_to_students', models.BooleanField(default=False)), ('color',\n    colorfield.fields.ColorField(default='#CD0000', help_text=\n    'Color that is used for this tag.', max_length=10)), ('course_instance',\n    models.ForeignKey(related_name='usertags', to='course.CourseInstance'))\n    ], options={}, bases=(lib.models.UrlMixin, models.Model)), migrations.\n    CreateModel(name='UserTagging', fields=[('id', models.AutoField(\n    auto_created=True, serialize=False, primary_key=True, verbose_name='ID'\n    )), ('course_instance', models.ForeignKey(related_name='taggings', to=\n    'course.CourseInstance')), ('tag', models.ForeignKey(related_name=\n    'taggings', to='course.UserTag')), ('user', models.ForeignKey(\n    related_name='taggings', to='userprofile.UserProfile'))], options={},\n    bases=(models.Model,)), migrations.AlterUniqueTogether(name=\n    'usertagging', unique_together=set([('tag', 'user', 'course_instance')]\n    )), migrations.AlterIndexTogether(name='usertagging', index_together=\n    set([('user', 'course_instance')]))]\n""]",1
"[""def FUNC_18(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n"", ""self.check_example('telnetlib.py', VAR_2)\n""]",0
"[""def FUNC_2(VAR_11):...\n"", ""VAR_12 = 'meal_planner.db'\n"", ""VAR_15 = datetime.datetime.now()\n"", ""VAR_16 = datetime.date(VAR_15.year, VAR_15.month, VAR_15.day)\n"", ""VAR_17 = VAR_16.isocalendar()[1]\n"", ""VAR_18 = 'recipes_' + str(VAR_17)\n"", ""VAR_20 = conn.cursor()\n"", ""VAR_20.execute('SELECT recipe FROM ' + VAR_18 + ' WHERE recipe = ' + '\""' +\n    VAR_11 + '\""')\n"", ""VAR_23 = VAR_20.fetchone()\n"", ""if VAR_23:\n"", ""print(VAR_23[0])\n"", ""FUNC_3(VAR_11)\n"", ""messagebox.showerror('Cannot Delete',\n    \""Cannot delete recipe when it's used in the current week's menu.\"")\n""]",1
"[""def FUNC_22(VAR_48):...\n"", ""for VAR_29, VAR_51 in sorted(VAR_48.options.items()):\n"", ""if VAR_51 is None:\n"", ""VAR_46.append('unset(%s CACHE)\\n' % VAR_29)\n"", ""if isinstance(VAR_51, bool):\n"", ""VAR_79 = 'BOOL'\n"", ""VAR_79 = 'STRING'\n"", ""VAR_51 = 'ON' if VAR_51 else 'OFF'\n"", ""VAR_46.append('set(%s %s CACHE INTERNAL \""\"" FORCE)\\n' % (VAR_29, VAR_51))\n""]",0
"[""def FUNC_15(self, VAR_34, VAR_29):...\n"", ""\""\""\""docstring\""\""\""\n""]",0
"[""def __str__(self):...\n"", ""return self.name\n""]",0
"[""@VAR_0.inclusion_tag('news/user_news.html', takes_context=True)...\n"", ""if not 'instance' in VAR_1:\n"", ""if not 'now' in VAR_1:\n"", ""VAR_1['now'] = timezone.now()\n"", ""if not 'course_news' in VAR_1:\n"", ""VAR_1['course_news'] = CachedNews(VAR_1['instance'])\n"", ""VAR_7 = VAR_1['course_news']\n"", ""if VAR_1['is_course_staff']:\n"", ""VAR_9, VAR_7 = VAR_7.for_staff()\n"", ""VAR_10 = VAR_1['request'].user\n"", ""VAR_8 = 0\n"", ""VAR_9, VAR_7 = VAR_7.for_user(not VAR_10.is_authenticated() or VAR_10.\n    userprofile.is_external)\n"", ""for VAR_11 in VAR_7:\n"", ""VAR_8 += 1\n"", ""return {'is_course_staff': VAR_1['is_course_staff'], 'now': VAR_1['now'],\n    'alerts': VAR_9, 'news': VAR_7, 'more': VAR_3}\n"", ""VAR_11['collapsed'] = VAR_8 > VAR_2\n"", ""if VAR_3 > 0 and VAR_8 == VAR_3:\n"", ""VAR_11['begin_more'] = True\n""]",1
"[""@VAR_0.route('/autocomplete', methods=['GET'])...\n"", ""VAR_4 = mysql.get_db()\n"", ""VAR_5 = []\n"", ""VAR_6 = VAR_4.cursor()\n"", ""VAR_6.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_6.fetchall(), VAR_6.description))\n"", ""if len(VAR_5) == 100:\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n"", ""VAR_7 = VAR_4.cursor()\n"", ""VAR_7.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_7.fetchall(), VAR_7.description))\n"", ""if len(VAR_5) == 100:\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n"", ""VAR_8 = VAR_4.cursor()\n"", ""VAR_8.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_8.fetchall(), VAR_8.description))\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n""]",1
"[""__packagename__ = 'dwave-hybrid'\n"", ""__title__ = 'D-Wave Hybrid'\n"", ""__version__ = '0.1.4'\n"", ""__author__ = 'D-Wave Systems Inc.'\n"", ""__authoremail__ = 'radomir@dwavesys.com'\n"", ""__description__ = 'Hybrid Asynchronous Decomposition Solver Framework'\n"", ""__url__ = 'https://github.com/dwavesystems/dwave-hybrid'\n"", ""__license__ = 'Apache 2.0'\n"", ""__copyright__ = '2018, D-Wave Systems Inc.'\n""]",1
"[""def FUNC_0(self, VAR_1: bool) ->bool:...\n"", ""...\n""]",0
"[""from flask import Flask, render_template, request, redirect, url_for, session\n"", ""from flask_bootstrap import Bootstrap\n"", ""from flask_wtf import FlaskForm\n"", ""from flask_login import LoginManager, current_user, login_user, logout_user, UserMixin\n"", ""from werkzeug.security import generate_password_hash, check_password_hash\n"", ""from wtforms import IntegerField, FloatField, DateField, SelectField, SelectMultipleField, FieldList, FormField, StringField, PasswordField, validators\n"", ""from datetime import datetime\n"", ""import os.path\n"", ""import json\n"", ""import redis\n"", ""import re\n"", ""import pprint\n"", ""VAR_0 = pprint.PrettyPrinter(indent=4)\n"", ""VAR_1 = Flask(__name__)\n"", ""VAR_1.config['SECRET_KEY'] = 'secret'\n"", ""VAR_1.jinja_env.filters['json_pretty'] = lambda value: json.dumps(value,\n    sort_keys=True, indent=4)\n"", ""Bootstrap(VAR_1)\n"", ""VAR_2 = redis.Redis('localhost')\n"", ""VAR_5 = ''\n"", ""VAR_3 = ''\n"", ""VAR_12 = ''\n"", ""def FUNC_26(self):...\n"", ""return self.user_id\n""]",1
"[""from engineauth.middleware import AuthMiddleware\n"", ""from engineauth.middleware import EngineAuthRequest\n"", ""from engineauth import models\n"", ""import test_base\n"", ""import webapp2\n"", ""__author__ = 'kyle.finley@gmail.com (Kyle Finley)'\n"", ""VAR_0 = AuthMiddleware(webapp2.WSGIApplication())\n"", ""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""def FUNC_1(self):...\n"", ""from engineauth.strategies.google import GoogleStrategy\n"", ""VAR_1 = VAR_0._load_strategy('google')\n"", ""self.assertEqual(VAR_1, GoogleStrategy)\n"", ""self.assertRaises(Exception, VAR_0._load_strategy, 'enron')\n"", ""from engineauth.strategies.appengine_openid import AppEngineOpenIDStrategy\n"", ""VAR_1 = VAR_0._load_strategy('appengine_openid')\n"", ""self.assertEqual(VAR_1, AppEngineOpenIDStrategy)\n"", ""def FUNC_2(self):...\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 0)\n"", ""VAR_4 = VAR_2._load_session()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 1)\n"", ""def FUNC_3(self):...\n"", ""VAR_5 = models.Session.create()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 1)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2.cookies['_eauth'] = VAR_5.serialize()\n"", ""VAR_2._load_session()\n"", ""self.assertTrue(VAR_2.session.session_id == VAR_5.session_id)\n"", ""VAR_6 = models.Session.query().count()\n"", ""self.assertTrue(VAR_6 == 1)\n"", ""def FUNC_4(self):...\n"", ""VAR_5 = models.Session.create()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 1)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2.cookies['_eauth'] = VAR_5.serialize()\n"", ""VAR_2._load_session()\n"", ""self.assertTrue(VAR_2.session.session_id == VAR_5.session_id)\n"", ""VAR_6 = models.Session.query().count()\n"", ""self.assertTrue(VAR_6 == 1)\n"", ""def FUNC_5(self):...\n"", ""VAR_5 = models.Session.create()\n"", ""VAR_7 = VAR_5.session_id\n"", ""VAR_8 = VAR_5.serialize()\n"", ""VAR_5.key.delete()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 0)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2.cookies['_eauth'] = VAR_8\n"", ""VAR_2._load_session()\n"", ""self.assertTrue(VAR_2.session.session_id != VAR_7)\n"", ""VAR_6 = models.Session.query().count()\n"", ""self.assertTrue(VAR_6 == 1)\n"", ""def FUNC_6(self):...\n"", ""VAR_5 = models.Session.create()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 1)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2.cookies['_eauth'] = VAR_5.serialize()\n"", ""VAR_9 = VAR_2.get_response(VAR_0)\n"", ""VAR_9.request = VAR_2\n"", ""VAR_9._save_session()\n"", ""self.assertTrue(VAR_9.request.session.session_id == VAR_5.session_id)\n"", ""VAR_6 = models.Session.query().count()\n"", ""self.assertTrue(VAR_6 == 1)\n"", ""VAR_9.request.session.user_id = '1'\n"", ""VAR_9._save_session()\n"", ""VAR_3 = models.Session.query().count()\n"", ""self.assertTrue(VAR_3 == 1)\n"", ""VAR_10 = models.Session.query().get()\n"", ""self.assertEqual(VAR_10.key.id(), '1')\n"", ""def FUNC_7(self):...\n"", ""VAR_11 = models.User.create_user('test:12345')\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2._load_session()\n"", ""VAR_2.session.user_id = VAR_11.get_id()\n"", ""VAR_2._load_user()\n"", ""self.assertEqual(VAR_11, VAR_2.user)\n"", ""def FUNC_8(self):...\n"", ""VAR_12 = 'test:12345'\n"", ""VAR_13 = {'auth_id': VAR_12, 'info': {}}\n"", ""VAR_14 = models.UserProfile.get_or_create(VAR_12, VAR_13)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2._load_session()\n"", ""VAR_2._load_user()\n"", ""VAR_15 = models.User.query().count()\n"", ""self.assertEqual(VAR_15, 0)\n"", ""VAR_2.load_user_by_profile(VAR_14)\n"", ""VAR_15 = models.User.query().count()\n"", ""self.assertEqual(VAR_15, 1)\n"", ""VAR_11 = models.User.query().get()\n"", ""self.assertTrue(VAR_14.key.id() in VAR_11.auth_ids)\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2._load_session()\n"", ""VAR_2._load_user()\n"", ""VAR_2.load_user_by_profile(VAR_14)\n"", ""VAR_15 = models.User.query().count()\n"", ""self.assertEqual(VAR_15, 1)\n"", ""VAR_12 = 'test:abc'\n"", ""VAR_13 = {'auth_id': VAR_12, 'info': {}}\n"", ""VAR_16 = models.UserProfile.get_or_create(VAR_12, VAR_13)\n"", ""VAR_2.load_user_by_profile(VAR_16)\n"", ""VAR_15 = models.User.query().count()\n"", ""self.assertEqual(VAR_15, 1)\n"", ""def FUNC_9(self):...\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2._load_session()\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, None)\n"", ""VAR_2.add_message('TEST MESSAGE')\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, [{'level': None, 'message': 'TEST MESSAGE'}])\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, None)\n"", ""VAR_2.add_message('TEST1', 'error')\n"", ""VAR_2.add_message('TEST2', 'success')\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, [{'level': 'error', 'message': 'TEST1'}, {'level':\n    'success', 'message': 'TEST2'}])\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, None)\n"", ""VAR_2.add_message('TEST1', 'error')\n"", ""VAR_2.add_message('TEST2', 'success', '_mykey')\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, [{'level': 'error', 'message': 'TEST1'}])\n"", ""VAR_18 = VAR_2.get_messages('_mykey')\n"", ""self.assertEquals(VAR_18, [{'level': 'success', 'message': 'TEST2'}])\n"", ""VAR_17 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_17, None)\n"", ""VAR_18 = VAR_2.get_messages()\n"", ""self.assertEquals(VAR_18, None)\n"", ""def FUNC_10(self):...\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google')\n"", ""VAR_2._load_session()\n"", ""VAR_2.set_redirect_uri()\n"", ""VAR_2._config = {'success_uri': '/callback'}\n"", ""VAR_19 = VAR_2.get_redirect_uri()\n"", ""self.assertEqual(VAR_19, '/callback')\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google?next=/newcallback')\n"", ""VAR_2._load_session()\n"", ""VAR_2.set_redirect_uri()\n"", ""VAR_2._config = {'success_uri': '/callback'}\n"", ""VAR_19 = VAR_2.get_redirect_uri()\n"", ""self.assertEqual(VAR_19, '/newcallback')\n"", ""VAR_2 = EngineAuthRequest.blank('/auth/google?next=/newcallback&a=121&123=a')\n"", ""VAR_2._load_session()\n"", ""VAR_2.set_redirect_uri()\n"", ""VAR_2._config = {'success_uri': '/callback'}\n"", ""VAR_19 = VAR_2.get_redirect_uri()\n"", ""self.assertEqual(VAR_19, '/newcallback')\n""]",1
"[""from __future__ import print_function\n"", ""import os\n"", ""import sys\n"", ""import etcd\n"", ""from custodia.store.interface import CSStore, CSStoreError, CSStoreExists\n"", ""def FUNC_0(VAR_0):...\n"", ""print(VAR_0, file=sys.stderr)\n"", ""def __init__(self, VAR_1):...\n"", ""self.server = VAR_1.get('etcd_server', '127.0.0.1')\n"", ""self.port = int(VAR_1.get('etcd_port', 4001))\n"", ""self.namespace = VAR_1.get('namespace', '/custodia')\n"", ""self.etcd = etcd.Client(self.server, self.port)\n"", ""FUNC_0('Error creating namespace %s: [%r]' % (self.namespace, repr(err)))\n"", ""def FUNC_1(self, VAR_2):...\n"", ""self.etcd.write(self.namespace, None, dir=True)\n"", ""VAR_7 = self.etcd.get(os.path.join(self.namespace, VAR_2))\n"", ""FUNC_0('Error fetching key %s: [%r]' % (VAR_2, repr(err)))\n"", ""return VAR_7.value\n""]",1
"[""def FUNC_8(self, VAR_20, VAR_21, VAR_22):...\n"", ""return\n""]",0
"[""def FUNC_2(self, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = {}\n"", ""VAR_5['clusterName'] = VAR_8\n"", ""VAR_5['searchDepth'] = '1'\n"", ""VAR_5['verbose'] = '0'\n"", ""VAR_18 = self._cliq_run_xml('getClusterInfo', VAR_5)\n"", ""return VAR_18\n""]",0
"[""def FUNC_1(VAR_0: str) ->List[str]:...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = FUNC_0(VAR_0)\n"", ""return [line.strip().decode() for line in VAR_3.splitlines()]\n""]",1
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self.options.for_global_scope().lock:\n"", ""if not self._lock.acquired:\n"", ""self._lock.acquire()\n""]",0
"[""def FUNC_4(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_24 = self.getfile(VAR_21, VAR_23=True)\n"", ""if VAR_24 is not False:\n"", ""return True\n""]",0
"[""def FUNC_4(self):...\n"", ""VAR_12 = Client()\n"", ""self.response = VAR_12.get('{}?{}'.format(reverse(\n    'email-confirmation-redirect'), 'token=ABXZ'))\n"", ""return self\n""]",0
"[""def FUNC_5(self, VAR_5, VAR_1, VAR_6, VAR_7, VAR_8):...\n"", ""VAR_20 = 'string' % (VAR_1, VAR_6, VAR_7, VAR_8, VAR_5)\n"", ""self.c.execute(VAR_20)\n""]",1
"[""def FUNC_14(self, VAR_18=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_18 is None:\n"", ""self.remove_completed()\n"", ""if not isinstance(VAR_18, list):\n"", ""self.save()\n"", ""VAR_18 = [VAR_18]\n"", ""for job in VAR_18:\n"", ""self.execute('DELETE FROM history WHERE nzo_id=?', (job,))\n"", ""logging.info('Removing job %s from history', job)\n""]",0
"[""def FUNC_39(VAR_101):...\n"", ""if VAR_101.input:\n"", ""VAR_13.set_input(*VAR_101.input[0], **ruleinfo.input[1])\n"", ""if VAR_101.output:\n"", ""VAR_13.set_output(*VAR_101.output[0], **ruleinfo.output[1])\n"", ""if VAR_101.params:\n"", ""VAR_13.set_params(*VAR_101.params[0], **ruleinfo.params[1])\n"", ""if VAR_101.threads:\n"", ""if not isinstance(VAR_101.threads, int):\n"", ""if VAR_101.resources:\n"", ""VAR_13.resources['_cores'] = VAR_101.threads\n"", ""VAR_76, VAR_52 = VAR_101.resources\n"", ""if VAR_101.priority:\n"", ""if VAR_76:\n"", ""if not isinstance(VAR_101.priority, int) and not isinstance(VAR_101.\n"", ""if VAR_101.version:\n"", ""if not all(map(lambda r: isinstance(r, int), VAR_52.values())):\n"", ""VAR_13.priority = VAR_101.priority\n"", ""VAR_13.version = VAR_101.version\n"", ""if VAR_101.log:\n"", ""VAR_13.resources.update(VAR_52)\n"", ""VAR_13.set_log(*VAR_101.log[0], **ruleinfo.log[1])\n"", ""if VAR_101.message:\n"", ""VAR_13.message = VAR_101.message\n"", ""if VAR_101.benchmark:\n"", ""VAR_13.benchmark = VAR_101.benchmark\n"", ""VAR_13.norun = VAR_101.norun\n"", ""VAR_13.docstring = VAR_101.docstring\n"", ""VAR_13.run_func = VAR_101.func\n"", ""VAR_13.shellcmd = VAR_101.shellcmd\n"", ""VAR_101.func.__name__ = '__{}'.format(VAR_10)\n"", ""self.globals[VAR_101.func.__name__] = VAR_101.func\n"", ""setattr(VAR_86, VAR_10, VAR_13)\n"", ""return VAR_101.func\n""]",0
"[""def FUNC_13(VAR_25):...\n"", ""VAR_40 = []\n"", ""if os.path.exists(VAR_25):\n"", ""VAR_40 = json.loads(ocf.read())\n"", ""if not isinstance(VAR_40, list):\n"", ""return VAR_40\n""]",0
"[""def FUNC_14(self, VAR_23):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_23 = VAR_23.copy()\n"", ""VAR_25 = VAR_23.pop('env', os.environ).copy()\n"", ""VAR_25['PATH'] = self.bin_dir_path + os.path.pathsep + VAR_25['PATH'\n    ] if VAR_25.get('PATH', '') else self.bin_dir_path\n"", ""return VAR_25, VAR_23\n""]",1
"[""def FUNC_2(self, VAR_3, VAR_4):...\n"", ""return self.has_object_permission(VAR_3, VAR_4, VAR_4.instance)\n""]",0
"[""def FUNC_16(self):...\n"", ""VAR_7 = Pa11yCrawler('')\n"", ""VAR_7.get_test_course()\n"", ""self._mock_sh.assert_has_calls([call(\n    'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.\n    tar_gz_file, dir=suite.imports_dir)), call(\n    'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir))])\n""]",0
"[""def FUNC_11(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.client.login(username='autotest2', password='password')\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_8 = {'image': 'autotest/example', 'sha': 'a' * 40, 'procfile': json.\n    dumps({'web': 'node server.js', 'worker': 'node worker.js'})}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_8), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""self.client.login(username='autotest', password='password')\n"", ""VAR_4 = '/api/apps/{app_id}/scale'.format(**locals())\n"", ""VAR_8 = {'web': 4, 'worker': 2}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_8), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 204)\n""]",1
"[""def FUNC_20(VAR_5):...\n"", ""VAR_8 = {'Authorization': 'token ' + os.environ['GITHUB_TOKEN']}\n"", ""VAR_9 = os.environ['BOT_USERNAME'], os.environ['BOT_PASSWORD']\n"", ""VAR_10 = 'https://api.github.com/repos/{}/pulls'\n"", ""VAR_10 = VAR_10.format(VAR_5['target_repo_fullname'])\n"", ""VAR_40 = {'title': 'Fix pep8 errors', 'head': 'pep8speaks:{}'.format(VAR_5[\n    'new_branch']), 'base': VAR_5['target_repo_branch'], 'body':\n    'The changes are suggested by autopep8'}\n"", ""VAR_11 = requests.post(VAR_10, json=request_json, VAR_8=headers, VAR_9=auth)\n"", ""if VAR_11.status_code == 201:\n"", ""VAR_5['pr_url'] = VAR_11.json()['html_url']\n"", ""VAR_5['error'] = 'Pull request could not be created'\n""]",0
"[""from bottle import static_file\n"", ""from streamline import NonIterableRouteBase\n"", ""VAR_0 = '/static/<path:path>'\n"", ""def FUNC_0(self):...\n"", ""return self.config['runtime.static_dir']\n""]",1
"[""def __eq__(self, VAR_25):...\n"", ""VAR_0 = VAR_25._file if isinstance(VAR_25, CLASS_0) else VAR_25\n"", ""return self._file == VAR_0\n""]",0
"[""@FUNC_8.error...\n"", ""await self.bot.handle_error(VAR_5, VAR_1)\n""]",0
"[""def FUNC_15(VAR_33, VAR_5=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_52 = {}\n"", ""for VAR_82, info in VAR_33:\n"", ""VAR_52[VAR_82.output(VAR_5)] = {'numbers': len(info[0]), 'details': info[1]}\n"", ""return VAR_52\n""]",0
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = VAR_1[:]\n"", ""VAR_13 = 'view.payment',\n"", ""if not self.exported:\n"", ""VAR_13 += 'edit.payment',\n"", ""VAR_11.append((Allow, 'group:admin', VAR_13))\n"", ""VAR_11.append((Allow, 'group:manager', VAR_13))\n"", ""VAR_11.append((Allow, 'group:payment_admin', VAR_13))\n"", ""for user in self.task.company.employees:\n"", ""VAR_11.append((Allow, user.login, ('view.payment',)))\n"", ""return VAR_11\n""]",0
"[""\""\""\""string\""\""\""\n"", ""from builtins import str\n"", ""import json\n"", ""import logging\n"", ""import socket\n"", ""import threading\n"", ""import time\n"", ""from mobly.controllers.android_device_lib import adb\n"", ""from mobly.controllers.android_device_lib import callback_handler\n"", ""VAR_0 = 15\n"", ""VAR_1 = -1\n"", ""VAR_2 = 60\n"", ""VAR_3 = callback_handler.MAX_TIMEOUT\n"", ""\""\""\""Raised when the app is not able to be started.\""\""\""\n"", ""\""\""\""Raised when remote API reports an error.\""\""\""\n"", ""\""\""\""Raised when there is some error in exchanging data with server.\""\""\""\n"", ""VAR_4 = 'No response from handshake.'\n"", ""VAR_5 = 'No response from server.'\n"", ""VAR_6 = 'Mismatched API id.'\n"", ""\""\""\""string\""\""\""\n"", ""VAR_7 = 'initiate'\n"", ""VAR_8 = 'continue'\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_9, VAR_10, VAR_11, VAR_12, VAR_13=logging.getLogger()):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.host_port = VAR_9\n"", ""self.device_port = VAR_10\n"", ""self.app_name = VAR_11\n"", ""self.uid = None\n"", ""self._adb = VAR_12\n"", ""self._client = None\n"", ""self._conn = None\n"", ""self._counter = None\n"", ""self._lock = threading.Lock()\n"", ""self._event_client = None\n"", ""self._log = VAR_13\n"", ""def __del__(self):...\n"", ""self.close()\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_4(self, VAR_14=VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.check_app_installed()\n"", ""self._do_start_app()\n"", ""for _ in range(VAR_14):\n"", ""time.sleep(1)\n"", ""def FUNC_5(self, VAR_15=VAR_1, VAR_16=CLASS_4.INIT):...\n"", ""if self._is_app_running():\n"", ""\""\""\""docstring\""\""\""\n"", ""self._log.debug('Successfully started %s', self.app_name)\n"", ""self._counter = self._id_counter()\n"", ""return\n"", ""self._conn = socket.create_connection(('127.0.0.1', self.host_port), VAR_2)\n"", ""self._conn.settimeout(VAR_3)\n"", ""self._client = self._conn.makefile(mode='brw')\n"", ""VAR_22 = self._cmd(VAR_16, VAR_15)\n"", ""if not VAR_22:\n"", ""VAR_23 = json.loads(str(VAR_22, encoding='utf8'))\n"", ""if VAR_23['status']:\n"", ""self.uid = VAR_23['uid']\n"", ""self.uid = VAR_1\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self._conn:\n"", ""self._conn.close()\n"", ""def FUNC_7(self, VAR_17):...\n"", ""self._conn = None\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._adb.shell(VAR_17).decode('utf-8')\n"", ""if e.ret_code == 1 and not e.stdout and not e.stderr:\n"", ""def FUNC_8(self, VAR_18, VAR_15=None):...\n"", ""return False\n"", ""\""\""\""docstring\""\""\""\n"", ""if not VAR_15:\n"", ""VAR_15 = self.uid\n"", ""self._client.write(json.dumps({'cmd': VAR_18, 'uid': VAR_15}).encode('utf8'\n    ) + b'\\n')\n"", ""self._client.flush()\n"", ""return self._client.readline()\n""]",1
"[""\""\""\""\nCreated on Mon Jan  1 21:38:13 2018\n\n@author: Adam\n\""\""\""\n"", ""import time\n"", ""from random import random, gauss\n"", ""from .base import Device\n"", ""\""\""\"" simulate comms. with a serial device\""\""\""\n"", ""def __init__(self, VAR_0, VAR_1=False):...\n"", ""self.settings = VAR_0\n"", ""self.sensors = VAR_0['sensors']\n"", ""def FUNC_0(self, VAR_2=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_2 is None:\n"", ""VAR_2 = self.sensors\n"", ""for i, _ in enumerate(VAR_2):\n"", ""def FUNC_1(self):...\n"", ""if random() < 0.01:\n"", ""yield 'NULL'\n"", ""VAR_3 = gauss(293 + 0.5 * i, 0.1)\n"", ""yield f'{VAR_3:.4f}'\n""]",1
"[""import os\n"", ""from flask import Flask\n"", ""from flask import redirect\n"", ""from flask import render_template\n"", ""from flask import request\n"", ""import psycopg2\n"", ""import timeit\n"", ""from fieldValues import faculty_status, fields_of_study, departments, careerareas, ipedssectornames\n"", ""from occupations import occupations\n"", ""VAR_0 = os.path.dirname(os.path.abspath(__file__))\n"", ""VAR_1 = Flask(__name__, static_url_path='', static_folder='static')\n"", ""VAR_2 = (\n    'SELECT year,faculty, count(*) as N from hej where faculty=1 group by faculty,year;'\n    )\n"", ""@VAR_1.route('/', methods=['GET'])...\n"", ""return render_template('home.html')\n""]",1
"[""@then(parsers.parse(\""the hostname '{hostname}' should be resolved\""))...\n"", ""VAR_8 = (\n    'kubectl --kubeconfig=/etc/kubernetes/admin.conf exec -ti {0} nslookup {1}'\n    .format(pod_name, VAR_3))\n"", ""VAR_9 = VAR_1.run(VAR_8)\n"", ""assert VAR_9.rc == 0, 'Cannot resolve {}'.format(VAR_3)\n""]",1
"[""def FUNC_3(VAR_3, VAR_2):...\n"", ""VAR_19 = VAR_2.find_customer(VAR_3)\n"", ""if VAR_19 is not None:\n"", ""print('Welcome Back', VAR_19[1], VAR_19[2])\n"", ""return FUNC_2(VAR_3, VAR_2)\n"", ""return VAR_19[7]\n""]",1
"[""\""\""\""Setup file for cheshire3 package.\""\""\""\n"", ""from __future__ import with_statement\n"", ""import sys\n"", ""import os\n"", ""import inspect\n"", ""from warnings import warn\n"", ""import distribute_setup\n"", ""distribute_setup.use_setuptools()\n"", ""from setuptools import setup, find_packages\n"", ""from pkg_resources import DistributionNotFound\n"", ""VAR_0 = getattr(sys, 'version_info', (0, 0, 0))\n"", ""if VAR_0 < (2, 6):\n"", ""warn(\n    'Cheshire3 requires Python 2.6 or later; some code may be incompatible with earlier versions.'\n    )\n"", ""VAR_1 = inspect.getfile(inspect.currentframe())\n"", ""VAR_2 = os.path.dirname(VAR_1)\n"", ""VAR_3 = 'cheshire3'\n"", ""VAR_4 = 'Cheshire3 Search and Retrieval Engine and Information Framework'\n"", ""VAR_7 = vfh.read().strip()\n"", ""VAR_5 = 'http://download.cheshire3.org/{0}/src/{1}-{2}.tar.gz'.format(VAR_7\n    [:3], VAR_3, VAR_7)\n"", ""VAR_8 = open(os.path.join(VAR_2, 'README.rst'), 'r')\n"", ""VAR_9 = ''\n"", ""VAR_9 = VAR_8.read()\n"", ""VAR_10 = VAR_8.readlines()\n"", ""VAR_8.close()\n"", ""VAR_6 = []\n"", ""if VAR_0 < (3, 0):\n"", ""VAR_11 = 'python-dateutil == 1.5'\n"", ""VAR_11 = 'python-dateutil >= 2.0'\n"", ""if VAR_0 < (2, 7):\n"", ""VAR_10.append(VAR_11)\n"", ""VAR_10.append('argparse')\n"", ""setup(name=_name, version=_version, packages=[_name], include_package_data=\n    True, package_data={'cheshire3': ['configs/*.xml',\n    'configs/extra/*.xml']}, exclude_package_data={'': ['README.*',\n    '.gitignore']}, requires=['lxml(>=2.1)', 'bsddb', 'dateutil',\n    'argparse'], tests_require=_tests_require, install_requires=\n    _install_requires, setup_requires=['setuptools-git'], dependency_links=\n    ['http://labix.org/python-dateutil',\n    'http://www.panix.com/~asl2/software/PyZ3950/',\n    'http://download.cheshire3.org/latest/reqs/'], extras_require={'graph':\n    ['rdflib'], 'datamining': ['svm'], 'lucene': ['lucene'], 'sql': [\n    'PyGreSQL >= 3.8.1'], 'textmining': ['numpy', 'nltk >= 2.0'], 'web': [\n    'pyoai', 'PyZ3950 >= 2.04', 'ZSI < 2.0']}, test_suite=\n    'cheshire3.test.testAll.suite', scripts=['scripts/DocumentConverter.py'\n    ], entry_points={'console_scripts': [\n    'cheshire3 = cheshire3.commands.console:main',\n    'cheshire3-init = cheshire3.commands.init:main',\n    'cheshire3-load = cheshire3.commands.load:main',\n    'cheshire3-register = cheshire3.commands.register:main',\n    'cheshire3-search = cheshire3.commands.search:main',\n    'cheshire3-serve = cheshire3.commands.serve:main']}, keywords=\n    'xml document search information retrieval engine data text',\n    description=_description, long_description=_long_description, author=\n    'Rob Sanderson, et al.', author_email='azaroth@liv.ac.uk', maintainer=\n    'John Harrison', maintainer_email='john.harrison@liv.ac.uk', license=\n    'BSD', classifiers=['Intended Audience :: Developers',\n    'Intended Audience :: Information Technology',\n    'License :: OSI Approved :: BSD License',\n    'Programming Language :: Python :: 2.6',\n    'Programming Language :: Python :: 2.7',\n    'Topic :: Internet :: WWW/HTTP :: Indexing/Search',\n    'Topic :: Internet :: WWW/HTTP :: WSGI :: Application',\n    'Topic :: Internet :: Z39.50', 'Topic :: Text Processing :: Indexing',\n    'Topic :: Text Processing :: Linguistic',\n    'Topic :: Text Processing :: Markup'], url='http://www.cheshire3.org/',\n    download_url=_download_url)\n"", ""VAR_6.append('unittest2')\n""]",1
"[""import logging\n"", ""from django.conf import settings\n"", ""from django.contrib.auth import REDIRECT_FIELD_NAME\n"", ""from django.contrib.auth.views import login as django_login\n"", ""from django.core.cache import cache\n"", ""from django.core.cache.utils import make_template_fragment_key\n"", ""from django.http.response import HttpResponseRedirect\n"", ""from django.shortcuts import resolve_url\n"", ""from django.template.loader import TemplateDoesNotExist, get_template\n"", ""from django.utils.http import is_safe_url\n"", ""from django.utils.translation import get_language\n"", ""from django.utils.translation import ugettext_lazy as _\n"", ""from lib.helpers import settings_text\n"", ""from authorization.permissions import ACCESS\n"", ""from .viewbase import UserProfileView\n"", ""VAR_0 = logging.getLogger('userprofile.views')\n"", ""def FUNC_0(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.user.is_authenticated():\n"", ""VAR_5 = VAR_1.POST.get(REDIRECT_FIELD_NAME, VAR_1.GET.get(\n    REDIRECT_FIELD_NAME, ''))\n"", ""return django_login(VAR_1, VAR_4='userprofile/login.html', extra_context={\n    'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,\n    'mooc_login': 'social_django' in settings.INSTALLED_APPS,\n    'login_title_text': settings_text('LOGIN_TITLE_TEXT'),\n    'login_body_text': settings_text('LOGIN_BODY_TEXT'),\n    'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),\n    'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),\n    'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),\n    'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),\n    'mooc_title_text': settings_text('MOOC_TITLE_TEXT'), 'mooc_body_text':\n    settings_text('MOOC_BODY_TEXT')})\n"", ""if not is_safe_url(url=redirect_to, host=request.get_host()):\n"", ""VAR_5 = resolve_url(settings.LOGIN_REDIRECT_URL)\n"", ""return HttpResponseRedirect(VAR_5)\n""]",1
"[""@property...\n"", ""for VAR_24 in self._homes:\n"", ""yield self.Location.from_home(VAR_24)\n""]",0
"[""def FUNC_16(self, VAR_22):...\n"", ""VAR_34 = ', '.join([str(each) for each in VAR_22])\n"", ""VAR_0.delete('file', 'id in (' + VAR_34 + ')')\n""]",1
"[""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", """"]",0
"[""@app.route('/api/commands/<id>/run', methods=['POST'])...\n"", ""return commands.run(VAR_4)\n""]",1
"[""def FUNC_13(self):...\n"", ""VAR_11 = {}\n"", ""for VAR_12 in self.parent_groups:\n"", ""VAR_11[VAR_12.name] = VAR_12\n"", ""return VAR_11\n"", ""VAR_11.update(VAR_12._get_ancestors())\n""]",1
"[""def FUNC_2(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = VAR_38(VAR_0)\n"", ""VAR_6 = VAR_6[VAR_6.find(\""'\"") + 1:VAR_6.rfind(\""'\"")]\n"", ""VAR_6 = ':'.join(VAR_6.rsplit('.', 1))\n"", ""return VAR_6\n""]",0
"[""def FUNC_3(self, VAR_18):...\n"", ""self.base.execute(VAR_18)\n""]",0
"[""@neko.command(VAR_21='rtfm', VAR_17=...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = neko.Book(VAR_3)\n"", ""VAR_8 = {}\n"", ""VAR_7 += await self.gen_front_page(VAR_3)\n"", ""VAR_8[None] = 0\n"", ""VAR_9 = sorted(set(self.bot.walk_commands()), key=lambda c: c.qualified_name)\n"", ""VAR_10 = len(VAR_7)\n"", ""for i, VAR_5 in enumerate(VAR_9):\n"", ""VAR_7 += await self.gen_spec_page(VAR_3, VAR_5)\n"", ""VAR_24 = VAR_8[VAR_4]\n"", ""await VAR_3.send(f'I could not find a command called {VAR_4}!')\n"", ""VAR_7.index = VAR_24\n"", ""VAR_8[VAR_5.qualified_name] = i + VAR_10\n"", ""await VAR_7.send()\n""]",1
"[""def FUNC_3(VAR_0, VAR_3):...\n"", ""VAR_4 = VAR_0.cursor()\n"", ""VAR_5 = 'ALTER TABLE Presets DROP COLUMN id;'\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = (\n    'ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;'\n    )\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_6 = Table('Presets')\n"", ""VAR_7 = MySQLQuery.from_(VAR_6).select(VAR_6.querval).where(VAR_6.id == VAR_3)\n"", ""print(VAR_7)\n"", ""VAR_5 = str(VAR_7)\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_8 = VAR_4.fetchone()\n"", ""VAR_9 = str(VAR_8)\n"", ""return VAR_9[2:-3]\n""]",1
"[""@jwt_required...\n"", ""VAR_7 = request.get_json(force=True)\n"", ""VAR_8 = Table.update(VAR_3, VAR_4, VAR_7)\n"", ""if VAR_8 == 200:\n"", ""VAR_10 = {'status': 'success', 'message': 'Update successful'}\n"", ""if VAR_8 == 302:\n"", ""return make_response(jsonify(VAR_10)), 200\n"", ""VAR_10 = {'status': 'fail', 'message':\n    'Please provide correct answer and question id'}\n"", ""if VAR_8 == 203:\n"", ""return make_response(jsonify(VAR_10)), 400\n"", ""VAR_10 = {'status': 'fail', 'message': 'Unauthorized request.'}\n"", ""VAR_10 = {'status': 'fail', 'message':\n    'Please provide correct answer and question id'}\n"", ""return make_response(jsonify(VAR_10)), 401\n"", ""return make_response(jsonify(VAR_10)), 400\n""]",1
"[""def FUNC_2(self, VAR_1):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = \""INSERT INTO crimes(description) VALUES ('{}');\"".format(VAR_1)\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",1
"[""@classmethod...\n"", ""assert engine\n"", ""VAR_9 = text(\n    'SELECT * FROM users WHERE username = :username AND expire_date is null')\n"", ""VAR_7 = engine.connect()\n"", ""VAR_10 = False if VAR_7.execute(VAR_9, VAR_1=username).fetchone(\n    ) is None else True\n"", ""VAR_7.close()\n"", ""return VAR_10\n""]",1
"[""def __str__(self):...\n"", ""VAR_10 = []\n"", ""for VAR_14, VAR_13, VAR_7 in self._path:\n"", ""if VAR_14 is CLASS_0:\n"", ""return '.'.join(VAR_10)\n"", ""VAR_10.append(VAR_7)\n"", ""if VAR_13 is CLASS_0:\n"", ""VAR_10.append('{}[{}]'.format(VAR_7, VAR_14))\n"", ""VAR_10.append('{}{{{}={}}}'.format(VAR_7, VAR_13, VAR_14))\n""]",0
"[""def __repr__(self):...\n"", ""return f'<DepthLimit {self.maxdepth}>'\n""]",0
"[""\""\""\""SchoolCMS-schoolcms-init.\""\""\""\n"", ""from __future__ import absolute_import\n"", ""from __future__ import print_function\n"", ""from __future__ import unicode_literals\n"", ""VAR_0 = '0.0.3dev2'\n"", ""VAR_1 = 0, 0, 3, 12\n""]",1
"[""def FUNC_17(self):...\n"", ""def FUNC_23(VAR_11):...\n"", ""return '%s> ' % self.configuration.eqlx_group_name\n""]",0
"[""@property...\n"", ""if not self.current_user or not self.current_user.has_key('role'):\n"", ""return self.current_user['role'] == 'receiver'\n""]",0
"[""import os\n"", ""import time\n"", ""from cauldron.render import texts as render_texts\n"", ""from cauldron.session.buffering import RedirectBuffer\n"", ""from cauldron.session.caching import SharedCache\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0=None):...\n"", ""self.step = VAR_0\n"", ""self.body = []\n"", ""self.css = []\n"", ""self.data = SharedCache()\n"", ""self.files = SharedCache()\n"", ""self.title = self.definition.get('title')\n"", ""self.subtitle = self.definition.get('subtitle')\n"", ""self.summary = self.definition.get('summary')\n"", ""self.library_includes = []\n"", ""self.stdout_interceptor = None\n"", ""self.stderr_interceptor = None\n"", ""self._last_update_time = 0\n"", ""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = self.stdout_interceptor\n"", ""VAR_3 = self.stderr_interceptor\n"", ""return max([self._last_update_time, VAR_2.last_write_time if VAR_2 else 0, \n    VAR_3.last_write_time if VAR_3 else 0])\n""]",0
"[""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.do_step(HomepageRequest(self.browser, self.username, loggedin=False,\n    VAR_10=self.base_url))\n"", ""self.do_step(LoginRequest(self.browser, self.username, self.password,\n    VAR_10=self.base_url))\n"", ""self.do_step(HomepageRequest(self.browser, self.username, loggedin=True,\n    VAR_10=self.base_url))\n""]",1
"[""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""VAR_15 = None\n"", ""VAR_75 = ''\n"", ""if os.path.isdir(entry):\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n""]",1
"[""\""\""\""Networks plugin - allows you to manipulate connections to various configured networks.\""\""\""\n"", ""import importlib\n"", ""import types\n"", ""from pylinkirc import utils, world, conf, classes\n"", ""from pylinkirc.log import log\n"", ""from pylinkirc.coremods import control, permissions\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.disconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: network name (case sensitive)).')\n"", ""VAR_0.reply(\n    \""Done. If you want to reconnect this network, use the 'rehash' command.\"")\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""return\n"", ""control.remove_network(VAR_4)\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.autoconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error(\n    'Not enough arguments (needs 2: network name (case sensitive), autoconnect time (in seconds)).'\n    )\n"", ""VAR_4.serverdata['autoconnect'] = VAR_11\n"", ""VAR_11 = float(VAR_2[1])\n"", ""return\n"", ""VAR_0.reply('Done.')\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""VAR_3 = utils.IRCParser()\n"", ""VAR_3.add_argument('network')\n"", ""VAR_3.add_argument('--service', type=str, default='pylink')\n"", ""VAR_3.add_argument('command', nargs=utils.IRCParser.REMAINDER)\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.remote'])\n"", ""VAR_2 = VAR_3.parse_args(VAR_2)\n"", ""VAR_5 = VAR_2.network\n"", ""if VAR_5 == VAR_0.name:\n"", ""VAR_0.error(\n    'Cannot remote-send a command to the local network; use a normal command!')\n"", ""VAR_12 = world.networkobjects[VAR_5]\n"", ""VAR_0.error('No such network \""%s\"" (case sensitive).' % VAR_5)\n"", ""if VAR_2.service not in world.services:\n"", ""return\n"", ""return\n"", ""VAR_0.error('Unknown service %r.' % VAR_2.service)\n"", ""VAR_12.called_in = VAR_12.called_by = VAR_12.pseudoclient.uid\n"", ""return\n"", ""VAR_12.pseudoclient.account = VAR_0.users[VAR_1].account\n"", ""def FUNC_4(VAR_6, VAR_7, **VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""assert VAR_0.name != VAR_6.name, 'Refusing to route reply back to the same network, as this would cause a recursive loop'\n"", ""log.debug('(%s) networks.remote: re-routing reply %r from network %s',\n    VAR_0.name, VAR_7, VAR_6.name)\n"", ""if 'source' in VAR_8:\n"", ""VAR_0.reply(VAR_7, VAR_1=irc.pseudoclient.uid, **kwargs)\n"", ""VAR_9 = VAR_12.reply\n"", ""log.debug('(%s) networks.remote: overriding reply() of IRC object %s',\n    VAR_0.name, VAR_5)\n"", ""log.debug('(%s) networks.remote: restoring reply() of IRC object %s', VAR_0\n    .name, VAR_5)\n"", ""@utils.add_cmd...\n"", ""VAR_12.reply = types.MethodType(FUNC_4, VAR_12)\n"", ""VAR_12.reply = VAR_9\n"", ""\""\""\""docstring\""\""\""\n"", ""world.services[VAR_2.service].call_cmd(VAR_12, VAR_12.pseudoclient.uid, ' '\n    .join(VAR_2.command))\n"", ""VAR_12.pseudoclient.account = ''\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.reloadproto'])\n"", ""VAR_13 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: protocol module name)')\n"", ""VAR_10 = utils.getProtocolModule(VAR_13)\n"", ""return\n"", ""importlib.reload(VAR_10)\n"", ""VAR_0.reply('string' % VAR_13)\n""]",1
"[""def FUNC_10(VAR_11, VAR_3):...\n"", ""VAR_18 = get_current_http_request()\n"", ""if 'XMLHttpRequest' == VAR_18.headers.get('X-Requested-With', None):\n"", ""return VAR_11\n"", ""if VAR_18.path.startswith('/-test/'):\n"", ""return VAR_11\n"", ""if not VAR_3:\n"", ""return VAR_11\n"", ""VAR_19 = lxml.html.document_fromstring(VAR_11)\n"", ""VAR_20 = VAR_19.makeelement('script', attrib={'type': 'text/javascript',\n    'src': '/-test/veil-test.js'})\n"", ""VAR_19.find('body').append(VAR_20)\n"", ""VAR_20 = VAR_19.makeelement('script', attrib={'type': 'text/javascript'})\n"", ""VAR_20.text = (\n    \""\""\""\n    $(document).ready(function() {\n        %s\n    });\n    \""\""\"" %\n    VAR_3.pop())\n"", ""VAR_19.find('body').append(VAR_20)\n"", ""return open_closed_tags(lxml.html.tostring(VAR_19, method='xml'))\n""]",1
"[""import discord\n"", ""from argparse import ArgumentParser\n"", ""from configparser import ConfigParser\n"", ""from subprocess import call\n"", ""VAR_0 = '[Discord] '\n"", ""VAR_1 = '#gatekeep'\n"", ""VAR_2 = 'tmux send-keys -t \""0:0\"" Enter \""whitelist add {}\"" Enter'\n"", ""VAR_3 = ConfigParser()\n"", ""VAR_4 = 'config.ini'\n"", ""VAR_3.read(VAR_4)\n"", ""if not VAR_3.sections():\n"", ""print('No existing config was found')\n"", ""if 'Discord' not in VAR_3:\n"", ""print('Copy the following blank template into ' + VAR_4 +\n    ' and fill in the blanks:')\n"", ""print(\""Failed to read config: 'Discord' section missing\"")\n"", ""if 'client_id' not in VAR_3['Discord']:\n"", ""print('[Discord]\\n' + 'client_id = \\n' + 'client_secret = \\n' +\n    'bot_token = \\n' + 'bot_owner = \\n' + 'bot_server = \\n')\n"", ""exit(1)\n"", ""print(\""Failed to read config: 'client_id' missing from section 'Discord'\"")\n"", ""if 'bot_token' not in VAR_3['Discord']:\n"", ""exit(1)\n"", ""exit(1)\n"", ""print(\""Failed to read config: 'bot_token' missing from section 'Discord'\"")\n"", ""if 'bot_server' not in VAR_3['Discord']:\n"", ""exit(1)\n"", ""print(\""Failed to read config: 'bot_server' missing from section 'Discord'\"")\n"", ""VAR_5 = VAR_3['Discord']['client_id']\n"", ""exit(1)\n"", ""VAR_6 = VAR_3['Discord']['bot_token']\n"", ""VAR_7 = VAR_3['Discord']['bot_server']\n"", ""VAR_13 = VAR_3['Discord']['bot_owner']\n"", ""VAR_13 = ''\n"", ""VAR_8 = ArgumentParser()\n"", ""VAR_9 = VAR_8.parse_args()\n"", ""def FUNC_0(VAR_10: str):...\n"", ""for user in VAR_10.split():\n"", ""call(VAR_2.format(user))\n"", ""VAR_11 = discord.Client()\n"", ""@VAR_11.event...\n"", ""print(VAR_0 + 'Bot logged in!')\n"", ""@VAR_11.event...\n"", ""if str(VAR_12.guild.id) != VAR_7:\n"", ""return\n"", ""if VAR_13 and str(VAR_12.author.id) not in VAR_13:\n"", ""return\n"", ""VAR_14 = ''\n"", ""if VAR_12.content.startswith(VAR_1):\n"", ""VAR_14 = VAR_1\n"", ""if VAR_12.content.startswith('<@' + str(VAR_5) + '>'):\n"", ""async def FUNC_3():...\n"", ""VAR_14 = '@{}#{}'.format(VAR_11.user.name, VAR_11.user.discriminator)\n"", ""return\n"", ""VAR_12.channel.send('Command list:\\n' + '\\n' +\n    '`help` - Shows this help text\\n' +\n    '`whitelist` - Add user(s) to the whitelist')\n"", ""VAR_9 = VAR_12.content.strip().split()[1:]\n"", ""if not VAR_9:\n"", ""await VAR_12.channel.send('Usage: `{} whitelist <username> [username...]`'.\n    format(VAR_14), delete_after=30)\n"", ""if VAR_9[0] == 'help':\n"", ""await VAR_12.delete()\n"", ""await FUNC_3()\n"", ""if VAR_9[0] == 'whitelist':\n"", ""VAR_11.run(VAR_6)\n"", ""if len(VAR_9) < 1:\n"", ""await FUNC_3()\n"", ""await FUNC_0(' '.join(VAR_9[1:]))\n""]",1
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render\n"", ""from django.views.generic import ListView, DetailView\n"", ""from pure_pagination.mixins import PaginationMixin\n"", ""from django.db.models import Q\n"", ""from .models import tweet\n"", ""from .forms import SearchForm\n"", ""from django.http import JsonResponse\n"", ""from urllib.parse import urlparse\n"", ""from http.client import HTTPSConnection\n"", ""from datetime import datetime, timezone, timedelta\n"", ""VAR_2 = 'twitter/index.html'\n"", ""VAR_3 = 'tws'\n"", ""VAR_4 = 30\n"", ""def FUNC_2(self, **VAR_5):...\n"", ""VAR_10 = super().get_context_data(**kwargs)\n"", ""VAR_11 = SearchForm(self.request.GET)\n"", ""VAR_10['search_form'] = VAR_11\n"", ""VAR_12 = self.object_list.count()\n"", ""VAR_10['count'] = VAR_12\n"", ""VAR_10['30_day_labels'] = self.thirty_day_labels()\n"", ""VAR_10['30_day_data'] = self.thirty_day_data()\n"", ""return VAR_10\n""]",1
"[""def __init__(self, VAR_8):...\n"", ""self.entries = []\n"", ""self.filename = VAR_8\n"", ""VAR_36 = theFile.read()\n"", ""return None\n"", ""VAR_15 = False\n"", ""theFile.close()\n"", ""VAR_16 = VAR_36.split(VAR_4())[-1]\n"", ""VAR_17 = VAR_16.split('\\n')\n"", ""VAR_18 = 'string'\n"", ""for VAR_44 in VAR_17:\n"", ""if VAR_44.strip() == '':\n"", ""if VAR_15 == False:\n"", ""VAR_35 = re.search(VAR_18, VAR_44)\n"", ""VAR_36 = VAR_36.strip()\n"", ""if VAR_35:\n"", ""VAR_37 = VAR_36.split('\\n')[0]\n"", ""VAR_43 = VAR_35.group(0)\n"", ""VAR_45 = None\n"", ""VAR_38 = VAR_36[:150]\n"", ""VAR_44 = VAR_44.replace(VAR_43, '').strip()\n"", ""if ':' in VAR_44:\n"", ""VAR_38 = VAR_38.split('------------')[0]\n"", ""VAR_45 = datetime.datetime.strptime(VAR_43, '<%a., %b. %d, %Y, %I:%M %p>')\n"", ""VAR_46 = VAR_44.split(':')[0]\n"", ""VAR_46 = '(no_key)'\n"", ""self.entries.append(CLASS_0('title', VAR_37, None))\n"", ""VAR_6 = ''.join(VAR_44.split(':')[1:]).strip()\n"", ""VAR_6 = VAR_44\n"", ""if '|' in VAR_6:\n"", ""if VAR_46 == 'title':\n"", ""VAR_51 = VAR_6.split('|')\n"", ""VAR_15 = True\n"", ""self.entries.append(CLASS_0(VAR_46, VAR_6, VAR_45))\n"", ""VAR_6 = []\n"", ""VAR_37 = VAR_6\n"", ""for VAR_52 in VAR_51:\n"", ""VAR_6.append(VAR_52.strip())\n""]",1
"[""def __init__(self, VAR_1, VAR_7, VAR_8, VAR_9, VAR_10=None, VAR_4=None):...\n"", ""GenericRequest.__init__(self, VAR_1, VAR_4)\n"", ""self.url = '%stasks/%s/submit' % (self.base_url, VAR_7[1])\n"", ""self.task = VAR_7\n"", ""self.submission_format = VAR_8\n"", ""self.filenames = VAR_9\n"", ""self.data = {}\n"", ""if VAR_10 is None:\n"", ""for filename in VAR_9:\n"", ""if VAR_10 is not None:\n"", ""VAR_23 = filename_to_language(filename)\n"", ""self.data = {'language': VAR_10}\n"", ""if VAR_23 is not None:\n"", ""VAR_10 = VAR_23.name\n""]",1
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_1.status_code, 200)\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_6 = mock.Mock()\n"", ""VAR_6.nsxlib_config = mock.Mock()\n"", ""VAR_6.nsxlib_config.username = 'nsxuser'\n"", ""VAR_6.nsxlib_config.password = 'nsxpassword'\n"", ""VAR_6.nsxlib_config.retries = 100\n"", ""VAR_6.nsxlib_config.insecure = True\n"", ""VAR_6.nsxlib_config.ca_file = None\n"", ""VAR_6.nsxlib_config.http_timeout = 99\n"", ""VAR_6.nsxlib_config.conn_idle_timeout = 39\n"", ""VAR_6.nsxlib_config.client_cert_provider = None\n"", ""VAR_7 = cluster.NSXRequestsHTTPProvider()\n"", ""VAR_8 = VAR_7.new_connection(VAR_6, cluster.Provider('9.8.7.6',\n    'https://9.8.7.6', 'nsxuser', 'nsxpassword', None))\n"", ""self.assertEqual(('nsxuser', 'nsxpassword'), VAR_8.auth)\n"", ""self.assertFalse(VAR_8.verify)\n"", ""self.assertIsNone(VAR_8.cert)\n"", ""self.assertEqual(100, VAR_8.adapters['https://'].max_retries.total)\n"", ""self.assertEqual(99, VAR_8.timeout)\n""]",1
"[""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""def FUNC_14(self):...\n"", ""while True:\n"", ""VAR_3 = random.randint(1, 2 ** 64 - 1)\n"", ""if not VAR_3 in self.response_handlers:\n"", ""return VAR_3\n""]",1
"[""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.disconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: network name (case sensitive)).')\n"", ""VAR_0.reply(\n    \""Done. If you want to reconnect this network, use the 'rehash' command.\"")\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""return\n"", ""control.remove_network(VAR_4)\n""]",0
"[""def FUNC_16(self):...\n"", ""self.assertTrue(zf._allowZip64)\n""]",0
"[""def FUNC_2(self):...\n"", ""return \""\""\""Task: %s (ID %d)\nFile: %s\n\""\""\"" % (self.task[1], self.task[0], repr\n    (self.filenames)) + GenericRequest.specific_info(self)\n""]",0
"[""def FUNC_16(VAR_0, VAR_3, VAR_1, VAR_4):...\n"", ""VAR_26 = int(VAR_0[3:])\n"", ""VAR_27 = VAR_1[-VAR_26]\n"", ""if VAR_27 < 0:\n"", ""VAR_22 = VAR_3[VAR_27]\n"", ""VAR_1.append(VAR_27)\n"", ""VAR_7 = SymbolicInput(VAR_4[0], 'Dup', VAR_22)\n"", ""VAR_3[VAR_4[0]] = VAR_7\n"", ""VAR_4[0] -= 1\n""]",1
"[""def FUNC_1(self):...\n"", ""return 'submit sources %s for task %s (ID %d) %s' % (repr(self.filenames),\n    self.task[1], self.task[0], self.url)\n""]",0
"[""def FUNC_6(self):...\n"", ""c.get(url_for('oauthclient.login', remote_app='test'))\n"", ""self.mock_response(VAR_5='test')\n"", ""self.mock_response(VAR_5='test_invalid')\n"", ""VAR_1 = c.get(url_for('oauthclient.authorized', remote_app='test', code='test')\n    )\n"", ""assert VAR_1.data == 'TEST'\n"", ""assert self.handled_remote.name == 'test'\n"", ""assert not self.handled_args\n"", ""assert not self.handled_kwargs\n"", ""assert self.handled_resp['access_token'] == 'test_access_token'\n"", ""VAR_1 = self.assertRaises(TypeError, c.get, url_for(\n    'oauthclient.authorized', remote_app='test_invalid', code='test'))\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import base64\n"", ""import json\n"", ""import logging\n"", ""import optparse\n"", ""import os\n"", ""import signal\n"", ""import sys\n"", ""import time\n"", ""import xsrf_client\n"", ""from utils import net\n"", ""from utils import on_error\n"", ""from utils import subprocess42\n"", ""from utils import zip_package\n"", ""VAR_0 = os.path.abspath(zip_package.get_main_script_path())\n"", ""VAR_1 = 102400\n"", ""VAR_2 = 30\n"", ""VAR_3 = 10\n"", ""VAR_4 = 3\n"", ""VAR_5 = signal.SIGBREAK if sys.platform == 'win32' else signal.SIGTERM\n"", ""VAR_6 = 0\n"", ""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = time.time()\n"", ""if VAR_20 > VAR_6:\n"", ""VAR_6 = VAR_20\n"", ""return VAR_6\n""]",1
"[""def __init__(self, *VAR_0, **VAR_1):...\n"", ""self.dbStr = '../Databases/Product.db'\n"", ""self.table_name = 'products'\n"", ""self.id_column = 'id'\n"", ""self.column_2 = 'upc'\n"", ""self.column_3 = 'name'\n"", ""self.column_4 = 'image'\n"", ""self.some_upc = ''\n"", ""self.result = ''\n""]",1
"[""def FUNC_13(VAR_7, VAR_1, VAR_12=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_7, six.text_type):\n"", ""VAR_7 = import_string(VAR_7)\n"", ""@wraps(VAR_7)...\n"", ""if VAR_12:\n"", ""return VAR_7(VAR_8[0], VAR_1, *VAR_8[1:], **kwargs)\n"", ""return VAR_7(VAR_1, *VAR_8, **kwargs)\n""]",0
"[""\""\""\""\ntakes in the name of a state as an argument and lists all cities of that state\n\""\""\""\n"", ""import MySQLdb\n"", ""from sys import argv\n"", ""if __name__ == '__main__':\n"", ""VAR_0 = []\n"", ""VAR_1 = MySQLdb.Connect(host='localhost', port=3306, user=argv[1], passwd=\n    argv[2], VAR_1=argv[3])\n"", ""VAR_2 = VAR_1.cursor()\n"", ""VAR_2.execute('string')\n"", ""VAR_3 = VAR_2.fetchall()\n"", ""for city in VAR_3:\n"", ""if city[2] == argv[4]:\n"", ""print(', '.join(VAR_0))\n"", ""VAR_0.append(city[1])\n"", ""VAR_2.close()\n"", ""VAR_1.close()\n""]",1
"[""def FUNC_8(VAR_15):...\n"", ""VAR_32 = VAR_15.to_dict()\n"", ""VAR_32['tags'] = AnnTag.get_ann_tags(VAR_15.id, self.sql_session)\n"", ""return VAR_32\n""]",0
"[""@memoized_property...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_44 = sha1()\n"", ""for cp_entry in [self._zinc.zinc, self._zinc.compiler_interface, self._zinc\n"", ""VAR_44.update(os.path.relpath(cp_entry, self.get_options().pants_workdir))\n"", ""VAR_45 = VAR_44.hexdigest()[:12]\n"", ""return os.path.join(self.get_options().pants_bootstrapdir, 'zinc', VAR_45)\n""]",1
"[""def FUNC_3(VAR_4):...\n"", """"]",0
"[""def FUNC_14(self, VAR_11, VAR_12):...\n"", ""self.common._cli_run('createhost -iscsi -add %s %s' % (VAR_11, VAR_12), None)\n""]",1
"[""import collections\n"", ""import csv\n"", ""import functools\n"", ""import io\n"", ""import zipfile\n"", ""from operator import attrgetter\n"", ""import mimetypes\n"", ""from django.conf import settings\n"", ""from django.core.exceptions import ValidationError\n"", ""from django.db import connection, models\n"", ""from django.http import HttpResponse, StreamingHttpResponse\n"", ""from django.utils.decorators import method_decorator\n"", ""from django.utils.timezone import now\n"", ""from django.views.decorators.gzip import gzip_page\n"", ""from rest_framework import permissions\n"", ""from rest_framework.views import APIView\n"", ""from alice.authenticators import IsDataTeamServer\n"", ""from ..constants import BREAKDOWN_TYPES\n"", ""from ..models import Advisor, Breakdown, CustomerResponse, Notification, Win\n"", ""from ..serializers import CustomerResponseSerializer, WinSerializer\n"", ""from users.models import User\n"", ""\""\""\"" Endpoint returning CSV of all Win data, with foreign keys flattened \""\""\""\n"", ""VAR_0 = permissions.IsAdminUser,\n"", ""VAR_1 = WinSerializer().fields\n"", ""VAR_2 = CustomerResponseSerializer().fields\n"", ""VAR_3 = ['responded', 'sent', 'country_name', 'updated', 'complete', 'type',\n    'type_display', 'export_experience_display', 'location']\n"", ""def __init__(self, **VAR_4):...\n"", ""self.users_map = {u.id: u for u in User.objects.all()}\n"", ""VAR_18 = [('advisors', Advisor), ('breakdowns', Breakdown), (\n    'confirmations', CustomerResponse), ('notifications', Notification)]\n"", ""self.table_maps = {}\n"", ""for VAR_11, VAR_6 in VAR_18:\n"", ""VAR_42 = collections.defaultdict(list)\n"", ""super().__init__(**kwargs)\n"", ""VAR_43 = VAR_6.objects.all()\n"", ""def FUNC_0(self, VAR_5):...\n"", ""if VAR_11 == 'notifications':\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_43 = VAR_43.filter(type='c').order_by('created')\n"", ""for instance in VAR_43:\n"", ""VAR_19 = self.table_maps['breakdowns'][VAR_5['id']]\n"", ""VAR_42[instance.win_id].append(instance)\n"", ""self.table_maps[VAR_11] = VAR_42\n"", ""VAR_20 = []\n"", ""for db_val, VAR_7 in BREAKDOWN_TYPES:\n"", ""VAR_44 = [b for b in VAR_19 if b.type == db_val]\n"", ""return VAR_20\n"", ""VAR_44 = sorted(VAR_44, key=attrgetter('year'))\n"", ""for index in range(5):\n"", ""VAR_52 = '{0}: {1:,}'.format(VAR_44[index].year, VAR_44[index].value)\n"", ""VAR_52 = None\n"", ""VAR_20.append(('{0} breakdown {1}'.format(VAR_7, index + 1), VAR_52))\n""]",0
"[""import sqlobject\n"", ""import vdm.sqlobject.base as vdmbase\n"", ""import vdm.base as vdmbase\n"", ""VAR_16 = 'name'\n"", ""from vdm.sqlobject.base import State\n"", ""from vdm.base import State\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_1 = sqlobject.MultipleJoin('Package')\n"", ""VAR_2 = sqlobject.ForeignKey('Package', cascade=True)\n"", ""VAR_3 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_4 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_5 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_6 = sqlobject.ForeignKey('License', default=None)\n"", ""VAR_7 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_2 = sqlobject.ForeignKey('Tag', cascade=True)\n"", ""VAR_2 = sqlobject.ForeignKey('PackageTag', cascade=True)\n"", ""VAR_8 = CLASS_1\n"", ""VAR_9 = vdmbase.get_attribute_names(VAR_8)\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_10 = [('tags', 'ckan.models.package', 'Tag', 'PackageTag')]\n"", ""def FUNC_0(self, VAR_11):...\n"", ""VAR_14 = self.revision.model.tags.get(VAR_11)\n"", ""VAR_14 = self.transaction.model.tags.create(VAR_0=tagname)\n"", ""self.tags.create(VAR_14=tag)\n"", ""VAR_8 = CLASS_2\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_9 = vdmbase.get_attribute_names(VAR_8)\n"", ""VAR_10 = [('packages', 'ckan.models.package', 'Package', 'PackageTag')]\n"", ""@classmethod...\n"", ""VAR_17 = str(VAR_12)\n"", ""VAR_18 = \""UPPER(tag.name) LIKE UPPER('%%%s%%')\"" % VAR_17\n"", ""return self.select(VAR_18)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from __future__ import print_function\n"", ""import os\n"", ""from six import iteritems\n"", ""import config as bconfig\n"", ""from invenio.legacy.bibclassify import ontology_reader as reader\n"", ""import text_extractor as extractor\n"", ""import text_normalizer as normalizer\n"", ""import keyword_analyzer as keyworder\n"", ""import acronym_analyzer as acronymer\n"", ""from invenio.utils.url import make_user_agent_string\n"", ""from invenio.utils.text import encode_for_xml\n"", ""VAR_0 = bconfig.get_logger('bibclassify.engine')\n"", ""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""def FUNC_1(VAR_14, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""VAR_15 = None\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_75 = ''\n"", ""VAR_0.info('Analyzing keywords for local file %s.' % VAR_14)\n"", ""if os.path.isdir(entry):\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_14)\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""return FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5=\n    spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""@VAR_0.route('/<page_name>/edit')...\n"", ""VAR_3 = VAR_1.query('string' % VAR_2)\n"", ""VAR_4 = VAR_3.namedresult()\n"", ""if len(VAR_4) > 0:\n"", ""VAR_7 = VAR_4[0].content\n"", ""VAR_7 = ''\n"", ""return render_template('edit_page.html', VAR_2=page_name, VAR_7=content)\n""]",1
"[""def FUNC_11(self):...\n"", ""self.assertFalse(self.course_module.is_after_open(self.yesterday))\n"", ""self.assertTrue(self.course_module.is_after_open(self.today))\n"", ""self.assertTrue(self.course_module.is_after_open())\n"", ""self.assertTrue(self.course_module.is_after_open(self.tomorrow))\n"", ""self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))\n""]",0
"[""@mock.patch('requests.post', FUNC_0)...\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 404)\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_7 = {'values': json.dumps({'NEW_URL1': 'http://localhost:8080/'})}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_10 = json.dumps({'PATH': 'bin:/usr/local/bin:/usr/bin:/bin'})\n"", ""VAR_7 = {'image': 'autotest/example'}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['count'], 4)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v2'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_9 = VAR_5.data\n"", ""self.assertEquals(VAR_9['version'], 2)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v4'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_12 = VAR_5.data\n"", ""self.assertEquals(VAR_12['version'], 4)\n"", ""self.assertNotEqual(VAR_9['uuid'], VAR_12['uuid'])\n"", ""self.assertEqual(VAR_9['build'], VAR_12['build'])\n"", ""self.assertEqual(VAR_9['config'], VAR_12['config'])\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_7 = {'version': 1}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['count'], 5)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v1'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_8 = VAR_5.data\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v5'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_13 = VAR_5.data\n"", ""self.assertEqual(VAR_13['version'], 5)\n"", ""self.assertNotEqual(VAR_8['uuid'], VAR_13['uuid'])\n"", ""self.assertEqual(VAR_8['build'], VAR_13['build'])\n"", ""self.assertEqual(VAR_8['config'], VAR_13['config'])\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['values'], {})\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_7 = {'version': 3}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_14 = VAR_5.data['values']\n"", ""self.assertIn('NEW_URL1', VAR_14)\n"", ""self.assertEqual('http://localhost:8080/', VAR_14['NEW_URL1'])\n""]",1
"[""def FUNC_20(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_21 = VAR_21.rstrip('/')\n"", ""VAR_60 = os.path.basename(VAR_21)\n"", ""VAR_61 = os.path.dirname(VAR_21)\n"", ""VAR_58 = self.getfile(VAR_21, VAR_23=False)\n"", ""if VAR_58 == False:\n"", ""if VAR_58[VAR_2] != VAR_12:\n"", ""if len(self.get_path(VAR_21)) > 0:\n"", ""VAR_62 = self.get_path(VAR_61, VAR_23=True)\n"", ""for i in VAR_62[:]:\n"", ""if i[VAR_1] == VAR_60:\n"", ""return False\n"", ""VAR_62.remove(i)\n"", ""return True\n""]",0
"[""@VAR_0.route('/statistics/<int:cid>')...\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('SELECT * FROM Crawls WHERE cid = %s' % VAR_7)\n"", ""VAR_30 = VAR_28.fetchall()[0]\n"", ""VAR_28.close()\n"", ""print(VAR_10.get('stats', None))\n"", ""print(VAR_30['stats'])\n"", ""VAR_31 = json.loads(VAR_30['stats'])\n"", ""VAR_32 = json.loads(VAR_30['hierarchy'])\n"", ""VAR_33 = VAR_31.items()\n"", ""VAR_34 = sum([subdict['n_tables_pages'] for filename, subdict in VAR_33])\n"", ""VAR_35 = sum([subdict['n_table_rows'] for filename, subdict in VAR_33])\n"", ""VAR_36 = sum([subdict['table_sizes']['medium'] for filename, subdict in VAR_33]\n    )\n"", ""VAR_37 = sum([subdict['table_sizes']['small'] for filename, subdict in VAR_33])\n"", ""VAR_38 = sum([subdict['table_sizes']['large'] for filename, subdict in VAR_33])\n"", ""VAR_39 = [subdict['creation_date'] for filename, subdict in VAR_33]\n"", ""VAR_40 = list(map(lambda str: pdf_date_format_to_datetime(str), VAR_39))\n"", ""if len(VAR_40) > 0:\n"", ""VAR_50 = min(VAR_40)\n"", ""VAR_50 = 'None'\n"", ""VAR_51 = max(VAR_40)\n"", ""VAR_51 = 'None'\n"", ""return render_template('statistics.html', VAR_21=crawl['pdf_crawled'],\n    VAR_24=crawl['pdf_processed'], VAR_34=n_tables, VAR_35=n_rows, n_errors\n    =crawl['process_errors'], VAR_17=crawl['domain'], VAR_37=small_tables,\n    VAR_36=medium_tables, VAR_38=large_tables, VAR_22=json_stats, hierarchy\n    =json_hierarchy, end_time=crawl['crawl_date'], crawl_total_time=round(\n    crawl['crawl_total_time'] / 60.0, 1), VAR_27=round(crawl[\n    'proc_total_time'] / 60.0, 1), VAR_50=oldest_pdf, VAR_51=most_recent_pdf)\n""]",1
"[""def FUNC_3(self, VAR_1, VAR_2, VAR_5, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_30 = VAR_4.get('states', [])\n"", ""VAR_31 = VAR_4.get('what', ())\n"", ""if not VAR_5:\n"", ""VAR_5 = self.search(VAR_1, VAR_2, [])\n"", ""VAR_29 = {}.fromkeys(VAR_5, 0.0)\n"", ""if not VAR_5:\n"", ""return VAR_29\n"", ""if VAR_4.get('shop', False):\n"", ""VAR_1.execute('select warehouse_id from sale_shop where id=%s', (int(VAR_4[\n    'shop']),))\n"", ""if VAR_4.get('warehouse', False):\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""VAR_1.execute('select lot_stock_id from stock_warehouse where id=%s', (int(\n    VAR_4['warehouse']),))\n"", ""if VAR_4.get('location', False):\n"", ""if VAR_41:\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""if type(VAR_4['location']) == type(1):\n"", ""VAR_42 = []\n"", ""VAR_4['warehouse'] = VAR_41[0]\n"", ""if VAR_41:\n"", ""VAR_42 = [VAR_4['location']]\n"", ""if type(VAR_4['location']) in (type(''), type(u'')):\n"", ""VAR_43 = self.pool.get('stock.warehouse').search(VAR_1, VAR_2, [], VAR_4=\n    context)\n"", ""VAR_4['location'] = VAR_41[0]\n"", ""if VAR_4.get('compute_child', True):\n"", ""VAR_42 = self.pool.get('stock.location').search(VAR_1, VAR_2, [('name',\n    'ilike', VAR_4['location'])], VAR_4=context)\n"", ""VAR_42 = VAR_4['location']\n"", ""for w in self.pool.get('stock.warehouse').browse(VAR_1, VAR_2, VAR_43,\n"", ""VAR_44 = self.pool.get('stock.location').search(VAR_1, VAR_2, [(\n    'location_id', 'child_of', VAR_42)])\n"", ""VAR_42 = VAR_42\n"", ""VAR_42.append(w.lot_stock_id.id)\n"", ""VAR_42 = VAR_44 or VAR_42\n"", ""VAR_32 = {}\n"", ""VAR_33 = {}\n"", ""for VAR_45 in self.browse(VAR_1, VAR_2, VAR_5, VAR_4=context):\n"", ""VAR_33[VAR_45.id] = VAR_45.uom_id.id\n"", ""VAR_34 = []\n"", ""VAR_32[VAR_45.uom_id.id] = VAR_45.uom_id\n"", ""VAR_35 = []\n"", ""VAR_36 = VAR_4.get('from_date', False)\n"", ""VAR_37 = VAR_4.get('to_date', False)\n"", ""VAR_38 = False\n"", ""if VAR_36 and VAR_37:\n"", ""VAR_38 = \""date_planned>='%s' and date_planned<='%s'\"" % (VAR_36, VAR_37)\n"", ""if VAR_36:\n"", ""if 'in' in VAR_31:\n"", ""VAR_38 = \""date_planned>='%s'\"" % VAR_36\n"", ""if VAR_37:\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""if 'out' in VAR_31:\n"", ""VAR_38 = \""date_planned<='%s'\"" % VAR_37\n"", ""VAR_34 = VAR_1.fetchall()\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""VAR_39 = self.pool.get('product.uom')\n"", ""VAR_35 = VAR_1.fetchall()\n"", ""VAR_40 = map(lambda x: x[2], VAR_34) + map(lambda x: x[2], VAR_35)\n"", ""if VAR_4.get('uom', False):\n"", ""VAR_40 += [VAR_4['uom']]\n"", ""VAR_40 = filter(lambda x: x not in VAR_32.keys(), VAR_40)\n"", ""if VAR_40:\n"", ""VAR_40 = VAR_39.browse(VAR_1, VAR_2, list(set(VAR_40)), VAR_4=context)\n"", ""for VAR_46 in VAR_40:\n"", ""VAR_32[VAR_46.id] = VAR_46\n"", ""for VAR_47, prod_id, prod_uom in VAR_34:\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""for VAR_47, prod_id, prod_uom in VAR_35:\n"", ""VAR_29[prod_id] += VAR_47\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""return VAR_29\n"", ""VAR_29[prod_id] -= VAR_47\n""]",1
"[""@tornado.web.asynchronous...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_5():...\n"", ""self.set_status(404, 'Not Found')\n"", ""self._headers = tornado.httputil.HTTPHeaders()\n"", ""self.add_header('Content-Length', '0')\n"", ""self.flush()\n"", ""return\n""]",1
"[""\""\""\""API endpoints dealing with surveys.\""\""\""\n"", ""from tornado.escape import json_encode\n"", ""import api.survey\n"", ""from pages.util.base import APIHandler, get_email\n"", ""\""\""\""The endpoint for getting all of a user's surveys.\""\""\""\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.write(api.survey.get_all(get_email(self)))\n"", ""\""\""\""The endpoint for getting a single survey.\""\""\""\n"", ""def FUNC_0(self, VAR_0: str):...\n"", ""VAR_1 = get_email(self)\n"", ""self.write(api.survey.get_one(VAR_0, VAR_1=email))\n""]",1
"[""def FUNC_1(self, VAR_6):...\n"", ""print('Login')\n"", ""print(VAR_6.url)\n"", ""yield scrapy.FormRequest.from_response(VAR_6, formdata=self.login_data,\n    callback=self.start_crawl)\n""]",1
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render\n"", ""from django.views.generic import TemplateView, DetailView\n"", ""from .forms import SearchForm\n"", ""from lib.geoip import GeoIP\n"", ""from lib.vt import VT\n"", ""from lib.threatminer import ThreatMiner\n"", ""import socket\n"", ""from django.db.models import Q\n"", ""from apps.threat.models import Event, Attribute\n"", ""from apps.reputation.models import blacklist\n"", ""from apps.twitter.models import tweet\n"", ""from apps.exploit.models import Exploit\n"", ""VAR_0 = 'domain/index.html'\n"", ""def FUNC_0(self, **VAR_1):...\n"", ""VAR_3 = super().get_context_data(**kwargs)\n"", ""VAR_3['search_form'] = SearchForm()\n"", ""return VAR_3\n""]",1
"[""@data(('9991', 'B0046A36-3F1C-11E9-9A87-005056AA6F01', 0, 0, 0), ('9992',...\n"", ""VAR_13 = {'sender': 'Alex Roy <Alex.Roy@dilfo.com>', 'subject':\n    f'Re: [EXTERNAL] Upcoming Holdback Release: #{VAR_6}', 'date':\n    'Thu, 30 May 2019 00:41:05 +0000', 'content':\n    f'{VAR_11}string{VAR_6}string{VAR_6}string{VAR_7}string'}\n"", ""VAR_14 = \""\""\""\n            INSERT INTO df_dilfo (job_number, closed)\n            VALUES ({}, {})\n        \""\""\""\n"", ""VAR_15 = \""\""\""\n            INSERT INTO df_matched (job_number, ground_truth)\n            VALUES ({}, {})\n        \""\""\""\n"", ""conn.cursor().execute(VAR_14.format(VAR_6, VAR_9))\n"", ""if VAR_8:\n"", ""if VAR_9:\n"", ""VAR_30 = pd.read_sql(f'SELECT * FROM df_dilfo WHERE job_number={VAR_6}', conn)\n"", ""conn.cursor().execute(VAR_15.format(VAR_6, 1))\n"", ""conn.cursor().execute(VAR_15.format(VAR_6, 0))\n"", ""VAR_31 = pd.read_sql(f'SELECT * FROM df_matched WHERE job_number={VAR_6}', conn\n    )\n"", ""process_as_reply(VAR_13)\n"", ""VAR_32 = pd.read_sql(f'SELECT * FROM df_dilfo WHERE job_number={VAR_6}', conn)\n"", ""VAR_33 = pd.read_sql(f'SELECT * FROM df_matched WHERE job_number={VAR_6}', conn\n    )\n"", ""self.assertEqual(len(VAR_30), len(VAR_32))\n"", ""self.assertEqual(VAR_32.iloc[0].closed, VAR_9 or VAR_11)\n"", ""self.assertEqual(any(VAR_33.ground_truth), VAR_9 or VAR_11)\n"", ""self.assertEqual(len(VAR_31) + (not VAR_9), len(VAR_33))\n"", ""self.assertEqual(list(VAR_31.columns), list(VAR_33.columns))\n"", ""self.assertEqual(list(VAR_30.columns), list(VAR_32.columns))\n""]",1
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""def FUNC_1(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12 = utils.param_to_list(VAR_0.query_params.get('org', []))\n"", ""VAR_12 = VAR_12 and VAR_12[0]\n"", ""VAR_2 = None\n"", ""if 'org_type' in VAR_0.query_params:\n"", ""VAR_2 = VAR_0.query_params['org_type'] + '_id'\n"", ""if VAR_12:\n"", ""if VAR_2 in ['pct_id', 'ccg_id']:\n"", ""if len(VAR_12) == 3:\n"", ""return VAR_12, VAR_2\n"", ""VAR_2 = 'pr.ccg_id'\n"", ""VAR_2 = 'pr.ccg_id'\n"", ""if len(VAR_12) == 6:\n"", ""VAR_2 = 'practice_id'\n"", ""assert False, 'Unexpected org: {}'.format(VAR_12)\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_0 = TestApp(main({}))\n"", ""self.assertTrue('filtered response' in VAR_0.get('/filtered').body)\n"", ""self.assertTrue('unfiltered' in VAR_0.post('/filtered').body)\n""]",0
"[""def FUNC_6(self, VAR_64):...\n"", ""if not VAR_64:\n"", ""return None\n"", ""VAR_88 = [int(i, 36) for i in VAR_64.split(',')]\n"", ""VAR_89 = Comment._byID(VAR_88, data=True, return_dict=False)\n"", ""return VAR_89\n""]",0
"[""def FUNC_3(VAR_3, VAR_4, VAR_0, VAR_1):...\n"", ""VAR_9 = []\n"", ""for table in VAR_4:\n"", ""VAR_2 = 'SELECT * FROM {} WHERE 1=0'.format(table)\n"", ""return VAR_9\n"", ""VAR_5 = FUNC_2(VAR_0, VAR_1, VAR_2)[0]\n"", ""VAR_15 = []\n"", ""for col in VAR_5:\n"", ""VAR_15.append(\""{} LIKE '%{}%'\"".format(col, VAR_3))\n"", ""VAR_15 = ' OR '.join(VAR_15)\n"", ""VAR_2 = 'SELECT * FROM {} WHERE {}'.format(table, VAR_15)\n"", ""VAR_16, VAR_17 = FUNC_2(VAR_0, VAR_1, VAR_2)\n"", ""VAR_9.append((table, VAR_16, VAR_17))\n""]",1
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {}\n"", ""for count in range(0, 50):\n"", ""if kb.dbms == 'Oracle' and VAR_0.endswith(' FROM DUAL'):\n"", ""return None\n"", ""VAR_0 = VAR_0[:-len(' FROM DUAL')]\n"", ""if count:\n"", ""VAR_0 += ', NULL'\n"", ""if kb.dbms == 'Oracle':\n"", ""VAR_0 += ' FROM DUAL'\n"", ""VAR_5 = agent.postfixQuery(VAR_0, VAR_1)\n"", ""VAR_6 = agent.payload(newValue=commentedQuery)\n"", ""VAR_7 = Request.queryPage(VAR_6)\n"", ""if not VAR_7 in VAR_2.keys():\n"", ""VAR_2[VAR_7] = 1, VAR_5\n"", ""VAR_2[VAR_7] = VAR_2[VAR_7][0] + 1, VAR_5\n"", ""if count:\n"", ""for element in VAR_2.values():\n"", ""if element[0] == 1:\n"", ""if kb.injPlace == 'GET':\n"", ""VAR_4 = '%s?%s' % (conf.url, VAR_6)\n"", ""if kb.injPlace == 'POST':\n"", ""return VAR_4\n"", ""VAR_4 = \""URL:\\t'%s'\"" % conf.url\n"", ""if kb.injPlace == 'Cookie':\n"", ""VAR_4 += \""\\nPOST:\\t'%s'\\n\"" % VAR_6\n"", ""VAR_4 = \""URL:\\t'%s'\"" % conf.url\n"", ""if kb.injPlace == 'User-Agent':\n"", ""VAR_4 += \""\\nCookie:\\t'%s'\\n\"" % VAR_6\n"", ""VAR_4 = \""URL:\\t\\t'%s'\"" % conf.url\n"", ""VAR_4 += \""\""\""\nUser-Agent:\t'%s'\n\""\""\"" % VAR_6\n""]",1
"[""def FUNC_0(self, VAR_3):...\n"", ""VAR_5 = '%s bool' % str(VAR_3)\n"", ""return VAR_5\n""]",0
"[""def FUNC_11(self):...\n"", ""if len(self.path) == 1:\n"", ""return '/'\n"", ""VAR_32 = ', '.join([str(each) for each in self.path])\n"", ""VAR_33 = VAR_0.select('directory', 'id in (' + VAR_32 + ')')\n"", ""return '/'.join([directory['name'] for directory in VAR_33])[1:]\n""]",1
"[""from __future__ import unicode_literals\n"", ""import frappe, json\n"", ""from frappe.utils import cstr, unique\n"", ""from frappe import _\n"", ""from six import string_types\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_12 = ['select', 'delete', 'drop', 'update', 'case', 'and', 'or', 'like']\n"", ""def FUNC_6():...\n"", ""VAR_13.throw(_('Invalid Search Field'), VAR_13.DataError)\n"", ""if len(VAR_0) >= 3:\n"", ""if '=' in VAR_0:\n"", ""@VAR_13.whitelist()...\n"", ""FUNC_6()\n"", ""if ' --' in VAR_0:\n"", ""FUNC_2(VAR_1, VAR_2, VAR_3, VAR_0=searchfield, VAR_5=page_length, VAR_4=filters\n    )\n"", ""FUNC_6()\n"", ""if any(' {0} '.format(keyword) in VAR_0.split() for keyword in VAR_12):\n"", ""VAR_13.response['results'] = FUNC_4(VAR_13.response['values'])\n"", ""FUNC_6()\n"", ""if any(keyword in VAR_0.split() for keyword in VAR_12):\n"", ""@VAR_13.whitelist()...\n"", ""FUNC_6()\n"", ""if isinstance(VAR_4, string_types):\n"", ""VAR_4 = json.loads(VAR_4)\n"", ""VAR_9 = VAR_13.get_meta(VAR_1)\n"", ""if VAR_0:\n"", ""FUNC_0(VAR_0)\n"", ""if not VAR_0:\n"", ""VAR_0 = 'name'\n"", ""VAR_14 = VAR_13.get_hooks().standard_queries or {}\n"", ""if VAR_3 and VAR_3.split()[0].lower() != 'select':\n"", ""VAR_13.response['values'] = VAR_13.call(VAR_3, VAR_1, VAR_2, VAR_0, VAR_6,\n    VAR_5, VAR_4, VAR_8=as_dict)\n"", ""if not VAR_3 and VAR_1 in VAR_14:\n"", ""def FUNC_3(VAR_9, VAR_10):...\n"", ""FUNC_2(VAR_1, VAR_2, VAR_14[VAR_1][0], VAR_0, VAR_6, VAR_5, VAR_4)\n"", ""if VAR_3:\n"", ""VAR_15 = VAR_9.search_fields and VAR_9.search_fields.split(',') or []\n"", ""VAR_13.throw(_('This query style is discontinued'))\n"", ""if isinstance(VAR_4, dict):\n"", ""VAR_16 = [VAR_9.title_field\n    ] if VAR_9.title_field and VAR_9.title_field not in VAR_15 else []\n"", ""VAR_25 = VAR_4.items()\n"", ""if VAR_4 == None:\n"", ""VAR_15 = ['name'] + VAR_15 + VAR_16\n"", ""VAR_4 = []\n"", ""VAR_4 = []\n"", ""VAR_19 = []\n"", ""if not VAR_10 in VAR_15:\n"", ""for f in VAR_25:\n"", ""if VAR_2:\n"", ""VAR_15 = VAR_15 + [VAR_10]\n"", ""return VAR_15\n"", ""if isinstance(f[1], (list, tuple)):\n"", ""VAR_26 = ['name']\n"", ""if VAR_9.get('fields', {'fieldname': 'enabled', 'fieldtype': 'Check'}):\n"", ""VAR_4.append([VAR_1, f[0], f[1][0], f[1][1]])\n"", ""VAR_4.append([VAR_1, f[0], '=', f[1]])\n"", ""if VAR_9.title_field:\n"", ""VAR_4.append([VAR_1, 'enabled', '=', 1])\n"", ""if VAR_9.get('fields', {'fieldname': 'disabled', 'fieldtype': 'Check'}):\n"", ""VAR_26.append(VAR_9.title_field)\n"", ""if VAR_9.search_fields:\n"", ""VAR_4.append([VAR_1, 'disabled', '!=', 1])\n"", ""VAR_20 = FUNC_3(VAR_9, VAR_0 or 'name')\n"", ""VAR_26.extend(VAR_9.get_search_fields())\n"", ""for f in VAR_26:\n"", ""if VAR_7:\n"", ""VAR_27 = VAR_9.get_field(f.strip())\n"", ""VAR_20 = list(set(VAR_20 + json.loads(VAR_7)))\n"", ""VAR_21 = [('`tab%s`.`%s`' % (VAR_9.name, f.strip())) for f in VAR_20]\n"", ""if f == 'name' or VAR_27 and VAR_27.fieldtype in ['Data', 'Text',\n"", ""VAR_21.append('locate(\""{_txt}\"", `tab{doctype}`.`name`) as `_relevance`'.\n    format(_txt=frappe.db.escape((txt or '').replace('%', '')), VAR_1=\n    frappe.db.escape(doctype)))\n"", ""VAR_19.append([VAR_1, f.strip(), 'like', '%{0}%'.format(VAR_2)])\n"", ""from frappe.model.db_query import get_order_by\n"", ""VAR_22 = get_order_by(VAR_1, VAR_9)\n"", ""VAR_23 = 'if(_relevance, _relevance, 99999), `tab{0}`.idx desc, {1}'.format(\n    VAR_1, VAR_22)\n"", ""VAR_24 = VAR_13.get_list(VAR_1, VAR_4=filters, VAR_20=formatted_fields,\n    VAR_19=or_filters, limit_start=start, limit_page_length=page_length,\n    VAR_23=order_by, ignore_permissions=True if doctype == 'DocType' else \n    False, as_list=not as_dict)\n"", ""if VAR_8:\n"", ""for r in VAR_24:\n"", ""VAR_13.response['values'] = [r[:-1] for r in VAR_24]\n"", ""r.pop('_relevance')\n"", ""VAR_13.response['values'] = VAR_24\n""]",1
"[""def FUNC_8(self, VAR_9, VAR_10=None, VAR_11=None):...\n"", ""get_and_check_project(VAR_9, VAR_11)\n"", ""VAR_28 = self.queryset.get(VAR_10=pk, VAR_1=project_pk)\n"", ""VAR_26 = CLASS_1(VAR_28)\n"", ""return Response(VAR_26.data)\n""]",0
"[""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n""]",0
"[""@property...\n"", ""return self.settings['collection']\n""]",0
"[""from __future__ import absolute_import\n"", ""from __future__ import division\n"", ""from __future__ import print_function\n"", ""import argparse\n"", ""import logging\n"", ""import os\n"", ""import time\n"", ""import traceback\n"", ""import redis\n"", ""import ray\n"", ""from ray.autoscaler.autoscaler import LoadMetrics, StandardAutoscaler\n"", ""import ray.cloudpickle as pickle\n"", ""import ray.gcs_utils\n"", ""import ray.utils\n"", ""import ray.ray_constants as ray_constants\n"", ""from ray.services import get_ip_address, get_port\n"", ""from ray.utils import binary_to_hex, binary_to_object_id, hex_to_binary, setup_logger\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""self.state = ray.experimental.state.GlobalState()\n"", ""self.state._initialize_global_state(VAR_1, VAR_2, VAR_4=redis_password)\n"", ""self.redis = VAR_42.StrictRedis(host=redis_address, port=redis_port, db=0,\n    password=redis_password)\n"", ""self.primary_subscribe_client = self.redis.pubsub(ignore_subscribe_messages\n    =True)\n"", ""self.local_scheduler_id_to_ip_map = {}\n"", ""self.load_metrics = LoadMetrics()\n"", ""if VAR_3:\n"", ""self.autoscaler = StandardAutoscaler(VAR_3, self.load_metrics)\n"", ""self.autoscaler = None\n"", ""self.issue_gcs_flushes = 'RAY_USE_NEW_GCS' in os.environ\n"", ""self.gcs_flush_policy = None\n"", ""if self.issue_gcs_flushes:\n"", ""VAR_31 = self.redis.lrange('RedisShards', 0, -1)\n"", ""def FUNC_0(self, VAR_5):...\n"", ""if len(VAR_31) > 1:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0.warning(\n    'Monitor: TODO: if launching > 1 redis shard, flushing needs to touch shards in parallel.'\n    )\n"", ""VAR_31 = VAR_31[0].split(b':')\n"", ""self.primary_subscribe_client.subscribe(VAR_5)\n"", ""self.issue_gcs_flushes = False\n"", ""self.redis_shard = VAR_42.StrictRedis(host=addr_port[0], port=addr_port[1],\n    password=redis_password)\n"", ""def FUNC_1(self, VAR_6, VAR_7):...\n"", ""self.redis_shard.execute_command('HEAD.FLUSH 0')\n"", ""VAR_0.info('Monitor: Turning off flushing due to exception: {}'.format(str(e)))\n"", ""\""\""\""docstring\""\""\""\n"", ""self.issue_gcs_flushes = False\n"", ""VAR_14 = ray.gcs_utils.GcsTableEntry.GetRootAsGcsTableEntry(VAR_7, 0)\n"", ""VAR_15 = VAR_14.Entries(0)\n"", ""VAR_16 = (ray.gcs_utils.HeartbeatBatchTableData.\n    GetRootAsHeartbeatBatchTableData(VAR_15, 0))\n"", ""for j in range(VAR_16.BatchLength()):\n"", ""VAR_32 = VAR_16.Batch(j)\n"", ""def FUNC_2(self, VAR_8):...\n"", ""VAR_33 = VAR_32.ResourcesAvailableLabelLength()\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_34 = {}\n"", ""VAR_17 = ray.gcs_utils.TablePrefix_RAYLET_TASK_string.encode('ascii')\n"", ""VAR_35 = {}\n"", ""VAR_18 = ray.gcs_utils.TablePrefix_OBJECT_string.encode('ascii')\n"", ""for i in range(VAR_33):\n"", ""VAR_19 = self.state.task_table()\n"", ""VAR_48 = VAR_32.ResourcesAvailableLabel(i)\n"", ""VAR_36 = ray.utils.binary_to_hex(VAR_32.ClientId())\n"", ""VAR_20 = binary_to_hex(VAR_8)\n"", ""VAR_49 = VAR_32.ResourcesTotalLabel(i)\n"", ""VAR_37 = self.local_scheduler_id_to_ip_map.get(VAR_36)\n"", ""VAR_21 = set()\n"", ""VAR_35[VAR_48] = VAR_32.ResourcesAvailableCapacity(i)\n"", ""if VAR_37:\n"", ""for task_id_hex, task_info in VAR_19.items():\n"", ""VAR_34[VAR_49] = VAR_32.ResourcesTotalCapacity(i)\n"", ""self.load_metrics.update(VAR_37, VAR_34, VAR_35)\n"", ""VAR_0.warning('Monitor: could not find ip for client {}'.format(VAR_36))\n"", ""VAR_38 = task_info['TaskSpec']\n"", ""VAR_22 = self.state.object_table()\n"", ""VAR_39 = VAR_38['DriverID']\n"", ""VAR_23 = set()\n"", ""if VAR_20 != VAR_39:\n"", ""for object_id, _ in VAR_22.items():\n"", ""VAR_21.add(hex_to_binary(task_id_hex))\n"", ""VAR_40 = ray._raylet.compute_task_id(object_id).binary()\n"", ""def FUNC_8(VAR_24):...\n"", ""if VAR_40 in VAR_21:\n"", ""return binary_to_object_id(VAR_24).redis_shard_hash() % len(self.state.\n    redis_clients)\n"", ""VAR_23.add(object_id.binary())\n""]",1
"[""def __str__(self):...\n"", ""return self.name\n""]",0
"[""def __init__(self, VAR_15):...\n"", ""self._store = []\n"", ""self._ds = VAR_15\n""]",0
"[""@property...\n"", ""return [(Allow, self.note.user_id, ('view', 'edit'))]\n""]",0
"[""def FUNC_23(VAR_3: int, VAR_4: str, VAR_19: str):...\n"", ""VAR_40 = get_template('level_upgrade_message_en.txt')\n"", ""if VAR_4 is not None:\n"", ""VAR_40 = VAR_40.replace('[USERNAME]', VAR_4)\n"", ""VAR_40 = VAR_40.replace('[LEVEL]', VAR_19)\n"", ""VAR_41 = Message()\n"", ""VAR_41.to_user_id = VAR_3\n"", ""VAR_41.subject = 'Mapper Level Upgrade '\n"", ""VAR_41.message = VAR_40\n"", ""VAR_41.save()\n""]",0
"[""def FUNC_2(self):...\n"", ""if self.resources is not None:\n"", ""assert 'CPU' not in self.resources, \""'CPU' should not be included in the resource dictionary. Use num_cpus instead.\""\n"", ""if self.num_workers is not None:\n"", ""assert 'GPU' not in self.resources, \""'GPU' should not be included in the resource dictionary. Use num_gpus instead.\""\n"", ""if self.include_java is None and self.java_worker_options is not None:\n""]",0
"[""def FUNC_39(self, VAR_20):...\n"", ""for VAR_14 in self.list_properties.keys():\n"", ""if self.is_relation(VAR_14):\n"", ""if VAR_20 == self.get_related_model(VAR_14):\n"", ""return VAR_14\n""]",0
"[""def FUNC_18(self, VAR_26, VAR_18):...\n"", ""VAR_31 = VAR_18.target.sources_snapshot(scheduler=self.context._scheduler)\n"", ""VAR_32 = tuple(os.path.relpath(f.path.replace('.java', '.class'), VAR_18.\n    target.target_base) for f in VAR_31.files if f.path.endswith('.java'))\n"", ""VAR_33 = ExecuteProcessRequest(argv=tuple(cmd), input_files=input_snapshot.\n    directory_digest, VAR_32=output_files, description=\n    'Compiling {} with javac'.format(ctx.target.address.spec))\n"", ""VAR_34 = self.context.execute_process_synchronously(VAR_33, 'javac', (\n    WorkUnitLabel.TASK, WorkUnitLabel.JVM))\n"", ""VAR_35 = VAR_18.classes_dir\n"", ""self.context._scheduler.materialize_directories((DirectoryToMaterialize(\n    text_type(VAR_35), VAR_34.output_directory_digest),))\n""]",1
"[""def FUNC_4(self, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = self.__con.cursor()\n"", ""VAR_19.execute(\n    \""DELETE FROM tasks WHERE tagid=(SELECT tagid FROM tags WHERE name='%s')\"" %\n    VAR_14)\n"", ""return CLASS_0.SUCCESS if VAR_19.execute(\""DELETE FROM tags WHERE name='%s'\"" %\n    VAR_14) else CLASS_0.DOES_NOT_EXIST\n""]",1
"[""def FUNC_1(self, VAR_3):...\n"", ""VAR_0 = [c for c in self.commands if c.id == VAR_3]\n"", ""if not VAR_0:\n"", ""VAR_7 = VAR_0[0]\n"", ""return VAR_7.run()\n""]",1
"[""def FUNC_0(VAR_2, VAR_3=None, VAR_4=None, VAR_5=5, VAR_6=None, VAR_7='POST'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 <= 0:\n"", ""logging.error('UrlOpen(%s): Invalid number of tries: %d', VAR_2, VAR_5)\n"", ""if VAR_6 and VAR_6 < 0:\n"", ""return None\n"", ""logging.error('UrlOpen(%s): Invalid wait duration: %d', VAR_2, VAR_6)\n"", ""VAR_3 = VAR_3 or {}\n"", ""return None\n"", ""if VAR_17.COUNT_KEY in VAR_3:\n"", ""logging.error(\""UrlOpen(%s): key '%s' is duplicate.\"", VAR_2, VAR_17.COUNT_KEY)\n"", ""VAR_11 = None\n"", ""return None\n"", ""for attempt in range(VAR_5):\n"", ""VAR_3[VAR_17.COUNT_KEY] = attempt\n"", ""logging.error('UrlOpen(%s): Unable to open after %d attempts', VAR_2, VAR_5)\n"", ""for VAR_18, VAR_9 in VAR_3.iteritems():\n"", ""if e.code >= 500:\n"", ""if VAR_11 is not None:\n"", ""return None\n"", ""if isinstance(VAR_9, basestring):\n"", ""VAR_20 = urllib.urlencode(VAR_3)\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s ', VAR_2, attempt, e)\n"", ""logging.exception('UrlOpen(%s): %s', VAR_2, e)\n"", ""logging.info('UrlOpen(%s) got %d bytes.', VAR_2, len(VAR_11))\n"", ""if attempt != VAR_5 - 1:\n"", ""VAR_3[VAR_18] = VAR_9.encode('utf-8', 'xmlcharrefreplace')\n"", ""if VAR_7 == 'POSTFORM':\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s', VAR_2, attempt, e)\n"", ""return None\n"", ""return VAR_11\n"", ""if VAR_6 is None:\n"", ""VAR_16, VAR_15 = FUNC_3(VAR_10=data.iteritems(), VAR_4=files)\n"", ""if VAR_7 == 'POST':\n"", ""VAR_23 = random.random() * 3 + math.pow(1.5, attempt + 1)\n"", ""VAR_23 = VAR_6\n"", ""VAR_15 = VAR_15 or ''\n"", ""VAR_11 = urllib2.urlopen(VAR_2, VAR_20, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_22 = list(urlparse.urlparse(VAR_2))\n"", ""VAR_23 = min(10, max(0.1, VAR_23))\n"", ""time.sleep(VAR_23)\n"", ""VAR_21 = urllib2.Request(VAR_2, VAR_3=body)\n"", ""VAR_22[VAR_0] = VAR_20\n"", ""VAR_21.add_header('Content-Type', VAR_16)\n"", ""VAR_2 = urlparse.urlunparse(VAR_22)\n"", ""VAR_21.add_header('Content-Length', len(VAR_15))\n"", ""VAR_11 = urllib2.urlopen(VAR_2, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_11 = urllib2.urlopen(VAR_21, timeout=URL_OPEN_TIMEOUT).read()\n""]",1
"[""def FUNC_0(VAR_4, VAR_5, VAR_6, VAR_7):...\n"", ""VAR_9 = FUNC_2()\n"", ""VAR_10 = VAR_9.cursor()\n"", ""VAR_10.execute('string'.format(VAR_4=playlist_id, VAR_5=title, VAR_6=\n    thumbnail, VAR_7=position))\n"", ""VAR_9.commit()\n"", ""VAR_9.close()\n""]",1
"[""def FUNC_7(self, VAR_13, VAR_4):...\n"", ""VAR_17, VAR_18 = VAR_13.compile(self.lhs)\n"", ""return \""(%s -> '%s')\"" % (VAR_17, self.key_name), VAR_18\n""]",1
"[""def FUNC_6(self):...\n"", ""VAR_20 = ''\n"", ""VAR_21 = self.UPC_Entry.get()\n"", ""if VAR_21 == '':\n"", ""VAR_33 = tk.Label(self.statusbar, text='UPC Cannot Be Empty', fg='red')\n"", ""if self.UPC_Entry.get() != '':\n"", ""VAR_33.pack()\n"", ""self.View_Result_Button = tk.Button(self.navbar, text='View Result', font=\n    self.controller.itemFont, command=lambda : self.controller.custom_frame())\n"", ""self.View_Result_Button.pack(side='left', pady=10, padx=10)\n"", ""VAR_20 = self.UPC_Entry.get()\n"", ""VAR_34 = dbc.DB_Connector()\n"", ""VAR_34.some_upc = VAR_20\n"", ""VAR_4 = VAR_34.fetch_product()\n"", ""self.controller.set_result(VAR_4)\n"", ""if VAR_4 is None:\n"", ""VAR_35 = tk.Label(self, text='No Result Found!', font=self.controller.itemFont)\n"", ""if VAR_4 is not None:\n"", ""VAR_35.pack()\n"", ""VAR_36 = tk.Label(self, text='Results Found!', font=self.controller.itemFont)\n"", ""self.View_Result_Button.config(state='disabled')\n"", ""VAR_36.pack()\n"", ""self.View_Result_Button.config(state='normal')\n""]",1
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = BokChoyTestSuite('', num_processes=2, verbosity=3)\n"", ""BokChoyTestSuite.verbosity_processes_string(VAR_7)\n""]",0
"[""@api.public...\n"", ""FUNC_31(self, 'DELETE')\n""]",0
"[""def FUNC_1(self):...\n"", ""return 'release test the %s-th submission for task %s (ID %d)' % (self.\n    submission_num, self.task[1], self.task[0])\n""]",0
"[""from __future__ import unicode_literals\n"", ""import tempfile\n"", ""import collections\n"", ""import six\n"", ""import json\n"", ""import yaml\n"", ""from flex.core import load_source\n"", ""def FUNC_0():...\n"", ""VAR_1 = {'foo': 'bar'}\n"", ""VAR_2 = load_source(VAR_1)\n"", ""assert VAR_2 == VAR_1\n"", ""def FUNC_1():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = json.dumps(VAR_3)\n"", ""VAR_2 = load_source(VAR_1)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_2():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = yaml.dump(VAR_3)\n"", ""VAR_2 = load_source(VAR_1)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_3():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = json.dumps(VAR_3)\n"", ""VAR_4 = tempfile.NamedTemporaryFile(mode='w')\n"", ""VAR_4.write(VAR_1)\n"", ""VAR_4.file.seek(0)\n"", ""VAR_2 = load_source(json_file)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_4():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = json.dumps(VAR_3)\n"", ""VAR_4 = tempfile.NamedTemporaryFile(mode='w', suffix='.json')\n"", ""VAR_4.write(VAR_1)\n"", ""VAR_4.flush()\n"", ""VAR_2 = load_source(VAR_4.name)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_5():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = yaml.dump(VAR_3)\n"", ""VAR_4 = tempfile.NamedTemporaryFile(mode='w')\n"", ""VAR_4.write(VAR_1)\n"", ""VAR_4.flush()\n"", ""VAR_2 = load_source(yaml_file)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_6():...\n"", ""VAR_3 = {'foo': 'bar'}\n"", ""VAR_1 = yaml.dump(VAR_3)\n"", ""VAR_4 = tempfile.NamedTemporaryFile(mode='w', suffix='.yaml')\n"", ""VAR_4.write(VAR_1)\n"", ""VAR_4.flush()\n"", ""VAR_2 = load_source(VAR_4.name)\n"", ""assert VAR_2 == VAR_3\n"", ""def FUNC_7(VAR_0):...\n"", ""VAR_3 = {'origin': '127.0.0.1', 'args': {}}\n"", ""VAR_1 = VAR_0.url + '/get'\n"", ""VAR_2 = load_source(VAR_1)\n"", ""assert isinstance(VAR_2, collections.Mapping)\n"", ""VAR_2.pop('headers')\n"", ""VAR_2.pop('url')\n"", ""assert VAR_2 == VAR_3\n""]",1
"[""def FUNC_12(self, **VAR_2):...\n"", ""VAR_27 = super().get_context_data(**kwargs)\n"", ""VAR_27['header'] = self.header\n"", ""VAR_27['filter'] = self.filter\n"", ""VAR_27['is_filtered'] = self.is_filtered\n"", ""return VAR_27\n""]",0
"[""def FUNC_24(VAR_6):...\n"", ""if 'Cache-Control' in VAR_6.headers:\n"", ""return True\n"", ""return False\n""]",0
"[""import rdflib\n"", ""import RDFClosure as owl_rl\n"", ""from pyshacl.shape import find_shapes\n"", ""if owl_rl.json_ld_available:\n"", ""import rdflib_jsonld\n"", ""import logging\n"", ""logging.basicConfig()\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""@classmethod...\n"", ""VAR_9['inference'] = True\n"", ""VAR_9['abort_on_error'] = False\n"", ""@classmethod...\n"", ""VAR_19 = owl_rl.DeductiveClosure(owl_rl.RDFS_OWLRL_Semantics)\n"", ""VAR_0.error('Error during creation of OWL-RL Deductive Closure')\n"", ""VAR_19.expand(VAR_2)\n"", ""VAR_0.error('Error while running OWL-RL Deductive Closure')\n"", ""def __init__(self, VAR_2, *VAR_3, VAR_4=None, VAR_10=None, **VAR_7):...\n"", ""if VAR_10 is None:\n"", ""VAR_10 = {}\n"", ""self._load_default_options(VAR_10)\n"", ""self.options = VAR_10\n"", ""assert isinstance(VAR_2, rdflib.Graph\n    ), 'target_graph must be a rdflib Graph object'\n"", ""self.target_graph = VAR_2\n"", ""if VAR_4 is None:\n"", ""VAR_4 = VAR_2\n"", ""assert isinstance(VAR_4, rdflib.Graph\n    ), 'shacl_graph must be a rdflib Graph object'\n"", ""self.shacl_graph = VAR_4\n"", ""def FUNC_4(self):...\n"", ""if self.options['inference']:\n"", ""self._run_pre_inference(self.target_graph)\n"", ""VAR_16 = find_shapes(self.shacl_graph)\n"", ""VAR_17 = {}\n"", ""for VAR_21 in VAR_16:\n"", ""VAR_20 = VAR_21.validate(self.target_graph)\n"", ""return VAR_17\n"", ""VAR_17[VAR_21.node] = VAR_20\n""]",1
"[""def FUNC_12():...\n"", ""populate_test_database()\n"", ""FUNC_1('first playlist')\n"", ""VAR_11 = VAR_3.post('/videos/1/title/thumbnail')\n"", ""assert VAR_11.json['status'] == 'OK'\n"", ""VAR_12 = VAR_3.delete('/videos/1/1')\n"", ""assert VAR_12.json['status'] == 'OK'\n"", ""VAR_13 = VAR_3.get('/videos/1')\n"", ""assert VAR_13.json['status'] == 'OK'\n"", ""assert VAR_13.json['data'] == []\n"", ""VAR_14 = VAR_3.get('/playlists/1')\n"", ""assert VAR_14.json['status'] == 'OK'\n"", ""assert VAR_14.json['data'] == dict(id=1, VAR_8='first playlist',\n    video_position=0)\n""]",0
"[""@eqlx.with_timeout...\n"", ""return 'no timeout'\n""]",0
"[""def FUNC_2(VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = \""\""\""\n    SELECT boot_val,\n           reset_val\n    FROM pg_settings\n    WHERE name = '%s'\n    \""\""\""\n"", ""VAR_3.execute(VAR_7 % VAR_4)\n"", ""VAR_8 = VAR_3.fetchone()\n"", ""if VAR_3.rowcount > 0:\n"", ""VAR_15, VAR_16 = VAR_8[0], VAR_8[1]\n"", ""return False\n"", ""return VAR_15 == VAR_16\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from lxml import etree\n"", ""from cinder import exception\n"", ""from cinder.openstack.common import log as logging\n"", ""from cinder.volume.drivers.san.san import SanISCSIDriver\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""VAR_1 = {}\n"", ""def __init__(self, *VAR_2, **VAR_3):...\n"", ""super(CLASS_0, self).__init__(*VAR_2, **kwargs)\n"", ""self.cluster_vip = None\n"", ""def FUNC_0(self, VAR_4, VAR_5, VAR_6=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = []\n"", ""for VAR_43, v in VAR_5.items():\n"", ""VAR_14.append(' %s=%s' % (VAR_43, v))\n"", ""VAR_15 = VAR_4 + ''.join(VAR_14)\n"", ""return self._run_ssh(VAR_15, VAR_6)\n""]",1
"[""def __hash__(self):...\n"", ""return self.name.__hash__()\n""]",0
"[""from osv import osv\n"", ""from tools.translate import _\n"", ""VAR_0 = 'pos.close.statement'\n"", ""VAR_1 = 'Close Statements'\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""def FUNC_10(VAR_18):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_35 = FUNC_8('contest/' + VAR_68(VAR_18) + '/users')\n"", ""VAR_36 = re.findall('string', VAR_35.text, re.X)\n"", ""VAR_38 = {}\n"", ""for VAR_46 in VAR_36:\n"", ""VAR_60, VAR_61, VAR_57, VAR_54 = VAR_46\n"", ""return VAR_38\n"", ""VAR_57 = int(VAR_57)\n"", ""VAR_38[VAR_54] = {'firstname': VAR_60, 'lastname': VAR_61, 'id': VAR_57}\n""]",0
"[""def __init__(self, VAR_7):...\n"", ""self._user_options = VAR_7\n"", ""self._user_notified_about_crash = False\n"", ""self._diag_interface = DiagnosticInterface(VAR_7)\n"", ""self._omnicomp = OmniCompleter(VAR_7)\n"", ""self._latest_completion_request = None\n"", ""self._latest_file_parse_request = None\n"", ""self._server_stdout = None\n"", ""self._server_stderr = None\n"", ""self._server_popen = None\n"", ""self._filetypes_with_keywords_loaded = set()\n"", ""self._temp_options_filename = None\n"", ""self._ycmd_keepalive = YcmdKeepalive()\n"", ""self._SetupServer()\n"", ""self._ycmd_keepalive.Start()\n""]",1
"[""def FUNC_6(VAR_1):...\n"", ""VAR_6 = sqlite3.connect('database.db')\n"", ""VAR_7 = VAR_6.cursor()\n"", ""return VAR_7.execute(\n    \""SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\"" + str(VAR_1\n    .id) + \""'\"").fetchone()[0]\n""]",1
"[""def FUNC_3(VAR_1, VAR_2=False):...\n"", ""VAR_4 = current_app.config.get('SAML2_LOGIN_REDIRECT_URL', '/')\n"", ""VAR_5 = request.args.get('next', VAR_4)\n"", ""VAR_6 = current_app.saml2_config.getattr('idp')\n"", ""assert len(VAR_6) == 1\n"", ""VAR_7 = VAR_6.keys()[0]\n"", ""VAR_7 = request.args.get('idp', VAR_7)\n"", ""VAR_8 = request.args.get('required_loa', None)\n"", ""VAR_9 = get_authn_request(current_app.config, VAR_3, VAR_5, VAR_7,\n    required_loa=loa, VAR_2=force_authn)\n"", ""schedule_action(VAR_1)\n"", ""current_app.logger.info('Redirecting the user to the IdP for ' + VAR_1)\n"", ""return redirect(get_location(VAR_9))\n""]",1
"[""@utils.synchronized('3par', external=True)...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.common.client_login()\n"", ""self.common.terminate_connection(VAR_6, VAR_9['host'], VAR_9['wwpns'])\n"", ""self.common.client_logout()\n""]",0
"[""def FUNC_2(self):...\n"", ""VAR_4 = {'username': 'first', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(VAR_6.data['is_superuser'])\n"", ""VAR_4 = {'username': 'second', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertFalse(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='first', VAR_2='password'))\n"", ""VAR_5 = '/api/admin/perms'\n"", ""VAR_7 = {'username': 'second'}\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""VAR_6 = self.client.get(VAR_5)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 2)\n"", ""self.assertIn('second', str(VAR_6.data['results']))\n""]",1
"[""import MELEE_SINGLES_BRACKETS\n"", ""import WIIU_BRACKETS\n"", ""import SMASH_5_BRACKETS\n"", ""VAR_0 = 'ec2-18-218-117-97.us-east-2.compute.amazonaws.com'\n"", ""VAR_1 = [['christmasmike', 'thanksgiving mike', 'christmas mike',\n    'christmas mike xmas', 'christmas mike late', 'halloween mike', 'im 12',\n    'im12'], ['circuits', 'circuits', 'jkelle', 'circuits xmas'], [\n    'gamepad', 'sms gamepad'], ['remo', 'su remo'], ['kuro', 'ss kuro'], [\n    'pixlsugr', 'pixlsug', 'pixlsugar'], ['b00', 'boo'], ['hnic',\n    'hnic xmas'], ['1111', '11 11', 'vuibol'], ['qmantra', 'qmantra xmas'],\n    ['megafox', 'su | megafox'], ['hakii', 'su l hakii', 'su | hakii',\n    'su redriot i hakii', 'hih | hakii', 'su | sleepyhakii', 'su|hakii',\n    'su | hakii $', 'su  redriot i hakii', 'hoh | hakii', 'su| hakii'], [\n    'lucy', 'ttn | lucy'], ['moist', 'f9moist', 'kuyamoist'], ['sassy',\n    'atx | sassy', 'f9sassy'], ['crump', 'donald crump', 'captain crump',\n    'abc | crump'], ['dragonite', 'datuglynigwhofkurmomin2ndgrade',\n    'tmg dragonite', 'su dragonite', 'su | dragonite', 'tpwn | dragonite',\n    'tpwn | dragonite_pr', 'tpwn| dragonite (gnw)', 'atx hoh | dragonite',\n    'dragonite_pr', 'hoh | dragonite', 'mega dragonite', 'tpwn|dragonite',\n    'armada | dragonite', 'aes | dragonite'], ['gallium', 's.e.s punk',\n    'ses punk'], ['mt', 'mt_'], ['wolf', ' wolf'], ['fx | albert', 'albert'\n    ], ['ul | jf', 'jf', 'ul| jf', 'ul i jf'], ['take a seat', 'take a \\\\_',\n    'take a \\\\_', 'takeaseat', 'take a seat xmas'], ['bobby big ballz',\n    'bobby big balls'], ['prof. cube', 'type r professor cube', 'prof cube',\n    'professor cube', 'profesor cube', 'cube', 'processorcube',\n    'prof cube $'], ['cashoo', 'hoh | cashoo', 'hoh l cashoo', 'cash00'], [\n    'ul | chandy', 'ul| chandy', 'cnb | chandy', 'chandy'], ['spankey',\n    'spanky'], ['jack the reaper', 'jackthereaper'], ['xlll', 'xiii'], [\n    'cheesedud6', '/cheesedud6'], ['kj', 'go! kj', 'go kj'], ['jtag',\n    'tgl | jtag', 'sms | jtag', 'sms jtag', 'jtg', 'j tag'], ['jka',\n    'tgl | jka'], ['fcar', 'tgl | fcar'], ['resident', 'tgl | resident'], [\n    'minty!', 'tgl | minty!', 'tgl | minty', 'minty'], ['willow',\n    'willowette'], ['messiah', 'maple'], ['tenni', 'go! tenni'], ['cruzin',\n    'sa  cruzin'], ['christmasmitch', 'mitchell', 'mitchell slan'], ['jibs',\n    'sfu jibs'], ['trane', 'irn trane'], ['ninjafish', 'sa  ninjafish'], [\n    'mufin', 'sfu mufin'], ['jowii', 'jo wii'], ['gudlucifer',\n    'good lucifer', 'goodlucifer', 'gudlucifer wolf'], ['ehmon',\n    'tgl ehmon', 'tgl  ehmon', 'ah ehmon', 'sms ehmon', 'sms | ehmon',\n    'tgl | ehmon', 'ehhhmon'], ['pollo loco', 'pollo'], ['doombase',\n    'retiredbase'], ['majinmike', 'majin mike'], ['karonite', 'red velvet',\n    'aos redvelvet', 'redvelvet']]\n"", ""VAR_2 = 'austin', {'enumerated': ['http://challonge.com/heatwave###',\n    'https://challonge.com/NP9ATX###', 'http://challonge.com/hw###',\n    'https://challonge.com/alibaba###'], 'users': [\n    'https://challonge.com/users/kuya_mark96',\n    'https://austinsmash4.challonge.com']}\n"", ""VAR_3 = 'smashbrews', {'enumerated': ['https://challonge.com/Smashbrews###',\n    'https://challonge.com/smashbrewsS3W###',\n    'https://challonge.com/smashbrewsS4W###',\n    'https://challonge.com/smashbrewsS5W###']}\n"", ""VAR_4 = 'colorado', {'enumerated': [\n    'http://smashco.challonge.com/CSUWW###WUS',\n    'http://smascho.challonge.com/FCWUA###',\n    'http://smascho.challonge.com/FCWUIB###']}\n"", ""VAR_5 = 'colorado_doubles', {'enumerated': [\n    'http://smashco.challonge.com/CSUWW###WUD',\n    'http://smashco.challonge.com/FCWUDC###']}\n"", ""VAR_6 = 'colorado_both', {'enumerated': VAR_4 + VAR_5}\n"", ""VAR_7 = 'sms', {'enumerated': ['http://challonge.com/RAA_###',\n    'http://challonge.com/SMSH_###'], 'users': [\n    'https://challonge.com/users/yellocake']}\n"", ""VAR_8 = {'heatwave': 'Heatwave', 'NP9ATX': 'NP9', 'challonge.com/hw':\n    'Heatwave', 'challonge.com/atx': 'Smashpack', 'alibaba': 'Alibaba',\n    'Mothership': 'Mothership', 'atxfiles': 'ATX Files', 'ARFI': 'ARFI',\n    'arcadian': 'Arcadian', 'ooples': 'Ooples', 'challonge.com/mbh':\n    'Michaels Big House', 'challonge.com/sth': 'Smash The Halls',\n    'smashbrewsS3': 'Smashbrews S3', 'smashbrewsS4': 'Smashbrews S4',\n    'smashbrewsS5': 'Smashbrews S5', 'Smashbrews': 'Smashbrews', 'smashco':\n    'CSU', 'smascho': 'CSU', 'RAA': 'Reading At Alkek'}\n"", ""VAR_9 = MELEE_SINGLES_BRACKETS.MELEE_SINGLES\n"", ""VAR_10 = WIIU_BRACKETS.WII_U_BRACKETS\n"", ""VAR_11 = SMASH_5_BRACKETS.SMASH_5_BRACKETS\n"", ""VAR_12 = 10 * 60 * 6\n"", ""VAR_13 = 20\n"", ""VAR_14 = [('test1', ['https://challonge.com/smash_web_test_###']), ('test2',\n    ['https://challonge.com/smash_web_scene_two_###'])]\n"", ""\""\""\""string\""\""\""\n""]",1
"[""def FUNC_5(self):...\n"", ""for VAR_21 in range(0, self.dim_x):\n"", ""self.board.append([])\n"", ""for VAR_22 in range(0, self.dim_y):\n"", ""VAR_25 = CLASS_0()\n"", ""self.board[VAR_21].append(VAR_25)\n""]",0
"[""@login_required()...\n"", ""VAR_3 = get_object_or_404(DataGroup, VAR_2=pk)\n"", ""VAR_18 = DataGroupForm(VAR_0.POST or None, instance=datagroup)\n"", ""VAR_16 = f'Update Data Group for Data Source \""{VAR_3.data_source}\""'\n"", ""if VAR_18.is_valid():\n"", ""if VAR_18.has_changed():\n"", ""VAR_18.referer = VAR_0.META.get('HTTP_REFERER', None)\n"", ""VAR_18.save()\n"", ""return redirect('data_group_detail', VAR_2=datagroup.id)\n"", ""if VAR_3.extracted_docs():\n"", ""VAR_18.fields['group_type'].disabled = True\n"", ""VAR_19 = GroupType.objects.all()\n"", ""for group in VAR_19:\n"", ""group.codes = DocumentType.objects.filter(group_type=group)\n"", ""return render(VAR_0, VAR_1, {'datagroup': VAR_3, 'form': VAR_18, 'header':\n    VAR_16, 'groups': VAR_19})\n""]",0
"[""import wzrpc\n"", ""from sup.ticker import Ticker\n"", ""def __init__(self, VAR_0, *VAR_1, **VAR_2):...\n"", ""super().__init__()\n"", ""self.ev_init = VAR_0\n"", ""self.bind_kt_ticker = Ticker()\n"", ""self.bind_kt = 5\n"", ""def FUNC_0(self, VAR_3, VAR_4, VAR_5, VAR_6):...\n"", ""VAR_10, VAR_11 = VAR_6\n"", ""self.p.log.info('Recvd page %s, working on', VAR_3)\n"", ""VAR_12 = self.ev.solve_capage(VAR_10, VAR_11)\n"", ""self.p.log.info('Done, sending answer: %s', VAR_12)\n"", ""self.p.send_success_rep(VAR_3, [v.encode('utf-8') for v in VAR_12])\n"", ""def FUNC_1(self):...\n"", ""VAR_13 = self.p.wz.make_req_msg(b'Router', b'bind-keepalive', [], self.\n    handle_keepalive_reply)\n"", ""VAR_13.insert(0, b'')\n"", ""self.p.wz_sock.send_multipart(VAR_13)\n"", ""def FUNC_2(self, VAR_3, VAR_7, VAR_8, VAR_6):...\n"", ""if VAR_8 == wzrpc.status.success:\n"", ""self.p.log.debug('Keepalive was successfull')\n"", ""if VAR_8 == wzrpc.status.e_req_denied:\n"", ""def __call__(self, VAR_9):...\n"", ""self.p.log.warn('Keepalive status {0}, reauthentificating and rebinding'.\n    format(wzrpc.name_status(VAR_8)))\n"", ""if VAR_8 == wzrpc.status.e_timeout:\n"", ""self.p = VAR_9\n"", ""self.p.auth_requests()\n"", ""self.p.log.warn('Keepalive timeout')\n"", ""self.p.log.warn('Keepalive status {0}'.format(wzrpc.name_status(VAR_8)))\n"", ""self.p.wz_connect()\n"", ""self.p.bind_methods()\n"", ""self.p.wz_auth_requests = [(b'Router', b'auth-bind-route'), (b'Router',\n    b'auth-unbind-route'), (b'Router', b'auth-set-route-type')]\n"", ""self.p.wz_bind_methods = [(b'Evaluator', b'evaluate', self.handle_evaluate,\n    wzrpc.routetype.random)]\n"", ""self.p.auth_requests()\n"", ""self.p.bind_methods()\n"", ""self.ev = self.ev_init()\n"", ""self.bind_kt_ticker.tick()\n"", ""while self.p.running.is_set():\n"", ""VAR_14 = self.p.poll()\n"", ""if self.bind_kt_ticker.elapsed(False) > self.bind_kt:\n"", ""self.bind_kt_ticker.tick()\n"", ""self.send_keepalive()\n""]",1
"[""def FUNC_10(VAR_32=None, VAR_33=None, VAR_22=None, VAR_23=None, VAR_5=False,...\n"", ""if VAR_34:\n"", ""VAR_78 = VAR_32[0:VAR_34]\n"", ""VAR_78 = VAR_32\n"", ""VAR_79 = VAR_33[0:VAR_34]\n"", ""VAR_79 = VAR_33\n"", ""VAR_57 = {'Core keywords': FUNC_19(VAR_32, VAR_33, VAR_5=spires)}\n"", ""if not VAR_10:\n"", ""VAR_57['Author keywords'] = FUNC_17(VAR_22, VAR_5=spires)\n"", ""return VAR_57\n"", ""VAR_57['Composite keywords'] = FUNC_15(VAR_79, VAR_5=spires)\n"", ""VAR_57['Single keywords'] = FUNC_14(VAR_78, VAR_5=spires)\n"", ""VAR_57['Field codes'] = FUNC_18(VAR_78, VAR_79, VAR_5=spires)\n"", ""VAR_57['Acronyms'] = FUNC_16(VAR_23)\n""]",0
"[""def FUNC_5(self):...\n"", ""VAR_24 = 'katotest-httplb-' + self.test_id\n"", ""self.__use_http_lb_name = VAR_24\n"", ""self.__use_http_lb_hc_name = VAR_24 + '-health-check'\n"", ""self.__use_http_lb_bs_name = VAR_24 + '-backend-service'\n"", ""self.__use_http_lb_fr_name = VAR_24\n"", ""self.__use_http_lb_map_name = VAR_24 + '-url-map'\n"", ""self.__use_http_lb_proxy_name = VAR_24 + '-target-http-proxy'\n"", ""VAR_25 = 231\n"", ""VAR_26 = 8\n"", ""VAR_27 = 9\n"", ""VAR_28 = 65\n"", ""VAR_29 = '/hello/world'\n"", ""VAR_30 = '80-80'\n"", ""VAR_31 = {'checkIntervalSec': VAR_25, 'healthyThreshold': VAR_26,\n    'unhealthyThreshold': VAR_27, 'timeoutSec': VAR_28, 'requestPath': VAR_29}\n"", ""VAR_21 = self.agent.type_to_payload('createGoogleHttpLoadBalancerDescription',\n    {'healthCheck': VAR_31, 'portRange': VAR_30, 'loadBalancerName': VAR_24,\n    'credentials': self.bindings['GCE_CREDENTIALS']})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Http Health Check Added').list_resources(\n    'http-health-checks').contains_pred_list([jc.PathContainsPredicate(\n    'name', self.__use_http_lb_hc_name), jc.PathContainsPredicate(None,\n    VAR_31)])\n"", ""VAR_20.new_clause_builder('Forwarding Rule Added', retryable_for_secs=15\n    ).list_resources('forwarding-rules').contains_pred_list([jc.\n    PathContainsPredicate('name', self.__use_http_lb_fr_name), jc.\n    PathContainsPredicate('portRange', VAR_30)])\n"", ""VAR_20.new_clause_builder('Backend Service Added').list_resources(\n    'backend-services').contains_pred_list([jc.PathContainsPredicate('name',\n    self.__use_http_lb_bs_name), jc.PathElementsContainPredicate(\n    'healthChecks', self.__use_http_lb_hc_name)])\n"", ""VAR_20.new_clause_builder('Url Map Added').list_resources('url-maps'\n    ).contains_pred_list([jc.PathContainsPredicate('name', self.\n    __use_http_lb_map_name), jc.PathContainsPredicate('defaultService',\n    self.__use_http_lb_bs_name)])\n"", ""VAR_20.new_clause_builder('Target Http Proxy Added').list_resources(\n    'target-http-proxies').contains_pred_list([jc.PathContainsPredicate(\n    'name', self.__use_http_lb_proxy_name), jc.PathContainsPredicate(\n    'urlMap', self.__use_http_lb_map_name)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'create_http_load_balancer', data=payload, VAR_29='ops'), contract=\n    builder.build())\n""]",1
"[""def FUNC_17():...\n"", ""VAR_56 = constants.AUSTIN_URLS\n"", ""VAR_57 = constants.SMASHBREWS_RULS\n"", ""VAR_58 = constants.COLORADO_SINGLES_URLS\n"", ""VAR_59 = constants.COLORADO_DOUBLES_URLS\n"", ""VAR_60 = constants.SMS_URLS\n"", ""VAR_20 = [VAR_60, VAR_57, VAR_56, VAR_59, VAR_58]\n"", ""return VAR_20\n""]",1
"[""import pymysql.cursors\n"", ""from config import create_connection\n"", ""VAR_0 = 'product_types'\n"", ""def FUNC_0():...\n"", ""VAR_1 = f\""\""\""\n            SELECT name\n            FROM {VAR_0}\n            \""\""\""\n"", ""VAR_2 = create_connection()\n"", ""VAR_2.close()\n"", ""VAR_3 = VAR_2.cursor()\n"", ""VAR_3.execute(VAR_1)\n"", ""return VAR_3.fetchall()\n""]",1
"[""def FUNC_4(self, VAR_2, VAR_1):...\n"", ""VAR_4 = 'delete from post_like where postid=%d and userid=%d;' % (VAR_2, VAR_1)\n"", ""VAR_5 = sql.deleteDB(self.conn, VAR_4)\n"", ""return VAR_5\n""]",1
"[""def FUNC_4(VAR_0, VAR_7: Note) ->CLASS_0:...\n"", ""if VAR_7.note_id:\n"", ""VAR_5.execute(\n    'UPDATE note SET content = ?, updated_at = CURRENT_TIMESTAMP WHERE note_id = ?'\n    , (VAR_7.content, VAR_7.note_id))\n"", ""VAR_5.execute('INSERT INTO note(user_id, content) VALUES(?, ?)', (VAR_7.\n    user_id, VAR_7.content))\n"", ""VAR_11 = FUNC_1(VAR_5, VAR_7.note_id)\n"", ""VAR_7.note_id = VAR_5.lastrowid\n"", ""return VAR_11\n""]",1
"[""def FUNC_40(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return list(self.list_properties.keys())\n""]",0
"[""def FUNC_5(self, VAR_2, VAR_1, VAR_3):...\n"", ""self.cursor.execute('string' % (VAR_1, VAR_2, VAR_3))\n"", ""self.db.commit()\n""]",1
"[""@VAR_0.route('/sloka')...\n"", ""VAR_9 = request.args.get('sloka_number')\n"", ""VAR_10 = VAR_9.split('.')\n"", ""VAR_11 = '%s.%s.%d' % (VAR_10[0], VAR_10[1], int(VAR_10[2]) - 1)\n"", ""VAR_12 = '%s.%s.%d' % (VAR_10[0], VAR_10[1], int(VAR_10[2]) + 1)\n"", ""con.row_factory = sql.Row\n"", ""con.close()\n"", ""VAR_15 = con.cursor()\n"", ""VAR_15.execute(\n    \""select * from mula where sloka_number = '%s' order by sloka_line;\"" % VAR_9\n    )\n"", ""VAR_16 = VAR_15.fetchall()\n"", ""VAR_15.execute(\""select * from pada where sloka_number = '%s' order by id;\"" %\n    VAR_9)\n"", ""VAR_17 = VAR_15.fetchall()\n"", ""VAR_13 = ''\n"", ""if len(VAR_17) > 0:\n"", ""VAR_13 = VAR_17[0]['varga']\n"", ""return render_template('sloka.html', VAR_16=mula, VAR_17=pada, VAR_13=varga,\n    VAR_9=sloka_number, VAR_11=sloka_number_previous, VAR_12=sloka_number_next)\n""]",1
"[""import logging\n"", ""import re\n"", ""import time\n"", ""from six.moves import queue, range\n"", ""from clickhouse_driver import Client, errors\n"", ""from snuba import settings\n"", ""VAR_0 = logging.getLogger('snuba.clickhouse')\n"", ""VAR_1 = re.compile('^-?[a-zA-Z][a-zA-Z0-9_\\\\.]*$')\n"", ""VAR_2 = re.compile('^(-?)(.*)$')\n"", ""def FUNC_0(VAR_3):...\n"", ""if not VAR_3:\n"", ""return VAR_3\n"", ""if VAR_1.match(VAR_3):\n"", ""return VAR_3\n"", ""return u'{}`{}`'.format(*VAR_2.match(VAR_3).groups())\n""]",1
"[""def __init__(self, VAR_3, VAR_4, VAR_5=None, VAR_6=None):...\n"", ""self.rule = VAR_3\n"", ""self.dag = VAR_4\n"", ""self.targetfile = VAR_5\n"", ""self.wildcards_dict = self.rule.get_wildcards(VAR_5)\n"", ""self.wildcards = Wildcards(fromdict=self.wildcards_dict)\n"", ""self._format_wildcards = self.wildcards if VAR_6 is None else Wildcards(\n    fromdict=format_wildcards)\n"", ""(self.input, self.output, self.params, self.log, self.benchmark, self.\n    ruleio, self.dependencies) = VAR_3.expand_wildcards(self.wildcards_dict)\n"", ""self.resources_dict = {name: min(self.rule.workflow.global_resources.get(\n    name, res), res) for name, res in VAR_3.resources.items()}\n"", ""self.threads = self.resources_dict['_cores']\n"", ""self.resources = Resources(fromdict=self.resources_dict)\n"", ""self._inputsize = None\n"", ""self.dynamic_output, self.dynamic_input = set(), set()\n"", ""self.temp_output, self.protected_output = set(), set()\n"", ""self.touch_output = set()\n"", ""self.subworkflow_input = dict()\n"", ""for VAR_28 in self.output:\n"", ""VAR_27 = self.ruleio[VAR_28]\n"", ""for VAR_28 in self.input:\n"", ""if VAR_27 in self.rule.dynamic_output:\n"", ""VAR_27 = self.ruleio[VAR_28]\n"", ""self._hash = self.rule.__hash__()\n"", ""self.dynamic_output.add(VAR_28)\n"", ""if VAR_27 in self.rule.temp_output:\n"", ""if VAR_27 in self.rule.dynamic_input:\n"", ""if True or not self.dynamic_output:\n"", ""self.temp_output.add(VAR_28)\n"", ""if VAR_27 in self.rule.protected_output:\n"", ""self.dynamic_input.add(VAR_28)\n"", ""if VAR_27 in self.rule.subworkflow_input:\n"", ""for o in self.output:\n"", ""self.protected_output.add(VAR_28)\n"", ""if VAR_27 in self.rule.touch_output:\n"", ""self.subworkflow_input[VAR_28] = self.rule.subworkflow_input[VAR_27]\n"", ""self._hash ^= o.__hash__()\n"", ""self.touch_output.add(VAR_28)\n""]",0
"[""def FUNC_12(self):...\n"", ""return self._omnicomp\n""]",0
"[""from functools import wraps\n"", ""import os\n"", ""import json\n"", ""from base64 import b64encode\n"", ""import time as time_module\n"", ""from copy import copy\n"", ""import logging\n"", ""from six.moves.urllib.parse import urlencode\n"", ""from flask import request, session, redirect, url_for, g\n"", ""from oauth2client.client import flow_from_clientsecrets, OAuth2WebServerFlow, AccessTokenRefreshError\n"", ""import httplib2\n"", ""from itsdangerous import TimedJSONWebSignatureSerializer, SignatureExpired\n"", ""__all__ = ['OpenIDConnect', 'MemoryCredentials']\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_1=None, VAR_2=None, VAR_3=None, VAR_4=None, VAR_5=None):...\n"", ""self.credentials_store = VAR_2 if VAR_2 is not None else CLASS_0()\n"", ""self.http = VAR_3 if VAR_3 is not None else httplib2.Http()\n"", ""self.time = VAR_4 if VAR_4 is not None else time_module.time\n"", ""self.urandom = VAR_5 if VAR_5 is not None else os.urandom\n"", ""if VAR_1 is not None:\n"", ""self.init_app(VAR_1)\n"", ""def FUNC_0(self, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.app = VAR_1\n"", ""VAR_1.config.setdefault('OIDC_SCOPES', ['openid', 'email'])\n"", ""VAR_1.config.setdefault('OIDC_GOOGLE_APPS_DOMAIN', None)\n"", ""VAR_1.config.setdefault('OIDC_ID_TOKEN_COOKIE_NAME', 'oidc_id_token')\n"", ""VAR_1.config.setdefault('OIDC_ID_TOKEN_COOKIE_TTL', 7 * 86400)\n"", ""VAR_1.config.setdefault('OIDC_ID_TOKEN_COOKIE_SECURE', True)\n"", ""VAR_1.config.setdefault('OIDC_VALID_ISSUERS', ['accounts.google.com',\n    'https://accounts.google.com'])\n"", ""VAR_1.config.setdefault('OIDC_CLOCK_SKEW', 60)\n"", ""VAR_1.config.setdefault('OIDC_REQUIRE_VERIFIED_EMAIL', True)\n"", ""VAR_1.route('/oidc_callback')(self.oidc_callback)\n"", ""VAR_1.before_request(self.before_request)\n"", ""VAR_1.after_request(self.after_request)\n"", ""self.flow = flow_from_clientsecrets(VAR_1.config['OIDC_CLIENT_SECRETS'],\n    scope=app.config['OIDC_SCOPES'])\n"", ""assert isinstance(self.flow, OAuth2WebServerFlow)\n"", ""self.cookie_serializer = TimedJSONWebSignatureSerializer(VAR_1.config[\n    'SECRET_KEY'])\n"", ""self.credentials_store = VAR_1.config['OIDC_CREDENTIALS_STORE']\n"", ""def FUNC_1(self):...\n"", ""VAR_23 = request.cookies[self.app.config['OIDC_ID_TOKEN_COOKIE_NAME']]\n"", ""VAR_0.debug('Missing or invalid ID token cookie', exc_info=True)\n"", ""def FUNC_2(self, VAR_6):...\n"", ""return self.cookie_serializer.loads(VAR_23)\n"", ""return None\n"", ""\""\""\""docstring\""\""\""\n"", ""g.oidc_id_token = VAR_6\n"", ""g.oidc_id_token_dirty = True\n"", ""def FUNC_3(self, VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if getattr(g, 'oidc_id_token_dirty', False):\n"", ""VAR_24 = self.cookie_serializer.dumps(g.oidc_id_token)\n"", ""return VAR_7\n"", ""VAR_7.set_cookie(self.app.config['OIDC_ID_TOKEN_COOKIE_NAME'], VAR_24,\n    secure=self.app.config['OIDC_ID_TOKEN_COOKIE_SECURE'], httponly=True,\n    max_age=self.app.config['OIDC_ID_TOKEN_COOKIE_TTL'])\n""]",1
"[""def FUNC_1(self, VAR_5, VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 not in ('strings', 'files'):\n"", ""VAR_0.error(\""Bad parameter '%s' for submit_type\"", VAR_5)\n"", ""VAR_13 = Folders.create_temp()\n"", ""return False\n"", ""VAR_14 = {'data': [], 'errors': []}\n"", ""if VAR_5 == 'strings':\n"", ""for VAR_4 in VAR_6:\n"", ""if VAR_5 == 'files':\n"", ""self._handle_string(VAR_14, VAR_13, VAR_4)\n"", ""for entry in VAR_6:\n"", ""return Database().add_submit(VAR_13, VAR_5, VAR_14)\n"", ""VAR_22 = Storage.get_filename_from_path(entry['name'])\n"", ""VAR_18 = Files.create(VAR_13, VAR_22, entry['data'])\n"", ""VAR_14['data'].append({'type': 'file', 'data': VAR_18})\n""]",1
"[""def FUNC_5(self, VAR_16):...\n"", ""for VAR_10, VAR_11 in self.directories:\n"", ""if VAR_16.startswith(VAR_11):\n"", ""yield os.path.join(VAR_10, VAR_16[len(VAR_11):])\n""]",1
"[""def FUNC_4(self):...\n"", ""VAR_23 = 'katotest-server-group'\n"", ""VAR_21 = self.agent.type_to_payload('upsertGoogleServerGroupTagsDescription',\n    {'credentials': self.bindings['GCE_CREDENTIALS'], 'zone': self.bindings\n    ['TEST_GCE_ZONE'], 'serverGroupName': 'katotest-server-group', 'tags':\n    ['test-tag-1', 'test-tag-2']})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Server Group Tags Added').inspect_resource(\n    'managed-instance-groups', VAR_23).contains_pred_list([jc.\n    PathContainsPredicate('name', VAR_23), jc.PathContainsPredicate(\n    'tags/items', ['test-tag-1', 'test-tag-2'])])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_server_group_tags', data=payload, VAR_29='ops'), contract=\n    builder.build())\n""]",1
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_32 = (\""select * from users where id = {0} and projects_mapped @> '{{{1}}}'\""\n    .format(VAR_18, VAR_23))\n"", ""VAR_33 = db.engine.execute(VAR_32)\n"", ""if VAR_33.rowcount > 0:\n"", ""return\n"", ""VAR_32 = 'string'.format(VAR_23, VAR_18)\n"", ""db.engine.execute(VAR_32)\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_12 = str('')\n"", ""VAR_13 = 1\n"", ""VAR_14 = self.sudo().registration_ids\n"", ""VAR_14 = sorted(VAR_14, key=lambda x: x.date_open, reverse=False)\n"", ""for registration in VAR_14:\n"", ""if registration.state == 'open':\n"", ""return VAR_12\n"", ""if VAR_13 == 1:\n"", ""VAR_12 += registration.partner_id.sudo().name\n"", ""VAR_12 += ', ' + registration.partner_id.sudo().name\n"", ""VAR_13 += 1\n""]",0
"[""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_47 = re.compile('^.*[,();].*')\n"", ""VAR_48 = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n"", ""VAR_49 = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n    'connection_id', 'current_user', 'database', 'last_insert_id',\n    'session_user', 'system_user', 'user', 'version']\n"", ""def FUNC_26():...\n"", ""frappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n"", ""for field in self.fields:\n"", ""if VAR_47.match(field):\n"", ""if any(keyword in field.lower() for keyword in VAR_48):\n"", ""FUNC_26()\n"", ""if any('{0}('.format(keyword) in field.lower() for keyword in VAR_49):\n"", ""FUNC_26()\n""]",1
"[""def FUNC_6(self, VAR_47):...\n"", ""if VAR_101.user_is_admin:\n"", ""return True\n"", ""if VAR_101.user_is_loggedin:\n"", ""VAR_18 = Thing._by_fullname(VAR_47, data=True)\n"", ""abort(403, 'forbidden')\n"", ""VAR_109 = VAR_18.subreddit_slow\n"", ""if VAR_109.is_special(VAR_101.user):\n"", ""return True\n""]",0
"[""def FUNC_29(self, *VAR_33):...\n"", ""self._run_tracker.log(Report.WARN, *VAR_33)\n""]",0
"[""def FUNC_15(self):...\n"", ""self._omnicomp.OnFileReadyToParse(None)\n"", ""if not self._IsServerAlive():\n"", ""self._NotifyUserIfServerCrashed()\n"", ""VAR_5 = {}\n"", ""self._AddTagsFilesIfNeeded(VAR_5)\n"", ""self._AddSyntaxDataIfNeeded(VAR_5)\n"", ""self._AddExtraConfDataIfNeeded(VAR_5)\n"", ""self._latest_file_parse_request = EventNotification('FileReadyToParse', VAR_5)\n"", ""self._latest_file_parse_request.Start()\n""]",0
"[""def FUNC_2():...\n"", ""bw2.projects.set_current(IMPORT_PROJECT_NAME)\n"", ""VAR_2 = DisclosureImporter(os.path.join(os.path.dirname(os.path.realpath(\n    __file__)), TEST_FOLDER, '{}.json'.format(TEST_FILENAME)))\n"", ""VAR_2.apply_strategies()\n"", ""assert VAR_2.statistics()[2] == 0\n"", ""VAR_2.write_database()\n"", ""assert len(bw2.Database(VAR_2.db_name)) != 0\n""]",1
"[""def FUNC_14(VAR_24=sys.argv):...\n"", ""VAR_39 = FUNC_12(VAR_24)\n"", ""if VAR_39.print_templates:\n"", ""print(VAR_39.templates)\n"", ""if not VAR_39.metadata:\n"", ""return 0\n"", ""if 'OS_CONFIG_FILES' in os.environ:\n"", ""if VAR_39.templates is None:\n"", ""VAR_28.error(e)\n"", ""return 0\n"", ""VAR_39.metadata = os.environ['OS_CONFIG_FILES'].split(':')\n"", ""VAR_39.metadata = FUNC_13(VAR_39.os_config_files)\n"", ""if VAR_39.key:\n"", ""return 1\n"", ""if not VAR_39.metadata and VAR_39.os_config_files == VAR_2:\n"", ""FUNC_2(VAR_39.metadata, VAR_39.key, VAR_39.type, VAR_39.key_default, VAR_39\n    .fallback_metadata)\n"", ""FUNC_1(VAR_39.metadata, VAR_39.templates, VAR_39.output, VAR_39.validate,\n    VAR_39.subhash, VAR_39.fallback_metadata)\n"", ""VAR_28.warning('DEPRECATED: falling back to %s' % VAR_3)\n"", ""VAR_28.info('success')\n"", ""VAR_39.metadata = FUNC_13(VAR_3)\n""]",0
"[""from argparse import ArgumentParser\n"", ""from ply import lex, yacc\n"", ""import locale\n"", ""import traceback\n"", ""import sys\n"", ""import git\n"", ""import re\n"", ""import os\n"", ""def __init__(self, VAR_3, VAR_4):...\n"", ""self.tok = VAR_3\n"", ""self.txt = VAR_4\n"", ""def __init__(self, VAR_5, VAR_4):...\n"", ""self.el = VAR_5\n"", ""self.txt = VAR_4\n"", ""def __init__(self):...\n"", ""self.license_files = 0\n"", ""self.exception_files = 0\n"", ""self.licenses = []\n"", ""self.exceptions = {}\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_6 = ['preferred', 'other', 'exceptions']\n"", ""VAR_7 = VAR_0.head.commit.tree['LICENSES']\n"", ""VAR_8 = CLASS_2()\n"", ""for d in VAR_6:\n"", ""for VAR_5 in VAR_7[d].traverse():\n"", ""return VAR_8\n"", ""if not os.path.isfile(VAR_5.path):\n"", ""VAR_23 = None\n"", ""for l in open(VAR_5.path).readlines():\n"", ""if l.startswith('Valid-License-Identifier:'):\n"", ""VAR_26 = l.split(':')[1].strip().upper()\n"", ""if l.startswith('SPDX-Exception-Identifier:'):\n"", ""if VAR_26 in VAR_8.licenses:\n"", ""VAR_23 = l.split(':')[1].strip().upper()\n"", ""if l.startswith('SPDX-Licenses:'):\n"", ""VAR_8.licenses.append(VAR_26)\n"", ""VAR_8.exceptions[VAR_23] = []\n"", ""for lic in l.split(':')[1].upper().strip().replace(' ', '').replace('\\t', ''\n"", ""if l.startswith('License-Text:'):\n"", ""if not lic in VAR_8.licenses:\n"", ""if VAR_23:\n"", ""VAR_8.exceptions[VAR_23].append(lic)\n"", ""if not len(VAR_8.exceptions[VAR_23]):\n"", ""VAR_8.license_files += 1\n"", ""VAR_8.exception_files += 1\n""]",1
"[""@VAR_7.route('/login', methods=['GET', 'POST'])...\n"", ""if request.method == 'POST':\n"", ""VAR_9 = usr.validateCredentials(request.form['username'], request.form[\n    'password'], VAR_6)\n"", ""return render_template('user/login.html')\n"", ""if VAR_9:\n"", ""VAR_21 = request.form['username']\n"", ""return render_template('user/login-error.html')\n"", ""VAR_3 = request.form['password']\n"", ""VAR_22 = VAR_6.connect().cursor()\n"", ""VAR_22.execute('SELECT userId from Users WHERE userEmail=\""{0}\"";'.format(VAR_21)\n    )\n"", ""VAR_23 = VAR_22.fetchall()\n"", ""VAR_22 = VAR_6.connect().cursor()\n"", ""VAR_22.execute('SELECT name from Calendars WHERE userId=\""{0}\"";'.format(VAR_23))\n"", ""VAR_12 = VAR_22.fetchall()\n"", ""VAR_24['username'] = VAR_21\n"", ""VAR_24['password'] = VAR_3\n"", ""return redirect(url_for('dashboard', VAR_12=calendars))\n""]",1
"[""def FUNC_6(self):...\n"", ""VAR_11 = PasswordHasher()\n"", ""VAR_6 = None\n"", ""VAR_7 = VAR_3.users.find_one({'username': self.username})\n"", ""if VAR_7 == None:\n"", ""VAR_6 = \""User doesn't exist. Please sign up first!\""\n"", ""if VAR_11.verify(VAR_7['password'], self.password) == False:\n"", ""return VAR_6\n"", ""VAR_6 = 'Password is wrong, try again!'\n""]",1
"[""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n""]",1
"[""def FUNC_1(VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return '{t.day} {t:%b} {t:%y} {t:%X} PDT'.format(t=dt)\n""]",0
"[""def FUNC_3(self, VAR_2, VAR_1):...\n"", ""VAR_4 = 'insert into post_like values(%d,%d);' % (VAR_2, VAR_1)\n"", ""VAR_5 = sql.insertDB(self.conn, VAR_4)\n"", ""return VAR_5\n""]",1
"[""def __call__(self, VAR_2, VAR_3, VAR_4=None):...\n"", ""VAR_45 = subprocess.Popen(['host', VAR_3], VAR_66=subprocess.PIPE)\n"", ""VAR_46, VAR_47 = VAR_45.communicate()\n"", ""VAR_46 = VAR_46.decode().strip()\n"", ""self.reply(VAR_2, VAR_46)\n""]",1
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_21 = [VAR_28 for VAR_28 in self.expanded_output if VAR_28.exists]\n"", ""if VAR_21:\n"", ""logger.info(\n    \""\""\""Removing output files of failed job {} since they might be corrupted:\n{}\""\""\""\n    .format(self, ', '.join(VAR_21)))\n"", ""for VAR_28 in VAR_21:\n"", ""VAR_28.remove()\n""]",0
"[""def FUNC_9(self, VAR_5, VAR_6=None):...\n"", ""VAR_15 = CLASS_1(VAR_6=error_msg, VAR_7=self._disclaimer_banner)\n"", ""return renderElement(VAR_5, VAR_15)\n""]",0
"[""def FUNC_0(VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not FUNC_4('pdftotext'):\n"", ""VAR_0.warning(\n    'GNU file was not found on the system. Switching to a weak file extension test.'\n    )\n"", ""VAR_9 = os.popen('file ' + re.escape(VAR_2)).read()\n"", ""if VAR_2.lower().endswith('.pdf'):\n"", ""VAR_19 = VAR_9.split(':')[1]\n"", ""VAR_0.error('string')\n"", ""VAR_10 = VAR_19.find('PDF') > -1\n"", ""return True\n"", ""return False\n"", ""return VAR_10\n""]",1
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""def __repr__(self):...\n"", ""return self.rule.name\n""]",0
"[""def FUNC_0(self):...\n"", ""if not hasattr(self, '_user'):\n"", ""VAR_3 = (\""select * from account_access where access_token = '%s'\"" % self.\n    access_token)\n"", ""return self._user\n"", ""VAR_4 = self.db.get(VAR_3)\n"", ""if VAR_4:\n"", ""self._user = VAR_4\n"", ""self._user = None\n""]",1
"[""@abc.abstractmethod...\n"", ""return NotImplementedError()\n""]",1
"[""def FUNC_6(self):...\n"", ""if not CLASS_1.test_success(self):\n"", ""return False\n"", ""return True\n""]",0
"[""def FUNC_4(self):...\n"", ""VAR_1 = 'http://my.url.com'\n"", ""VAR_2 = 'True'\n"", ""url_helper.urllib2.urlopen(mox.StrContains(VAR_1), timeout=mox.IgnoreArg()\n    ).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(url_helper.UrlOpen(VAR_1, method='GET'), VAR_2)\n"", ""self._mox.VerifyAll()\n""]",1
"[""@VAR_0.route('/')...\n"", ""return FUNC_3()\n""]",0
"[""import webapp2\n"", ""import jinja2\n"", ""import os\n"", ""import logging\n"", ""import hashlib\n"", ""import cgi\n"", ""from google.appengine.api import users\n"", ""from google.appengine.ext import webapp\n"", ""from google.appengine.ext.webapp.util import run_wsgi_app\n"", ""from google.appengine.ext import db\n"", ""from google.appengine.api import images\n"", ""VAR_0 = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(\n    __file__)))\n"", ""def FUNC_0(VAR_1, VAR_2, VAR_3):...\n"", ""VAR_6 = users.get_current_user()\n"", ""if VAR_6:\n"", ""VAR_26 = db.GqlQuery('SELECT * FROM LoginInformation WHERE user_id = :1',\n    VAR_6.user_id()).get()\n"", ""VAR_26 = None\n"", ""VAR_3['current_li'] = VAR_26\n"", ""VAR_3['user'] = VAR_6\n"", ""VAR_3['logout_url'] = users.create_logout_url('/')\n"", ""VAR_3['login_url'] = users.create_login_url('/users/verify_user/')\n"", ""VAR_3['is_admin'] = users.is_current_user_admin()\n"", ""if VAR_6:\n"", ""VAR_27 = db.GqlQuery('SELECT * FROM LoginInformation WHERE user_id = :1',\n    VAR_6.user_id()).get()\n"", ""VAR_7 = VAR_0.get_template(VAR_2)\n"", ""VAR_3['unread_messages'] = db.GqlQuery(\n    'SELECT * FROM Message WHERE recipient_id = :1 AND read = :2', VAR_6.\n    user_id(), False).count()\n"", ""VAR_1.response.out.write(VAR_7.render(VAR_3))\n"", ""if VAR_27 and not VAR_27.is_active:\n"", ""def FUNC_1():...\n"", ""VAR_2 = '/users/inactive_notification.html'\n"", ""return db.GqlQuery('SELECT * FROM LoginInformation WHERE user_id = :1',\n    users.get_current_user.user_id()).get()\n""]",1
"[""import os\n"", ""import sys\n"", ""import socket\n"", ""import string\n"", ""import time\n"", ""import urllib2\n"", ""import HTMLParser\n"", ""import zlib\n"", ""import libirc\n"", ""VAR_0 = 'irc.freenode.net'\n"", ""VAR_1 = 6667\n"", ""VAR_2 = 'titlebot'\n"", ""VAR_3 = 'titlebot'\n"", ""VAR_4 = 'titlebot'\n"", ""VAR_5 = ['##Orz']\n"", ""def FUNC_0(VAR_6):...\n"", ""VAR_10 = VAR_6.find('http:')\n"", ""VAR_11 = VAR_6.find('https:')\n"", ""if VAR_11 == -1:\n"", ""if VAR_10 == -1:\n"", ""if VAR_10 == -1:\n"", ""return None\n"", ""return VAR_6[VAR_10:]\n"", ""return VAR_6[VAR_11:]\n"", ""return VAR_6[min(VAR_10, VAR_11):]\n""]",0
"[""def __repr__(self):...\n"", ""return '%d/%s' % (self.user_id, self.username)\n""]",1
"[""from flask_restful import Resource\n"", ""from werkzeug.exceptions import BadRequest\n"", ""from flask import request, jsonify, g\n"", ""from datetime import datetime\n"", ""from sqlalchemy import exists, and_\n"", ""from sqlalchemy.orm.exc import NoResultFound\n"", ""from common.json_schema import User_Schema\n"", ""from common.utils import headers, is_logged_in, has_admin_privileges\n"", ""from common.utils import bad_request, unauthorized, forbidden, not_found, internal_server_error, unprocessable_entity, conflict\n"", ""def FUNC_0(self, VAR_0):...\n"", ""def FUNC_1(self, VAR_0):...\n"", ""def FUNC_2(self, VAR_0):...\n"", ""def FUNC_0(self):...\n"", ""def FUNC_3(self):...\n""]",0
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_0 is None:\n"", ""return True\n"", ""return shutil.which(VAR_0) is not None\n""]",0
"[""@app.route('/json/politicians/all')...\n"", ""VAR_9 = Politician.all()\n"", ""VAR_7 = []\n"", ""for pol in VAR_9:\n"", ""VAR_23 = pol.name.title().split(' ')\n"", ""VAR_10 = Response(VAR_22=json.dumps(politicians), status=200, mimetype=\n    'application/json')\n"", ""VAR_2 = {'value': pol.name.title(), 'tokens': VAR_23, 'search_count': pol.\n    search_count}\n"", ""return VAR_10\n"", ""VAR_7.append(VAR_2)\n""]",0
"[""import collections\n"", ""import os\n"", ""import pymongo\n"", ""from django.http import Http404\n"", ""from cuckoo.core.database import Database, TASK_PENDING\n"", ""from cuckoo.common.mongo import mongo\n"", ""VAR_0 = Database()\n"", ""@staticmethod...\n"", ""if not isinstance(VAR_1, int):\n"", ""VAR_9 = {}\n"", ""VAR_10 = VAR_0.view_task(VAR_1, details=True)\n"", ""if VAR_10:\n"", ""VAR_19 = VAR_10.to_dict()\n"", ""return Exception('Task not found')\n"", ""VAR_19['guest'] = {}\n"", ""if VAR_10.guest:\n"", ""VAR_19['guest'] = VAR_10.guest.to_dict()\n"", ""VAR_19['errors'] = []\n"", ""for error in VAR_10.errors:\n"", ""VAR_19['errors'].append(error.message)\n"", ""VAR_19['sample'] = {}\n"", ""if VAR_10.sample_id:\n"", ""VAR_26 = VAR_0.view_sample(VAR_10.sample_id)\n"", ""VAR_9['task'] = VAR_19\n"", ""VAR_19['sample'] = VAR_26.to_dict()\n"", ""return VAR_9\n""]",1
"[""def FUNC_6():...\n"", ""populate_test_database()\n"", ""VAR_11 = VAR_3.post('/playlists/nn')\n"", ""assert VAR_11.json['status'] == 'OK'\n"", ""VAR_12 = VAR_3.put('/playlists/1/name')\n"", ""assert VAR_12.json['status'] == 'OK'\n"", ""VAR_13 = VAR_3.get('/playlists')\n"", ""assert VAR_13.json['status'] == 'OK'\n"", ""assert VAR_13.json['data'] == [dict(id=1, VAR_8='name')]\n""]",0
"[""def FUNC_2(self):...\n"", ""VAR_12 = 'string'\n"", ""VAR_13 = VAR_12.format(VAR_1=self.name, psw=self.password, VAR_3=self.email,\n    VAR_4=self.country)\n"", ""VAR_9 = \""select count(*) from users where name='%s';\"" % self.name\n"", ""VAR_10 = sql.queryDB(self.conn, VAR_9)\n"", ""if VAR_10[0][0] == 0:\n"", ""sql.insertDB(self.conn, VAR_13)\n"", ""return False\n"", ""return True\n""]",1
"[""def FUNC_3(self, VAR_1, VAR_2):...\n"", ""VAR_12 = self._formatCredentials(VAR_1, VAR_8='current')\n"", ""VAR_9 = '{credentials} rclone lsjson current:{path}'.format(VAR_12=\n    credentials, VAR_2=path)\n"", ""VAR_28 = self._execute(VAR_9)\n"", ""VAR_28 = json.loads(VAR_28)\n"", ""return VAR_28\n""]",1
"[""def FUNC_12(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return block.path_to_kname(VAR_1).startswith('md')\n""]",0
"[""def FUNC_4():...\n"", ""return FUNC_2() + FUNC_3()\n""]",1
"[""@staticmethod...\n"", """"]",1
"[""\""\""\""string\""\""\""\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.translation import gettext as _, gettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def FUNC_1(self):...\n"", ""VAR_2 = DummyRequest([''])\n"", ""VAR_3 = self.web.get(VAR_2)\n"", ""def FUNC_2(VAR_4):...\n"", ""VAR_5 = '<title>{0}</title>'.format(self.MAIL_ADDRESS)\n"", ""VAR_6 = re.findall(VAR_5, VAR_2.written[0])\n"", ""self.assertEquals(len(VAR_6), 1)\n"", ""VAR_3.addCallback(FUNC_2)\n"", ""return VAR_3\n""]",0
"[""def FUNC_2(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1.value = beamr.interpreters.Slide(VAR_1.value)\n"", ""return VAR_1\n""]",1
"[""def FUNC_5(VAR_16, VAR_19):...\n"", ""for update in VAR_16['result']:\n"", ""VAR_17 = update['message']['text']\n"", ""VAR_33 = update['message']['chat']['id']\n"", ""VAR_34 = update['message']['from']['id']\n"", ""VAR_35 = all(ord(char) < 128 for char in VAR_17)\n"", ""logging.info('handle_updates: Received %s from %d', VAR_17.encode('utf-8'),\n    VAR_34)\n"", ""if not VAR_35:\n"", ""FUNC_4(VAR_2['invalid'][0], VAR_33)\n"", ""if VAR_34 in VAR_4:\n"", ""if FUNC_7(VAR_17):\n"", ""if VAR_17 == '/help':\n"", ""VAR_4[VAR_34].append(VAR_17)\n"", ""FUNC_4(VAR_2['invalid'][0], VAR_33)\n"", ""FUNC_4(VAR_2[VAR_17][0], VAR_33)\n"", ""if VAR_17 == '/start':\n"", ""VAR_4[VAR_34][0] += 1\n"", ""FUNC_4(VAR_2['questions'][VAR_4[VAR_34][0]], VAR_33)\n"", ""FUNC_4('\\n'.join(VAR_2[VAR_17]), VAR_33)\n"", ""if VAR_17 == '/report':\n"", ""if VAR_4[VAR_34][0] >= VAR_11:\n"", ""if VAR_34 in VAR_3:\n"", ""if VAR_17 == '/view':\n"", ""VAR_36 = VAR_4[VAR_34][1:]\n"", ""FUNC_4(VAR_2['questions'][VAR_4[VAR_34][0]], VAR_33)\n"", ""FUNC_4(VAR_2['blacklisted'][0], VAR_33)\n"", ""if FUNC_6(VAR_34):\n"", ""FUNC_4(VAR_2[VAR_17][0] + VAR_0.select_recent_pretty(), VAR_33)\n"", ""FUNC_4(VAR_2['dk'][0], VAR_33)\n"", ""VAR_37, VAR_38 = VAR_0.insert(VAR_36)\n"", ""logging.info('handle_updates: %d not in blacklist', VAR_34)\n"", ""FUNC_4(VAR_2[VAR_17][0], VAR_33)\n"", ""VAR_4.pop(VAR_34)\n"", ""FUNC_4(VAR_2['cooldown'][0], VAR_33)\n"", ""VAR_4[VAR_34] = [0]\n"", ""if VAR_37:\n"", ""FUNC_4(VAR_2['questions'][0], VAR_33)\n"", ""logging.info('handle_updates: Insert %s returns %r', str(VAR_36), VAR_37)\n"", ""FUNC_4(VAR_2['invalid'][0], VAR_33)\n"", ""FUNC_4(VAR_2['thanks'][0], VAR_33)\n"", ""VAR_39 = int(time.time())\n"", ""VAR_5[VAR_34] = VAR_39\n"", ""VAR_6.append(VAR_34)\n"", ""VAR_7.append(VAR_39)\n""]",1
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = []\n"", ""for student in self.students:\n"", ""VAR_14 = [self.results[student.id][VAR_0.id] for VAR_0 in self.exercises]\n"", ""return VAR_9\n"", ""VAR_15 = sum(g for g in VAR_14 if g is not None)\n"", ""VAR_9.append((student, VAR_14, VAR_15))\n""]",0
"[""\""\""\""string\""\""\""\n"", ""from __future__ import print_function\n"", ""import os\n"", ""from six import iteritems\n"", ""import config as bconfig\n"", ""from invenio.legacy.bibclassify import ontology_reader as reader\n"", ""import text_extractor as extractor\n"", ""import text_normalizer as normalizer\n"", ""import keyword_analyzer as keyworder\n"", ""import acronym_analyzer as acronymer\n"", ""from invenio.utils.url import make_user_agent_string\n"", ""from invenio.utils.text import encode_for_xml\n"", ""VAR_0 = bconfig.get_logger('bibclassify.engine')\n"", ""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""def FUNC_1(VAR_14, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""VAR_15 = None\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_75 = ''\n"", ""VAR_0.info('Analyzing keywords for local file %s.' % VAR_14)\n"", ""if os.path.isdir(entry):\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_14)\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""return FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5=\n    spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""def FUNC_0(self):...\n"", ""VAR_2 = sql.connect(self.dbStr)\n"", ""VAR_3 = VAR_2.cursor()\n"", ""VAR_3.execute('SELECT * FROM {tn} WHERE {upc}={my_upc}'.format(tn=self.\n    table_name, cn=self.column_2, upc=self.column_2, my_upc=self.some_upc))\n"", ""VAR_4 = VAR_3.fetchone()\n"", ""return VAR_4\n""]",1
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import django.db.models.deletion\n"", ""VAR_0 = [('userprofile', '0003_auto_20160728_1139'), ('course',\n    '0024_auto_20160726_1232')]\n"", ""VAR_1 = [migrations.CreateModel(name='StudentGroup', fields=[('id', models.\n    AutoField(verbose_name='ID', primary_key=True, auto_created=True,\n    serialize=False)), ('timestamp', models.DateTimeField(auto_now_add=True\n    )), ('course_instance', models.ForeignKey(related_name='groups', to=\n    'course.CourseInstance')), ('members', models.ManyToManyField(to=\n    'userprofile.UserProfile', related_name='groups'))], options={\n    'ordering': ['course_instance', 'timestamp']}, bases=(models.Model,)),\n    migrations.AddField(model_name='enrollment', name='selected_group',\n    field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.\n    SET_NULL, default=None, blank=True, to='course.StudentGroup'),\n    preserve_default=True)]\n""]",1
"[""@skip...\n"", ""def FUNC_4(VAR_3):...\n"", ""VAR_10 = {onboarding.INTRODUCTION_INTRO: {'html': '<p>instructor_intro</p>',\n    'description': 'instructor_intro desc', 'title': 'instructor_intro'},\n    onboarding.CREATE_COURSE: {'html': '<p>create_course</p>',\n    'description': 'create_course desc', 'title': 'create_course'},\n    onboarding.CREATE_COURSELET: {'html': '<p>create_courselet</p>',\n    'description': 'create_courselet desc', 'title': 'create_courselet'},\n    onboarding.NEXT_STEPS: {'html': '<p>next_steps</p>', 'description':\n    'next_steps desc', 'title': 'next_steps'}, onboarding.INVITE_SOMEBODY:\n    {'html': '<p>invite_somebody</p>', 'description':\n    'invite_somebody desc', 'title': 'invite_somebody'}, onboarding.\n    CREATE_THREAD: {'html': '<p>create_thread</p>', 'description':\n    'create_thread desc', 'title': 'create_thread'}, onboarding.\n    VIEW_INTRODUCTION: {'html': '<p>view_introduction</p>', 'description':\n    'view_introduction desc', 'title': 'view_introduction'}, onboarding.\n    PREVIEW_COURSELET: {'html': '<p>preview_courselet</p>', 'description':\n    'preview_courselet desc', 'title': 'preview_courselet'}}\n"", ""return VAR_10[VAR_3]\n""]",1
"[""def FUNC_0(self):...\n"", ""if self.model_class._meta.database:\n"", ""return '{0}({1})'.format(self.model_class._meta.database.TYPES[self.TYPE],\n    self.max_length)\n"", ""return self.TYPE\n""]",0
"[""def FUNC_0(self):...\n"", ""return self.get_serializer_class().setup_eager_loading(Organization.objects\n    .all().order_by('-modified'))\n""]",0
"[""def FUNC_3(self, VAR_2, VAR_3, VAR_4, *VAR_5):...\n"", ""self.write_data({'type': 'upgrader_tick', 'event': {'text': VAR_5[0]}})\n""]",0
"[""@property...\n"", ""return await CLASS_0.filter(VAR_8=self.id).count()\n""]",0
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return os.__file__[0] != '/'\n""]",0
"[""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""VAR_15 = None\n"", ""VAR_75 = ''\n"", ""if os.path.isdir(entry):\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""def FUNC_9(self):...\n"", ""return combine_vars(self.vars, self.get_magic_vars())\n""]",0
"[""def FUNC_18(self, VAR_3, VAR_4, VAR_5, VAR_11=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.__make_proxy('make_proxy', VAR_3, (VAR_4, VAR_5), dict(VAR_11=\n    options))\n""]",0
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render\n"", ""from django.views.generic import TemplateView, DetailView\n"", ""from .forms import SearchForm\n"", ""from lib.vt import VT\n"", ""from lib.threatminer import ThreatMiner\n"", ""from django.db.models import Q\n"", ""from apps.threat.models import Event, Attribute\n"", ""from apps.reputation.models import blacklist\n"", ""from apps.twitter.models import tweet\n"", ""from apps.exploit.models import Exploit\n"", ""VAR_2 = 'filehash/index.html'\n"", ""def FUNC_1(self, **VAR_3):...\n"", ""VAR_5 = super().get_context_data(**kwargs)\n"", ""VAR_5['search_form'] = SearchForm()\n"", ""return VAR_5\n""]",1
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.config.get(self.section, 'server_cert')\n""]",0
"[""def __repr__(self):...\n"", ""return self.get_name()\n""]",0
"[""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def FUNC_0(self):...\n"", ""return self.label\n""]",0
"[""import logging\n"", ""import os\n"", ""import sys\n"", ""import threading\n"", ""VAR_0 = os.path.dirname(os.path.abspath(__file__))\n"", ""VAR_1 = os.path.dirname(VAR_0)\n"", ""sys.path.insert(0, VAR_1)\n"", ""sys.path.insert(0, os.path.join(VAR_1, 'third_party'))\n"", ""from depot_tools import auto_stub\n"", ""from utils import net\n"", ""def FUNC_0(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = dict(VAR_4 or {})\n"", ""VAR_4['Content-Length'] = len(VAR_2)\n"", ""def __init__(self):...\n"", ""self.content = VAR_2\n"", ""def FUNC_6(self, VAR_7):...\n"", ""VAR_8 = self.content\n"", ""while VAR_8:\n"", ""yield VAR_8[:VAR_7]\n"", ""def FUNC_7(self):...\n"", ""VAR_8 = VAR_8[VAR_7:]\n"", ""return self.content\n""]",0
"[""def FUNC_0(self, VAR_0='crimemap'):...\n"", ""return pymysql.connect(host='localhost', user=dbconfig.db_user, passwd=\n    dbconfig.db_password, db=database)\n""]",0
"[""def FUNC_28(VAR_21):...\n"", ""if not VAR_25(VAR_21):\n"", ""return VAR_21, False\n"", ""VAR_19.set()\n"", ""return VAR_21, True\n""]",0
"[""from const import *\n"", ""from model import *\n"", ""from utils import *\n"", ""import reveal\n"", ""\""\""\""An admin page to delete person records.\""\""\""\n"", ""VAR_0 = True\n"", ""VAR_1 = False\n"", ""VAR_2 = True\n"", ""def FUNC_0(self):...\n"", ""VAR_3 = XsrfTool()\n"", ""VAR_4 = users.get_current_user()\n"", ""self.render('admin_delete_record.html', id=self.env.domain + '/person.',\n    xsrf_token=xsrf_tool.generate_token(user.user_id(), 'admin_delete_record'))\n"", ""def FUNC_1(self):...\n"", ""VAR_3 = XsrfTool()\n"", ""VAR_4 = users.get_current_user()\n"", ""if not (self.params.xsrf_token and VAR_3.verify_token(self.params.\n"", ""self.error(403)\n"", ""VAR_5 = 'delete', str(self.params.id)\n"", ""return False\n"", ""self.redirect('/delete', id=self.params.id, signature=reveal.sign(action))\n""]",1
"[""def __init__(self, VAR_18, *VAR_15, **VAR_16):...\n"", ""self.item = VAR_18\n"", ""CLASS_0.__init__(self, VAR_18, *VAR_15, **kw)\n""]",0
"[""def FUNC_25(self):...\n"", ""VAR_13 = webapp2.Request({'HTTP_X_APPENGINE_INBOUND_APPID': 'some-app'})\n"", ""self.assertEqual(model.Identity(model.IDENTITY_SERVICE, 'some-app'),\n    handler.service_to_service_authentication(VAR_13))\n""]",0
"[""def FUNC_0(self):...\n"", ""for path, directories, files in self.walk_fn(self.base_directory_path):\n"", ""VAR_3 = relpath(path, self.base_directory_path)\n"", ""VAR_4 = basename(path)\n"", ""if VAR_3 != '.' and not self.directory_filter(VAR_4):\n"", ""for file in files:\n"", ""if not self.file_filter(file):\n"", ""yield join(path, file)\n""]",1
"[""def FUNC_3():...\n"", ""populate_test_database()\n"", ""FUNC_1('first playlist')\n"", ""FUNC_1('second playlist')\n"", ""VAR_11 = VAR_3.get('/playlists')\n"", ""assert VAR_11.json['status'] == 'OK'\n"", ""assert VAR_11.json['data'] == [dict(id=1, VAR_8='first playlist'), dict(id=\n    2, VAR_8='second playlist')]\n""]",0
"[""def FUNC_4(self, VAR_15, VAR_16, VAR_17=None):...\n"", ""self.logger.info('### Starting detection of valid extensions ...')\n"", ""VAR_25 = 0\n"", ""if VAR_17:\n"", ""VAR_38 = []\n"", ""VAR_38 = VAR_15\n"", ""for e in VAR_17:\n"", ""VAR_26 = []\n"", ""VAR_38.append((e, getMime(VAR_15, e)))\n"", ""VAR_27 = VAR_38[0:VAR_16]\n"", ""VAR_39 = []\n"", ""for VAR_37 in VAR_27:\n"", ""self.shouldLog = False\n"", ""return VAR_25\n"", ""VAR_46 = executor.submit(self.uploadFile, '.' + VAR_37[0], VAR_37[1], os.\n    urandom(self.size))\n"", ""for VAR_14 in concurrent.futures.as_completed(VAR_39):\n"", ""executor.shutdown(wait=False)\n"", ""VAR_46.ext = VAR_37\n"", ""VAR_47 = VAR_14.result()\n"", ""self.stopThreads = True\n"", ""VAR_46.add_done_callback(self.detectValidExtension)\n"", ""VAR_25 += 1\n"", ""executor._threads.clear()\n"", ""VAR_39.append(VAR_46)\n"", ""concurrent.futures.thread._threads_queues.clear()\n""]",0
"[""import requests\n"", ""import json\n"", ""import bs4\n"", ""import re\n"", ""import sys\n"", ""from multiprocessing import Pool\n"", ""from time import strftime\n"", ""if sys.version_info < (3, 0):\n"", ""\""\""\""\n    Custom KijijiApi exception class\n    \""\""\""\n"", ""def __init__(self, VAR_2=None):...\n"", ""self.dumpfilepath = ''\n"", ""if VAR_2:\n"", ""self.dumpfilepath = 'kijiji_dump_{}.txt'.format(strftime('%Y%m%dT%H%M%S'))\n"", ""def __str__(self):...\n"", ""f.write(VAR_2)\n"", ""if self.dumpfilepath:\n"", ""return 'See {} in current directory for latest dumpfile.'.format(self.\n    dumpfilepath)\n"", ""return ''\n""]",1
"[""@synchronized(VAR_0)...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.con = self.c = None\n"", ""if not CLASS_0.db_path:\n"", ""CLASS_0.db_path = os.path.join(sabnzbd.cfg.admin_dir.get_path(),\n    DB_HISTORY_NAME)\n"", ""self.connect()\n""]",0
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import django.utils.timezone\n"", ""import lib.fields\n"", ""import django.core.validators\n"", ""VAR_0 = [('exercise', '0006_auto_20150625_1823'), ('userprofile',\n    '0002_auto_20150427_1717'), ('inheritance', '0001_initial'), ('course',\n    '0004_auto_20150625_1821')]\n"", ""VAR_1 = [migrations.CreateModel(name='CourseModule', fields=[('id', models.\n    AutoField(primary_key=True, serialize=False, auto_created=True,\n    verbose_name='ID')), ('name', models.CharField(max_length=255)), ('url',\n    models.CharField(max_length=255, validators=[django.core.validators.\n    RegexValidator(regex='^(?!teachers$)(?!user$)[\\\\w\\\\-\\\\.]*$')],\n    help_text=\n    'Input an URL identifier for this module. Taken words include: teachers, user'\n    )), ('chapter', models.IntegerField(default=1)), ('subchapter', models.\n    IntegerField(default=1)), ('points_to_pass', models.\n    PositiveIntegerField(default=0)), ('introduction', models.TextField(\n    blank=True)), ('opening_time', models.DateTimeField(default=django.\n    utils.timezone.now)), ('closing_time', models.DateTimeField(default=\n    django.utils.timezone.now)), ('content_url', models.URLField(blank=True\n    )), ('late_submissions_allowed', models.BooleanField(default=False)), (\n    'late_submission_deadline', models.DateTimeField(default=django.utils.\n    timezone.now)), ('late_submission_penalty', lib.fields.PercentField(\n    default=0.5, help_text=\n    'Multiplier of points to reduce, as decimal. 0.1 = 10%')), (\n    'course_instance', models.ForeignKey(related_name='course_modules', to=\n    'course.CourseInstance'))], options={'ordering': ['closing_time', 'id']\n    }, bases=(models.Model,)), migrations.CreateModel(name=\n    'LearningObjectCategory', fields=[('id', models.AutoField(primary_key=\n    True, serialize=False, auto_created=True, verbose_name='ID')), ('name',\n    models.CharField(max_length=35)), ('description', models.TextField(\n    blank=True)), ('points_to_pass', models.PositiveIntegerField(default=0)\n    ), ('course_instance', models.ForeignKey(related_name='categories', to=\n    'course.CourseInstance')), ('hidden_to', models.ManyToManyField(blank=\n    True, related_name='hidden_categories', null=True, to=\n    'userprofile.UserProfile'))], options={}, bases=(models.Model,)),\n    migrations.AlterUniqueTogether(name='learningobjectcategory',\n    unique_together=set([('name', 'course_instance')])), migrations.\n    AlterUniqueTogether(name='coursemodule', unique_together=set([(\n    'course_instance', 'url')]))]\n"", ""VAR_2 = [migrations.SeparateDatabaseAndState(VAR_1=state_operations)]\n""]",1
"[""def FUNC_15(VAR_6):...\n"", ""VAR_4.register_jvm_tool(VAR_8, VAR_4._key_for_tool_version('scalastyle',\n    VAR_6), VAR_15=[scala_style_jar])\n""]",1
"[""def FUNC_5(self):...\n"", ""VAR_1 = self.client.get(url_for('oauthclient.login', remote_app='test'))\n"", ""self.assertStatus(VAR_1, 302)\n"", ""self.assertEqual(VAR_1.location, \n    'https://foo.bar/oauth/authorize?response_type=code&client_id=testid&redirect_uri=%s'\n     % quote_plus(url_for('oauthclient.authorized', remote_app='test',\n    _external=True)))\n"", ""VAR_1 = self.client.get(url_for('oauthclient.login', remote_app='invalid'))\n"", ""self.assertStatus(VAR_1, 404)\n""]",1
"[""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = psycopg2.connect(database=DBNAME)\n"", ""VAR_3 = VAR_2.cursor()\n"", ""VAR_3.execute('select content,time from posts order by time desc')\n"", ""return VAR_3.fetchall()\n""]",0
"[""def FUNC_2(VAR_7, VAR_8=True):...\n"", ""VAR_24 = telebot.types.InlineKeyboardMarkup()\n"", ""if VAR_8:\n"", ""VAR_24.add(telebot.types.InlineKeyboardButton(' Go up', callback_data='..'))\n"", ""if VAR_7['directories']:\n"", ""for each in VAR_7['directories']:\n"", ""if VAR_7['files']:\n"", ""VAR_24.add(telebot.types.InlineKeyboardButton(' ' + each['name'],\n    callback_data='d' + str(each['id'])), telebot.types.\n    InlineKeyboardButton('', callback_data='rd' + str(each['id'])))\n"", ""for each in VAR_7['files']:\n"", ""return VAR_24\n"", ""if each['mime'] in VAR_5:\n"", ""VAR_41 = VAR_5[each['mime']]\n"", ""VAR_41 = VAR_5['U']\n"", ""VAR_24.add(telebot.types.InlineKeyboardButton(VAR_41 + ' ' + each['name'],\n    callback_data='f' + str(each['id'])), telebot.types.\n    InlineKeyboardButton('', callback_data='rf' + str(each['id'])))\n""]",1
"[""def FUNC_22(self):...\n"", ""self.assertRaises(NotImplementedError, self.driver.local_path, '')\n""]",0
"[""def __str__(self):...\n"", ""if self.dumpfilepath:\n"", ""return 'See {} in current directory for latest dumpfile.'.format(self.\n    dumpfilepath)\n"", ""return ''\n""]",1
"[""def FUNC_5(VAR_13, VAR_14, VAR_11, VAR_12):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_27 = FUNC_3(VAR_11, VAR_12)\n"", ""VAR_26 = FUNC_4(VAR_13, VAR_14)\n"", ""VAR_28 = len(VAR_26) > 100\n"", ""for VAR_35 in VAR_26:\n"", ""if VAR_28 and VAR_35 not in VAR_27:\n"", ""for current_source in VAR_27:\n"", ""VAR_7 = 'string' % VAR_35\n"", ""if current_source not in VAR_26:\n"", ""FUNC_0(VAR_7)\n"", ""VAR_7 = 'The source %s is new in Solr.' % current_source\n"", ""if VAR_28:\n"", ""FUNC_0(VAR_7)\n"", ""logging.info(VAR_7)\n"", ""VAR_40 = 'INSERT INTO source (source) VALUES (%s)' % current_source\n"", ""VAR_14.execute(VAR_40)\n"", ""VAR_13.commit()\n""]",1
"[""def FUNC_3(self):...\n"", ""VAR_14 = self.new_mocked_client(client.RESTClient, url_prefix='/cloud/api')\n"", ""VAR_14.list()\n"", ""FUNC_1('get', VAR_14, 'https://1.2.3.4/cloud/api')\n"", ""VAR_14 = self.new_mocked_client(client.RESTClient, url_prefix='/cloud/api')\n"", ""VAR_14.url_list('v1/ports')\n"", ""FUNC_1('get', VAR_14, 'https://1.2.3.4/cloud/api/v1/ports')\n""]",0
"[""from argparse import ArgumentParser\n"", ""import utilities\n"", ""VAR_0 = ArgumentParser(description=\n    'The Dynamic Robust Single Event Upset Simulator was created by Ed Carlisle IV'\n    , epilog=\n    'Begin by creating a new campaign with \""%(prog)s new APPLICATION\"". Then run injections with \""%(prog)s inject\"".'\n    )\n"", ""VAR_0.add_argument('-C', '--campaign', action='store', type=int, metavar=\n    'ID', dest='campaign_id', default=0, help=\n    'campaign to use, defaults to last campaign created')\n"", ""VAR_0.add_argument('-D', '--debug', action='store_true', dest='debug', help\n    ='display device output for parallel injections')\n"", ""VAR_0.add_argument('-T', '--timeout', action='store', type=int, metavar=\n    'SECONDS', dest='timeout', default=300, help=\n    'device read timeout [default=300]')\n"", ""VAR_0.add_argument('--serial', action='store', metavar='PORT', dest=\n    'dut_serial_port', help=\n    'DUT serial port [p2020 default=/dev/ttyUSB1] [a9 default=/dev/ttyACM0] (overridden by Simics)'\n    )\n"", ""VAR_0.add_argument('--baud', action='store', type=int, metavar='RATE', dest\n    ='dut_baud_rate', default=115200, help=\n    'DUT serial port baud rate [default=115200]')\n"", ""VAR_0.add_argument('--scp', action='store', type=int, metavar='PORT', dest=\n    'dut_scp_port', default=22, help=\n    'DUT scp port [default=22] (overridden by Simics)')\n"", ""VAR_0.add_argument('--prompt', action='store', metavar='PROMPT', dest=\n    'dut_prompt', help=\n    'DUT console prompt [p2020 default=root@p2020rdb:~#] [a9 default=[root@ZED]#] (overridden by Simics)'\n    )\n"", ""VAR_0.add_argument('--user', action='store', dest='username', default=\n    'root', help='device username')\n"", ""VAR_0.add_argument('--pass', action='store', dest='password', default=\n    'chrec', help='device password')\n"", ""VAR_0.add_argument('--uboot', action='store', metavar='COMMAND', dest=\n    'dut_uboot', default='', help='DUT u-boot command')\n"", ""VAR_0.add_argument('--aux_serial', action='store', metavar='PORT', dest=\n    'aux_serial_port', help=\n    'AUX serial port [p2020 default=/dev/ttyUSB1] [a9 default=/dev/ttyACM0] (overridden by Simics)'\n    )\n"", ""VAR_0.add_argument('--aux_baud', action='store', type=int, metavar='RATE',\n    dest='aux_baud_rate', default=115200, help=\n    'AUX serial port baud rate [default=115200]')\n"", ""VAR_0.add_argument('--aux_scp', action='store', type=int, metavar='PORT',\n    dest='aux_scp_port', default=22, help=\n    'AUX scp port [default=22] (overridden by Simics)')\n"", ""VAR_0.add_argument('--aux_prompt', action='store', metavar='PROMPT', dest=\n    'aux_prompt', help=\n    'AUX console prompt [p2020 default=root@p2020rdb:~#] [a9 default=[root@ZED]#] (overridden by Simics)'\n    )\n"", ""VAR_0.add_argument('--aux_uboot', action='store', metavar='COMMAND', dest=\n    'aux_uboot', default='', help='AUX u-boot command')\n"", ""VAR_0.add_argument('--debugger_ip', action='store', metavar='ADDRESS', dest\n    ='debugger_ip_address', default='10.42.0.50', help=\n    'debugger ip address [default=10.42.0.50] (ignored by Simics and ZedBoards)'\n    )\n"", ""VAR_0.add_argument('--no_jtag', action='store_false', dest='jtag', help=\n    'do not connect to jtag debugger (ignored by Simics)')\n"", ""VAR_1 = VAR_0.add_subparsers(title='commands', description=\n    'Run \""%(prog)s COMMAND -h\"" to get additional help for each command',\n    metavar='COMMAND', dest='command')\n"", ""VAR_2 = VAR_1.add_parser('new', aliases=['n'], help='create a new campaign',\n    description='create a new campaign')\n"", ""VAR_2.add_argument('application', action='store', metavar='APPLICATION',\n    help='application to run on device')\n"", ""VAR_2.add_argument('-A', '--arch', action='store', choices=('a9', 'p2020'),\n    dest='architecture', default='p2020', help=\n    'target architecture [default=p2020]')\n"", ""VAR_2.add_argument('-t', '--timing', action='store', type=int, dest=\n    'iterations', default=5, help=\n    'number of timing iterations to run [default=5]')\n"", ""VAR_2.add_argument('-a', '--args', action='store', nargs='+', dest=\n    'arguments', help='arguments for application')\n"", ""VAR_2.add_argument('-d', '--dir', action='store', dest='directory', default\n    ='fiapps', help='directory to look for files [default=fiapps]')\n"", ""VAR_2.add_argument('-f', '--files', action='store', nargs='+', metavar=\n    'FILE', dest='files', help='files to copy to device')\n"", ""VAR_2.add_argument('-o', '--output', action='store', dest='file', default=\n    'result.dat', help='target application output file [default=result.dat]')\n"", ""VAR_2.add_argument('-x', '--aux', action='store_true', dest='use_aux', help\n    ='use auxiliary device during testing')\n"", ""VAR_2.add_argument('-y', '--aux_app', action='store', metavar='APPLICATION',\n    dest='aux_application', help='target application for auxiliary device')\n"", ""VAR_2.add_argument('-z', '--aux_args', action='store', metavar='ARGUMENTS',\n    dest='aux_arguments', help='arguments for auxiliary application')\n"", ""VAR_2.add_argument('-F', '--aux_files', action='store', nargs='+', metavar=\n    'FILE', dest='aux_files', help='files to copy to auxiliary device')\n"", ""VAR_2.add_argument('-O', '--aux_output', action='store_true', dest=\n    'use_aux_output', help='use output file from auxiliary device')\n"", ""VAR_2.add_argument('-k', '--kill_dut', action='store_true', dest='kill_dut',\n    help='send ctrl-c to DUT after auxiliary device completes execution')\n"", ""VAR_2.add_argument('-s', '--simics', action='store_true', dest='use_simics',\n    help='use Simics simulator')\n"", ""VAR_3 = VAR_2.add_argument_group('Simics campaigns',\n    'Additional options for Simics campaigns only')\n"", ""VAR_3.add_argument('-c', '--checkpoints', action='store', type=int, metavar\n    ='CHECKPOINTS', dest='checkpoints', default=50, help=\n    'number of gold checkpoints to target for creation (actual number of checkpoints may be different) [default=50]'\n    )\n"", ""VAR_2.set_defaults(func=utilities.create_campaign)\n"", ""VAR_4 = VAR_1.add_parser('inject', aliases=['i', 'I', 'inj'], help=\n    'perform fault injections on a campaign', description=\n    'perform fault injections on a campaign')\n"", ""VAR_4.add_argument('-n', '--iterations', action='store', type=int, dest=\n    'iterations', help='number of iterations to perform [default=infinite]')\n"", ""VAR_4.add_argument('-i', '--injections', action='store', type=int, dest=\n    'injections', default=1, help=\n    'number of injections per iteration [default=1]')\n"", ""VAR_4.add_argument('-t', '--targets', action='store', nargs='+', metavar=\n    'TARGET', dest='selected_targets', help='list of targets for injection')\n"", ""VAR_4.add_argument('-p', '--processes', action='store', type=int, dest=\n    'processes', default=1, help=\n    'number of injections to perform in parallel (only supported for ZedBoards and Simics)'\n    )\n"", ""VAR_5 = VAR_4.add_argument_group('Simics campaigns',\n    'Additional options for Simics campaigns only')\n"", ""VAR_5.add_argument('-a', '--compare_all', action='store_true', dest=\n    'compare_all', help=\n    'monitor all checkpoints (only last by default), IMPORTANT: do NOT use with \""-p\"" or \""--processes\"" when using this option for the first time in a campaign'\n    )\n"", ""VAR_4.set_defaults(func=utilities.inject_campaign)\n"", ""VAR_6 = VAR_1.add_parser('supervise', aliases=['s', 'S'], help=\n    'run interactive supervisor', description='run interactive supervisor')\n"", ""VAR_6.add_argument('-w', '--wireshark', action='store_true', dest='capture',\n    help='run remote packet capture')\n"", ""VAR_6.set_defaults(func=utilities.launch_supervisor)\n"", ""VAR_7 = VAR_1.add_parser('log', aliases=['l'], help=\n    'start the log web server', description='start the log web server')\n"", ""VAR_7.add_argument('-p', '--port', action='store', type=int, dest='port',\n    default=8000, help='log web server port [default=8000]')\n"", ""VAR_7.set_defaults(func=utilities.view_logs)\n"", ""VAR_8 = VAR_1.add_parser('zedboards', aliases=['z', 'Z'], help=\n    'print information about attached ZedBoards', description=\n    'print information about attached ZedBoards')\n"", ""VAR_8.set_defaults(func=utilities.print_zedboard_info)\n"", ""VAR_9 = VAR_1.add_parser('list', aliases=['L', 'ls'], help='list campaigns',\n    description='list campaigns')\n"", ""VAR_9.set_defaults(func=utilities.list_campaigns)\n"", ""VAR_10 = VAR_1.add_parser('delete', aliases=['d', 'D'], description=\n    'delete results and campaigns', help='delete results and campaigns')\n"", ""VAR_10.add_argument('delete', action='store', choices=('all', 'results',\n    'campaign'), help=\n    'delete {results} for the selected campaign, delete selected {campaign} and its results, or delete {all} campaigns and results'\n    )\n"", ""VAR_10.set_defaults(func=utilities.delete)\n"", ""VAR_11 = VAR_1.add_parser('merge', aliases=['m', 'M'], help=\n    'merge campaigns', description='merge campaigns')\n"", ""VAR_11.add_argument('directory', action='store', metavar='DIRECTORY', help=\n    'merge campaigns from external directory into the local directory')\n"", ""VAR_11.set_defaults(func=utilities.merge_campaigns)\n"", ""VAR_12 = VAR_1.add_parser('openocd', aliases=['o', 'O'], help=\n    'launch openocd for DUT (only supported for ZedBoards)', description=\n    'launch openocd for DUT (only supported for ZedBoards)')\n"", ""VAR_12.set_defaults(func=utilities.launch_openocd)\n"", ""VAR_13 = VAR_1.add_parser('regenerate', aliases=['r', 'R'], help=\n    'regenerate injected state and launch in Simics (only supported for Simics campaigns)'\n    , description=\n    'regenerate injected state and launch in Simics (only supported for Simics campaigns)'\n    )\n"", ""VAR_13.add_argument('result_id', action='store', metavar='RESULT_ID', help=\n    'result to regenerate')\n"", ""VAR_13.set_defaults(func=utilities.regenerate)\n"", ""VAR_14 = VAR_1.add_parser('update', aliases=['u', 'U'], help=\n    'update gold checkpoint dependency paths (only supported for Simics campaigns)'\n    , description=\n    'update gold checkpoint dependency paths (only supported for Simics campaigns)'\n    )\n"", ""VAR_14.set_defaults(func=utilities.update_dependencies)\n"", ""VAR_15 = VAR_1.add_parser('backup', aliases=['b', 'B'], help=\n    'backup the results database', description='backup the results database')\n"", ""VAR_15.set_defaults(func=utilities.backup_database)\n"", ""VAR_16 = VAR_0.parse_args()\n"", ""if VAR_16.command is None:\n"", ""VAR_0.print_help()\n"", ""if VAR_16.command != 'new':\n"", ""if not VAR_16.campaign_id:\n"", ""if VAR_16.command == 'new' or VAR_16.campaign_id:\n"", ""VAR_16.campaign_id = utilities.get_last_campaign()\n"", ""if VAR_16.campaign_id:\n"", ""if VAR_16.architecture == 'p2020':\n"", ""if VAR_16.command == 'new' and VAR_16.arguments:\n"", ""VAR_16.architecture = utilities.get_campaign_data(VAR_16.campaign_id)[\n    'architecture']\n"", ""if VAR_16.dut_serial_port is None:\n"", ""if VAR_16.architecture == 'a9':\n"", ""VAR_16.arguments = ' '.join(VAR_16.arguments)\n"", ""VAR_16.func(VAR_16)\n"", ""VAR_16.dut_serial_port = '/dev/ttyUSB1'\n"", ""if VAR_16.dut_prompt is None:\n"", ""if VAR_16.dut_serial_port is None:\n"", ""VAR_16.dut_prompt = 'root@p2020rdb:~#'\n"", ""if VAR_16.aux_serial_port is None:\n"", ""VAR_16.dut_serial_port = '/dev/ttyACM0'\n"", ""if VAR_16.dut_prompt is None:\n"", ""VAR_16.aux_serial_port = '/dev/ttyUSB0'\n"", ""if VAR_16.aux_prompt is None:\n"", ""VAR_16.dut_prompt = '[root@ZED]#'\n"", ""if VAR_16.aux_serial_port is None:\n"", ""VAR_16.aux_prompt = 'root@p2020rdb:~#'\n"", ""VAR_16.aux_serial_port = '/dev/ttyACM1'\n"", ""if VAR_16.aux_prompt is None:\n"", ""VAR_16.aux_prompt = '[root@ZED]#'\n""]",1
"[""def FUNC_1(self, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/keys'\n"", ""VAR_5 = {'id': 'mykey@box.local', 'public': VAR_3}\n"", ""VAR_6 = self.client.post(VAR_4, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""VAR_7 = VAR_6.data['id']\n"", ""VAR_6 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""VAR_4 = '/api/keys/{key_id}'.format(**locals())\n"", ""VAR_6 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(VAR_5['id'], VAR_6.data['id'])\n"", ""self.assertEqual(VAR_5['public'], VAR_6.data['public'])\n"", ""VAR_6 = self.client.delete(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 204)\n""]",1
"[""def FUNC_4(self, VAR_6, VAR_7):...\n"", """"]",0
"[""def FUNC_6(self, VAR_45):...\n"", """"]",0
"[""def FUNC_11(self):...\n"", ""if os.path.exists(self.filechooser_creation_dialog.get_filename()):\n"", ""VAR_28 = Gtk.Builder()\n"", ""self.copy_database_file()\n"", ""VAR_28.add_from_resource('/run/terminal/KeepassGtk/override_dialog.ui')\n"", ""VAR_15 = self.create_tab_title_from_filepath(self.\n    filechooser_creation_dialog.get_current_name())\n"", ""self.override_dialog = VAR_28.get_object('override_dialog')\n"", ""self.start_database_creation_routine(VAR_15)\n"", ""self.override_dialog.set_destroy_with_parent(True)\n"", ""self.override_dialog.set_modal(True)\n"", ""self.override_dialog.set_transient_for(self.filechooser_creation_dialog)\n"", ""VAR_48 = VAR_28.get_object('cancel_button')\n"", ""VAR_49 = VAR_28.get_object('override_button')\n"", ""VAR_48.connect('clicked', self.on_cancel_button_clicked)\n"", ""VAR_49.connect('clicked', self.on_override_button_clicked)\n"", ""self.override_dialog.present()\n""]",0
"[""@VAR_0.route('/change_type', methods=['POST'])...\n"", ""VAR_1 = get_dataset_with_id(request.args.get('dataset_id'))\n"", ""VAR_7 = table_name_to_object(VAR_1.working_copy)\n"", ""VAR_2 = request.form['column']\n"", ""VAR_2 = VAR_2[:VAR_2.find('(') - 1]\n"", ""VAR_13 = request.form['type']\n"", ""if VAR_2 != '' and VAR_13 != '':\n"", ""return redirect(request.referrer)\n"", ""change_attribute_type(VAR_7.name, VAR_2, VAR_13)\n"", ""flash('{0} could not be converted to {1}'.format(VAR_2, VAR_13), 'danger')\n"", ""flash('{0} successfully  converted to {1}'.format(VAR_2, VAR_13), 'success')\n"", ""create_action('type {0} changed to {1}'.format(VAR_2, VAR_13), VAR_1.id,\n    current_user.id)\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_15 = self._server_popen.poll()\n"", ""return VAR_15 is None\n""]",0
"[""from flask import redirect, make_response\n"", ""from random import randint\n"", ""import redis\n"", ""import uuid\n"", ""import time\n"", ""def FUNC_0():...\n"", ""VAR_1 = redis.Redis(host='127.0.0.1', port=6379, db=0)\n"", ""return VAR_1\n""]",1
"[""def FUNC_2(self, **VAR_6):...\n"", ""return self.sendstring(json.dumps(VAR_6))\n""]",0
"[""def FUNC_6(self, VAR_19):...\n"", ""return VAR_19 if VAR_19 and self.measure.match(VAR_19) else ''\n""]",0
"[""def FUNC_35(VAR_29):...\n"", ""VAR_40 = VAR_29.group('name')\n"", ""VAR_16 = VAR_11[VAR_40]\n"", ""if VAR_15:\n"", ""if VAR_13 and VAR_16 == VAR_14:\n"", ""return '{{{}}}'.format(VAR_40)\n"", ""if VAR_12:\n"", ""return str(VAR_16)\n"", ""return VAR_14\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._version\n""]",0
"[""def __init__(self):...\n"", ""self.actors = {}\n"", ""self.ids = 0\n"", ""self.removed_actors = 0\n""]",0
"[""def __init__(self, VAR_20, VAR_6=None, VAR_7=None):...\n"", ""self._cache = {}\n"", ""self._distribution_environment = VAR_20\n"", ""self._minimum_version = VAR_6\n"", ""self._maximum_version = VAR_7\n""]",0
"[""\""\""\""\nCreated on 1 Feb 2018\n\n@author: Teodor Gherasim Nistor\n\""\""\""\n"", ""import beamr.debug as debug\n"", ""from beamr.parsers.generic import p_nil, p_error\n"", ""from ply import yacc\n"", ""from beamr.lexers.slide import tokens\n"", ""VAR_0 = 'main'\n"", ""def FUNC_0(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if len(VAR_1) > 2:\n"", ""VAR_1[0] = VAR_1[1]\n"", ""VAR_1[0] = []\n"", ""VAR_1[0].append(VAR_1[2])\n"", ""def FUNC_1(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1[0] = VAR_1[1]\n"", ""VAR_2 = yacc.yacc(tabmodule='slide_parsetab', debugfile='slide_parsedbg',\n    debug=not debug.quiet)\n""]",1
"[""def FUNC_14(VAR_1):...\n"", ""import sql\n"", ""VAR_45 = sql.get_setting('haproxy_sock_port')\n"", ""VAR_54 = ''\n"", ""VAR_15 = \""echo 'show info' |nc %s %s |grep Version |awk '{print $2}'\"" % (VAR_1,\n    VAR_45)\n"", ""VAR_41, VAR_42 = FUNC_24(VAR_15)\n"", ""for line in VAR_41:\n"", ""VAR_54 = line\n"", ""return VAR_54\n""]",0
"[""def FUNC_13():...\n"", ""VAR_20 = fernet.Fernet.generate_key()\n"", ""return base64.urlsafe_b64decode(VAR_20)\n""]",0
"[""def __init__(self, VAR_1, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""super(CLASS_0, self).__init__(VAR_1, VAR_4)\n"", ""VAR_1 = self.bindings\n"", ""VAR_1['TEST_APP_COMPONENT_NAME'] = '{app}-{stack}-{detail}'.format(app=\n    bindings['TEST_APP'], stack=bindings['TEST_STACK'], detail=bindings[\n    'TEST_COMPONENT_DETAIL'])\n"", ""self.TEST_APP = VAR_1['TEST_APP']\n""]",0
"[""@frappe.whitelist()...\n"", ""\""\""\""docstring\""\""\""\n"", ""FUNC_3()\n"", ""VAR_1 = 1\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_13 = int(VAR_12['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n"", ""while VAR_13 >= VAR_1:\n"", ""for item in VAR_12['ActiveList']['ItemArray']['Item']:\n"", ""VAR_3 = item['ItemID']\n"", ""VAR_1 += 1\n"", ""VAR_4 = int(item['QuantityAvailable'])\n"", ""if VAR_13 >= VAR_1:\n"", ""VAR_2 = item['SKU']\n"", ""VAR_2 = ''\n"", ""VAR_20 = float(item['SellingStatus']['CurrentPrice']['value'])\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_21 = VAR_20 / ugssettings.VAT\n"", ""VAR_22 = 0\n"", ""VAR_23 = 0\n"", ""VAR_24 = 0\n"", ""VAR_6 = ''\n"", ""FUNC_4(VAR_2, VAR_3, VAR_4, VAR_20, VAR_6, VAR_22, VAR_23, VAR_24)\n""]",1
"[""import mimetypes\n"", ""import os\n"", ""from django.contrib.gis.db.models import GeometryField\n"", ""from django.contrib.gis.db.models.functions import Envelope\n"", ""from django.core.exceptions import ObjectDoesNotExist\n"", ""from django.db.models.functions import Cast\n"", ""from django.http import HttpResponse\n"", ""from wsgiref.util import FileWrapper\n"", ""from rest_framework import status, serializers, viewsets, filters, exceptions, permissions, parsers\n"", ""from rest_framework.response import Response\n"", ""from rest_framework.decorators import detail_route\n"", ""from rest_framework.views import APIView\n"", ""from .common import get_and_check_project, get_tile_json\n"", ""from app import models, scheduler, pending_actions\n"", ""from nodeodm.models import ProcessingNode\n"", ""def FUNC_0(self, VAR_0):...\n"", ""return VAR_0.id\n""]",1
"[""def __init__(self, VAR_0, VAR_1, VAR_2):...\n"", ""self.uid = VAR_0\n"", ""self.email = VAR_1\n"", ""self.name = VAR_2\n""]",0
"[""def FUNC_1(self, VAR_8):...\n"", ""VAR_10 = self.reference.get_db_field()\n"", ""VAR_11 = '%s %s REFERENCES %s(%s)' % (self.name, VAR_10, self.rel_model.\n    _meta.table_name, self.reference.name)\n"", ""if self.on_delete:\n"", ""VAR_11 += ' ON DELETE CASCADE'\n"", ""if self.on_update:\n"", ""VAR_11 += ' ON UPDATE CASCADE'\n"", ""if self.unique:\n"", ""VAR_11 += ' UNIQUE'\n"", ""return VAR_11\n""]",0
"[""@staticmethod...\n"", ""def FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10):...\n"", ""if VAR_11 == 'POST':\n"", ""return CLASS_0.session.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=\n    _HEADERS, VAR_10=timeout)\n"", ""if VAR_11 == 'GET':\n"", ""return CLASS_0.session.get(FUNC_2(VAR_7), headers=_HEADERS, VAR_10=timeout)\n"", ""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n"", ""if not FUNC_3():\n"", ""return VAR_1.submit(FUNC_14, VAR_9, VAR_7, VAR_11)\n"", ""return FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10)\n""]",1
"[""def FUNC_17(self, VAR_34):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not VAR_34:\n"", ""return True\n"", ""if self.tempfiles[VAR_34] is not None:\n"", ""VAR_70 = hashlib.sha256(FUNC_14(self.tempfiles[VAR_34], 'rb').read()\n    ).hexdigest()\n"", ""return os.close(VAR_34)\n"", ""VAR_71 = self.cfg.get('honeypot', 'download_path') + '/' + VAR_70\n"", ""if os.path.exists(VAR_71):\n"", ""os.remove(self.tempfiles[VAR_34])\n"", ""os.rename(self.tempfiles[VAR_34], VAR_71)\n"", ""self.update_realfile(self.getfile(self.filenames[VAR_34]), VAR_71)\n"", ""log.msg(format='SFTP Uploaded file \""%(filename)s\"" to %(outfile)s', eventid=\n    'cowrie.session.file_upload', VAR_32=os.path.basename(self.filenames[fd\n    ]), VAR_59=shasumfile, VAR_70=shasum)\n""]",0
"[""def FUNC_7(self, VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = VAR_9.args.get('csessid')[0]\n"", ""VAR_18 = VAR_9.getClientIP()\n"", ""VAR_19 = '%s (%s:%s)' % (VAR_2, VAR_9.getRequestHostname(), VAR_9.getHost()\n    .port)\n"", ""VAR_20 = CLASS_2()\n"", ""VAR_20.client = self\n"", ""VAR_20.init_session('ajax/comet', VAR_18, self.sessionhandler)\n"", ""VAR_20.csessid = VAR_8\n"", ""VAR_21 = VAR_0(session_key=sess.csessid)\n"", ""VAR_22 = VAR_21 and VAR_21.get('webclient_authenticated_uid', False)\n"", ""if VAR_22:\n"", ""VAR_20.uid = VAR_22\n"", ""VAR_20.sessionhandler.connect(VAR_20)\n"", ""VAR_20.logged_in = True\n"", ""self.last_alive[VAR_8] = time.time(), False\n"", ""if not self.keep_alive:\n"", ""self.keep_alive = LoopingCall(self._keepalive)\n"", ""return FUNC_0({'msg': VAR_19, 'csessid': VAR_8})\n"", ""self.keep_alive.start(VAR_3, VAR_15=False)\n""]",1
"[""@permission_required('tournament.add_roundplayer')...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_modifiable_tournament_or_404(VAR_3, VAR_2.user)\n"", ""VAR_10 = formset_factory(PlayerRoundForm, extra=2, VAR_24=\n    BasePlayerRoundFormset)\n"", ""if VAR_1:\n"", ""VAR_8 = FUNC_0(VAR_7, VAR_1)\n"", ""VAR_27 = VAR_7.round_set.all()\n"", ""VAR_27 = VAR_7.round_set.filter(pk=r.pk)\n"", ""VAR_11 = []\n"", ""for tp in VAR_7.tournamentplayer_set.all():\n"", ""VAR_28 = {'player': tp.player}\n"", ""if VAR_1:\n"", ""VAR_18 = tp.roundplayers()\n"", ""VAR_24 = VAR_10(VAR_2.POST or None, VAR_0=t, VAR_1=int(round_num), initial=data\n    )\n"", ""VAR_24 = VAR_10(VAR_2.POST or None, VAR_0=t, initial=data)\n"", ""for VAR_8 in VAR_27:\n"", ""if VAR_24.is_valid():\n"", ""VAR_33 = VAR_18.filter(VAR_5=r).exists()\n"", ""VAR_11.append(VAR_28)\n"", ""for VAR_15 in VAR_24:\n"", ""return render(VAR_2, 'tournaments/round_players.html', {'title': _(\n    'Roll Call'), 'tournament': VAR_7, 'post_url': reverse('roll_call',\n    args=(tournament_id,)), 'formset': VAR_24})\n"", ""VAR_28['round_%d' % VAR_8.number()] = VAR_33\n"", ""VAR_8 = VAR_7.current_round()\n"", ""VAR_40 = VAR_15.cleaned_data['player']\n"", ""VAR_34, VAR_35 = TournamentPlayer.objects.get_or_create(player=p, VAR_0=t)\n"", ""if not VAR_1 or VAR_8.number() == VAR_1:\n"", ""VAR_34.full_clean()\n"", ""VAR_15.add_error(VAR_15.fields['player'], e)\n"", ""if VAR_35:\n"", ""if VAR_7.seed_games:\n"", ""VAR_34.delete()\n"", ""VAR_34.save()\n"", ""for r_name, value in VAR_15.cleaned_data.items():\n"", ""if VAR_8.roundplayer_set.count() % 7 == 0:\n"", ""return HttpResponseRedirect(reverse('create_games', args=(tournament_id, r.\n    number())))\n"", ""return render(VAR_2, 'tournaments/round_players.html', {'title': _(\n    'Roll Call'), 'tournament': VAR_7, 'post_url': reverse('roll_call',\n    args=(tournament_id,)), 'formset': VAR_24})\n"", ""if r_name == 'player':\n"", ""return HttpResponseRedirect(reverse('seed_games', args=(tournament_id, r.\n    number())))\n"", ""return HttpResponseRedirect(reverse('get_seven', args=(tournament_id, r.\n    number())))\n"", ""VAR_34 = int(r_name[6:])\n"", ""VAR_8 = VAR_7.round_numbered(VAR_34)\n"", ""if value is True:\n"", ""VAR_34, VAR_35 = RoundPlayer.objects.get_or_create(player=p, VAR_5=r)\n"", ""RoundPlayer.objects.filter(player=p, VAR_5=r).delete()\n"", ""VAR_34.full_clean()\n"", ""VAR_15.add_error(None, e)\n"", ""if VAR_35:\n"", ""VAR_34.delete()\n"", ""VAR_34.save()\n"", ""return render(VAR_2, 'tournaments/round_players.html', {'title': _(\n    'Roll Call'), 'tournament': VAR_7, 'post_url': reverse('roll_call',\n    args=(tournament_id,)), 'formset': VAR_24})\n""]",1
"[""def FUNC_8(VAR_4):...\n"", ""if not os.path.exists('D:' + VAR_4):\n"", ""return VAR_4\n"", ""VAR_28 = 1\n"", ""while VAR_28 < 101:\n"", ""VAR_32 = re.sub('\\\\.(.*?)$', ' (%d).\\\\1' % VAR_28, VAR_4)\n"", ""return ''\n"", ""if not os.path.exists('D:' + VAR_32):\n"", ""return VAR_32\n"", ""VAR_28 = VAR_28 + 1\n""]",1
"[""def FUNC_0(VAR_2, VAR_3=None, VAR_4=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""import atexit, os, subprocess, signal\n"", ""if VAR_3:\n"", ""from watchdog.observers import Observer\n"", ""def FUNC_11(VAR_18):...\n"", ""from watchdog.events import FileSystemEventHandler\n"", ""if not VAR_4:\n"", ""print('Restarting worker due to change in %s' % VAR_18.src_path)\n"", ""log.info('modified %s' % VAR_18.src_path)\n"", ""FUNC_13()\n"", ""log.exception('Error while restarting worker')\n"", ""VAR_19 = FileSystemEventHandler()\n"", ""FUNC_12()\n"", ""VAR_19.on_modified = FUNC_11\n"", ""VAR_20 = []\n"", ""log.info('starting %s workers' % VAR_2)\n"", ""def FUNC_12():...\n"", ""VAR_20 = []\n"", ""for i in range(int(VAR_2)):\n"", ""VAR_26 = subprocess.Popen([sys.executable, __file__], stdout=subprocess.\n    PIPE, stderr=subprocess.PIPE)\n"", ""def FUNC_13():...\n"", ""VAR_20.append(VAR_26.pid)\n"", ""\""\""\""docstring\""\""\""\n"", ""log.info('Started worker with pid %s' % VAR_26.pid)\n"", ""log.info('Stopping worker(s)')\n"", ""for pid in VAR_20:\n"", ""if pid is not None:\n"", ""FUNC_12()\n"", ""os.kill(pid, VAR_7.SIGTERM)\n"", ""atexit.register(FUNC_13)\n"", ""VAR_7.signal(VAR_7.SIGTERM, FUNC_13)\n"", ""if VAR_3:\n"", ""VAR_24 = Observer()\n"", ""while 1:\n"", ""for path in VAR_3:\n"", ""sleep(1)\n"", ""log.info('Keyboard interrupt, exiting')\n"", ""if not VAR_4:\n"", ""VAR_24.start()\n"", ""if VAR_3:\n"", ""print('Watching for changes under %s' % path)\n"", ""VAR_24.schedule(VAR_19, path=path, recursive=True)\n"", ""VAR_24.stop()\n"", ""sys.exit(0)\n"", ""VAR_24.join()\n""]",0
"[""def __init__(self, VAR_0='cache', VAR_1=timedelta(days=30), VAR_2=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.cache_dir = VAR_0\n"", ""self.expires = VAR_1\n"", ""self.compress = VAR_2\n""]",0
"[""def FUNC_19(VAR_18, VAR_20, VAR_10, VAR_26, VAR_27, VAR_28):...\n"", ""VAR_48 = VAR_20, VAR_4[VAR_20]['name']\n"", ""VAR_34 = FUNC_1(VAR_10)\n"", ""VAR_49 = SubmitRequest(VAR_34, VAR_48, base_url=CWS_BASE_URL, VAR_26=\n    submission_format, VAR_27=filenames, VAR_28=language)\n"", ""VAR_49.execute()\n"", ""VAR_29 = VAR_49.get_submission_id()\n"", ""if VAR_29 is None:\n"", ""return VAR_29\n""]",0
"[""def FUNC_16(self, VAR_15):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_15 = log_remove_escapes(VAR_15)\n"", ""VAR_15 = log_encode_html(VAR_15)\n"", ""fdesc.writeToFD(fd.fileno(), VAR_15 + '\\n')\n"", ""log.err('Unable to open %s: %s' % (GLSetting.httplogfile, excep))\n""]",0
"[""def FUNC_3(VAR_5):...\n"", ""VAR_12 = 'string'\n"", ""VAR_14 = create_connection()\n"", ""VAR_14.close()\n"", ""VAR_15 = VAR_14.cursor()\n"", ""VAR_15.execute(VAR_12, VAR_5)\n"", ""return VAR_15.fetchall()\n""]",1
"[""def FUNC_2(VAR_2):...\n"", ""VAR_6 = (\""SELECT * FROM articles WHERE subject='\"" + VAR_2 +\n    \""' ORDER BY last_submitted DESC\"")\n"", ""VAR_5.execute(VAR_6)\n"", ""VAR_19 = VAR_5.fetchall()\n"", ""return VAR_19\n""]",1
"[""def FUNC_9(VAR_0):...\n"", ""if VAR_0.do_not_run is True:\n"", ""VAR_15 = 'DNR'\n"", ""VAR_15 = 'RUN'\n"", ""VAR_15 += '_{}'.format(VAR_0.id)\n"", ""return VAR_15\n""]",1
"[""def FUNC_10(self, VAR_11, VAR_12=NoDefault):...\n"", ""if VAR_11 == 'SQLConnectionPoolSize':\n"", ""return 0\n"", ""return SQLObjectStore.setting(self, VAR_11, VAR_12)\n""]",0
"[""from __future__ import absolute_import\n"", ""import logging\n"", ""import os\n"", ""import sys\n"", ""import atexit\n"", ""from lore import env, util, ansi\n"", ""from lore.ansi import underline\n"", ""from lore.util import timer\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""if not (sys.version_info.major == 3 and sys.version_info.minor >= 6):\n"", ""VAR_2 = ImportError\n"", ""__author__ = 'Montana Low and Jeremy Stanley'\n"", ""__copyright__ = 'Copyright  2017, Instacart'\n"", ""__credits__ = ['Montana Low', 'Jeremy Stanley', 'Emmanuel Turlay']\n"", ""__license__ = 'MIT'\n"", ""__version__ = '0.4.45'\n"", ""__maintainer__ = 'Montana Low'\n"", ""__email__ = 'montana@instacart.com'\n"", ""__status__ = 'Development Status :: 3 - Alpha'\n"", ""def FUNC_0():...\n"", ""import socket\n"", ""import getpass\n"", ""return '%s in %s on %s' % (ansi.foreground(ansi.GREEN, env.project), ansi.\n    foreground(env.color, env.name), ansi.foreground(ansi.CYAN, getpass.\n    getuser() + '@' + socket.gethostname()))\n""]",1
"[""def FUNC_25(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return any(self.live_processes())\n""]",0
"[""def FUNC_12(self, VAR_10=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = vars(self.parse_known_args(VAR_15=True)[0])\n"", ""VAR_13 = VAR_30.get('image_mode', None)\n"", ""if VAR_13 is not None and VAR_13 != 'none':\n"", ""self.add_image_args(VAR_13)\n"", ""VAR_12 = VAR_30.get('task', None)\n"", ""if VAR_12 is not None:\n"", ""self.add_task_args(VAR_12)\n"", ""VAR_31 = VAR_30.get('evaltask', None)\n"", ""if VAR_31 is not None:\n"", ""self.add_task_args(VAR_31)\n"", ""VAR_11 = VAR_30.get('model', None)\n"", ""if VAR_11 is not None:\n"", ""self.add_model_subargs(VAR_11)\n"", ""self.set_defaults(**self._defaults)\n""]",1
"[""def FUNC_6(self, VAR_2, VAR_1):...\n"", ""VAR_5 = dict()\n"", ""VAR_17, VAR_18 = self.get_epoch_month(VAR_1)\n"", ""VAR_5['interval'] = {'from': self.convert_local_ts_to_utc(VAR_17, self.\n    local_timezone), 'to': self.convert_local_ts_to_utc(VAR_18, self.\n    local_timezone)}\n"", ""VAR_19 = 0\n"", ""VAR_12 = 'string'\n"", ""VAR_5['data'] = list()\n"", ""for VAR_13 in self.c.execute(VAR_12 % (VAR_17, VAR_18, VAR_2)):\n"", ""VAR_5['data'].append({'time': self.convert_local_ts_to_utc(VAR_13[0], self.\n    local_timezone), 'power': VAR_13[1]})\n"", ""VAR_5['total'] = VAR_19\n"", ""VAR_19 += VAR_13[1]\n"", ""VAR_12 = 'string' % VAR_2\n"", ""self.c.execute(VAR_12)\n"", ""VAR_14, VAR_15 = self.c.fetchone()\n"", ""if VAR_14:\n"", ""VAR_5['hasPrevious'] = VAR_14 < VAR_17\n"", ""VAR_5['hasPrevious'] = False\n"", ""if VAR_15:\n"", ""VAR_5['hasNext'] = VAR_15 > VAR_18\n"", ""VAR_5['hasNext'] = False\n"", ""return VAR_5\n""]",1
"[""def FUNC_1(self):...\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    limit_page_length=None))\n""]",0
"[""@query_cached...\n"", ""VAR_25 = hashlib.sha1(str(VAR_20).encode('utf-8')).hexdigest()\n"", ""VAR_35 = re.match('.*?select\\\\s(.*)from.*', VAR_20, flags=re.IGNORECASE |\n    re.UNICODE | re.DOTALL)\n"", ""if VAR_35:\n"", ""VAR_26 = []\n"", ""VAR_26 = []\n"", ""VAR_44 = 0\n"", ""VAR_0.warning(\n    'Redshift unload requires poorly parsing column names from sql, found: {}'\n    .format(VAR_26))\n"", ""VAR_45 = VAR_35[1].split(',')\n"", ""VAR_20 = \""UNLOAD ('\"" + VAR_20.replace('\\\\', '\\\\\\\\').replace(\""'\"", \""\\\\'\"") + \""') \""\n"", ""for VAR_51 in VAR_45:\n"", ""VAR_20 += \""TO 's3://\"" + os.path.join(lore.io.bucket.name, self.\n    UNLOAD_PREFIX, VAR_25, '') + \""' \""\n"", ""VAR_44 += VAR_51.count('(')\n"", ""if CLASS_0.IAM_ROLE:\n"", ""VAR_44 -= VAR_51.count(')')\n"", ""VAR_20 += \""IAM_ROLE '\"" + CLASS_0.IAM_ROLE + \""' \""\n"", ""VAR_20 += \""DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE\""\n"", ""if VAR_44 == 0:\n"", ""if re.match('(.*?)(limit\\\\s+\\\\d+)(.*)', VAR_20, re.IGNORECASE | re.UNICODE |\n"", ""VAR_26.append(VAR_51.split()[-1].split('.')[-1].strip())\n"", ""if VAR_51 == VAR_45[-1]:\n"", ""VAR_0.warning('LIMIT clause is not supported by unload, returning full set.')\n"", ""self.__execute(VAR_20, VAR_24)\n"", ""VAR_51 = re.split('from', VAR_51, flags=re.IGNORECASE)[0].strip()\n"", ""VAR_20 = re.sub('(.*?)(limit\\\\s+\\\\d+)(.*)', '\\\\1\\\\3', VAR_20, flags=re.\n    IGNORECASE | re.UNICODE | re.DOTALL)\n"", ""return VAR_25, VAR_26\n"", ""VAR_26.append(VAR_51.split()[-1].split('.')[-1].strip())\n""]",0
"[""def FUNC_4(VAR_0):...\n"", ""VAR_9 = VAR_0.last_attempted_swarming_task_id\n"", ""VAR_10 = VAR_0.last_attempted_build_number\n"", ""VAR_11 = VAR_9 if VAR_9 and VAR_9.lower() not in (NO_TASK, NO_TASK_EXCEPTION\n    ) else None\n"", ""return {'task_id': VAR_11, 'build_number': VAR_10}\n""]",0
"[""def FUNC_0(self, VAR_0='crimemap'):...\n"", """"]",0
"[""def __init__(self, VAR_15, VAR_16, VAR_17):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self._name = 'Netatmo {} {}'.format(VAR_16, VAR_5[VAR_17][0])\n"", ""self.netatmo_data = VAR_15\n"", ""self.module_name = VAR_16\n"", ""self.type = VAR_17\n"", ""self._state = None\n"", ""self._device_class = VAR_5[self.type][3]\n"", ""self._icon = VAR_5[self.type][2]\n"", ""self._unit_of_measurement = VAR_5[self.type][1]\n"", ""VAR_20 = self.netatmo_data.station_data.moduleByName(module=module_name)['_id']\n"", ""self.module_id = VAR_20[1]\n""]",0
"[""def FUNC_26(self, VAR_32, VAR_17, VAR_18=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_48 = self._scheduler.product_request(FallibleExecuteProcessResult, [VAR_32]\n    )[0]\n"", ""workunit.output('stdout').write(VAR_48.stdout)\n"", ""workunit.output('stderr').write(VAR_48.stderr)\n"", ""workunit.set_outcome(WorkUnit.FAILURE if VAR_48.exit_code else WorkUnit.SUCCESS\n    )\n"", ""return VAR_48\n""]",0
"[""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""assert self._redis_address is None\n"", ""self._redis_address, VAR_11, VAR_12 = ray.services.start_redis(self.\n    _node_ip_address, port=self._ray_params.redis_port, redis_shard_ports=\n    self._ray_params.redis_shard_ports, num_redis_shards=self._ray_params.\n    num_redis_shards, redis_max_clients=self._ray_params.redis_max_clients,\n    redirect_output=self._ray_params.redirect_output,\n    redirect_worker_output=self._ray_params.redirect_worker_output,\n    password=self._ray_params.redis_password, redis_max_memory=self.\n    _ray_params.redis_max_memory)\n"", ""assert VAR_13.PROCESS_TYPE_REDIS_SERVER not in self.all_processes\n"", ""self.all_processes[VAR_13.PROCESS_TYPE_REDIS_SERVER] = VAR_12\n""]",1
"[""def FUNC_11(self):...\n"", ""VAR_3 = 5\n"", ""for i in range(VAR_3):\n"", ""VAR_11 = urllib.urlencode({url_helper.swarm_constants.COUNT_KEY: i})\n"", ""self._mox.ReplayAll()\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), VAR_11, timeout=mox.IgnoreArg()\n    ).AndRaise(urllib2.URLError('url'))\n"", ""self.assertEqual(url_helper.UrlOpen('url', max_tries=attempts), None)\n"", ""if i != VAR_3 - 1:\n"", ""self._mox.VerifyAll()\n"", ""time.sleep(mox.IgnoreArg())\n""]",1
"[""from aputils.trainee_utils import is_trainee\n"", ""from .models import GospelTrip\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_1 = VAR_0.user\n"", ""if not hasattr(VAR_1, 'type') or not is_trainee(VAR_1):\n"", ""return {'gospel_trips_available': False}\n"", ""VAR_2 = next((gt for gt in GospelTrip.objects.order_by('-open_time') if gt.\n    is_open), None)\n"", ""return {'gospel_trips_available': False}\n"", ""if VAR_2:\n"", ""if VAR_2.is_open:\n"", ""return {'gospel_trips_available': False}\n"", ""return {'gospel_trips_available': True}\n""]",1
"[""import os\n"", ""import queue\n"", ""import subprocess\n"", ""import sys\n"", ""import traceback\n"", ""from PyQt5.QtCore import pyqtSlot\n"", ""from PyQt5.QtGui import QTextCursor\n"", ""from PyQt5.QtWidgets import QVBoxLayout, QMainWindow, QWidget, QTextEdit, QInputDialog, QMessageBox, QApplication\n"", ""from matisse import Matisse\n"", ""from .handled_decorators import handled_function, handled_slot\n"", ""from .logging_stream import LoggingStream\n"", ""from .status_monitor import StatusMonitor\n"", ""from .threading import ExitFlag, LoggingThread\n"", ""VAR_0 = 42\n"", ""def __init__(self, *VAR_1, **VAR_2):...\n"", ""super().__init__(*VAR_1, **kwargs)\n"", ""self.setup_logging()\n"", ""self.setup_window()\n"", ""self.setup_menus()\n"", ""self.setup_action_listeners()\n"", ""self.setup_log_window()\n"", ""self.setup_matisse()\n"", ""self.setup_widgets()\n"", ""self.aboutToQuit.connect(self.clean_up)\n"", ""VAR_5 = QWidget()\n"", ""VAR_5.setLayout(self.layout)\n"", ""self.window.setCentralWidget(VAR_5)\n"", ""self.window.show()\n"", ""def FUNC_0(self):...\n"", ""self.log_area = QTextEdit()\n"", ""self.log_area.setReadOnly(True)\n"", ""self.log_queue = queue.Queue()\n"", ""self.log_stream = LoggingStream(self.log_queue)\n"", ""self.log_thread = LoggingThread(self.log_queue, parent=self)\n"", ""self.log_thread.message_received.connect(self.log)\n"", ""self.log_thread.start()\n"", ""def FUNC_1(self):...\n"", ""self.window = VAR_6 = QMainWindow()\n"", ""self.layout = QVBoxLayout()\n"", ""VAR_6.setWindowTitle('Matisse Controller')\n"", ""VAR_6.resize(600, 200)\n"", ""def FUNC_2(self):...\n"", ""VAR_7 = self.window.menuBar()\n"", ""VAR_8 = VAR_7.addMenu('Console')\n"", ""self.clear_log_area_action = VAR_8.addAction('Clear Log')\n"", ""self.open_idle_action = VAR_8.addAction('Open Python Shell...')\n"", ""self.restart_action = VAR_8.addAction('Restart')\n"", ""VAR_9 = VAR_7.addMenu('Set')\n"", ""self.set_wavelength_action = VAR_9.addAction('Wavelength')\n"", ""self.set_bifi_approx_wavelength_action = VAR_9.addAction(\n    'BiFi Approx. Wavelength')\n"", ""self.set_bifi_motor_pos_action = VAR_9.addAction('BiFi Motor Position')\n"", ""self.set_thin_eta_motor_pos_action = VAR_9.addAction(\n    'Thin Etalon Motor Position')\n"", ""VAR_10 = VAR_7.addMenu('Scan')\n"", ""self.bifi_scan_action = VAR_10.addAction('Birefringent Filter')\n"", ""self.thin_eta_scan_action = VAR_10.addAction('Thin Etalon')\n"", ""VAR_11 = VAR_7.addMenu('Lock')\n"", ""self.lock_all_action = VAR_11.addAction('Lock All')\n"", ""self.lock_all_action.setCheckable(True)\n"", ""self.lock_slow_piezo_action = VAR_11.addAction('Lock Slow Piezo')\n"", ""self.lock_slow_piezo_action.setCheckable(True)\n"", ""self.lock_thin_etalon_action = VAR_11.addAction('Lock Thin Etalon')\n"", ""self.lock_thin_etalon_action.setCheckable(True)\n"", ""self.lock_piezo_etalon_action = VAR_11.addAction('Lock Piezo Etalon')\n"", ""self.lock_piezo_etalon_action.setCheckable(True)\n"", ""self.lock_fast_piezo_action = VAR_11.addAction('Lock Fast Piezo')\n"", ""self.lock_fast_piezo_action.setCheckable(True)\n"", ""VAR_12 = VAR_7.addMenu('Tools')\n"", ""self.lock_actions = [self.lock_slow_piezo_action, self.\n    lock_thin_etalon_action, self.lock_piezo_etalon_action, self.\n    lock_fast_piezo_action]\n"", ""def FUNC_3(self):...\n"", ""self.clear_log_area_action.triggered.connect(self.clear_log_area)\n"", ""self.open_idle_action.triggered.connect(self.open_idle)\n"", ""self.restart_action.triggered.connect(self.restart)\n"", ""self.set_wavelength_action.triggered.connect(self.set_wavelength_dialog)\n"", ""self.set_bifi_approx_wavelength_action.triggered.connect(self.\n    set_bifi_approx_wavelength_dialog)\n"", ""self.set_bifi_motor_pos_action.triggered.connect(self.set_bifi_motor_pos_dialog\n    )\n"", ""self.set_thin_eta_motor_pos_action.triggered.connect(self.\n    set_thin_eta_motor_pos_dialog)\n"", ""self.bifi_scan_action.triggered.connect(self.start_bifi_scan)\n"", ""self.thin_eta_scan_action.triggered.connect(self.start_thin_etalon_scan)\n"", ""self.lock_all_action.triggered.connect(self.toggle_lock_all)\n"", ""self.lock_slow_piezo_action.triggered.connect(self.toggle_slow_piezo_lock)\n"", ""self.lock_thin_etalon_action.triggered.connect(self.toggle_thin_etalon_lock)\n"", ""self.lock_piezo_etalon_action.triggered.connect(self.toggle_piezo_etalon_lock)\n"", ""self.lock_fast_piezo_action.triggered.connect(self.toggle_fast_piezo_lock)\n"", ""def FUNC_4(self):...\n"", ""self.layout.addWidget(self.log_area)\n"", ""@handled_function...\n"", ""self.status_monitor_queue = queue.Queue(maxsize=1)\n"", ""self.status_monitor = StatusMonitor(self.matisse, self.status_monitor_queue)\n"", ""self.layout.addWidget(self.status_monitor)\n"", ""@handled_function...\n"", ""self.matisse: Matisse = Matisse(device_id=sys.argv[1], wavemeter_port=sys.\n    argv[2])\n"", ""self.matisse: Matisse = None\n"", ""@pyqtSlot()...\n"", ""self.status_monitor_queue.put(ExitFlag())\n"", ""self.status_monitor.update_thread.wait()\n"", ""self.log_queue.put(ExitFlag())\n"", ""self.log_thread.wait()\n"", ""@pyqtSlot(str)...\n"", ""self.log_area.moveCursor(QTextCursor.End)\n"", ""self.log_area.insertPlainText(VAR_3)\n"", ""def FUNC_9(self):...\n"", ""VAR_13 = list(traceback.format_exception(*sys.exc_info()))\n"", ""VAR_14 = min(max([len(line) for line in VAR_13]), 185)\n"", ""VAR_15 = VAR_13.pop()\n"", ""print(VAR_15, end='')\n"", ""VAR_13 = filter(lambda item: os.path.join('gui', 'handled_decorators.py')\n     not in item, VAR_13)\n"", ""VAR_16 = QMessageBox(icon=QMessageBox.Critical)\n"", ""VAR_16.setWindowTitle('Error')\n"", ""VAR_16.setText(f\""\""\""{VAR_15 + '_' * VAR_14}\n\n{''.join(VAR_13)}\""\""\"")\n"", ""VAR_16.exec()\n"", ""@handled_slot(bool)...\n"", ""self.log_area.clear()\n"", ""@handled_slot(bool)...\n"", ""print('Opening IDLE.')\n"", ""subprocess.Popen(\n    'python -m idlelib -t \""Matisse Controller - Python Shell\"" -c \""from matisse import Matisse; '\n     +\n    'matisse = Matisse(); print(\\'Access the Matisse using \\\\\\'matisse.[method]\\\\\\'\\')\""'\n    )\n"", ""@handled_slot(bool)...\n"", ""self.exit(self.EXIT_CODE_RESTART)\n"", ""@handled_slot(bool)...\n"", ""VAR_17, VAR_18 = QInputDialog.getDouble(self.window, title='Set Wavelength',\n    label='Wavelength (nm): ', value=self.matisse.target_wavelength)\n"", ""if VAR_18:\n"", ""print(f'Setting wavelength to {VAR_17} nm...')\n"", ""@handled_slot(bool)...\n"", ""self.matisse.set_wavelength(VAR_17)\n"", ""VAR_17, VAR_18 = QInputDialog.getDouble(self.window, title=\n    'Set Approx. Wavelength', label='Wavelength (nm): ', value=self.matisse\n    .query('MOTBI:WL?', numeric_result=True))\n"", ""if VAR_18:\n"", ""print(f'Setting BiFi approximate wavelength to {VAR_17} nm...')\n"", ""@handled_slot(bool)...\n"", ""self.matisse.set_bifi_wavelength(VAR_17)\n"", ""VAR_19, VAR_18 = QInputDialog.getInt(self.window, title=\n    'Set BiFi Motor Position', label='Absolute Position:', value=self.\n    matisse.query('MOTBI:POS?', numeric_result=True))\n"", ""if VAR_18:\n"", ""print(f'Setting BiFi motor position to {VAR_19}.')\n"", ""@handled_slot(bool)...\n"", ""self.matisse.set_bifi_motor_pos(VAR_19)\n"", ""VAR_19, VAR_18 = QInputDialog.getInt(self.window, title=\n    'Set Thin Etalon Motor Position', label='Absolute Position:', value=\n    self.matisse.query('MOTTE:POS?', numeric_result=True))\n"", ""if VAR_18:\n"", ""print(f'Setting thin etalon motor position to {VAR_19}.')\n"", ""@handled_slot(bool)...\n"", ""self.matisse.set_thin_etalon_motor_pos(VAR_19)\n"", ""print('Starting BiFi scan...')\n"", ""self.matisse.birefringent_filter_scan()\n"", ""@handled_slot(bool)...\n"", ""print('Starting thin etalon scan...')\n"", ""self.matisse.thin_etalon_scan()\n"", ""@handled_slot(bool)...\n"", ""if VAR_4:\n"", ""for action in self.lock_actions:\n"", ""for action in reversed(self.lock_actions):\n"", ""if not action.isChecked():\n"", ""if all([action.isChecked() for action in self.lock_actions]):\n"", ""action.trigger()\n"", ""@handled_slot(bool)...\n"", ""action.trigger()\n"", ""[action.setEnabled(False) for action in self.lock_actions]\n"", ""self.lock_all_action.setChecked(False)\n"", ""action.setEnabled(True)\n"", ""print(f\""{'Locking' if VAR_4 else 'Unlocking'} slow piezo.\"")\n"", ""print(\""Couldn't lock all laser components.\"")\n"", ""self.lock_slow_piezo_action.setChecked(not VAR_4)\n"", ""self.matisse.set_slow_piezo_lock(VAR_4)\n"", ""self.lock_slow_piezo_action.setChecked(VAR_4)\n"", ""@handled_slot(bool)...\n"", ""print(f\""{'Locking' if VAR_4 else 'Unlocking'} thin etalon.\"")\n"", ""self.lock_thin_etalon_action.setChecked(not VAR_4)\n"", ""self.matisse.set_thin_etalon_lock(VAR_4)\n"", ""self.lock_thin_etalon_action.setChecked(VAR_4)\n"", ""@handled_slot(bool)...\n"", ""print(f\""{'Locking' if VAR_4 else 'Unlocking'} piezo etalon.\"")\n"", ""self.lock_piezo_etalon_action.setChecked(not VAR_4)\n"", ""self.matisse.set_piezo_etalon_lock(VAR_4)\n"", ""self.lock_piezo_etalon_action.setChecked(VAR_4)\n"", ""@handled_slot(bool)...\n"", ""print(f\""{'Locking' if VAR_4 else 'Unlocking'} fast piezo.\"")\n"", ""self.lock_fast_piezo_action.setChecked(not VAR_4)\n"", ""self.matisse.set_piezo_etalon_lock(VAR_4)\n"", ""self.lock_fast_piezo_action.setChecked(VAR_4)\n""]",1
"[""import json\n"", ""import logging\n"", ""import os\n"", ""import sys\n"", ""import webapp2\n"", ""from google.appengine.api import users\n"", ""from webapp2_extras import jinja2\n"", ""import common\n"", ""\""\""\""Base class for administrative commands.\n\n  Implement get() and post() methods in the subclasses.\n  \""\""\""\n"", ""def __init__(self, VAR_3):...\n"", ""self._handler = VAR_3\n"", ""@property...\n"", ""return self._handler.request\n""]",1
"[""def FUNC_7(self):...\n"", ""self.client.login(username=self.tester.username, password='password')\n"", ""VAR_2 = 'new comment'\n"", ""VAR_1 = self.client.post(self.many_comments_url, {'comment': VAR_2, 'run':\n    ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])})\n"", ""self.assertJSONEqual(str(VAR_1.content, encoding=settings.DEFAULT_CHARSET),\n    {'rc': 0, 'response': 'ok'})\n"", ""VAR_3 = ContentType.objects.get_for_model(TestCaseRun)\n"", ""for case_run_pk in (self.case_run_1.pk, self.case_run_2.pk):\n"", ""VAR_9 = Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct)\n"", ""self.assertEqual(VAR_2, VAR_9[0].comment)\n"", ""self.assertEqual(self.tester, VAR_9[0].user)\n""]",0
"[""import os\n"", ""import sys\n"", ""import unittest\n"", ""from coalib.misc.Shell import escape_path_argument, prepare_string_argument, run_interactive_shell_command, run_shell_command\n"", ""def FUNC_0(self):...\n"", ""VAR_1 = 'sh'\n"", ""self.assertEqual(escape_path_argument('/home/usr/a-file', VAR_1),\n    '/home/usr/a-file')\n"", ""self.assertEqual(escape_path_argument('/home/usr/a-dir/', VAR_1),\n    '/home/usr/a-dir/')\n"", ""self.assertEqual(escape_path_argument('/home/us r/a-file with spaces.bla',\n    VAR_1), '/home/us\\\\ r/a-file\\\\ with\\\\ spaces.bla')\n"", ""self.assertEqual(escape_path_argument('/home/us r/a-dir with spaces/x/',\n    VAR_1), '/home/us\\\\ r/a-dir\\\\ with\\\\ spaces/x/')\n"", ""self.assertEqual(escape_path_argument(\n    'relative something/with cherries and/pickles.delicious', VAR_1),\n    'relative\\\\ something/with\\\\ cherries\\\\ and/pickles.delicious')\n"", ""def FUNC_1(self):...\n"", ""VAR_1 = 'cmd'\n"", ""self.assertEqual(escape_path_argument('C:\\\\Windows\\\\has-a-weird-shell.txt',\n    VAR_1), '\""C:\\\\Windows\\\\has-a-weird-shell.txt\""')\n"", ""self.assertEqual(escape_path_argument('C:\\\\Windows\\\\lolrofl\\\\dirs\\\\', VAR_1\n    ), '\""C:\\\\Windows\\\\lolrofl\\\\dirs\\\\\""')\n"", ""self.assertEqual(escape_path_argument('X:\\\\Users\\\\Maito Gai\\\\fi le.exe',\n    VAR_1), '\""X:\\\\Users\\\\Maito Gai\\\\fi le.exe\""')\n"", ""self.assertEqual(escape_path_argument('X:\\\\Users\\\\Mai to Gai\\\\director y\\\\',\n    VAR_1), '\""X:\\\\Users\\\\Mai to Gai\\\\director y\\\\\""')\n"", ""self.assertEqual(escape_path_argument(\n    'X:\\\\Users\\\\Maito Gai\\\\\""seven-gates\"".y', VAR_1),\n    '\""X:\\\\Users\\\\Maito Gai\\\\^\""seven-gates^\"".y\""')\n"", ""self.assertEqual(escape_path_argument('System32\\\\my-custom relative tool\\\\',\n    VAR_1), '\""System32\\\\my-custom relative tool\\\\\""')\n"", ""self.assertEqual(escape_path_argument('System32\\\\illegal\"" name \""\"".curd',\n    VAR_1), '\""System32\\\\illegal^\"" name ^\""^\"".curd\""')\n"", ""def FUNC_2(self):...\n"", ""VAR_1 = 'INVALID'\n"", ""self.assertEqual(escape_path_argument('/home/usr/a-file', VAR_1),\n    '/home/usr/a-file')\n"", ""self.assertEqual(escape_path_argument('/home/us r/a-file with spaces.bla',\n    VAR_1), '/home/us r/a-file with spaces.bla')\n"", ""self.assertEqual(escape_path_argument('|home|us r|a*dir with spaces|x|',\n    VAR_1), '|home|us r|a*dir with spaces|x|')\n"", ""self.assertEqual(escape_path_argument('system|a|b|c?d', VAR_1),\n    'system|a|b|c?d')\n"", ""@staticmethod...\n"", ""return ' '.join(escape_path_argument(s) for s in (sys.executable, os.path.\n    join(os.path.dirname(os.path.realpath(__file__)),\n    'run_shell_command_testfiles', VAR_0)))\n""]",1
"[""def __getitem__(self, VAR_17):...\n"", ""if self._r_item_ is VAR_0:\n"", ""if not self._r_via_alternate_lookup_:\n"", ""VAR_28 = CLASS_3(self)\n"", ""self._r_path_.log_getitem(VAR_17, self)\n"", ""return self\n"", ""if VAR_28._r_is_multi_item_ and not isinstance(VAR_17, slice):\n"", ""if isinstance(VAR_17, int):\n"", ""VAR_28._r_item_ = VAR_28._r_item_[VAR_17]\n"", ""VAR_28._r_item_ = VAR_0\n"", ""if isinstance(VAR_17, slice):\n"", ""VAR_33 = []\n"", ""VAR_28._r_item_ = VAR_28._r_item_[VAR_17]\n"", ""VAR_28._r_item_ = VAR_0\n"", ""VAR_28._r_is_multi_item_ = False\n"", ""VAR_28._r_is_multi_item_ = True\n"", ""if VAR_28._r_item_ is VAR_0 and not self._r_via_alternate_lookup_ and not isinstance(\n"", ""for i in VAR_28._r_item_:\n"", ""if not self._r_via_alternate_lookup_:\n"", ""self._r_via_alternate_lookup_ = True\n"", ""VAR_28._r_path_.log_getitem(VAR_17, VAR_28)\n"", ""if VAR_28._r_item_ is VAR_0 and VAR_28._r_raise_:\n"", ""VAR_36 = None\n"", ""VAR_28._r_item_ = tuple(VAR_33)\n"", ""VAR_28._r_path_.log_getitem(VAR_17, VAR_28)\n"", ""VAR_28 = getattr(self, VAR_17)\n"", ""self._r_via_alternate_lookup_ = False\n"", ""return VAR_28\n"", ""VAR_36 = i[VAR_17]\n"", ""if isinstance(VAR_36, (tuple, list, range)):\n"", ""VAR_36 = getattr(i, VAR_17)\n"", ""VAR_33 += VAR_36\n"", ""if VAR_36 is not None:\n"", ""VAR_33.append(VAR_36)\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_6 = BeautifulSoup(self.res_data, 'html.parser')\n"", ""VAR_7 = {}\n"", ""VAR_8 = VAR_6.findAll(id='user_test_status')[0]\n"", ""VAR_7['status'] = VAR_8.text.strip()\n"", ""VAR_9 = VAR_6.findAll(id='compilation')\n"", ""if VAR_9:\n"", ""VAR_12 = VAR_9[0]\n"", ""VAR_7['compile_output'] = None\n"", ""VAR_7['compile_output'] = VAR_12.pre.text.strip()\n"", ""return VAR_7\n""]",0
"[""def FUNC_0():...\n"", ""VAR_7.pack_forget()\n"", ""VAR_5.pack(expand=True, fill='both')\n"", ""VAR_12 = 'meal_planner.db'\n"", ""VAR_20 = conn.cursor()\n"", ""VAR_21 = VAR_20.execute('SELECT * FROM recipe')\n"", ""for result in [VAR_21]:\n"", ""for row in result.fetchall():\n"", ""conn.close()\n"", ""VAR_24 = row[0]\n"", ""for i in range(len(VAR_2)):\n"", ""VAR_2.append(VAR_24)\n"", ""VAR_13 = Label(VAR_5, font=MEDIUM_FONT, bg='#f8f8f8', fg='#000000', text=\n    recipeNames[i])\n"", ""VAR_13.pack()\n"", ""VAR_13.bind('<Button-1>', lambda event, x=VAR_2[i]: [FUNC_1(x), VAR_5.\n    pack_forget()])\n""]",1
"[""def FUNC_11(self, VAR_17):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_44 = 'confirmation', 'paging', 'events', 'formatoutput'\n"", ""VAR_0.error(_('Failed to setup the Dell EqualLogic driver'))\n"", ""for feature in VAR_44:\n"", ""self._eql_execute('cli-settings', feature, 'off')\n"", ""for line in self._eql_execute('grpparams', 'show'):\n"", ""if line.startswith('Group-Ipaddress:'):\n"", ""VAR_0.info(_('EQL-driver: Setup is complete, group IP is %s'), self._group_ip)\n"", ""VAR_50 = line.rstrip().partition(' ')\n"", ""self._group_ip = VAR_50[-1]\n""]",0
"[""def FUNC_14(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""self.driver._eql_execute('pool', 'select', self.configuration.eqlx_pool, 'show'\n    ).AndReturn(['TotalCapacity: 111GB', 'FreeSpace: 11GB'])\n"", ""self.mox.ReplayAll()\n"", ""self.driver._update_volume_stats()\n"", ""self.assertEqual(self.driver._stats['total_capacity_gb'], 111.0)\n"", ""self.assertEqual(self.driver._stats['free_capacity_gb'], 11.0)\n""]",0
"[""def FUNC_1(self):...\n"", ""VAR_4 = {'username': 'firstuser', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='firstuser', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/admin/perms', content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""self.assertEqual(VAR_6.data['results'][0]['username'], 'firstuser')\n"", ""self.assertTrue(VAR_6.data['results'][0]['is_superuser'])\n"", ""VAR_4 = {'username': 'seconduser', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertFalse(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='seconduser', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/admin/perms', content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 403)\n"", ""self.assertIn('You do not have permission', VAR_6.data['detail'])\n""]",1
"[""def FUNC_2(self, VAR_1):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = \""INSERT INTO crimes (description) VALUES('{}');\"".format(VAR_1)\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",1
"[""def FUNC_2(VAR_0, VAR_1):...\n"", ""VAR_5 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) +\n    '\\\\users\\\\' + VAR_0 + '.db')\n"", ""VAR_6 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n"", ""VAR_7 = VAR_5.cursor()\n"", ""VAR_8 = VAR_6.cursor()\n"", ""VAR_7.execute(\n    'CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)')\n"", ""VAR_8.execute('SELECT * FROM problems')\n"", ""VAR_9 = VAR_8.fetchone()\n"", ""while VAR_9 != None:\n"", ""VAR_7.execute('insert into result values (?, ?, ? )', (VAR_9[0], VAR_9[1],\n    'NULL'))\n"", ""VAR_10 = 'http://codeforces.com/submissions/' + VAR_0\n"", ""VAR_9 = VAR_8.fetchone()\n"", ""VAR_2 = requests.get(VAR_10)\n"", ""VAR_11 = 1\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""for link in VAR_3.find_all(attrs={'class': 'page-index'}):\n"", ""VAR_16 = link.find('a')\n"", ""VAR_12 = ''\n"", ""VAR_17 = VAR_16.get('href').split('/')\n"", ""VAR_2 = requests.get('http://codeforces.com/submissions/' + VAR_0 + '/page/0')\n"", ""VAR_11 = max(VAR_11, int(VAR_17[4]))\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""VAR_13 = VAR_3.find(attrs={'class': 'status-small'})\n"", ""if not VAR_13 == None:\n"", ""VAR_13 = str(VAR_13).split()\n"", ""for i in range(1, VAR_11 + 1):\n"", ""VAR_13 = str(VAR_13[2]) + str(VAR_13[3])\n"", ""VAR_2 = requests.get('http://codeforces.com/submissions/' + VAR_0 +\n    '/page/' + str(i))\n"", ""VAR_5.commit()\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""VAR_5.close()\n"", ""VAR_18 = 0\n"", ""VAR_6.close()\n"", ""VAR_19 = VAR_3.find_all(attrs={'class': 'submissionVerdictWrapper'})\n"", ""VAR_14 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) +\n    '\\\\settings.db')\n"", ""for link in VAR_3.find_all('a'):\n"", ""VAR_5 = VAR_14.cursor()\n"", ""VAR_16 = link.get('href')\n"", ""VAR_5.execute('select * from last_update_problemset')\n"", ""if VAR_16 != None and VAR_16.find('/problemset') != -1:\n"", ""VAR_15 = VAR_5.fetchone()\n"", ""VAR_16 = VAR_16.split('/')\n"", ""VAR_5.execute(\""select * from users where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""if len(VAR_16) == 5:\n"", ""VAR_9 = VAR_5.fetchone()\n"", ""VAR_17 = str(VAR_19[VAR_18]).split()\n"", ""if VAR_9 == None:\n"", ""VAR_17 = VAR_17[5].split('\""')\n"", ""VAR_5.execute('insert into users values (?, ?, ?, ?, ?)', (VAR_1, VAR_0,\n    str(VAR_13), str(VAR_15[0]), 1))\n"", ""VAR_5.execute(\""update users set username = '\"" + str(VAR_0) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_18 += 1\n"", ""VAR_14.commit()\n"", ""VAR_5.execute(\""update users set last_update = '\"" + str(VAR_13) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_7.execute(\""select * from result where problem = '\"" + VAR_16[3] +\n    \""'and diff = '\"" + VAR_16[4] + \""'\"")\n"", ""VAR_14.close()\n"", ""VAR_5.execute(\""update users set last_problem = '\"" + str(VAR_15[0]) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_9 = VAR_7.fetchone()\n"", ""VAR_5.execute(\""update users set state = '\"" + str(1) + \""' where chat_id = '\"" +\n    str(VAR_1) + \""'\"")\n"", ""if VAR_17[1] == 'OK' and VAR_9 != None:\n"", ""VAR_7.execute(\""update result set verdict = '\"" + VAR_17[1] +\n    \""' where problem = '\"" + VAR_16[3] + \""' and diff = '\"" + VAR_16[4] + \""'\"")\n"", ""if VAR_9 != None and VAR_9[2] != 'OK':\n"", ""VAR_7.execute(\""update result set verdict = '\"" + VAR_17[1] +\n    \""' where problem = '\"" + VAR_16[3] + \""' and diff = '\"" + VAR_16[4] + \""'\"")\n""]",1
"[""def FUNC_1(self, VAR_0, VAR_1, VAR_2, VAR_3):...\n"", ""for injection_types in self.signatures.keys():\n"", ""for sig in self.signatures[injection_types]:\n"", ""return False\n"", ""VAR_6 = re.findall(re.escape(sig), VAR_2)\n"", ""if VAR_6 and any(x in VAR_1 for x in '><'):\n"", ""self.found(injection_types, VAR_0, VAR_3, VAR_1)\n"", ""return True\n""]",1
"[""def FUNC_3(self, VAR_6, VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = ray.gcs_utils.GcsTableEntry.GetRootAsGcsTableEntry(VAR_7, 0)\n"", ""VAR_26 = VAR_14.Entries(0)\n"", ""VAR_16 = ray.gcs_utils.DriverTableData.GetRootAsDriverTableData(VAR_26, 0)\n"", ""VAR_8 = VAR_16.DriverId()\n"", ""VAR_0.info('Monitor: XRay Driver {} has been removed.'.format(binary_to_hex\n    (VAR_8)))\n"", ""self._xray_clean_up_entries_for_driver(VAR_8)\n""]",0
"[""def FUNC_5(VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if type(VAR_7) == type('') and len(VAR_7) >= 15 and len(VAR_7\n"", ""return True\n"", ""return False\n""]",1
"[""def FUNC_0(self):...\n"", ""def FUNC_33(self):...\n"", ""@api.public...\n"", ""@api.require(lambda : True)...\n""]",0
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_2=('PUT',))\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', {'xsrf_token': VAR_17})\n"", ""VAR_7.put('/request', {'xsrf_token': VAR_17})\n"", ""self.assertEqual([('POST', True), ('PUT', True)], VAR_12)\n"", ""self.assertEqual(200, VAR_7.post('/request').status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', expect_errors=True).status_int)\n"", ""VAR_18 = {'xsrf_token': 'boo'}\n"", ""self.assertEqual(403, VAR_7.post('/request', VAR_18, expect_errors=True).\n    status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', VAR_18, expect_errors=True).\n    status_int)\n""]",1
"[""def FUNC_10(VAR_12):...\n"", ""VAR_13 = binascii.hexlify(VAR_12)\n"", ""if sys.version_info >= (3, 0):\n"", ""VAR_13 = VAR_13.decode()\n"", ""return VAR_13\n""]",0
"[""def FUNC_23(self, VAR_14):...\n"", """"]",0
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""def FUNC_15(self, VAR_10, VAR_8):...\n"", ""VAR_29, VAR_28 = VAR_10.compile(self.lhs)\n"", ""return '%s[%s:%s]' % (VAR_29, self.start, self.end), VAR_28\n""]",1
"[""import helpers\n"", ""import ophandlers\n"", ""import oplists\n"", ""from copy import deepcopy\n"", ""def __init__(self, VAR_0, VAR_1, VAR_2=[], VAR_3=[], VAR_4={}, VAR_5={},...\n"", ""self.opcodes = VAR_0\n"", ""self.functions = VAR_1\n"", ""self.stack = VAR_2\n"", ""self.memory = VAR_3\n"", ""self.storage = VAR_4\n"", ""self.symbols = VAR_5\n"", ""self.userIn = VAR_6\n"", ""self.instrPtr = VAR_7\n"", ""self.symId = VAR_8\n"", ""def FUNC_0(self, VAR_9, VAR_5):...\n"", ""self.instrPtr = VAR_9[1][0]\n"", ""return ophandlers.makeJump(VAR_9[0], VAR_5, self.symId)\n""]",1
"[""def FUNC_7(self, VAR_2, VAR_1=None):...\n"", ""self.filter_string = self.filter_func(VAR_2, VAR_1)\n"", ""print(self.filter_string)\n""]",1
"[""def FUNC_10(self, VAR_16, VAR_15, VAR_12=None):...\n"", ""return self._rest_call(VAR_16, VAR_24='PUT', VAR_15=body, VAR_12=headers)\n""]",0
"[""from flask import Flask, g, render_template, request, jsonify\n"", ""from utils import get_db, get_queries, shutdown, ajax, execute_query, generic_search\n"", ""import os\n"", ""import atexit\n"", ""VAR_0 = Flask(__name__)\n"", ""atexit.register(shutdown, VAR_0=app, context=g)\n"", ""VAR_0.config.update({'DB_USER': os.environ['IDBS_USER'], 'DB_PWD': os.\n    environ['IDBS_PWD'], 'DB_SERVER': 'diassrv2.epfl.ch', 'DB_PORT': 1521,\n    'DB_SID': 'orcldias', 'DEBUG': True, 'QUERIES_PATH': 'queries.sql'})\n"", ""@VAR_0.route('/')...\n"", ""VAR_1 = get_db(VAR_0, g)\n"", ""return render_template('index.html')\n""]",1
"[""import re\n"", ""import subprocess\n"", ""import sqlite3\n"", ""VAR_0 = '/home/peter/projects/jdk/db/jdk_entries.db'\n"", ""VAR_1 = \""DATETIME(CURRENT_TIMESTAMP, 'localtime')\""\n"", ""VAR_2 = '/home/peter/projects/jdk/db/temp.jdk'\n"", ""def FUNC_0(VAR_3, VAR_4=False):...\n"", ""VAR_5 = sqlite3.connect(VAR_0)\n"", ""VAR_6 = VAR_5.cursor()\n"", ""VAR_6.execute(VAR_3)\n"", ""if VAR_4:\n"", ""VAR_17 = VAR_6.fetchall()\n"", ""VAR_17 = None\n"", ""VAR_5.close()\n"", ""VAR_5.commit()\n"", ""return VAR_17\n""]",0
"[""from __future__ import absolute_import\n"", ""from mock import MagicMock, patch\n"", ""from six.moves.urllib_parse import quote_plus\n"", ""from flask import url_for, session\n"", ""from invenio.testsuite import make_test_suite, run_test_suite\n"", ""from invenio.ext.sqlalchemy import db\n"", ""from .helpers import OAuth2ClientTestCase\n"", ""def FUNC_0(self):...\n"", ""VAR_8 = lambda x: dict(request_token_params={'scope': ''}, base_url=\n    'https://foo.bar/', request_token_url=None, access_token_url=\n    'https://foo.bar/oauth/access_token', authorize_url=\n    'https://foo.bar/oauth/authorize', consumer_key=x, consumer_secret=\n    'testsecret')\n"", ""self.app.config['OAUTHCLIENT_REMOTE_APPS'] = dict(test=dict(\n    authorized_handler=self.handler, params=params('testid'), title=\n    'MyLinkedTestAccount'), test_invalid=dict(authorized_handler=self.\n    handler_invalid, params=params('test_invalidid'), title='Test Invalid'),\n    full=dict(params=params('fullid'), title='Full'))\n"", ""self.handled_resp = None\n"", ""self.handled_remote = None\n"", ""self.handled_args = None\n"", ""self.handled_kwargs = None\n"", ""from invenio.modules.oauthclient.models import RemoteToken, RemoteAccount\n"", ""RemoteToken.query.delete()\n"", ""RemoteAccount.query.delete()\n"", ""db.session.commit()\n"", ""def FUNC_1(self):...\n"", ""self.handled_resp = None\n"", ""self.handled_remote = None\n"", ""self.handled_args = None\n"", ""self.handled_kwargs = None\n"", ""from invenio.modules.oauthclient.models import RemoteToken, RemoteAccount\n"", ""RemoteToken.query.delete()\n"", ""RemoteAccount.query.delete()\n"", ""db.session.commit()\n"", ""def FUNC_2(self, VAR_1, VAR_2, *VAR_3, **VAR_4):...\n"", ""self.handled_resp = VAR_1\n"", ""self.handled_remote = VAR_2\n"", ""self.handled_args = VAR_3\n"", ""self.handled_kwargs = VAR_4\n"", ""return 'TEST'\n""]",1
"[""def FUNC_4(VAR_3):...\n"", ""if not VAR_3:\n"", ""return errors.BAD_USERNAME_CHARS\n"", ""if len(VAR_3) < 3:\n"", ""return errors.BAD_USERNAME_SHORT\n"", ""if len(VAR_3) > 20:\n"", ""return errors.BAD_USERNAME_LONG\n"", ""return errors.BAD_USERNAME_CHARS\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_17 = [VAR_28.mtime for VAR_28 in self.input if VAR_28.exists]\n"", ""if VAR_17:\n"", ""return max(VAR_17)\n"", ""return None\n""]",0
"[""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_22 = 0.1\n"", ""VAR_23 = self.metrics['time_coeff'] * random.expovariate(self.metrics[\n    'time_lambda'])\n"", ""VAR_24 = int(VAR_23 / VAR_22)\n"", ""VAR_25 = VAR_23 - VAR_24 * VAR_22\n"", ""for i in xrange(VAR_24):\n"", ""time.sleep(VAR_22)\n"", ""time.sleep(VAR_25)\n"", ""if self.die:\n"", ""if self.die:\n""]",1
"[""@staticmethod...\n"", ""VAR_8 = dbaseConn()\n"", ""VAR_11 = ('SELECT `uid`,`email`,`name` FROM `User` WHERE `uid`=' + \""'\"" +\n    VAR_0 + \""'\"")\n"", ""cursor.execute(VAR_11)\n"", ""VAR_10 = cursor.fetchone()\n"", ""print(VAR_10)\n"", ""if VAR_10 is None:\n"", ""VAR_8.db_conn_close()\n"", ""VAR_12 = ('UPDATE `User` SET `name` = ' + \""'\"" + VAR_5 + \""'\"" +\n    ' WHERE `uid` = %s')\n"", ""VAR_8.db_conn_close()\n"", ""return True\n"", ""return False\n"", ""print(VAR_12)\n"", ""return False\n"", ""cursor.execute(VAR_12, (VAR_0,))\n"", ""VAR_8.db.commit()\n""]",1
"[""@staticmethod...\n"", ""VAR_0 = Database()\n"", ""VAR_11 = VAR_0.list_tasks(VAR_2=limit, VAR_3=offset, VAR_30='file',\n    not_status=TASK_PENDING)\n"", ""VAR_12 = VAR_0.list_tasks(VAR_2=limit, VAR_3=offset, VAR_30='url',\n    not_status=TASK_PENDING)\n"", ""VAR_9 = []\n"", ""if VAR_11:\n"", ""for VAR_10 in VAR_11:\n"", ""if VAR_12:\n"", ""VAR_27 = VAR_10.to_dict()\n"", ""for VAR_10 in VAR_12:\n"", ""return VAR_9\n"", ""VAR_27['sample'] = VAR_0.view_sample(VAR_27['sample_id']).to_dict()\n"", ""VAR_27 = VAR_10.to_dict()\n"", ""VAR_28 = os.path.basename(VAR_27['target'])\n"", ""if VAR_0.view_errors(VAR_10.id):\n"", ""VAR_27.update({'filename': VAR_28})\n"", ""VAR_27['errors'] = True\n"", ""VAR_9.append(VAR_27)\n"", ""if VAR_0.view_errors(VAR_10.id):\n"", ""VAR_27['errors'] = True\n"", ""VAR_9.append(VAR_27)\n""]",0
"[""def FUNC_1(self):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = 'SELECT description FROM crimes;'\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""return cursor.fetchall()\n""]",1
"[""def FUNC_3(self, VAR_1, VAR_2, VAR_5, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_30 = VAR_4.get('states', [])\n"", ""VAR_31 = VAR_4.get('what', ())\n"", ""if not VAR_5:\n"", ""VAR_5 = self.search(VAR_1, VAR_2, [])\n"", ""VAR_29 = {}.fromkeys(VAR_5, 0.0)\n"", ""if not VAR_5:\n"", ""return VAR_29\n"", ""if VAR_4.get('shop', False):\n"", ""VAR_1.execute('select warehouse_id from sale_shop where id=%s', (int(VAR_4[\n    'shop']),))\n"", ""if VAR_4.get('warehouse', False):\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""VAR_1.execute('select lot_stock_id from stock_warehouse where id=%s', (int(\n    VAR_4['warehouse']),))\n"", ""if VAR_4.get('location', False):\n"", ""if VAR_41:\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""if type(VAR_4['location']) == type(1):\n"", ""VAR_42 = []\n"", ""VAR_4['warehouse'] = VAR_41[0]\n"", ""if VAR_41:\n"", ""VAR_42 = [VAR_4['location']]\n"", ""if type(VAR_4['location']) in (type(''), type(u'')):\n"", ""VAR_43 = self.pool.get('stock.warehouse').search(VAR_1, VAR_2, [], VAR_4=\n    context)\n"", ""VAR_4['location'] = VAR_41[0]\n"", ""if VAR_4.get('compute_child', True):\n"", ""VAR_42 = self.pool.get('stock.location').search(VAR_1, VAR_2, [('name',\n    'ilike', VAR_4['location'])], VAR_4=context)\n"", ""VAR_42 = VAR_4['location']\n"", ""for w in self.pool.get('stock.warehouse').browse(VAR_1, VAR_2, VAR_43,\n"", ""VAR_44 = self.pool.get('stock.location').search(VAR_1, VAR_2, [(\n    'location_id', 'child_of', VAR_42)])\n"", ""VAR_42 = VAR_42\n"", ""VAR_42.append(w.lot_stock_id.id)\n"", ""VAR_42 = VAR_44 or VAR_42\n"", ""VAR_32 = {}\n"", ""VAR_33 = {}\n"", ""for VAR_45 in self.browse(VAR_1, VAR_2, VAR_5, VAR_4=context):\n"", ""VAR_33[VAR_45.id] = VAR_45.uom_id.id\n"", ""VAR_34 = []\n"", ""VAR_32[VAR_45.uom_id.id] = VAR_45.uom_id\n"", ""VAR_35 = []\n"", ""VAR_36 = VAR_4.get('from_date', False)\n"", ""VAR_37 = VAR_4.get('to_date', False)\n"", ""VAR_38 = False\n"", ""if VAR_36 and VAR_37:\n"", ""VAR_38 = \""date_planned>='%s' and date_planned<='%s'\"" % (VAR_36, VAR_37)\n"", ""if VAR_36:\n"", ""if 'in' in VAR_31:\n"", ""VAR_38 = \""date_planned>='%s'\"" % VAR_36\n"", ""if VAR_37:\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""if 'out' in VAR_31:\n"", ""VAR_38 = \""date_planned<='%s'\"" % VAR_37\n"", ""VAR_34 = VAR_1.fetchall()\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""VAR_39 = self.pool.get('product.uom')\n"", ""VAR_35 = VAR_1.fetchall()\n"", ""VAR_40 = map(lambda x: x[2], VAR_34) + map(lambda x: x[2], VAR_35)\n"", ""if VAR_4.get('uom', False):\n"", ""VAR_40 += [VAR_4['uom']]\n"", ""VAR_40 = filter(lambda x: x not in VAR_32.keys(), VAR_40)\n"", ""if VAR_40:\n"", ""VAR_40 = VAR_39.browse(VAR_1, VAR_2, list(set(VAR_40)), VAR_4=context)\n"", ""for VAR_46 in VAR_40:\n"", ""VAR_32[VAR_46.id] = VAR_46\n"", ""for VAR_47, prod_id, prod_uom in VAR_34:\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""for VAR_47, prod_id, prod_uom in VAR_35:\n"", ""VAR_29[prod_id] += VAR_47\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""return VAR_29\n"", ""VAR_29[prod_id] -= VAR_47\n""]",1
"[""def FUNC_2(self, VAR_2):...\n"", ""return self._xsrf_tool.generate_token(CLASS_0._USER_ID, VAR_2)\n""]",1
"[""from __future__ import absolute_import, division, print_function, unicode_literals\n"", ""import errno\n"", ""import logging\n"", ""import os\n"", ""import re\n"", ""import textwrap\n"", ""from builtins import open\n"", ""from collections import defaultdict\n"", ""from contextlib import closing\n"", ""from hashlib import sha1\n"", ""from xml.etree import ElementTree\n"", ""from future.utils import PY3, text_type\n"", ""from pants.backend.jvm.subsystems.java import Java\n"", ""from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform\n"", ""from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform\n"", ""from pants.backend.jvm.subsystems.zinc import Zinc\n"", ""from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor\n"", ""from pants.backend.jvm.targets.javac_plugin import JavacPlugin\n"", ""from pants.backend.jvm.targets.jvm_target import JvmTarget\n"", ""from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin\n"", ""from pants.backend.jvm.tasks.classpath_util import ClasspathUtil\n"", ""from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile\n"", ""from pants.base.build_environment import get_buildroot\n"", ""from pants.base.exceptions import TaskError\n"", ""from pants.base.hash_utils import hash_file\n"", ""from pants.base.workunit import WorkUnitLabel\n"", ""from pants.engine.fs import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot\n"", ""from pants.engine.isolated_process import ExecuteProcessRequest\n"", ""from pants.java.distribution.distribution import DistributionLocator\n"", ""from pants.util.contextutil import open_zip\n"", ""from pants.util.dirutil import fast_relpath, safe_open\n"", ""from pants.util.memo import memoized_method, memoized_property\n"", ""VAR_0 = 'scalac-plugin.xml'\n"", ""VAR_1 = 'META-INF/services/com.sun.source.util.Plugin'\n"", ""VAR_2 = 'META-INF/services/javax.annotation.processing.Processor'\n"", ""VAR_3 = logging.getLogger(__name__)\n"", ""\""\""\""An abstract base class for zinc compilation tasks.\""\""\""\n"", ""VAR_4 = 'zinc'\n"", ""@staticmethod...\n"", ""VAR_37 = os.path.join(VAR_5, VAR_0)\n"", ""f.write(textwrap.dedent('string'.format(VAR_6.plugin, VAR_6.classname)).strip()\n    )\n"", ""@staticmethod...\n"", ""VAR_38 = os.path.join(VAR_5, VAR_1)\n"", ""VAR_67 = VAR_7.classname if PY3 else VAR_7.classname.decode('utf-8')\n"", ""f.write(VAR_67)\n"", ""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_39 = {re.compile(p): v for p, v in VAR_9.items()}\n"", ""def FUNC_35(VAR_40):...\n"", ""VAR_68 = VAR_10[VAR_40]\n"", ""for pattern, has_argument in VAR_39.items():\n"", ""if pattern.match(VAR_68):\n"", ""VAR_8.warn(\n    \""Zinc argument '{}' is not supported, and is subject to change/removal!\""\n    .format(VAR_68))\n"", ""return 2 if has_argument else 1\n"", ""return 1\n""]",1
"[""def FUNC_14(self):...\n"", ""VAR_14 = self.new_mocked_client(client.RESTClient, url_prefix='api/v1/ports')\n"", ""VAR_14.url_put('connections/1', jsonutils.dumps({'name': 'conn1'}))\n"", ""FUNC_1('put', VAR_14, 'https://1.2.3.4/api/v1/ports/connections/1', VAR_8=\n    jsonutils.dumps({'name': 'conn1'}))\n""]",0
"[""def FUNC_2(self, VAR_5=None, VAR_6=None, VAR_7='', VAR_8=''):...\n"", ""if VAR_6:\n"", ""VAR_5 = VAR_6.apply_all(VAR_5)\n"", ""if VAR_7 != '':\n"", ""if hasattr(self.obj, VAR_7):\n"", ""return VAR_5\n"", ""if hasattr(getattr(self.obj, VAR_7), '_col_name'):\n"", ""VAR_5 = VAR_5.order_by(VAR_7 + ' ' + VAR_8)\n"", ""VAR_7 = getattr(getattr(self.obj, VAR_7), '_col_name')\n""]",1
"[""\""\""\""\nModule for gathering disk information\n\""\""\""\n"", ""import logging\n"", ""import salt.utils\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""def __virtual__():...\n"", ""\""\""\""docstring\""\""\""\n"", ""if salt.utils.is_windows():\n"", ""return False\n"", ""return 'disk'\n""]",0
"[""import os\n"", ""import csv\n"", ""import zipfile\n"", ""from itertools import islice\n"", ""from collections import OrderedDict\n"", ""from djqscsv import render_to_csv_response\n"", ""from pathlib import Path\n"", ""from django import forms\n"", ""from django.urls import reverse\n"", ""from django.conf import settings\n"", ""from django.core.files import File\n"", ""from django.core.exceptions import ValidationError\n"", ""from django.core.files.storage import FileSystemStorage\n"", ""from django.contrib.auth.decorators import login_required\n"", ""from django.shortcuts import render, redirect, get_object_or_404\n"", ""from django.http import HttpResponse\n"", ""from django.core.paginator import Paginator\n"", ""from dashboard.models import *\n"", ""from dashboard.forms import DataGroupForm, ExtractionScriptForm, CleanCompDataForm, create_detail_formset, include_extract_form, include_clean_comp_data_form\n"", ""from dashboard.utils import get_extracted_models, clean_dict, update_fields\n"", ""from django.db.models import Max\n"", ""@login_required()...\n"", ""VAR_3 = DataGroup.objects.all()\n"", ""VAR_4 = {}\n"", ""VAR_4['object_list'] = VAR_3\n"", ""return render(VAR_0, VAR_1, VAR_4)\n""]",1
"[""def FUNC_9(self):...\n"", ""self._hosts_cache = None\n"", ""for VAR_12 in self.parent_groups:\n"", ""VAR_12.clear_hosts_cache()\n""]",1
"[""def FUNC_34(VAR_39):...\n"", ""self.fail()\n""]",0
"[""@functools.wraps(VAR_58)...\n"", ""return VAR_58(*VAR_61, **kwargs)\n""]",0
"[""def FUNC_8(VAR_7):...\n"", ""VAR_11 = f\""\""\""\n            SELECT COUNT(r.id) AS total\n            FROM {VAR_2} AS r\n            WHERE r.product_id={VAR_7}\n            \""\""\""\n"", ""VAR_12 = create_connection()\n"", ""VAR_12.close()\n"", ""VAR_13 = VAR_12.cursor()\n"", ""VAR_13.execute(VAR_11)\n"", ""return int(VAR_13.fetchone()['total'])\n""]",1
"[""def FUNC_18(VAR_3):...\n"", ""VAR_0, VAR_10 = FUNC_0()\n"", ""VAR_18 = \""SELECT options from {} where name = '{}'\"".format(CFG(\n    'poll_table_name'), VAR_3)\n"", ""VAR_25 = FUNC_3(VAR_10, VAR_18)\n"", ""if not VAR_25:\n"", ""VAR_26 = 0\n"", ""VAR_24 = VAR_25.split(',')\n"", ""VAR_27 = dict()\n"", ""for opt in VAR_24:\n"", ""VAR_12 = FUNC_17(VAR_10, VAR_3, opt)\n"", ""VAR_0.close()\n"", ""VAR_26 += int(VAR_12)\n"", ""return VAR_27, VAR_26\n"", ""VAR_27.update({opt: VAR_12})\n""]",1
"[""def FUNC_24(self):...\n"", ""self.cursor.execute(u'select 1')\n""]",0
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""def FUNC_4(self, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))\n"", ""VAR_8 = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')\n"", ""VAR_9 = {'response_type': 'code', 'scope': 'openid', 'client_id': self.\n    OIDC_RP_CLIENT_ID, 'redirect_uri': absolutify(VAR_1, reverse(\n    'oidc_authentication_callback')), 'state': VAR_7}\n"", ""if import_from_settings('OIDC_USE_NONCE', True):\n"", ""VAR_6 = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))\n"", ""VAR_1.session['oidc_state'] = VAR_7\n"", ""VAR_9.update({'nonce': VAR_6})\n"", ""VAR_1.session['oidc_login_next'] = VAR_1.GET.get(VAR_8)\n"", ""VAR_1.session['oidc_nonce'] = VAR_6\n"", ""VAR_10 = urlencode(VAR_9)\n"", ""VAR_11 = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, VAR_10=query)\n"", ""return HttpResponseRedirect(VAR_11)\n""]",1
"[""def FUNC_22(self, VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from reframe.core.deferrable import evaluate\n"", ""self.begin_stamps = []\n"", ""self.end_stamps = []\n"", ""for VAR_33 in VAR_6:\n"", ""self.begin_stamps.append(float(f.readline().strip()))\n"", ""self.begin_stamps.sort()\n"", ""self.end_stamps.append(float(f.readline().strip()))\n"", ""self.end_stamps.sort()\n""]",0
"[""@classmethod...\n"", ""VAR_17 = str(VAR_12)\n"", ""VAR_18 = \""UPPER(tag.name) LIKE UPPER('%%%s%%')\"" % VAR_17\n"", ""return self.select(VAR_18)\n""]",1
"[""def FUNC_13(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14, VAR_15 = new_raylet_monitor_log_file(self._ray_params.redirect_output)\n"", ""VAR_16 = ray.services.start_raylet_monitor(self._redis_address, VAR_14=\n    stdout_file, VAR_15=stderr_file, redis_password=self._ray_params.\n    redis_password, config=self._config)\n"", ""assert VAR_13.PROCESS_TYPE_RAYLET_MONITOR not in self.all_processes\n"", ""self.all_processes[VAR_13.PROCESS_TYPE_RAYLET_MONITOR] = [VAR_16]\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.r_handler.current_user\n""]",0
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import lib.models\n"", ""import django.utils.timezone\n"", ""VAR_0 = [('course', '0028_auto_20160825_0601')]\n"", ""VAR_1 = [migrations.CreateModel(name='News', fields=[('id', models.\n    AutoField(serialize=False, primary_key=True, auto_created=True,\n    verbose_name='ID')), ('audience', models.IntegerField(choices=[(1,\n    'Internal users'), (2, 'External users'), (3,\n    'Internal and external users')], default=3)), ('publish', models.\n    DateTimeField(default=django.utils.timezone.now)), ('title', models.\n    CharField(max_length=255)), ('body', models.TextField()), ('pin',\n    models.BooleanField(default=False)), ('alert', models.CharField(choices\n    =[('', 'No alert'), ('danger', 'Red / Danger'), ('info', 'Blue / Info'),\n    ('success', 'Green / Success'), ('warning', 'Yellow / Warning')],\n    max_length=8, blank=True, default='')), ('course_instance', models.\n    ForeignKey(to='course.CourseInstance', related_name='news'))], options=\n    {'ordering': ['course_instance', '-pin', '-publish']}, bases=(models.\n    Model, lib.models.UrlMixin))]\n""]",1
"[""from m5.params import *\n"", ""from m5.proxy import *\n"", ""from m5.util.fdthelper import *\n"", ""from m5.SimObject import SimObject\n"", ""from m5.objects.Device import PioDevice\n"", ""from m5.objects.Platform import Platform\n"", ""VAR_0 = 'BaseGic'\n"", ""VAR_1 = True\n"", ""VAR_2 = 'dev/arm/base_gic.hh'\n"", ""VAR_3 = Param.Platform(Parent.any, 'Platform this device is part of.')\n"", ""VAR_4 = Param.UInt32(0, 'Distributor Implementer Identification Register')\n"", ""VAR_5 = Param.UInt32(0, 'Peripheral Identification Register')\n"", ""VAR_6 = Param.UInt32(0, 'CPU Interface Identification Register')\n"", ""VAR_7 = Param.UInt32(0, 'VM CPU Interface Identification Register')\n"", ""VAR_0 = 'ArmInterruptPin'\n"", ""VAR_2 = 'dev/arm/base_gic.hh'\n"", ""VAR_8 = 'ArmInterruptPinGen'\n"", ""VAR_1 = True\n"", ""VAR_3 = Param.Platform(Parent.any, 'Platform with interrupt controller')\n"", ""VAR_9 = Param.UInt32('Interrupt number in GIC')\n"", ""VAR_0 = 'ArmSPI'\n"", ""VAR_2 = 'dev/arm/base_gic.hh'\n"", ""VAR_8 = 'ArmSPIGen'\n"", ""VAR_0 = 'ArmPPI'\n"", ""VAR_2 = 'dev/arm/base_gic.hh'\n"", ""VAR_8 = 'ArmPPIGen'\n"", ""VAR_0 = 'GicV2'\n"", ""VAR_2 = 'dev/arm/gic_v2.hh'\n"", ""VAR_10 = Param.Addr('Address for distributor')\n"", ""VAR_11 = Param.Addr('Address for cpu')\n"", ""VAR_12 = Param.Addr(8192, 'Size of cpu register bank')\n"", ""VAR_13 = Param.Latency('10ns', 'Delay for PIO r/w to distributor')\n"", ""VAR_14 = Param.Latency('10ns', 'Delay for PIO r/w to cpu interface')\n"", ""VAR_15 = Param.Latency('10ns', 'Delay for interrupt to get to CPU')\n"", ""VAR_16 = Param.UInt32(128, 'Number of interrupt lines supported (max = 1020)')\n"", ""VAR_17 = Param.Bool(False, 'Enable gem5 extensions')\n"", ""\""\""\""string\""\""\""\n"", ""VAR_5 = 2864272\n"", ""VAR_4 = 33559611\n"", ""VAR_6 = 33690683\n"", ""VAR_7 = VAR_6\n"", ""VAR_0 = 'Gicv2mFrame'\n"", ""VAR_2 = 'dev/arm/gic_v2m.hh'\n"", ""VAR_18 = Param.UInt32(0, 'Frame SPI base number')\n"", ""VAR_19 = Param.UInt32(0, 'Frame SPI total number')\n"", ""VAR_20 = Param.Addr('Address for frame PIO')\n"", ""VAR_0 = 'Gicv2m'\n"", ""VAR_2 = 'dev/arm/gic_v2m.hh'\n"", ""VAR_21 = Param.Latency('10ns', 'Delay for PIO r/w')\n"", ""VAR_22 = Param.BaseGic(Parent.any, 'Gic on which to trigger interrupts')\n"", ""VAR_23 = VectorParam.Gicv2mFrame([], 'Power of two number of frames')\n"", ""VAR_0 = 'VGic'\n"", ""VAR_2 = 'dev/arm/vgic.hh'\n"", ""VAR_22 = Param.BaseGic(Parent.any, 'Gic to use for interrupting')\n"", ""VAR_3 = Param.Platform(Parent.any, 'Platform this device is part of.')\n"", ""VAR_24 = Param.Addr(0, 'Address for vcpu interfaces')\n"", ""VAR_25 = Param.Addr(0, 'Address for hv control')\n"", ""VAR_21 = Param.Latency('10ns', 'Delay for PIO r/w')\n"", ""VAR_26 = Param.UInt32('HV maintenance interrupt number')\n"", ""VAR_7 = Param.UInt32(Self.gic.gicc_iidr,\n    'VM CPU Interface Identification Register')\n"", ""def FUNC_0(self, VAR_27):...\n"", ""VAR_22 = self.gic.unproxy(self)\n"", ""VAR_32 = FdtNode('interrupt-controller')\n"", ""VAR_32.appendCompatible(['gem5,gic', 'arm,cortex-a15-gic', 'arm,cortex-a9-gic']\n    )\n"", ""VAR_32.append(FdtPropertyWords('#interrupt-cells', [3]))\n"", ""VAR_32.append(FdtPropertyWords('#address-cells', [0]))\n"", ""VAR_32.append(FdtProperty('interrupt-controller'))\n"", ""VAR_33 = VAR_27.addrCells(VAR_22.dist_addr) + VAR_27.sizeCells(4096\n    ) + VAR_27.addrCells(VAR_22.cpu_addr) + VAR_27.sizeCells(4096\n    ) + VAR_27.addrCells(self.hv_addr) + VAR_27.sizeCells(8192\n    ) + VAR_27.addrCells(self.vcpu_addr) + VAR_27.sizeCells(8192)\n"", ""VAR_32.append(FdtPropertyWords('reg', VAR_33))\n"", ""VAR_32.append(FdtPropertyWords('interrupts', [1, int(self.maint_int) - 16, \n    3844]))\n"", ""VAR_32.appendPhandle(VAR_22)\n"", ""yield VAR_32\n"", ""VAR_0 = 'Gicv3'\n"", ""VAR_2 = 'dev/arm/gic_v3.hh'\n"", ""VAR_10 = Param.Addr('Address for distributor')\n"", ""VAR_13 = Param.Latency('10ns', 'Delay for PIO r/w to distributor')\n"", ""VAR_28 = Param.Addr('Address for redistributors')\n"", ""VAR_29 = Param.Latency('10ns', 'Delay for PIO r/w to redistributors')\n"", ""VAR_16 = Param.UInt32(1020, 'Number of interrupt lines supported (max = 1020)')\n"", ""VAR_26 = Param.ArmInterruptPin('string')\n"", ""VAR_30 = Param.Unsigned(256,\n    'Maximum number of PE. This is affecting the maximum number of redistributors'\n    )\n"", ""VAR_31 = Param.Bool(True, 'GICv4 extension available')\n""]",1
"[""\""\""\""ebay active listings\nrun from: premium report, garagsale_xml\n\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""from __future__ import print_function\n"", ""import __builtin__ as builtins\n"", ""import sys\n"", ""import os.path\n"", ""import datetime\n"", ""from datetime import date\n"", ""from types import MethodType\n"", ""import string\n"", ""import frappe\n"", ""from frappe import msgprint\n"", ""sys.path.insert(0, '/Users/ben/dev/ebaysdk-python/dist/ebaysdk-2.1.5-py2.7.egg'\n    )\n"", ""sys.path.insert(0,\n    '/usr/local/lib/python2.7/dist-packages/ebaysdk-2.1.4-py2.7.egg')\n"", ""sys.path.insert(0,\n    '/usr/local/lib/python2.7/dist-packages/lxml-3.6.4-py2.7-linux-i686.egg')\n"", ""from ebaysdk.exception import ConnectionError\n"", ""from ebaysdk.trading import Connection as Trading\n"", ""import ugssettings\n"", ""sys.path.insert(0, frappe.get_app_path('unigreenscheme'))\n"", ""VAR_0 = os.path.join(os.sep, frappe.utils.get_bench_path(), 'sites', frappe\n    .get_site_path(), 'ebay.yaml')\n"", ""def FUNC_0():...\n"", ""VAR_11 = 'string'\n"", ""@frappe.whitelist()...\n"", ""\""\""\""docstring\""\""\""\n"", ""FUNC_3()\n"", ""VAR_1 = 1\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_13 = int(VAR_12['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n"", ""while VAR_13 >= VAR_1:\n"", ""for item in VAR_12['ActiveList']['ItemArray']['Item']:\n"", ""def FUNC_2(VAR_1):...\n"", ""VAR_3 = item['ItemID']\n"", ""VAR_1 += 1\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = int(item['QuantityAvailable'])\n"", ""if VAR_13 >= VAR_1:\n"", ""VAR_17 = Trading(config_file=PATH_TO_YAML, warnings=True, timeout=20)\n"", ""print(e)\n"", ""return VAR_19\n"", ""VAR_2 = item['SKU']\n"", ""VAR_2 = ''\n"", ""VAR_20 = float(item['SellingStatus']['CurrentPrice']['value'])\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_18 = {'ActiveList': {'Include': True, 'Pagination': {'EntriesPerPage': \n    100, 'PageNumber': VAR_1}, 'IncludeWatchCount': True}, 'DetailLevel':\n    'ReturnAll'}\n"", ""print(e.response.dict())\n"", ""VAR_21 = VAR_20 / ugssettings.VAT\n"", ""VAR_17.execute('GetMyeBaySelling', VAR_18)\n"", ""VAR_22 = 0\n"", ""VAR_19 = VAR_17.response.dict()\n"", ""VAR_23 = 0\n"", ""VAR_24 = 0\n"", ""VAR_6 = ''\n"", ""FUNC_4(VAR_2, VAR_3, VAR_4, VAR_20, VAR_6, VAR_22, VAR_23, VAR_24)\n""]",1
"[""def FUNC_0(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_17 = self.pool.get('product.product').browse(VAR_1, VAR_2, VAR_3, VAR_4\n    =context)\n"", ""VAR_18 = (VAR_17.property_stock_account_input and VAR_17.\n    property_stock_account_input.id or False)\n"", ""if not VAR_18:\n"", ""VAR_18 = (VAR_17.categ_id.property_stock_account_input_categ and VAR_17.\n    categ_id.property_stock_account_input_categ.id or False)\n"", ""VAR_19 = (VAR_17.property_stock_account_output and VAR_17.\n    property_stock_account_output.id or False)\n"", ""if not VAR_19:\n"", ""VAR_19 = (VAR_17.categ_id.property_stock_account_output_categ and VAR_17.\n    categ_id.property_stock_account_output_categ.id or False)\n"", ""VAR_20 = (VAR_17.categ_id.property_stock_journal and VAR_17.categ_id.\n    property_stock_journal.id or False)\n"", ""VAR_21 = (VAR_17.categ_id.property_stock_variation and VAR_17.categ_id.\n    property_stock_variation.id or False)\n"", ""return {'stock_account_input': VAR_18, 'stock_account_output': VAR_19,\n    'stock_journal': VAR_20, 'property_stock_variation': VAR_21}\n""]",0
"[""def FUNC_21(self, VAR_12):...\n"", ""return shellutil.run('ps -p {0}'.format(VAR_12), VAR_10=False) == 0\n""]",0
"[""def FUNC_6(VAR_4, VAR_5):...\n"", ""VAR_8 = subprocess.Popen(['nmcli', 'connection', 'delete', 'id', VAR_4],\n    stdout=subprocess.PIPE)\n"", ""print(VAR_8)\n"", ""print(VAR_1)\n"", ""VAR_12 = VAR_1[0]\n"", ""print(VAR_12)\n"", ""print(VAR_4)\n"", ""for dev in VAR_1:\n"", ""for ap in dev.AccessPoints:\n"", ""VAR_13 = {'802-11-wireless': {'security': '802-11-wireless-security'},\n    '802-11-wireless-security': {'key-mgmt': 'wpa-psk', 'psk': VAR_5}}\n"", ""if ap.Ssid == VAR_4:\n"", ""VAR_14 = VAR_0.AddAndActivateConnection(VAR_13, VAR_12, VAR_26)\n"", ""VAR_26 = ap\n"", ""return\n""]",0
"[""__author__ = 'Johannes Kster'\n"", ""__copyright__ = 'Copyright 2015, Johannes Kster'\n"", ""__email__ = 'koester@jimmy.harvard.edu'\n"", ""__license__ = 'MIT'\n"", ""import os\n"", ""import sys\n"", ""import base64\n"", ""import json\n"", ""from collections import defaultdict\n"", ""from itertools import chain\n"", ""from functools import partial\n"", ""from operator import attrgetter\n"", ""from snakemake.io import IOFile, Wildcards, Resources, _IOFile\n"", ""from snakemake.utils import format, listfiles\n"", ""from snakemake.exceptions import RuleException, ProtectedOutputException\n"", ""from snakemake.exceptions import UnexpectedOutputException\n"", ""from snakemake.logging import logger\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""return chain(*map(attrgetter(VAR_1), VAR_0))\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import copy\n"", ""from flask import current_app, session\n"", ""from flask.ext.login import current_user\n"", ""from invenio.ext.sqlalchemy.utils import session_manager\n"", ""VAR_0 = dict(title='ORCID', description=\n    'Connecting Research and Researchers.', icon='', authorized_handler=\n    'invenio.modules.oauthclient.handlers:authorized_signup_handler',\n    disconnect_handler=\n    'invenio.modules.oauthclient.handlers:disconnect_handler',\n    signup_handler=dict(info=\n    'invenio.modules.oauthclient.contrib.orcid:account_info', setup=\n    'invenio.modules.oauthclient.contrib.orcid:account_setup', view=\n    'invenio.modules.oauthclient.handlers:signup_handler'), params=dict(\n    request_token_params={'scope': '/authenticate'}, base_url=\n    'https://pub.orcid.com/', request_token_url=None, access_token_url=\n    'https://pub.orcid.org/oauth/token', access_token_method='POST',\n    authorize_url='https://orcid.org/oauth/authorize#show_login', app_key=\n    'ORCID_APP_CREDENTIALS', content_type='application/json'))\n"", ""\""\""\"" ORCID Remote Application. \""\""\""\n"", ""VAR_1 = copy.deepcopy(VAR_0)\n"", ""\""\""\""ORCID Sandbox Remote Application.\""\""\""\n"", ""VAR_1['params'].update(dict(base_url='https://api.sandbox.orcid.org/',\n    access_token_url='https://api.sandbox.orcid.org/oauth/token',\n    authorize_url='https://sandbox.orcid.org/oauth/authorize#show_login'))\n"", ""def FUNC_0(VAR_2, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = dict(external_id=resp.get('orcid'), external_method='orcid')\n"", ""return VAR_5\n""]",1
"[""def FUNC_12(VAR_27):...\n"", ""VAR_36 = datetime.utcfromtimestamp(VAR_27.created_utc)\n"", ""VAR_14 = str(VAR_27.author)\n"", ""VAR_28 = VAR_27.body.replace('\\\\', '').split('\\n')[0].split(' ')\n"", ""if len(VAR_28) < 2:\n"", ""VAR_39 = (\n    \""I couldn't parse your command. I was expecting 'minimum <amount>'. Be sure to check your spacing.\""\n    )\n"", ""if VAR_28[1].lower() == 'nan' or 'inf' in VAR_28[1].lower():\n"", ""VAR_27.reply(VAR_39)\n"", ""VAR_39 = (\n    \""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\""\n    )\n"", ""VAR_21 = float(VAR_28[1])\n"", ""VAR_39 = (\n    \""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\""\n    )\n"", ""if nano_to_raw(VAR_21) < nano_to_raw(0.01):\n"", ""return None\n"", ""VAR_27.reply(VAR_39)\n"", ""VAR_27.reply(VAR_39)\n"", ""VAR_39 = 'The overall tip minimum is 0.01 Nano.'\n"", ""VAR_32 = 'SELECT address FROM accounts WHERE username=%s'\n"", ""VAR_27.reply(VAR_39)\n"", ""VAR_33 = VAR_14,\n"", ""VAR_13.execute(VAR_32, VAR_33)\n"", ""VAR_34 = VAR_13.fetchall()\n"", ""print(VAR_34)\n"", ""if len(VAR_34) > 0:\n"", ""FUNC_2(VAR_14=username, VAR_15='minimum', VAR_21=nano_to_raw(amount),\n    VAR_17=result[0][0], VAR_18='message', VAR_25=message_time.strftime(\n    '%Y-%m-%d %H:%M:%S'), VAR_26=str(message.body)[:255])\n"", ""FUNC_2(VAR_14=username, VAR_15='minimum', VAR_25=message_time.strftime(\n    '%Y-%m-%d %H:%M:%S'), VAR_21=nano_to_raw(amount), VAR_26=str(message.\n    body)[:255])\n"", ""VAR_32 = 'UPDATE accounts SET minimum = %s WHERE username = %s'\n"", ""VAR_39 = 'string'\n"", ""print(VAR_21)\n"", ""VAR_27.reply(VAR_39)\n"", ""print(nano_to_raw(VAR_21))\n"", ""VAR_33 = str(nano_to_raw(VAR_21)), VAR_14\n"", ""print(VAR_33)\n"", ""VAR_13.execute(VAR_32, VAR_33)\n"", ""VAR_12.commit()\n"", ""VAR_39 = 'Updating tip minimum to %s' % VAR_21\n"", ""VAR_27.reply(VAR_39)\n""]",1
"[""def FUNC_2(self, VAR_4):...\n"", ""VAR_4 = np.float32(VAR_4)\n"", ""VAR_4 /= 255.0\n"", ""VAR_4 = np.expand_dims(VAR_4, axis=0)\n"", ""VAR_4 = np.expand_dims(VAR_4, axis=3)\n"", ""self.corner_detector_interpreter.set_tensor(self.\n    corner_detector_input_details[0]['index'], VAR_4)\n"", ""self.corner_detector_interpreter.invoke()\n"", ""return np.squeeze(self.corner_detector_interpreter.get_tensor(self.\n    corner_detector_output_details[0]['index']))\n""]",0
"[""def FUNC_6(self):...\n"", ""VAR_83 = []\n"", ""if self.rate_user and VAR_101.user_is_loggedin:\n"", ""VAR_83.append('user' + VAR_100(VAR_101.user._id36))\n"", ""if self.rate_ip:\n"", ""VAR_83.append('ip' + VAR_100(VAR_102.ip))\n"", ""VAR_84 = cache.get_multi(VAR_83, self.prefix)\n"", ""if VAR_84:\n"", ""VAR_87 = VAR_55(VAR_84.values())\n"", ""VAR_99 = utils.timeuntil(VAR_87)\n"", ""VAR_101.errors.add(errors.RATELIMIT, {'time': VAR_99})\n""]",0
"[""def FUNC_10(self):...\n"", ""self._tmp_dir = TempDir()\n"", ""self.accounts = {}\n""]",0
"[""def FUNC_0(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = dict(VAR_4 or {})\n"", ""VAR_4['Content-Length'] = len(VAR_2)\n"", ""def __init__(self):...\n"", ""self.content = VAR_2\n"", ""def FUNC_6(self, VAR_7):...\n"", ""VAR_8 = self.content\n"", ""while VAR_8:\n"", ""yield VAR_8[:VAR_7]\n"", ""def FUNC_7(self):...\n"", ""VAR_8 = VAR_8[VAR_7:]\n"", ""return self.content\n""]",0
"[""@VAR_1.before_request...\n"", ""return\n""]",1
"[""def FUNC_6():...\n"", ""VAR_2.test_locals = dict()\n"", ""VAR_2.test_locals.update(VAR_8.__dict__)\n"", ""exec(VAR_3, VAR_2.test_locals)\n""]",0
"[""@view_config(route_name='notes', permission='view', renderer=...\n"", ""VAR_5 = VAR_0.params.get('search', '')\n"", ""VAR_6 = VAR_0.params.get('from', '')\n"", ""VAR_7 = VAR_0.params.get('to', '')\n"", ""VAR_8 = db.note.find_notes(VAR_0.db, user_id=request.user.user_id, VAR_6=\n    from_date, VAR_7=to_date, VAR_5=search)\n"", ""return {'notes': VAR_8, 'from': VAR_6, 'to': VAR_7, 'search': VAR_5}\n""]",0
"[""def __init__(self, VAR_25, VAR_26):...\n"", ""self.fd = VAR_25\n"", ""self.backup = os.dup(VAR_25)\n"", ""VAR_44, VAR_47 = VAR_26\n"", ""self.newfd = VAR_26\n"", ""self.newfd = os.open(VAR_44, VAR_47)\n""]",1
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""VAR_0 = [('course', '0010_auto_20151214_1714')]\n"", ""VAR_1 = [migrations.AddField(model_name='coursechapter', name='parent',\n    field=models.ForeignKey(to='course.CourseChapter', blank=True, null=\n    True, related_name='children'), preserve_default=True), migrations.\n    AlterUniqueTogether(name='coursechapter', unique_together=set([]))]\n""]",1
"[""from django.db import models\n"", ""from .dsstox_lookup import DSSToxLookup\n"", ""from .extracted_text import ExtractedText\n"", ""from model_utils.managers import InheritanceManager\n"", ""from django.apps import apps\n"", ""from django.db.models.signals import pre_save\n"", ""from django.dispatch import receiver\n"", ""from model_utils import FieldTracker\n"", ""VAR_0 = models.ForeignKey(ExtractedText, related_name='rawchem', on_delete=\n    models.CASCADE, null=False, blank=False)\n"", ""VAR_1 = models.CharField('Raw CAS', max_length=100, null=True, blank=True)\n"", ""VAR_2 = models.CharField('Raw chemical name', max_length=500, null=True,\n    blank=True)\n"", ""VAR_3 = models.IntegerField(default=0, null=True, blank=True)\n"", ""VAR_4 = models.CharField(max_length=255, null=True, blank=True)\n"", ""VAR_5 = models.CharField(max_length=50, null=True, blank=True)\n"", ""VAR_6 = models.ForeignKey(DSSToxLookup, related_name='curated_chemical',\n    on_delete=models.PROTECT, null=True, blank=True)\n"", ""VAR_7 = InheritanceManager()\n"", ""VAR_8 = FieldTracker()\n"", ""def __str__(self):...\n"", ""return str(self.raw_chem_name) if self.raw_chem_name else ''\n""]",1
"[""def FUNC_1(VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""FUNC_5(VAR_6)\n"", ""VAR_8 = FUNC_6(VAR_6)\n"", ""VAR_15 = FUNC_7(request.data, VAR_8)\n"", ""FUNC_8(VAR_15)\n"", ""f.write(VAR_15['key'])\n"", ""return 'Key successfully created', VAR_2\n""]",0
"[""def __init__(self, VAR_5, VAR_6, VAR_7, VAR_8):...\n"", ""self.UserID = VAR_5\n"", ""self.Username = VAR_6\n"", ""self.PasswordHash = VAR_7\n"", ""self.DisplayName = VAR_8\n""]",0
"[""def __init__(self, VAR_0):...\n"", ""debug('Comment ', VAR_0)\n"", ""super(CLASS_1, self).__init__('% ' + VAR_0)\n""]",1
"[""def FUNC_6(VAR_12):...\n"", ""VAR_3.execute(\""UPDATE games set Running = 'No' WHERE ID = %i\"" % VAR_12)\n"", ""VAR_2.commit()\n""]",1
"[""def FUNC_0(VAR_0=None):...\n"", ""VAR_9 = frappe._dict(template='templates/includes/blog/blog.html', get_list\n    =get_blog_list, hide_filters=True, children=get_children(), title=_('Blog')\n    )\n"", ""VAR_10 = (frappe.local.form_dict.blog_category or frappe.local.form_dict.\n    category)\n"", ""if VAR_10:\n"", ""VAR_15 = FUNC_3(VAR_10)\n"", ""if frappe.local.form_dict.blogger:\n"", ""VAR_9.sub_title = _('Posts filed under {0}').format(VAR_15)\n"", ""VAR_16 = frappe.db.get_value('Blogger', {'name': frappe.local.form_dict.\n    blogger}, 'full_name')\n"", ""if frappe.local.form_dict.txt:\n"", ""VAR_9.title = VAR_15\n"", ""VAR_9.sub_title = _('Posts by {0}').format(VAR_16)\n"", ""VAR_9.sub_title = _('Filtered by \""{0}\""').format(frappe.local.form_dict.txt)\n"", ""if VAR_9.sub_title:\n"", ""VAR_9.title = VAR_16\n"", ""VAR_9.parents = [{'name': _('Home'), 'route': '/'}, {'name': 'Blog',\n    'route': '/blog'}]\n"", ""VAR_9.parents = [{'name': _('Home'), 'route': '/'}]\n"", ""VAR_9.update(frappe.get_doc('Blog Settings', 'Blog Settings').as_dict(\n    no_default_fields=True))\n"", ""return VAR_9\n""]",1
"[""def FUNC_2():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return [onboarding.STEP_1, onboarding.STEP_2, onboarding.STEP_3, onboarding\n    .STEP_4, onboarding.STEP_5, onboarding.STEP_6, onboarding.STEP_7,\n    onboarding.STEP_8]\n""]",1
"[""def FUNC_5(VAR_17):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_23 = {}\n"", ""VAR_46 = reader.KeywordToken\n"", ""for VAR_76, v in acronymer.get_acronyms(VAR_17).items():\n"", ""VAR_23[VAR_46(VAR_76, type='acronym')] = v\n"", ""return VAR_23\n""]",0
"[""@VAR_0.route('/unrestrict/<int:id>')...\n"", ""VAR_7 = get_db()\n"", ""VAR_15 = get_user(VAR_4)\n"", ""VAR_16 = None\n"", ""if VAR_15['restricted'] != 1:\n"", ""VAR_16 = 'User already unrestricted.'\n"", ""if VAR_16 is None:\n"", ""VAR_7.execute('UPDATE user SET restricted = 0 WHERE id = ?', (VAR_4,))\n"", ""flash(VAR_16)\n"", ""VAR_7.commit()\n"", ""return redirect(url_for('admin.user_view'))\n"", ""return redirect(url_for('admin.user_view'))\n""]",0
"[""def FUNC_0(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if '/' in VAR_1 or '\\\\' in VAR_1:\n"", ""return False\n"", ""if len(VAR_1) >= 10:\n"", ""return False\n"", ""return True\n""]",1
"[""def FUNC_4(self, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = []\n"", ""for VAR_5 in VAR_4:\n"", ""VAR_7.append(self._json_obj(VAR_5))\n"", ""return VAR_7\n""]",1
"[""@property...\n"", ""return filter(lambda VAR_28: VAR_28.exists, self.expanded_output)\n""]",0
"[""@VAR_0.route('/autocomplete', methods=['GET'])...\n"", ""VAR_4 = mysql.get_db()\n"", ""VAR_5 = []\n"", ""VAR_6 = VAR_4.cursor()\n"", ""VAR_6.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_6.fetchall(), VAR_6.description))\n"", ""if len(VAR_5) == 100:\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n"", ""VAR_7 = VAR_4.cursor()\n"", ""VAR_7.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_7.fetchall(), VAR_7.description))\n"", ""if len(VAR_5) == 100:\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n"", ""VAR_8 = VAR_4.cursor()\n"", ""VAR_8.execute('string', (request.args['input_text'],))\n"", ""VAR_5.extend(convert_objects(VAR_8.fetchall(), VAR_8.description))\n"", ""return make_response(jsonify(VAR_5), HTTPStatus.OK)\n""]",1
"[""def FUNC_2(VAR_0):...\n"", ""def FUNC_3(VAR_1):...\n"", ""return int(VAR_1)\n"", ""return 0\n"", ""if VAR_0.method == 'POST':\n"", ""VAR_3 = FUNC_3(VAR_0.POST.get('points'))\n"", ""return render(VAR_0, 'exercises/ajax_exercise.html', {'url': VAR_0.\n    build_absolute_uri('{}?{}'.format(reverse('ajax'), VAR_0.META.get(\n    'QUERY_STRING', '')))})\n"", ""VAR_4 = FUNC_3(VAR_0.POST.get('max_points'))\n"", ""VAR_5 = VAR_0.GET.get('submission_url')\n"", ""def FUNC_4(VAR_6):...\n"", ""VAR_7 = HttpResponse(VAR_6)\n"", ""VAR_7['Access-Control-Allow-Origin'] = '*'\n"", ""return VAR_7\n""]",0
"[""from webapp.web import BaseHandler\n"", ""from model import dbapi\n"", ""def FUNC_0(self):...\n"", ""if self.check_xsrf_cookie() == False:\n"", ""self.clear_cookies()\n"", ""def FUNC_1(self):...\n"", ""return self.redirect('/')\n"", ""VAR_1 = self.get_secure_cookie('sid')\n"", ""if not VAR_1:\n"", ""return False\n"", ""VAR_2 = self.session.get('email')\n"", ""VAR_3 = dbapi.User()\n"", ""if VAR_2 and VAR_3.get_user(VAR_2) == 0:\n"", ""VAR_9 = VAR_3.get_user_all(VAR_2)\n"", ""self.clear_cookies()\n"", ""if VAR_9:\n"", ""return False\n"", ""self.time = VAR_9[4]\n"", ""def FUNC_2(self, VAR_0=''):...\n"", ""self.email = VAR_2\n"", ""self.check()\n"", ""return True\n"", ""VAR_4 = {'error_info': VAR_0, 'name': self.email, 'xsrf_token': self.\n    xsrf_from_html()}\n"", ""VAR_5 = self.wrap_html('templates/pwdchange.html', VAR_4)\n"", ""return self.write(VAR_5)\n""]",1
"[""def FUNC_0(VAR_1):...\n"", ""VAR_1.execute('string')\n"", ""VAR_1.commit()\n"", ""VAR_0 = True\n""]",0
"[""def FUNC_5(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['like', 'J%']}))\n""]",0
"[""def FUNC_5(self, VAR_11='', VAR_6=None):...\n"", ""VAR_5 = self.session.query(self.obj)\n"", ""VAR_5 = self._get_base_query(VAR_5=query, VAR_6=filters)\n"", ""VAR_25 = VAR_5.all()\n"", ""VAR_26 = GroupByDateMonth(VAR_11, 'Group by Month')\n"", ""return VAR_26.apply(VAR_25)\n""]",0
"[""def FUNC_1(self, VAR_2):...\n"", ""VAR_4 = 'string' % VAR_2\n"", ""VAR_5 = sql.queryDB(self.conn, VAR_4)\n"", ""return VAR_5\n""]",1
"[""def FUNC_9(self, VAR_21, VAR_27, VAR_28, VAR_29, VAR_30, VAR_31=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self.newcount > 10000:\n"", ""return False\n"", ""if VAR_31 is None:\n"", ""VAR_31 = time.time()\n"", ""VAR_58 = self.get_path(os.path.dirname(VAR_21))\n"", ""VAR_59 = os.path.basename(VAR_21)\n"", ""if VAR_59 in [x[VAR_1] for x in VAR_58]:\n"", ""VAR_58.remove([x for x in VAR_58 if x[VAR_1] == VAR_59][0])\n"", ""VAR_58.append([VAR_59, VAR_13, VAR_27, VAR_28, VAR_29, VAR_30, VAR_31, [],\n    None, None])\n"", ""self.newcount += 1\n"", ""return True\n""]",0
"[""def FUNC_2(self, VAR_8, VAR_9, VAR_10=None, VAR_11=None, VAR_12=(...\n"", ""get_and_check_project(VAR_9, VAR_11, VAR_12)\n"", ""VAR_28 = self.queryset.get(VAR_10=pk, VAR_1=project_pk)\n"", ""VAR_28.pending_action = VAR_8\n"", ""VAR_28.last_error = None\n"", ""VAR_28.save()\n"", ""scheduler.process_pending_tasks(background=True)\n"", ""return Response({'success': True})\n""]",0
"[""def FUNC_0(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n"", ""settings.SSH_PRIVATE_KEY = '<some-ssh-private-key>'\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import abc\n"", ""import traceback\n"", ""import typing\n"", ""import discord.ext.commands as commands\n"", ""from neko import excuses, book, strings\n"", ""__all__ = ['NekoCommand', 'NekoGroup', 'command', 'group']\n"", ""\""\""\""Functionality to be inherited by a command or group type.\""\""\""\n"", ""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_17, commands.MissingRequiredArgument):\n"", ""await VAR_16.message.add_reaction('')\n"", ""traceback.print_exception(type(VAR_17), VAR_17, VAR_17.__traceback__)\n"", ""return\n"", ""VAR_17 = VAR_17.__cause__ if VAR_17.__cause__ else VAR_17\n"", ""if isinstance(VAR_17, commands.CheckFailure):\n"", ""return\n"", ""VAR_18 = book.Page(title='Whoops! Something went wrong!', VAR_9=strings.\n    capitalise(excuses.get_excuse()), color=16760576 if isinstance(error,\n    Warning) else 16711680)\n"", ""VAR_19 = strings.pascal_to_space(type(VAR_17).__name__)\n"", ""VAR_15 = strings.pascal_to_space(getattr(VAR_15, 'name', str(VAR_15)))\n"", ""VAR_19 += f' in {VAR_15}: {str(VAR_17)}'\n"", ""VAR_18.set_footer(text=error_description)\n"", ""await VAR_16.send(VAR_18=embed)\n"", ""traceback.print_exception(type(VAR_17), VAR_17, VAR_17.__traceback__)\n"", ""\""\""\""\n    Implementation of a command.\n    \""\""\""\n"", ""\""\""\""\n    Implementation of a command group.\n    \""\""\""\n"", ""def FUNC_0(self, **VAR_12):...\n"", ""VAR_12.setdefault('cls', CLASS_1)\n"", ""return super().command(**kwargs)\n""]",1
"[""@utils.synchronized('3par', external=True)...\n"", """"]",0
"[""def FUNC_2(self):...\n"", ""return DataDocument.objects.filter(extractedtext__qa_checked=True,\n    extractedtext__extraction_script=self.pk).count()\n""]",0
"[""@VAR_0.route('/get_table_names', methods=['GET'])...\n"", ""VAR_6 = 'SELECT table_name FROM user_tables'\n"", ""VAR_4 = execute_query(VAR_0, g, VAR_6)[1]\n"", ""return jsonify(VAR_4)\n""]",1
"[""def FUNC_0(self, VAR_1, VAR_2):...\n"", ""VAR_6 = 'string'.format(VAR_1, VAR_2.get_client_id())\n"", ""VAR_7 = self.__conn.cursor()\n"", ""VAR_7.execute(VAR_6)\n"", ""self.__conn.commit()\n"", ""VAR_2.set_message(VAR_1)\n""]",1
"[""def FUNC_4(self, VAR_6, VAR_12, VAR_13):...\n"", ""VAR_14 = []\n"", ""VAR_14.append('string'.format(VAR_6))\n"", ""VAR_14.append('string'.format(VAR_6, VAR_12, VAR_13))\n"", ""for query in VAR_14:\n"", ""self.cur.execute(query)\n"", ""self.conn.commit()\n""]",1
"[""@login_required...\n"", ""return HttpResponseRedirect(reverse('review_candidates', kwargs={'status':\n    'all'}))\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_28, VAR_27 in zip(self.output, self.rule.output):\n"", ""if VAR_28 in self.dynamic_output:\n"", ""VAR_29 = self.expand_dynamic(VAR_27, VAR_13=self.wildcards, VAR_14=_IOFile.\n    dynamic_fill)\n"", ""yield VAR_28\n"", ""if not VAR_29:\n"", ""yield VAR_27\n"", ""for VAR_28, _ in VAR_29:\n"", ""yield IOFile(VAR_28, self.rule)\n""]",1
"[""@VAR_0.route('/add', methods=['POST'])...\n"", """"]",0
"[""import scrapy\n"", ""import json\n"", ""from scrapers.scrapy_couchcrawl.helpers.profileLinkExtractor import KeyExtractor\n"", ""VAR_0 = 'fetch_profiles'\n"", ""VAR_1 = 'https://www.couchsurfing.com/users/sign_in'\n"", ""VAR_2 = 'q1686061@mvrht.net'\n"", ""VAR_3 = '3R3fk*CP'\n"", ""VAR_4 = {'user[login]': VAR_2, 'user[password]': VAR_3}\n"", ""VAR_5 = {'ITEM_PIPELINES': {'scrapy_couchcrawl.pipelines.ProfilesPipeline':\n    400}, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_START_DELAY': 2,\n    'AUTOTHROTTLE_MAX_DELAY': 60, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 1.0,\n    'AUTOTHROTTLE_DEBUG': True}\n"", ""def FUNC_0(self):...\n"", ""yield scrapy.Request(self.login_url, self.parse_login)\n"", ""def FUNC_1(self, VAR_6):...\n"", ""print('Login')\n"", ""print(VAR_6.url)\n"", ""yield scrapy.FormRequest.from_response(VAR_6, formdata=self.login_data,\n    callback=self.start_crawl)\n"", ""def FUNC_2(self, VAR_6):...\n"", ""print('Start Crawl')\n"", ""print(VAR_6.url)\n"", ""VAR_7 = KeyExtractor()\n"", ""while VAR_7.hasMoreProfileLinks():\n"", ""VAR_10 = VAR_7.getMoreProfileLinks()\n"", ""def FUNC_3(self, VAR_6):...\n"", ""for link in VAR_10:\n"", ""VAR_8 = VAR_6.url.split('/')\n"", ""VAR_13 = link\n"", ""if len(VAR_8) == 5:\n"", ""VAR_14 = link + '/couch'\n"", ""print('Mainpage')\n"", ""print('Not Mainpage')\n"", ""VAR_15 = link + '/photos'\n"", ""VAR_11 = 'Main'\n"", ""VAR_11 = VAR_8[len(VAR_8) - 1]\n"", ""VAR_16 = link + '/references'\n"", ""VAR_12 = VAR_8[len(VAR_8) - 1]\n"", ""VAR_12 = VAR_8[len(VAR_8) - 2]\n"", ""VAR_17 = link + '/friends'\n"", ""VAR_9 = {'_id': VAR_12, 'URL': VAR_6.url, VAR_11: VAR_6.body.decode('utf-8')}\n"", ""VAR_18 = link + '/favorites'\n"", ""yield {'websites': VAR_9}\n"", ""VAR_19 = [VAR_13, VAR_14, VAR_15, VAR_16, VAR_17, VAR_18]\n"", ""for sub_link in VAR_19:\n"", ""yield scrapy.Request(url=sub_link, callback=self.parse)\n""]",1
"[""def FUNC_5(self, VAR_12):...\n"", ""VAR_14 = 'string'.format(VAR_12)\n"", ""self.cur.execute(VAR_14)\n"", ""return self.cur.fetchall()\n""]",1
"[""def __init__(self, *VAR_20, **VAR_21):...\n"", ""FlaskForm.__init__(self, *VAR_20, **kwargs)\n"", ""self.user = None\n""]",0
"[""def FUNC_5(VAR_8):...\n"", ""return set(VAR_29.group('name') for VAR_29 in VAR_5.finditer(VAR_8))\n""]",0
"[""from osv import osv\n"", ""from tools.translate import _\n"", ""import time\n"", ""VAR_0 = 'pos.open.statement'\n"", ""VAR_1 = 'Open Statements'\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""@classmethod...\n"", ""if VAR_3.returns_rows:\n"", ""VAR_0 = VAR_3.keys()\n"", ""return VAR_2(None, None)\n"", ""VAR_1 = [make_row_serializable(row) for row in VAR_3]\n"", ""return VAR_2(VAR_0, VAR_1)\n""]",0
"[""def FUNC_9(self, VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = VAR_9.args.get('csessid')[0]\n"", ""self.last_alive[VAR_8] = time.time(), False\n"", ""VAR_20 = self.sessionhandler.sessions_from_csessid(VAR_8)\n"", ""if VAR_20:\n"", ""VAR_20 = VAR_20[0]\n"", ""return '\""\""'\n"", ""VAR_36 = json.loads(VAR_9.args.get('data')[0])\n"", ""VAR_20.sessionhandler.data_in(VAR_20, **{cmdarray[0]: [cmdarray[1],\n    cmdarray[2]]})\n""]",1
"[""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self.eng is not None:\n"", ""self.eng = None\n"", ""self.state = None\n""]",0
"[""def FUNC_6(self):...\n"", ""if len(self.data) == 0:\n"", ""return None\n"", ""return self.data.pop(len(self.data) - 1)\n""]",0
"[""def FUNC_6(self):...\n"", ""VAR_1 = '/api/apps'\n"", ""VAR_2 = self.client.post(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 201)\n"", ""VAR_3 = VAR_2.data['id']\n"", ""VAR_1 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_4 = {'image': 'autotest/example', 'sha': 'a' * 40, 'procfile': json.\n    dumps({'web': 'node server.js', 'worker': 'node worker.js'})}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 201)\n"", ""VAR_1 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 2)\n"", ""VAR_1 = '/api/apps/{app_id}/containers'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 1)\n"", ""VAR_1 = '/api/apps/{app_id}/scale'.format(**locals())\n"", ""VAR_4 = {'web': 20}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 204)\n"", ""chaos.CREATE_ERROR_RATE = 0.5\n"", ""chaos.START_ERROR_RATE = 0.5\n"", ""VAR_1 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_4 = {'values': json.dumps({'NEW_URL1': 'http://localhost:8080/'})}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 503)\n"", ""VAR_1 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 2)\n"", ""VAR_1 = '/api/apps/{app_id}/containers'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 20)\n"", ""VAR_5 = set([c['state'] for c in VAR_2.data['results']])\n"", ""self.assertEqual(VAR_5, set(['up']))\n""]",0
"[""def FUNC_1(self, VAR_4, VAR_5, VAR_6):...\n"", ""VAR_10 = str(VAR_4.event_type_id.name).lower()\n"", ""VAR_11 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'ai_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_12 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'cf_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_13 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bc_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_14 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bc_tickets'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_15 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bz_tickets'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""if VAR_11.subscription_is_active:\n"", ""return\n"", ""if VAR_10 == 'bokszaktraining':\n"", ""if VAR_15:\n"", ""if VAR_10 == 'bootcamp':\n"", ""VAR_15.subscription_counter += VAR_6\n"", ""if VAR_13 and VAR_13.subscription_is_active:\n"", ""return\n"", ""if VAR_12 and VAR_12.subscription_is_active:\n"", ""return\n"", ""if VAR_14:\n"", ""VAR_14.subscription_counter += VAR_6\n""]",1
"[""def FUNC_6(self, VAR_1):...\n"", ""self.cursor.execute('SELECT count(id) FROM projects where id = %s' % VAR_1)\n"", ""return self.cursor.fetchall()[0][0] == 1\n""]",1
"[""def FUNC_10(self):...\n"", ""VAR_6 = ('\""normal_string\""', '\""string with spaces\""',\n    '\""string with quotes\\\\\""a\""', '\""string with s-quotes\\'b\""', '\""bsn \\n A\""',\n    '\""unrecognized \\\\q escape\""')\n"", ""for string, result in zip(self.test_strings, VAR_6):\n"", ""self.assertEqual(prepare_string_argument(string, 'sh'), result)\n""]",0
"[""def FUNC_23(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {}, 'CONFIDENCE': {}}\n"", ""self.check_example('okay.py', VAR_2)\n""]",0
"[""def FUNC_0(self, VAR_3, VAR_4, VAR_5, VAR_6=None, VAR_7=None, VAR_8=None,...\n"", ""VAR_10 = Configuration()\n"", ""VAR_11 = VAR_10.db_info\n"", ""VAR_12 = json.loads(VAR_11)\n"", ""self.log.debug('Creating {} database adapter...'.format(self._type))\n"", ""if self._type == 'pymssql':\n"", ""VAR_18 = MsSqlAdapter()\n"", ""VAR_13 = VAR_18.get_sql(VAR_3, VAR_4, VAR_5, VAR_6, VAR_7, VAR_8)\n"", ""self.log.debug('SQL is [{}].'.format(VAR_13))\n"", ""VAR_14 = DatabaseFactory(self._type, hostname=db_info_json['host'], user=\n    db_info_json['username'], password=db_info_json['password'], database=\n    db_info_json['dbInstanceIdentifier'])\n"", ""VAR_15 = VAR_14.get_connection()\n"", ""VAR_16 = VAR_15.cursor()\n"", ""VAR_16.execute(VAR_13, None)\n"", ""VAR_17 = [dict((VAR_16.description[i][0], value) for i, value in enumerate(\n    row)) for row in VAR_16.fetchall()]\n"", ""return (VAR_17[0] if VAR_17 else None) if VAR_9 else VAR_17\n""]",1
"[""\""\""\""SchoolCMS-handler-init.\n\nroute.\n\""\""\""\n"", ""from __future__ import absolute_import\n"", ""from __future__ import print_function\n"", ""from __future__ import unicode_literals\n"", ""from .. import version as system_version\n"", ""from ..db import SQL_Session, User, GroupList, Login_Session\n"", ""from ..util import webassets_react\n"", ""import functools\n"", ""import os\n"", ""from webassets import Environment, Bundle\n"", ""import tornado.web\n"", ""from tornado.escape import json_encode\n"", ""from tornado.options import options\n"", ""def FUNC_0(self, VAR_1=True):...\n"", ""self.is_api = VAR_1\n"", ""self.assets = Environment(os.path.join(os.path.dirname(__file__),\n    '../static'), '/static')\n"", ""VAR_11 = Bundle('css/bootstrap.min.css', 'css/material.min.css', Bundle(\n    'css/schoolcms.css', 'css/dropdown.css', filters='cssmin'),\n    'outdatedbrowser/outdatedbrowser.min.css', output='dict/plugin.min.css')\n"", ""VAR_12 = Bundle(Bundle('outdatedbrowser/outdatedbrowser.min.js',\n    'react-0.13.2/react-with-addons.min.js', 'js/jquery-2.1.3.min.js',\n    'js/bootstrap.min.js', 'js/react-bootstrap.min.js',\n    'js/react-mini-router.min.js', 'js/marked.min.js', 'js/material.min.js',\n    'js/isMobile.min.js', 'js/moment-with-locales.min.js', 'js/dropdown.js',\n    filters='jsmin'), Bundle('schoolcms/init.jsx', 'schoolcms/mixin/*.jsx',\n    'schoolcms/component/*.jsx', 'schoolcms/page/*.jsx', filters=('react',\n    'jsmin')), output='dict/plugin.min.js')\n"", ""self.assets.register('css_all', VAR_11)\n"", ""self.assets.register('js_all', VAR_12)\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.sql_session = SQL_Session()\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.sql_session.close()\n"", ""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_13 = self.get_secure_cookie('session_key')\n"", ""if not VAR_13:\n"", ""return None\n"", ""VAR_14 = Login_Session.get_by_key(VAR_13, self.sql_session)\n"", ""if not VAR_14:\n"", ""return None\n"", ""return User.by_key(VAR_14.userkey, self.sql_session).scalar()\n""]",1
"[""import os\n"", ""import shutil\n"", ""import uuid\n"", ""from factotum import settings\n"", ""from pathlib import Path, PurePath\n"", ""from django.db import models\n"", ""from .common_info import CommonInfo\n"", ""from django.urls import reverse\n"", ""from django.db.models.signals import pre_save\n"", ""from django.dispatch import receiver\n"", ""from model_utils import FieldTracker\n"", ""from django.core.exceptions import ValidationError\n"", ""from .group_type import GroupType\n"", ""from .extracted_text import ExtractedText\n"", ""from .extracted_cpcat import ExtractedCPCat\n"", ""from .extracted_chemical import ExtractedChemical\n"", ""from .extracted_functional_use import ExtractedFunctionalUse\n"", ""from .extracted_list_presence import ExtractedListPresence\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""VAR_5 = VAR_0.name.replace(' ', '_')\n"", ""VAR_6 = '{0}/{0}_{1}'.format(VAR_5, VAR_1)\n"", ""return VAR_6\n""]",1
"[""def FUNC_0(self):...\n"", ""VAR_7 = []\n"", ""for parent in self.parent_groups:\n"", ""VAR_7.append(parent.serialize())\n"", ""self._hosts = None\n"", ""VAR_8 = dict(VAR_0=self.name, vars=self.vars.copy(), VAR_7=parent_groups,\n    depth=self.depth, VAR_9=self.hosts)\n"", ""return VAR_8\n""]",0
"[""def FUNC_10(self, VAR_17, VAR_16, VAR_18=None):...\n"", ""if VAR_18 is None and not os.path.exists(VAR_17):\n"", ""VAR_19 = Headers([])\n"", ""self.add_mime_headers(VAR_19, VAR_17, VAR_16)\n"", ""self.add_cache_headers(VAR_19, VAR_17, VAR_16)\n"", ""if self.allow_all_origins:\n"", ""VAR_19['Access-Control-Allow-Origin'] = '*'\n"", ""if self.add_headers_function:\n"", ""self.add_headers_function(VAR_19, VAR_17, VAR_16)\n"", ""return StaticFile(VAR_17, VAR_19.items(), VAR_18=stat_cache, encodings={\n    'gzip': path + '.gz', 'br': path + '.br'})\n""]",0
"[""def FUNC_12(self):...\n"", ""return self.vars.copy()\n""]",0
"[""import time\n"", ""import psycopg2\n"", ""def FUNC_0():...\n"", ""VAR_1 = psycopg2.connect('dbname=forum')\n"", ""VAR_2 = VAR_1.cursor()\n"", ""VAR_2.execute('SELECT time, content FROM posts ORDER BY time desc')\n"", ""VAR_3 = ({'content': str(row[1]), 'time': str(row[0])} for row in VAR_2.\n    fetchall())\n"", ""VAR_1.close()\n"", ""return VAR_3\n""]",1
"[""def FUNC_1(VAR_5, VAR_2):...\n"", ""VAR_6 = VAR_2.index('NULL')\n"", ""VAR_7 = 0\n"", ""while not VAR_5.ok:\n"", ""VAR_8 = VAR_2.index('NULL', VAR_6)\n"", ""print(f'Column {VAR_7} contains inserted text')\n"", ""VAR_6 = VAR_8 + 1\n"", ""VAR_7 += 1\n"", ""VAR_2[VAR_8] = \""'VULNERABLE_STRING'\""\n"", ""VAR_3['category'] = f\""Lifestyle{' '.join(VAR_2)}\""\n"", ""VAR_5 = VAR_4.get(VAR_0, VAR_1=sqli)\n"", ""VAR_2[VAR_8] = 'NULL'\n""]",1
"[""def __init__(self, VAR_20, *VAR_5, **VAR_6):...\n"", ""super().__init__(*VAR_5, **kwargs)\n"", ""self.key_name = VAR_20\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = 'DELETE FROM crimes;'\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",0
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_10 = self.session.get(self.login_url, allow_redirects=False)\n"", ""if VAR_10.status_code == 302:\n"", ""self.session.cookies.save()\n"", ""return False\n"", ""print('')\n"", ""return True\n""]",0
"[""def FUNC_7(self, VAR_0, VAR_1, VAR_2, VAR_3, VAR_4, VAR_8=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = CLASS_0(VAR_0, VAR_1, VAR_2, VAR_3, VAR_4)\n"", ""self.users[VAR_0] = VAR_7\n"", ""if VAR_8:\n"", ""self._add_to_db(VAR_7)\n"", ""return VAR_7\n""]",0
"[""from os.path import normcase, join\n"", ""from codewatch.file_walker import FileWalker\n"", ""VAR_0 = [('.', ['dir1', 'dir2'], ['file1', 'file2', 'file3']), (normcase(\n    './dir1'), [], ['dir1_file1', 'dir1_file2']), (normcase('./dir2'), [\n    'dir2_subdir'], ['dir2_file1']), (normcase('./dir2/dir2_subdir'), [], [\n    'subdir_file1'])]\n"", ""VAR_1 = normcase('/home/mock')\n"", ""def FUNC_0(VAR_2):...\n"", ""VAR_6 = VAR_0[VAR_2][0]\n"", ""VAR_7 = VAR_0[VAR_2][2]\n"", ""return [join(VAR_6, file) for file in VAR_7]\n""]",1
"[""def FUNC_27(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not self.exists and FUNC_0(self.file):\n""]",1
"[""def __init__(self, VAR_10):...\n"", ""def FUNC_2():...\n"", ""super(CLASS_8, self).__init__(slideParser.parse(VAR_10, slideLexer),\n    '\\\\footnote[frame]{', '}')\n"", ""CLASS_2.parsingQ.insert(0, FUNC_2)\n""]",1
"[""def FUNC_4(VAR_2):...\n"", ""return render(VAR_2, 'etd_app/faq.html')\n""]",0
"[""from modules.database import sql_execute\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_6 = (\""\""\""INSERT INTO dialogs (name, created_at)\nVALUES ('%s', NOW())\""\""\"" %\n    VAR_0)\n"", ""return {'status': 1}\n""]",1
"[""def FUNC_46(self, VAR_16):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_56 = self.regex.search(VAR_16)\n"", ""if VAR_56 is not None:\n"", ""return VAR_56.group('value')\n""]",0
"[""def FUNC_2(self):...\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""for user in VAR_1:\n"", ""if user['id'] != 191:\n"", ""VAR_3 = {'login': user['first_name'], 'password': user['first_name']}\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertGreater(user['id'], 0)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_3 = {'login': '', 'password': ''}\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertGreater(user['id'], 0)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_9 = \""select userid from users where name='%s';\"" % self.name\n"", ""VAR_5 = sql.queryDB(self.conn, VAR_9)\n"", ""return VAR_5[0][0]\n""]",1
"[""@handled_slot(bool)...\n"", ""print('Opening IDLE.')\n"", ""subprocess.Popen(\n    'python -m idlelib -t \""Matisse Controller - Python Shell\"" -c \""from matisse import Matisse; '\n     +\n    'matisse = Matisse(); print(\\'Access the Matisse using \\\\\\'matisse.[method]\\\\\\'\\')\""'\n    )\n""]",1
"[""@VAR_0.route('/api/<fbid>', methods=['GET'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_7 is None:\n"", ""return FUNC_0('error', 'Unknown id', 401)\n"", ""VAR_15 = storage.all('User').values()\n"", ""VAR_6 = None\n"", ""for user in VAR_15:\n"", ""VAR_22 = User.text_decrypt(user.fbid)\n"", ""if VAR_6 is None:\n"", ""if VAR_7 == VAR_22:\n"", ""return FUNC_0('error', 'Unknown id', 401)\n"", ""VAR_9 = FUNC_3(VAR_6)\n"", ""VAR_6 = user\n"", ""return jsonify(VAR_9), 201\n""]",1
"[""import unittest\n"", ""import re\n"", ""from mockito import mock, when, any as ANY\n"", ""from pixelated.application import UserAgentMode\n"", ""from test.unit.resources import DummySite\n"", ""from twisted.web.test.requesthelper import DummyRequest\n"", ""from pixelated.resources.root_resource import RootResource\n"", ""VAR_0 = 'test_user@pixelated-project.org'\n"", ""def FUNC_0(self):...\n"", ""self.mail_service = mock()\n"", ""self.services_factory = mock()\n"", ""self.services_factory.mode = UserAgentMode(is_single_user=True)\n"", ""self.services = mock()\n"", ""self.services.mail_service = self.mail_service\n"", ""self.services_factory._services_by_user = {'someuserid': self.mail_service}\n"", ""when(self.services_factory).services(ANY()).thenReturn(self.services)\n"", ""self.mail_service.account_email = self.MAIL_ADDRESS\n"", ""VAR_1 = RootResource(self.services_factory)\n"", ""VAR_1._html_template = (\n    '<html><head><title>$account_email</title></head></html>')\n"", ""VAR_1._mode = VAR_1\n"", ""self.web = DummySite(VAR_1)\n"", ""def FUNC_1(self):...\n"", ""VAR_2 = DummyRequest([''])\n"", ""VAR_3 = self.web.get(VAR_2)\n"", ""def FUNC_2(VAR_4):...\n"", ""VAR_5 = '<title>{0}</title>'.format(self.MAIL_ADDRESS)\n"", ""VAR_6 = re.findall(VAR_5, VAR_2.written[0])\n"", ""self.assertEquals(len(VAR_6), 1)\n"", ""VAR_3.addCallback(FUNC_2)\n"", ""return VAR_3\n""]",1
"[""@require_http_methods(['GET'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_next_url_for_login_page(VAR_3)\n"", ""if VAR_3.user.is_authenticated():\n"", ""return redirect(VAR_7)\n"", ""VAR_11 = FUNC_6(VAR_3)\n"", ""VAR_12 = None\n"", ""if '?' in VAR_7:\n"", ""if is_request_in_themed_site() and not configuration_helpers.get_value(\n"", ""VAR_38 = urlparse.parse_qs(urlparse.urlparse(VAR_7).query)\n"", ""if VAR_4 == 'login':\n"", ""VAR_13 = FUNC_7(VAR_3, VAR_4)\n"", ""VAR_39 = VAR_38['tpa_hint'][0]\n"", ""return old_login_view(VAR_3)\n"", ""if VAR_4 == 'register':\n"", ""if VAR_13 is not None:\n"", ""VAR_40 = third_party_auth.provider.Registry.get(VAR_39=provider_id)\n"", ""return old_register_view(VAR_3)\n"", ""return VAR_13\n"", ""VAR_14 = [{'message': message.message, 'tags': message.tags} for message in\n    messages.get_messages(VAR_3) if 'account-activation' in message.tags]\n"", ""if VAR_40:\n"", ""VAR_5 = {'data': {'login_redirect_url': VAR_7, 'initial_mode': VAR_4,\n    'third_party_auth': FUNC_5(VAR_3, VAR_7, VAR_12),\n    'third_party_auth_hint': VAR_12 or '', 'platform_name':\n    configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME\n    ), 'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK',\n    settings.SUPPORT_SITE_LINK), 'password_reset_support_link': \n    configuration_helpers.get_value('PASSWORD_RESET_SUPPORT_LINK', settings\n    .PASSWORD_RESET_SUPPORT_LINK) or settings.SUPPORT_SITE_LINK,\n    'account_activation_messages': VAR_14, 'login_form_desc': json.loads(\n    VAR_11['login']), 'registration_form_desc': json.loads(VAR_11[\n    'registration']), 'password_reset_form_desc': json.loads(VAR_11[\n    'password_reset']), 'account_creation_allowed': configuration_helpers.\n    get_value('ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get(\n    'ALLOW_PUBLIC_ACCOUNT_CREATION', True))}, 'login_redirect_url': VAR_7,\n    'responsive': True, 'allow_iframing': True, 'disable_courseware_js': \n    True, 'combined_login_and_register': True, 'disable_footer': not\n    configuration_helpers.get_value(\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER', settings.FEATURES[\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER'])}\n"", ""if VAR_40.skip_hinted_login_dialog:\n"", ""VAR_5 = FUNC_2(VAR_3, VAR_5)\n"", ""return redirect(pipeline.get_login_url(VAR_39, pipeline.AUTH_ENTRY_LOGIN,\n    redirect_url=redirect_to))\n"", ""VAR_12 = VAR_39\n"", ""VAR_15 = render_to_response('student_account/login_and_register.html', VAR_5)\n"", ""VAR_4 = 'hinted_login'\n"", ""VAR_15.delete_cookie(configuration_helpers.get_value(\n    'ENTERPRISE_CUSTOMER_COOKIE_NAME', settings.\n    ENTERPRISE_CUSTOMER_COOKIE_NAME), domain=configuration_helpers.\n    get_value('BASE_COOKIE_DOMAIN', settings.BASE_COOKIE_DOMAIN))\n"", ""return VAR_15\n""]",1
"[""def FUNC_0(self, VAR_6):...\n"", ""if len(VAR_6) == 0:\n"", ""warn('Skipping empty scissor command')\n"", ""if not (os.path.isfile(VAR_6[0]) or os.path.isfile(VAR_6[0] + '.pdf')):\n"", ""return ''\n"", ""warn('File included in scissor command not found, proceeding unsafely...')\n"", ""if len(VAR_6) > 1:\n"", ""if re.fullmatch('\\\\d+(-\\\\d+)?(,\\\\d+(-\\\\d+)?)*', VAR_6[1]):\n"", ""VAR_20 = self.includeCmd % ''\n"", ""VAR_20 = self.includeCmd % self.pagesSpec\n"", ""warn('Ignoring malformed page range in scissor command')\n"", ""return VAR_20 % VAR_6[0]\n"", ""return VAR_20 % (VAR_6[1], VAR_6[0])\n"", ""if len(VAR_6) > 2:\n"", ""warn('Ignoring extraneous arguments in scissor command')\n""]",1
"[""def FUNC_10(self):...\n"", ""frappe.set_user('test1@example.com')\n"", ""self.assertRaises(frappe.PermissionError, get_filters_cond, 'DocType', dict\n    (istable=1), [])\n"", ""self.assertTrue(get_filters_cond('DocType', dict(istable=1), [],\n    ignore_permissions=True))\n"", ""frappe.set_user('Administrator')\n""]",0
"[""def __init__(self, VAR_7, VAR_14, *VAR_15, **VAR_16):...\n"", ""CLASS_0.__init__(self, VAR_7, *VAR_15, **kw)\n"", ""self._error = VAR_14\n""]",0
"[""def FUNC_15(self, VAR_1):...\n"", ""def FUNC_31():...\n"", ""yield self._bin_path\n"", ""if self._is_jdk:\n"", ""yield os.path.join(self.home, 'jre', 'bin')\n"", ""for VAR_5 in FUNC_31():\n"", ""VAR_23 = os.path.join(VAR_5, VAR_1)\n"", ""if self._is_executable(VAR_23):\n"", ""return VAR_23\n""]",0
"[""@classmethod...\n"", ""return [lambda _req: VAR_11[0]]\n""]",0
"[""\""\""\""string\""\""\""\n"", ""from lxml import etree\n"", ""from cinder import exception\n"", ""from cinder.openstack.common import log as logging\n"", ""from cinder.volume.drivers.san.san import SanISCSIDriver\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""VAR_1 = {}\n"", ""def __init__(self, *VAR_2, **VAR_3):...\n"", ""super(CLASS_0, self).__init__(*VAR_2, **kwargs)\n"", ""self.cluster_vip = None\n"", ""def FUNC_0(self, VAR_4, VAR_5, VAR_6=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = []\n"", ""for VAR_43, v in VAR_5.items():\n"", ""VAR_14.append(' %s=%s' % (VAR_43, v))\n"", ""VAR_15 = VAR_4 + ''.join(VAR_14)\n"", ""return self._run_ssh(VAR_15, VAR_6)\n""]",1
"[""from flask import Flask, render_template, redirect, request\n"", ""from mysqlconnection import connectToMySQL\n"", ""VAR_0 = Flask(__name__)\n"", ""@VAR_0.route('/users')...\n"", ""VAR_2 = connectToMySQL('users_db')\n"", ""VAR_3 = VAR_2.query_db('SELECT * FROM users;')\n"", ""return render_template('index.html', VAR_3=users)\n""]",1
"[""@login_required...\n"", ""VAR_15 = get_object_or_404(Candidate, id=candidate_id)\n"", ""return render(VAR_2, 'etd_app/staff_view_abstract.html', {'candidate': VAR_15})\n""]",0
"[""import unittest\n"", ""import requests\n"", ""import json\n"", ""import random\n"", ""def FUNC_0(self):...\n"", ""for _ in range(3):\n"", ""VAR_2 = ''.join([chr(random.randint(65, 90)) for _ in range(9)])\n"", ""def FUNC_1(self):...\n"", ""VAR_3 = {'first_name': VAR_2, 'second_name': VAR_2, 'login': VAR_2,\n    'password': VAR_2}\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""print(VAR_3)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/register', json=data)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""print(VAR_0.text)\n"", ""print('/profiles get_user: {}'.format(VAR_0.text))\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""for user in VAR_1:\n"", ""self.assertEqual(VAR_4['status'], 1)\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profile/{}'.format(user['id']))\n"", ""def FUNC_2(self):...\n"", ""print('/register test_add_user: {}'.format(VAR_0.text))\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""print('/profile/{} get_user: {}'.format(user['id'], VAR_4))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""self.assertGreater(VAR_4['id'], 0)\n"", ""for user in VAR_1:\n"", ""if user['id'] != 191:\n"", ""def FUNC_3(self):...\n"", ""VAR_3 = {'login': user['first_name'], 'password': user['first_name']}\n"", ""VAR_2 = ''.join([chr(random.randint(33, 126)) for _ in range(9)])\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""self.assertGreater(user['id'], 0)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""for user in VAR_1:\n"", ""VAR_3 = {'login': '', 'password': ''}\n"", ""if user['id'] != 191:\n"", ""def FUNC_4(self):...\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""VAR_3 = {VAR_2: VAR_2, VAR_2: VAR_2}\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""VAR_0 = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']),\n    json=data)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertGreater(user['id'], 0)\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""print(VAR_4)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""for user in VAR_1:\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""if user['id'] != 191:\n"", ""if __name__ == '__main__':\n"", ""self.assertEqual(VAR_4['status'], 0)\n"", ""VAR_0 = requests.delete('http://127.0.0.1:5000/profile/{}'.format(user['id']))\n"", ""unittest.main()\n"", ""self.assertIsNotNone(VAR_4['message'])\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""print('[1] /profile/{} update_user: {}'.format(user['id'], VAR_0.text))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profile/{}'.format(user['id']),\n    json=data)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""self.assertEqual(VAR_4['status'], 1)\n"", ""VAR_3 = {'first_name': VAR_4['first_name'], 'second_name': VAR_2}\n"", ""print('/profile/{} del_user: {}'.format(user['id'], VAR_0.text))\n"", ""VAR_0 = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']),\n    json=data)\n"", ""VAR_5 = json.loads(VAR_0.text)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertEqual(VAR_5['status'], 1)\n"", ""self.assertIsNotNone(VAR_5['message'])\n"", ""print('[2] /profile/{} update_user: {}'.format(user['id'], VAR_0.text))\n"", ""VAR_3 = {'first_name': VAR_2 + 'a', 'second_name': VAR_2 + 'a'}\n"", ""VAR_0 = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']),\n    json=data)\n"", ""VAR_4 = json.loads(VAR_0.text)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertEqual(VAR_4['status'], 1)\n"", ""print('[3] /profile/{} update_user: {}'.format(user['id'], VAR_0.text))\n""]",1
"[""def FUNC_1(self, VAR_4, VAR_5=None):...\n"", ""if not VAR_4 or not VAR_4.is_authenticated():\n"", ""return {'count': 0, 'notifications': []}\n"", ""def FUNC_4(VAR_6):...\n"", ""VAR_8 = VAR_6.submission.exercise if VAR_6.submission else None\n"", ""return {'id': VAR_6.id, 'submission_id': VAR_6.submission.id if VAR_6.\n    submission else 0, 'name': '{} {}, {}'.format(VAR_6.course_instance.\n    course.code, str(VAR_8.parent) if VAR_8 and VAR_8.parent else VAR_6.\n    course_instance.instance_name, str(VAR_8) if VAR_8 else VAR_6.subject),\n    'link': VAR_6.get_display_url()}\n""]",1
"[""def FUNC_17(self, VAR_4):...\n"", ""super().on_task_run(VAR_4)\n"", ""VAR_19 = self.num_tasks[-1]\n"", ""self.num_tasks.append(VAR_19 + 1)\n"", ""self.tasks.append(VAR_4)\n""]",0
"[""def FUNC_2():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = 'string'\n"", ""VAR_3 = psycopg2.connect(database=DBNAME)\n"", ""VAR_4 = VAR_3.cursor()\n"", ""VAR_4.execute(VAR_2)\n"", ""VAR_5 = VAR_4.fetchall()\n"", ""VAR_3.close()\n"", ""return VAR_5\n""]",1
"[""def FUNC_0(self, **VAR_4):...\n"", ""VAR_21 = Attribute.objects.all()\n"", ""VAR_5 = super().get_context_data(**kwargs)\n"", ""VAR_5['categories'] = VAR_21.values_list('category', flat=True).order_by(\n    'category').distinct()\n"", ""VAR_5['types'] = VAR_21.values_list('type', flat=True).order_by('type'\n    ).distinct()\n"", ""VAR_5['count'] = self.object_list.count()\n"", ""VAR_7 = AttributeSearchForm(self.request.GET)\n"", ""VAR_5['search_form'] = VAR_7\n"", ""return VAR_5\n""]",0
"[""def FUNC_4(VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not FUNC_2(VAR_3, VAR_4):\n"", ""VAR_7 = \""ALTER SYSTEM SET %s TO '%s'\""\n"", ""return False\n"", ""VAR_3.execute(VAR_7 % (VAR_4, FUNC_1(VAR_3, VAR_4)))\n"", ""return True\n""]",1
"[""from osv import fields, osv\n"", ""from tools.translate import _\n"", ""VAR_0 = 'product.product'\n"", ""def FUNC_0(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_17 = self.pool.get('product.product').browse(VAR_1, VAR_2, VAR_3, VAR_4\n    =context)\n"", ""VAR_18 = (VAR_17.property_stock_account_input and VAR_17.\n    property_stock_account_input.id or False)\n"", ""if not VAR_18:\n"", ""VAR_18 = (VAR_17.categ_id.property_stock_account_input_categ and VAR_17.\n    categ_id.property_stock_account_input_categ.id or False)\n"", ""VAR_19 = (VAR_17.property_stock_account_output and VAR_17.\n    property_stock_account_output.id or False)\n"", ""if not VAR_19:\n"", ""VAR_19 = (VAR_17.categ_id.property_stock_account_output_categ and VAR_17.\n    categ_id.property_stock_account_output_categ.id or False)\n"", ""VAR_20 = (VAR_17.categ_id.property_stock_journal and VAR_17.categ_id.\n    property_stock_journal.id or False)\n"", ""VAR_21 = (VAR_17.categ_id.property_stock_variation and VAR_17.categ_id.\n    property_stock_variation.id or False)\n"", ""return {'stock_account_input': VAR_18, 'stock_account_output': VAR_19,\n    'stock_journal': VAR_20, 'property_stock_variation': VAR_21}\n""]",0
"[""\""\""\""string\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.six.moves.urllib.parse import unquote\n"", ""from django.utils.translation import ugettext as _, ugettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(unquote(VAR_1))\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""@VAR_1.route('/results')...\n"", ""VAR_17 = FUNC_7('results.json')\n"", ""VAR_18 = []\n"", ""for VAR_8, values in VAR_17.items():\n"", ""VAR_43 = {'id': VAR_8, 'values': {'x': [], 'y': []}}\n"", ""VAR_18.sort(VAR_13=lambda ts_item: ts_item['result_type'], reverse=False)\n"", ""VAR_44 = [VAR_13 for VAR_13 in values]\n"", ""return render_template('results.html', VAR_17=results, VAR_18=time_series)\n"", ""VAR_44.sort()\n"", ""for date in VAR_44:\n"", ""VAR_43['values']['x'].append(date)\n"", ""if re.search(':timeseries$', VAR_8):\n"", ""VAR_43['values']['y'].append(values[date])\n"", ""VAR_47 = VAR_8.split(':')\n"", ""if re.search('\\\\(output,.*\\\\)$', VAR_8):\n"", ""(VAR_49, VAR_50), VAR_48 = VAR_47[:2], VAR_47[2:]\n"", ""VAR_51 = re.sub('[()]', '', VAR_8)\n"", ""if re.search('input,source_type:', VAR_8):\n"", ""VAR_43['result_type'] = 'Input time series'\n"", ""VAR_47 = VAR_51.split(',')\n"", ""VAR_47 = VAR_8.split(',')\n"", ""VAR_18.append(VAR_43)\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""(VAR_49, VAR_50, VAR_52, VAR_53), VAR_48 = VAR_47[:4], VAR_47[4:]\n"", ""(VAR_49, VAR_53, VAR_50, VAR_52), VAR_54 = VAR_47[:4], VAR_47[4:]\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['result_type'] = 'Output time series'\n"", ""VAR_43['result_type'] = 'Intermediate input time series'\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['model_name'] = VAR_53\n"", ""VAR_43['model_name'] = VAR_53\n"", ""if re.search('input,source_type:output', VAR_8):\n"", ""VAR_55, VAR_48 = VAR_54[1], VAR_54[2:]\n"", ""VAR_43['source_type'] = 'timeseries'\n"", ""VAR_43['source_model_name'] = VAR_55\n"", ""VAR_43['source_type'] = 'model'\n""]",0
"[""def FUNC_3():...\n"", ""print('grocery== list')\n"", ""VAR_43 = Frame(self)\n"", ""VAR_43.rowconfigure(0, weight=1)\n"", ""VAR_43.columnconfigure(0, weight=1)\n"", ""VAR_43.rowconfigure(1, weight=3)\n"", ""VAR_43.columnconfigure(1, weight=3)\n"", ""VAR_43.pack()\n"", ""VAR_15.pack_forget()\n"", ""VAR_9.pack_forget()\n"", ""VAR_8.configure(text='Grocery List')\n"", ""VAR_44 = 0\n"", ""VAR_39 = 'meal_planner.db'\n"", ""VAR_45 = []\n"", ""VAR_48 = conn.cursor()\n"", ""VAR_50 = 'ingredients_' + str(VAR_13)\n"", ""VAR_49 = VAR_48.execute('SELECT * FROM ' + VAR_50)\n"", ""for result in [VAR_49]:\n"", ""for VAR_32 in result.fetchall():\n"", ""VAR_46 = 0\n"", ""print(VAR_32)\n"", ""for item in VAR_45:\n"", ""for ingredient in VAR_32:\n"", ""print(item)\n"", ""VAR_42 = Button(VAR_4, text='Return to Menu', highlightbackground='#e7e7e7',\n    command=lambda : [groceryListFrame.pack_forget(), menu.pack(),\n    returnButton.pack_forget(), label.configure(text='Meal Planer'),\n    groceryButton.pack(side=RIGHT)])\n"", ""print(ingredient)\n"", ""VAR_44 = VAR_44 + 1\n"", ""VAR_42.pack(side=RIGHT)\n"", ""VAR_45.append(str(ingredient).split())\n"", ""Label(VAR_43, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(VAR_32=\n    i, VAR_33=0, sticky='w')\n""]",1
"[""import logging\n"", ""import os\n"", ""import sys\n"", ""import threading\n"", ""VAR_0 = os.path.dirname(os.path.abspath(__file__))\n"", ""VAR_1 = os.path.dirname(VAR_0)\n"", ""sys.path.insert(0, VAR_1)\n"", ""sys.path.insert(0, os.path.join(VAR_1, 'third_party'))\n"", ""from depot_tools import auto_stub\n"", ""from utils import net\n"", ""def FUNC_0(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = dict(VAR_4 or {})\n"", ""VAR_4['Content-Length'] = len(VAR_2)\n"", ""def __init__(self):...\n"", ""self.content = VAR_2\n"", ""def FUNC_6(self, VAR_7):...\n"", ""VAR_8 = self.content\n"", ""while VAR_8:\n"", ""yield VAR_8[:VAR_7]\n"", ""def FUNC_7(self):...\n"", ""VAR_8 = VAR_8[VAR_7:]\n"", ""return self.content\n""]",0
"[""def FUNC_0(VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if __grains__['kernel'] == 'Linux':\n"", ""VAR_4 = 'df -P'\n"", ""if __grains__['kernel'] == 'OpenBSD':\n"", ""if VAR_1:\n"", ""VAR_4 = 'df -kP'\n"", ""VAR_4 = 'df'\n"", ""VAR_4 = VAR_4 + ' -' + VAR_1\n"", ""VAR_2 = {}\n"", ""VAR_3 = __salt__['cmd.run'](VAR_4).splitlines()\n"", ""for line in VAR_3:\n"", ""if not line:\n"", ""return VAR_2\n"", ""if line.startswith('Filesystem'):\n"", ""VAR_5 = line.split()\n"", ""while not VAR_5[1].isdigit():\n"", ""VAR_5[0] = '{0} {1}'.format(VAR_5[0], VAR_5[1])\n"", ""if __grains__['kernel'] == 'Darwin':\n"", ""VAR_0.warn('Problem parsing disk usage information')\n"", ""VAR_5.pop(1)\n"", ""VAR_2[VAR_5[8]] = {'filesystem': VAR_5[0], '512-blocks': VAR_5[1], 'used':\n    VAR_5[2], 'available': VAR_5[3], 'capacity': VAR_5[4], 'iused': VAR_5[5\n    ], 'ifree': VAR_5[6], '%iused': VAR_5[7]}\n"", ""VAR_2[VAR_5[5]] = {'filesystem': VAR_5[0], '1K-blocks': VAR_5[1], 'used':\n    VAR_5[2], 'available': VAR_5[3], 'capacity': VAR_5[4]}\n"", ""VAR_2 = {}\n""]",1
"[""@mock.patch('requests.post', FUNC_0)...\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 404)\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_7 = {'values': json.dumps({'NEW_URL1': 'http://localhost:8080/'})}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_10 = json.dumps({'PATH': 'bin:/usr/local/bin:/usr/bin:/bin'})\n"", ""VAR_7 = {'image': 'autotest/example'}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['count'], 4)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v2'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_9 = VAR_5.data\n"", ""self.assertEquals(VAR_9['version'], 2)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v4'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_12 = VAR_5.data\n"", ""self.assertEquals(VAR_12['version'], 4)\n"", ""self.assertNotEqual(VAR_9['uuid'], VAR_12['uuid'])\n"", ""self.assertEqual(VAR_9['build'], VAR_12['build'])\n"", ""self.assertEqual(VAR_9['config'], VAR_12['config'])\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_7 = {'version': 1}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4, content_type='application/json')\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['count'], 5)\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v1'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_8 = VAR_5.data\n"", ""VAR_4 = '/api/apps/{app_id}/releases/v5'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_13 = VAR_5.data\n"", ""self.assertEqual(VAR_13['version'], 5)\n"", ""self.assertNotEqual(VAR_8['uuid'], VAR_13['uuid'])\n"", ""self.assertEqual(VAR_8['build'], VAR_13['build'])\n"", ""self.assertEqual(VAR_8['config'], VAR_13['config'])\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(VAR_5.data['values'], {})\n"", ""VAR_4 = '/api/apps/{app_id}/releases/rollback/'.format(**locals())\n"", ""VAR_7 = {'version': 3}\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_4 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""VAR_14 = VAR_5.data['values']\n"", ""self.assertIn('NEW_URL1', VAR_14)\n"", ""self.assertEqual('http://localhost:8080/', VAR_14['NEW_URL1'])\n""]",1
"[""def FUNC_1(self, VAR_2, VAR_6, VAR_7, VAR_4, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""setattr(VAR_2, VAR_6, VAR_7)\n""]",0
"[""def FUNC_9(self, VAR_4, VAR_13, VAR_14):...\n"", ""VAR_35 = None\n"", ""if VAR_4.properties.commands:\n"", ""VAR_35 = VAR_4.properties.commands[0]\n"", ""if VAR_4.properties.command:\n"", ""VAR_36 = {'cmd': 'run', 'manifest': {'bot_id': VAR_14, 'command': VAR_35,\n    'dimensions': VAR_4.properties.dimensions, 'env': VAR_4.properties.env,\n    'extra_args': VAR_4.properties.extra_args, 'grace_period': VAR_4.\n    properties.grace_period_secs, 'hard_timeout': VAR_4.properties.\n    execution_timeout_secs, 'host': utils.get_versioned_hosturl(),\n    'io_timeout': VAR_4.properties.io_timeout_secs, 'inputs_ref': VAR_4.\n    properties.inputs_ref, 'task_id': task_pack.pack_run_result_key(VAR_13)}}\n"", ""VAR_35 = VAR_4.properties.command\n"", ""self.send_response(utils.to_json_encodable(VAR_36))\n""]",0
"[""def FUNC_0():...\n"", ""VAR_1 = psycopg2.connect('dbname=forum')\n"", ""VAR_2 = VAR_1.cursor()\n"", ""VAR_2.execute('SELECT time, content FROM posts ORDER BY time desc')\n"", ""VAR_3 = ({'content': str(row[1]), 'time': str(row[0])} for row in VAR_2.\n    fetchall())\n"", ""VAR_1.close()\n"", ""return VAR_3\n""]",1
"[""@VAR_0.route('/delete_crawl', methods=['POST'])...\n"", ""VAR_7 = request.form['cid']\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('DELETE FROM Crawls WHERE cid = %s' % VAR_7)\n"", ""VAR_1.connection.commit()\n"", ""VAR_28.close()\n"", ""flash('Crawl successfully removed', 'success')\n"", ""return redirect(url_for('dashboard'))\n""]",1
"[""def FUNC_11(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_32 = logging.getLogger(__name__)\n"", ""VAR_33 = self.gce_observer\n"", ""VAR_34 = self.bindings.get('GCE_SERVICE_ACCOUNT', None)\n"", ""VAR_35 = ['--account', VAR_34] if VAR_34 else []\n"", ""VAR_32.debug('Looking up available images.')\n"", ""VAR_36 = VAR_33.list_resources('images', VAR_35=extra_args)\n"", ""if not VAR_36.ok():\n"", ""VAR_37 = json_module.JSONDecoder().decode(VAR_36.output)\n"", ""VAR_38 = self.agent.deployed_config.get(\n    'providers.google.primaryCredentials.name')\n"", ""VAR_32.debug('Configured with Spinnaker account \""%s\""', VAR_38)\n"", ""VAR_39 = [{'account': VAR_38, 'imageName': image['name']} for image in VAR_37]\n"", ""VAR_39 = sorted(VAR_39, key=lambda k: k['imageName'])\n"", ""VAR_20 = HttpContractBuilder(self.agent)\n"", ""VAR_20.new_clause_builder('Has Expected Images').get_url_path(\n    '/gce/images/find').add_constraint(jc.EQUIVALENT(VAR_39))\n"", ""return st.OperationContract(NoOpOperation('List Available Images'),\n    contract=builder.build())\n""]",1
"[""def FUNC_2(self, VAR_1):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = (\""INSERT INTO crimes (description) VALUES                     ('{}');\""\n    .format(VAR_1))\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",1
"[""def FUNC_0(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n"", ""chaos.CREATE_ERROR_RATE = 0\n"", ""chaos.DESTROY_ERROR_RATE = 0\n"", ""chaos.START_ERROR_RATE = 0\n"", ""chaos.STOP_ERROR_RATE = 0\n"", ""settings.SCHEDULER_MODULE = 'chaos'\n"", ""settings.SSH_PRIVATE_KEY = '<some-ssh-private-key>'\n""]",1
"[""def FUNC_17(self, VAR_10='_cores _nodes'.split()):...\n"", ""VAR_23 = {name: res for name, res in self.resources.items() if name not in\n    VAR_10}\n"", ""VAR_24 = {name: value for name, value in self.params.items()}\n"", ""VAR_25 = {'rule': self.rule.name, 'local': self.dag.workflow.is_local(self.\n    rule), 'input': self.input, 'output': self.output, 'params': VAR_24,\n    'threads': self.threads, 'resources': VAR_23}\n"", ""return VAR_25\n""]",0
"[""def FUNC_7(self, VAR_21, VAR_23=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_21 == '/':\n"", ""return self.fs\n"", ""VAR_55 = VAR_21.strip('/').split('/')\n"", ""VAR_22 = ''\n"", ""VAR_57 = self.fs\n"", ""for VAR_66 in VAR_55:\n"", ""if VAR_66 not in [x[VAR_1] for x in VAR_57[VAR_8]]:\n"", ""return VAR_57\n"", ""return False\n"", ""for x in VAR_57[VAR_8]:\n"", ""if x[VAR_1] == VAR_66:\n"", ""VAR_22 = '/'.join((VAR_22, VAR_66))\n"", ""if VAR_66 == VAR_55[-1] and VAR_23 == False:\n"", ""VAR_57 = x\n"", ""if x[VAR_2] == VAR_11:\n"", ""if x[VAR_9][0] == '/':\n"", ""VAR_57 = x\n"", ""VAR_57 = self.getfile(x[VAR_9], VAR_23=follow_symlinks)\n"", ""VAR_57 = self.getfile('/'.join((VAR_22, x[VAR_9])), VAR_23=follow_symlinks)\n"", ""if VAR_57 == False:\n"", ""return False\n""]",1
"[""\""\""\""A helper script for wrapping url calls.\""\""\""\n"", ""import hashlib\n"", ""import httplib\n"", ""import logging\n"", ""import math\n"", ""import os\n"", ""import random\n"", ""import socket\n"", ""import time\n"", ""import urllib\n"", ""import urllib2\n"", ""import urlparse\n"", ""from common import swarm_constants\n"", ""VAR_0 = 4\n"", ""VAR_1 = 5 * 60\n"", ""def FUNC_0(VAR_2, VAR_3=None, VAR_4=None, VAR_5=5, VAR_6=None, VAR_7='POST'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 <= 0:\n"", ""logging.error('UrlOpen(%s): Invalid number of tries: %d', VAR_2, VAR_5)\n"", ""if VAR_6 and VAR_6 < 0:\n"", ""return None\n"", ""logging.error('UrlOpen(%s): Invalid wait duration: %d', VAR_2, VAR_6)\n"", ""VAR_3 = VAR_3 or {}\n"", ""return None\n"", ""if VAR_17.COUNT_KEY in VAR_3:\n"", ""logging.error(\""UrlOpen(%s): key '%s' is duplicate.\"", VAR_2, VAR_17.COUNT_KEY)\n"", ""VAR_11 = None\n"", ""return None\n"", ""for attempt in range(VAR_5):\n"", ""VAR_3[VAR_17.COUNT_KEY] = attempt\n"", ""logging.error('UrlOpen(%s): Unable to open after %d attempts', VAR_2, VAR_5)\n"", ""for VAR_18, VAR_9 in VAR_3.iteritems():\n"", ""if e.code >= 500:\n"", ""if VAR_11 is not None:\n"", ""return None\n"", ""if isinstance(VAR_9, basestring):\n"", ""VAR_20 = urllib.urlencode(VAR_3)\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s ', VAR_2, attempt, e)\n"", ""logging.exception('UrlOpen(%s): %s', VAR_2, e)\n"", ""logging.info('UrlOpen(%s) got %d bytes.', VAR_2, len(VAR_11))\n"", ""if attempt != VAR_5 - 1:\n"", ""VAR_3[VAR_18] = VAR_9.encode('utf-8', 'xmlcharrefreplace')\n"", ""if VAR_7 == 'POSTFORM':\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s', VAR_2, attempt, e)\n"", ""return None\n"", ""return VAR_11\n"", ""if VAR_6 is None:\n"", ""VAR_16, VAR_15 = FUNC_3(VAR_10=data.iteritems(), VAR_4=files)\n"", ""if VAR_7 == 'POST':\n"", ""VAR_23 = random.random() * 3 + math.pow(1.5, attempt + 1)\n"", ""VAR_23 = VAR_6\n"", ""VAR_15 = VAR_15 or ''\n"", ""VAR_11 = urllib2.urlopen(VAR_2, VAR_20, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_22 = list(urlparse.urlparse(VAR_2))\n"", ""VAR_23 = min(10, max(0.1, VAR_23))\n"", ""time.sleep(VAR_23)\n"", ""VAR_21 = urllib2.Request(VAR_2, VAR_3=body)\n"", ""VAR_22[VAR_0] = VAR_20\n"", ""VAR_21.add_header('Content-Type', VAR_16)\n"", ""VAR_2 = urlparse.urlunparse(VAR_22)\n"", ""VAR_21.add_header('Content-Length', len(VAR_15))\n"", ""VAR_11 = urllib2.urlopen(VAR_2, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_11 = urllib2.urlopen(VAR_21, timeout=URL_OPEN_TIMEOUT).read()\n""]",1
"[""@classmethod...\n"", ""return [lambda _request: VAR_22]\n""]",0
"[""def FUNC_1():...\n"", ""if VAR_2 == VAR_0:\n"", ""VAR_2 = VAR_1\n"", ""print(*VAR_2, sep='\\n')\n"", ""VAR_2 = VAR_2[0]\n""]",0
"[""def FUNC_10(VAR_4):...\n"", ""VAR_9 = FUNC_0()\n"", ""VAR_10 = VAR_9.cursor()\n"", ""VAR_10.execute(\n    \""\""\""\n            SELECT shame FROM people WHERE name='{}'\n            \""\""\""\n    .format(VAR_4))\n"", ""VAR_2.error('Execution failed with error: {}'.format(e))\n"", ""VAR_12 = VAR_10.fetchone()\n"", ""VAR_9.close()\n"", ""if VAR_12 is None:\n"", ""VAR_2.debug('No shame found for name {}'.format(VAR_4))\n"", ""VAR_12 = VAR_12[0]\n"", ""return VAR_12\n"", ""VAR_2.debug('shame of {} found for name {}'.format(VAR_12, VAR_4))\n"", ""return VAR_12\n""]",1
"[""import vim\n"", ""import requests\n"", ""import urlparse\n"", ""from retries import retries\n"", ""from requests_futures.sessions import FuturesSession\n"", ""from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor\n"", ""from ycm import vimsupport\n"", ""from ycm.utils import ToUtf8Json\n"", ""from ycm.server.responses import ServerError, UnknownExtraConf\n"", ""VAR_0 = {'content-type': 'application/json'}\n"", ""VAR_1 = UnsafeThreadPoolExecutor(max_workers=30)\n"", ""VAR_2 = 30\n"", ""def __init__(self):...\n"", ""def FUNC_5(self):...\n"", ""def FUNC_6(self):...\n"", ""return True\n""]",0
"[""def FUNC_36(self, VAR_20):...\n"", ""return ''.join(FUNC_8(VAR_20)) == '*'\n""]",0
"[""def FUNC_36(VAR_11):...\n"", ""for VAR_51, VAR_58 in VAR_11.items():\n"", ""if isinstance(VAR_58, str) or not isinstance(VAR_58, Iterable):\n"", ""VAR_58 = [VAR_58]\n"", ""yield [(VAR_51, VAR_16) for VAR_16 in VAR_58]\n""]",0
"[""def FUNC_6(self):...\n"", ""return self.title\n""]",0
"[""async def FUNC_1(VAR_0, VAR_1):...\n"", ""if not db.check(VAR_1.author.id, 'id', db.user_table):\n"", ""db.update(\""INSERT INTO {} (id, nickname) VALUES ('{}', '{}');\"".format(db.\n    user_table, VAR_1.author.id, VAR_1.author))\n""]",1
"[""def FUNC_8(VAR_1, VAR_4, VAR_3):...\n"", ""VAR_18 = \""SELECT name, options_selected from {} where token='{}'\"".format(CFG\n    ('tokens_table_name'), VAR_4)\n"", ""VAR_20 = FUNC_2(VAR_1, VAR_18)\n"", ""return VAR_20 and VAR_20[0][0] == VAR_3 and VAR_20[0][1] == 'NONE'\n""]",1
"[""from django.urls import resolve\n"", ""from django.test import TestCase, override_settings\n"", ""from django.test.client import Client\n"", ""from django.contrib.auth import authenticate\n"", ""from django.contrib.auth.models import User\n"", ""from dashboard.models import PUC, Product, ProductToPUC, ProductDocument, DSSToxLookup\n"", ""from dashboard.views.get_data import *\n"", ""from django.test import TestCase\n"", ""from django.test.client import Client\n"", ""from dashboard.views.get_data import *\n"", ""from dashboard.tests.loader import fixtures_standard\n"", ""VAR_0 = fixtures_standard\n"", ""def FUNC_0(self):...\n"", ""self.client = Client()\n"", ""def FUNC_1(self):...\n"", ""VAR_1 = ['DTXSID9022528', 'DTXSID1020273', 'DTXSID6026296', 'DTXSID2021781']\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""VAR_3 = VAR_2.get(sid='DTXSID9022528')\n"", ""self.assertEqual(0, VAR_3['pucs_n'])\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""VAR_4 = DataDocument.objects.filter(pk__in=ExtractedChemical.objects.filter\n    (dsstox__sid='DTXSID9022528').values('extracted_text__data_document'))\n"", ""VAR_5 = VAR_4[0]\n"", ""VAR_6 = VAR_5.data_group.data_source\n"", ""VAR_7 = Product.objects.create(data_source=ds, title='Test Product', upc=\n    'Test UPC for ProductToPUC')\n"", ""VAR_8 = ProductDocument.objects.create(document=dd, product=p)\n"", ""VAR_8.save()\n"", ""VAR_5.refresh_from_db()\n"", ""VAR_9 = VAR_5.products.first().pk\n"", ""VAR_10 = PUC.objects.get(id=20)\n"", ""VAR_11 = ProductToPUC.objects.create(product=Product.objects.get(pk=pid),\n    VAR_10=puc, puc_assigned_usr=User.objects.get(username='Karyn'))\n"", ""VAR_11.refresh_from_db()\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""VAR_3 = VAR_2.get(sid='DTXSID9022528')\n"", ""self.assertEqual(1, VAR_3['pucs_n'])\n"", ""def FUNC_2(self):...\n"", ""VAR_1 = ['DTXSID9022528', 'DTXSID1020273', 'DTXSID6026296', 'DTXSID2021781']\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(2, VAR_3['dds_n'],\n    'There should be 2 datadocuments associated with ethylaraben')\n"", ""VAR_3 = e\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""VAR_4 = DataDocument.objects.filter(pk__in=ExtractedChemical.objects.filter\n    (dsstox__sid='DTXSID9022528').values('extracted_text__data_document'))\n"", ""VAR_5 = VAR_4[0]\n"", ""VAR_5.delete()\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(1, VAR_3['dds_n'],\n    'There should now be 1 datadocument associated with ethylaraben')\n"", ""VAR_3 = e\n"", ""def FUNC_3(self):...\n"", ""VAR_1 = ['DTXSID9022528', 'DTXSID1020273', 'DTXSID6026296', 'DTXSID2021781']\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(1, VAR_3['dds_wf_n'],\n    'There should be 1 extracted chemical         with weight fraction data associated with ethylparaben'\n    )\n"", ""VAR_3 = e\n"", ""VAR_12 = ExtractedChemical.objects.get(rawchem_ptr_id=73)\n"", ""VAR_12.raw_min_comp = 0.1\n"", ""VAR_12.save()\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(2, VAR_3['dds_wf_n'], 'string')\n"", ""VAR_3 = e\n"", ""def FUNC_4(self):...\n"", ""VAR_1 = ['DTXSID9022528', 'DTXSID1020273', 'DTXSID6026296', 'DTXSID2021781']\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(0, VAR_3['products_n'],\n    'There should be 0 products         associated with ethylparaben')\n"", ""VAR_3 = e\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""VAR_4 = DataDocument.objects.filter(pk__in=ExtractedChemical.objects.filter\n    (dsstox__sid='DTXSID9022528').values('extracted_text__data_document'))\n"", ""VAR_5 = VAR_4[0]\n"", ""VAR_6 = VAR_5.data_group.data_source\n"", ""VAR_7 = Product.objects.create(data_source=ds, title='Test Product', upc=\n    'Test UPC for ProductToPUC')\n"", ""VAR_8 = ProductDocument.objects.create(document=dd, product=p)\n"", ""VAR_8.save()\n"", ""VAR_5.refresh_from_db()\n"", ""VAR_2 = stats_by_dtxsids(VAR_1)\n"", ""for e in VAR_2:\n"", ""if e['sid'] == 'DTXSID9022528':\n"", ""self.assertEqual(1, VAR_3['products_n'],\n    'There should now be 1 product         associated with ethylparaben')\n"", ""VAR_3 = e\n"", ""def FUNC_5(self):...\n"", ""VAR_13 = {'puc': ['2']}\n"", ""VAR_14 = self.client.post('/get_data/', VAR_13=data)\n"", ""for hnp in [b'ball bearings', b'motorcycle', b'vitamin a&amp;d', b'dish soap']:\n"", ""self.assertIn(hnp, VAR_14.content)\n"", ""def FUNC_6(self):...\n"", ""VAR_14 = self.client.get('/get_data/')\n"", ""self.assertEqual(VAR_14.status_code, 200)\n"", ""self.assertContains(VAR_14, 'Download PUCs')\n"", ""def FUNC_7(self):...\n"", ""VAR_14 = self.client.get('/get_data/')\n"", ""self.assertEqual(VAR_14.status_code, 200)\n"", ""self.assertContains(VAR_14, 'Download Uncurated Chemicals')\n"", ""VAR_15 = RawChem.objects.filter(dsstox_id__isnull=True).first()\n"", ""VAR_14 = self.client.get('/dl_raw_chems/')\n"", ""VAR_16 = f'%s,%s,%s,%s\\r\\n' % (VAR_15.id, VAR_15.raw_cas, VAR_15.\n    raw_chem_name, VAR_15.rid if VAR_15.rid else '')\n"", ""VAR_16 = bytes(VAR_16, 'utf-8')\n"", ""self.assertIn(VAR_16, VAR_14.content, 'The non-curated row should appear')\n"", ""VAR_16 = f'%s,%s,%s,%s,%s\\r\\n' % (VAR_15.extracted_text.data_document.\n    data_group.id, VAR_15.id, VAR_15.raw_cas, VAR_15.raw_chem_name, VAR_15.\n    rid if VAR_15.rid else '')\n"", ""VAR_16 = bytes(VAR_16, 'utf-8')\n"", ""self.assertIn(VAR_16, VAR_14.content,\n    'The data group id should be in the output')\n"", ""VAR_15 = RawChem.objects.filter(dsstox_id__isnull=False).first()\n"", ""VAR_16 = f'%s,%s,%s,%s\\r\\n' % (VAR_15.id, VAR_15.raw_cas, VAR_15.\n    raw_chem_name, VAR_15.sid if VAR_15.sid else '')\n"", ""VAR_16 = bytes(VAR_16, 'utf-8')\n"", ""self.assertNotIn(VAR_16, VAR_14.content, 'The curated row should not appear')\n""]",1
"[""@api.model...\n"", ""VAR_22 = self.env['crapo.automaton']\n"", ""VAR_23 = self.env['ir.model'].search([('model', '=', self._name)], limit=1)\n"", ""VAR_24 = VAR_22.search([('model_id', '=', VAR_23.id)], limit=1)\n"", ""if VAR_24:\n"", ""return VAR_24\n"", ""return VAR_22.create({'name': 'Automaton for {}'.format(self._name),\n    'model_id': VAR_23.id})\n""]",0
"[""def FUNC_2(self, VAR_5, VAR_7):...\n"", ""VAR_9 = ''\n"", ""for key in VAR_7:\n"", ""VAR_9 = VAR_9 + ', %s %s'\n"", ""VAR_11 = []\n"", ""VAR_11.append(VAR_5)\n"", ""for key in VAR_7:\n"", ""VAR_13 = self.connection.cursor()\n"", ""VAR_14 = self.__getType(VAR_7[key])\n"", ""print('Error with object %s at key %s with value %s'.format(VAR_7, key,\n    VAR_7[key]))\n"", ""VAR_13.execute('CREATE TABLE %s (TIMESTAMP TIMESTAMPTZ NOT NULL' + VAR_9 +\n    ')', VAR_11)\n"", ""print('CREATE TABLE Error: %s'.format(e))\n"", ""self.connection.commit()\n"", ""VAR_11.append(key)\n"", ""print('Caught error %s'.format(e))\n"", ""VAR_11.append(VAR_14)\n""]",1
"[""def FUNC_16(self, VAR_8, **VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_22 = dict()\n"", ""VAR_22.update(self.rule.workflow.globals)\n"", ""VAR_22.update(dict(input=self.input, output=self.output, VAR_24=self.params,\n    VAR_16=self._format_wildcards, threads=self.threads, VAR_23=self.\n    resources, log=self.log, version=self.rule.version, VAR_3=self.rule.name))\n"", ""VAR_22.update(VAR_9)\n"", ""return format(VAR_8, **_variables)\n""]",0
"[""\""\""\""\nFlask App for Todo List MVP\n\""\""\""\n"", ""from flask import abort, Flask, jsonify\n"", ""from flask import render_template, request, url_for\n"", ""import json\n"", ""from models import storage, Task, User, REQUIRED, PORT, HOST\n"", ""import requests\n"", ""from uuid import uuid4\n"", ""VAR_0 = Flask(__name__)\n"", ""VAR_0.url_map.strict_slashes = False\n"", ""VAR_1 = ['Not a JSON', 'Missing required information', 'Missing id',\n    'Wrong id type']\n"", ""def FUNC_0(VAR_2, VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12 = {VAR_2: VAR_3, 'status_code': VAR_4}\n"", ""VAR_13 = jsonify(VAR_3)\n"", ""return VAR_13\n""]",0
"[""def __repr__(self):...\n"", ""return self.get_name()\n""]",0
"[""def FUNC_40(VAR_87):...\n"", ""return filterfalse(self.is_rule, VAR_87)\n""]",0
"[""def FUNC_12(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_29 = self.config_file()\n"", ""VAR_21 = ''\n"", ""if VAR_29 is not None:\n"", ""for VAR_34, line in enumerate(VAR_29):\n"", ""return VAR_21\n"", ""VAR_29[VAR_34] = line if line.endswith('\\n') else line + '\\n'\n"", ""VAR_32, VAR_21 = tempfile.mkstemp()\n"", ""os.close(VAR_32)\n"", ""conf_file.writelines(VAR_29)\n""]",0
"[""def FUNC_6(self):...\n"", ""c.get(url_for('oauthclient.login', remote_app='test'))\n"", ""self.mock_response(VAR_5='test')\n"", ""self.mock_response(VAR_5='test_invalid')\n"", ""VAR_1 = c.get(url_for('oauthclient.authorized', remote_app='test', code='test')\n    )\n"", ""assert VAR_1.data == 'TEST'\n"", ""assert self.handled_remote.name == 'test'\n"", ""assert not self.handled_args\n"", ""assert not self.handled_kwargs\n"", ""assert self.handled_resp['access_token'] == 'test_access_token'\n"", ""VAR_1 = self.assertRaises(TypeError, c.get, url_for(\n    'oauthclient.authorized', remote_app='test_invalid', code='test'))\n""]",1
"[""def FUNC_2(self):...\n"", ""return \""\""\""Task: %s (ID %d)\nFile: %s\n\""\""\"" % (self.task[1], self.task[0], self\n    .source_path) + GenericRequest.specific_info(self)\n""]",0
"[""def FUNC_7(self):...\n"", ""self.mock(time, 'time', lambda : 126.0)\n"", ""self.mock(logging, 'error', lambda *VAR_15, **_kw: None)\n"", ""self.mock(bot_main, 'get_remote', lambda : self.server)\n"", ""self.mock(os_utilities, 'get_state', lambda : {'foo': 'bar'})\n"", ""VAR_13 = bot_main.get_attributes(None)\n"", ""self.expected_requests([(\n    'https://localhost:1/auth/api/v1/accounts/self/xsrf_token', {'data':\n    VAR_13, 'headers': {'X-XSRF-Token-Request': '1'}}, {'xsrf_token':\n    'token'}), ('https://localhost:1/swarming/api/v1/bot/task_error/23', {\n    'data': {'id': VAR_13['dimensions']['id'][0], 'message': 'error',\n    'task_id': 23}, 'headers': {'X-XSRF-Token': 'token'}}, {})])\n"", ""VAR_14 = bot_main.get_bot()\n"", ""bot_main.post_error_task(VAR_14, 'error', 23)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import urllib.request\n"", ""from ftplib import FTP, FTP_TLS, error_perm\n"", ""import time\n"", ""import csv\n"", ""import logging\n"", ""import os.path\n"", ""import pathlib\n"", ""import allel\n"", ""import sys\n"", ""import functools\n"", ""import numpy as np\n"", ""import zarr\n"", ""import numcodecs\n"", ""from numcodecs import Blosc, LZ4, LZMA\n"", ""from benchmark import config\n"", ""import gzip\n"", ""import shutil\n"", ""def FUNC_0(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0 = str(VAR_0)\n"", ""pathlib.Path(VAR_0).mkdir(parents=True, exist_ok=True)\n"", ""def FUNC_1(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if os.path.exists(VAR_0):\n"", ""shutil.rmtree(VAR_0, ignore_errors=True)\n"", ""def FUNC_2(VAR_1, VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.enabled:\n"", ""FUNC_0(VAR_2)\n"", ""def FUNC_3(VAR_3, VAR_2, VAR_4, VAR_5=None):...\n"", ""if VAR_1.use_tls:\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = FTP_TLS(VAR_1.server)\n"", ""VAR_3 = FTP(VAR_1.server)\n"", ""if VAR_5 is not None and len(VAR_5) > 0:\n"", ""VAR_3.login(VAR_1.username, VAR_1.password)\n"", ""VAR_3.login(VAR_1.username, VAR_1.password)\n"", ""VAR_27 = '/'.join(VAR_5)\n"", ""VAR_5 = []\n"", ""VAR_3.prot_p()\n"", ""if not VAR_1.files:\n"", ""VAR_28 = '/' + VAR_4 + '/' + VAR_27 + '/'\n"", ""VAR_27 = ''\n"", ""FUNC_3(VAR_3=ftp, VAR_2=local_directory, VAR_4=ftp_config.directory)\n"", ""VAR_3.cwd(VAR_1.directory)\n"", ""VAR_29 = VAR_2 + '/' + VAR_27\n"", ""print('[Setup][FTP] Error: Could not change to: {}'.format(VAR_28))\n"", ""VAR_3.cwd(VAR_28)\n"", ""VAR_28 = '/' + VAR_4 + '/'\n"", ""VAR_3.close()\n"", ""VAR_19 = 1\n"", ""os.mkdir(VAR_29)\n"", ""VAR_18 = VAR_3.nlst()\n"", ""VAR_20 = len(VAR_1.files)\n"", ""print('[Setup][FTP] Created local folder: {}'.format(VAR_29))\n"", ""VAR_19 = 1\n"", ""for remote_filename in VAR_1.files:\n"", ""VAR_20 = len(VAR_18)\n"", ""VAR_46 = remote_filename\n"", ""for file in VAR_18:\n"", ""VAR_47 = os.path.join(VAR_2, VAR_46)\n"", ""VAR_30 = VAR_2 + '/' + VAR_27 + '/' + file\n"", ""def FUNC_4(VAR_6, VAR_7):...\n"", ""if not os.path.exists(VAR_47):\n"", ""if not os.path.isfile(VAR_30):\n"", ""urllib.request.urlretrieve(VAR_6, VAR_7)\n"", ""print('[Setup][FTP] ({}/{}) File already exists. Skipping: {}'.format(\n    VAR_19, VAR_20, VAR_47))\n"", ""VAR_3.retrbinary('RETR %s' % remote_filename, VAR_7.write)\n"", ""print('[Setup][FTP] ({}/{}) Error downloading file. Skipping: {}'.format(\n    VAR_19, VAR_20, VAR_47))\n"", ""VAR_19 = VAR_19 + 1\n"", ""print('[Setup][FTP] ({}/{}) File already exists. Skipping: {}'.format(\n    VAR_19, VAR_20, VAR_30))\n"", ""VAR_3.cwd(VAR_28 + file)\n"", ""VAR_49 = VAR_3.nlst()\n"", ""VAR_19 = VAR_19 + 1\n"", ""def FUNC_5(VAR_8, VAR_7):...\n"", ""print('[Setup][FTP] ({}/{}) File downloaded: {}'.format(VAR_19, VAR_20, VAR_47)\n    )\n"", ""VAR_7.close()\n"", ""print('[Setup][FTP] Switching to directory: {}'.format(VAR_27 + '/' + file))\n"", ""if not os.path.isfile(VAR_30):\n"", ""shutil.copyfileobj(file_in, file_out)\n"", ""os.remove(VAR_47)\n"", ""VAR_48 = VAR_5.copy()\n"", ""VAR_3.retrbinary('RETR {}'.format(file), VAR_7.write)\n"", ""def FUNC_6(VAR_9, VAR_10, VAR_11):...\n"", ""VAR_48.append(file)\n"", ""print('[Setup][FTP] ({}/{}) File downloaded: {}'.format(VAR_19, VAR_20, VAR_30)\n    )\n"", ""\""\""\""docstring\""\""\""\n"", ""FUNC_3(VAR_3=ftp, VAR_2=local_directory, VAR_4=remote_directory, VAR_5=\n    new_remote_subdirs_list)\n"", ""VAR_9 = str(VAR_9)\n"", ""VAR_3.cwd(VAR_28)\n"", ""VAR_10 = str(VAR_10)\n"", ""VAR_11 = str(VAR_11)\n"", ""FUNC_0(VAR_9)\n"", ""FUNC_0(VAR_10)\n"", ""FUNC_0(VAR_11)\n"", ""VAR_21 = pathlib.Path(VAR_9).glob('**/*.gz')\n"", ""for VAR_0 in VAR_21:\n"", ""VAR_31 = str(VAR_0)\n"", ""VAR_22 = pathlib.Path(VAR_10).glob('**/*.vcf')\n"", ""VAR_32 = FUNC_8(VAR_31)\n"", ""for VAR_0 in VAR_22:\n"", ""VAR_32 = VAR_32[0:len(VAR_32) - 3]\n"", ""VAR_34 = str(VAR_0)\n"", ""FUNC_1(VAR_10)\n"", ""VAR_33 = str(pathlib.Path(VAR_10, VAR_32))\n"", ""VAR_35 = FUNC_8(VAR_34)\n"", ""VAR_23 = pathlib.Path(VAR_9).glob('**/*.vcf')\n"", ""print('[Setup][Data] Decompressing file: {}'.format(VAR_31))\n"", ""VAR_36 = str(pathlib.Path(VAR_11, VAR_35))\n"", ""for VAR_0 in VAR_23:\n"", ""print('  - Output: {}'.format(VAR_33))\n"", ""shutil.move(VAR_34, VAR_36)\n"", ""VAR_37 = str(VAR_0)\n"", ""def FUNC_7(VAR_0):...\n"", ""FUNC_5(VAR_31, VAR_33)\n"", ""VAR_35 = FUNC_8(VAR_37)\n"", ""VAR_24, VAR_25 = os.path.split(VAR_0)\n"", ""VAR_36 = str(pathlib.Path(VAR_11, VAR_35))\n"", ""return VAR_24\n"", ""shutil.copy(VAR_37, VAR_36)\n""]",1
"[""def FUNC_6(VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""@wraps(VAR_6)...\n"", ""if not request.is_xhr:\n"", ""return abort(401)\n"", ""return VAR_6(*VAR_11, **kwargs)\n""]",0
"[""def FUNC_2(self):...\n"", ""CLASS_4.ScenarioMaker().given_a_deep_link_domain('pachatary://app'\n    ).given_a_dynamic_link('').when_call_root_redirect(\n    ).then_response_should_be_a_redirect_to('pachatary://app/')\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_14 = utils.GetUnusedLocalhostPort()\n"", ""self._temp_options_filename = options_file.name\n"", ""json.dump(dict(self._user_options), options_file)\n"", ""options_file.flush()\n"", ""VAR_21 = [utils.PathToPythonInterpreter(), FUNC_0(), '--port={0}'.format(\n    VAR_14), '--options_file={0}'.format(options_file.name), '--log={0}'.\n    format(self._user_options['server_log_level']),\n    '--idle_suicide_seconds={0}'.format(VAR_4)]\n"", ""if not self._user_options['server_use_vim_stdout']:\n"", ""VAR_26 = VAR_0.path.join(utils.PathToTempDir(), 'server_{port}_{std}.log')\n"", ""self._server_popen = utils.SafePopen(VAR_21, stdout=PIPE, stderr=PIPE)\n"", ""self._server_stdout = VAR_26.format(port=server_port, std='stdout')\n"", ""BaseRequest.server_location = 'http://localhost:' + str(VAR_14)\n"", ""self._server_stderr = VAR_26.format(port=server_port, std='stderr')\n"", ""self._NotifyUserIfServerCrashed()\n"", ""VAR_21.append('--stdout={0}'.format(self._server_stdout))\n"", ""VAR_21.append('--stderr={0}'.format(self._server_stderr))\n"", ""if self._user_options['server_keep_logfiles']:\n"", ""VAR_21.append('--keep_logfiles')\n""]",1
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render, redirect\n"", ""from django.views.generic import ListView, DetailView\n"", ""from django.views.generic.edit import CreateView, UpdateView\n"", ""from pure_pagination.mixins import PaginationMixin\n"", ""from django.db.models import Q, Count\n"", ""from .models import tweet, Hunt\n"", ""from .forms import HuntForm\n"", ""import csv\n"", ""from io import StringIO, BytesIO\n"", ""from codecs import BOM_UTF8\n"", ""from pytz import timezone\n"", ""from django.http import JsonResponse\n"", ""from urllib.parse import urlparse\n"", ""from http.client import HTTPSConnection\n"", ""VAR_3 = 'twitter_hunter/index.html'\n"", ""VAR_4 = 'hts'\n"", ""VAR_5 = 30\n"", ""def FUNC_6(self, **VAR_6):...\n"", ""VAR_19 = super().get_context_data(**kwargs)\n"", ""return VAR_19\n""]",1
"[""def FUNC_3(self, VAR_5):...\n"", ""VAR_14 = 'string'.format(VAR_5)\n"", ""self.cur.execute(VAR_14)\n"", ""return self.cur.fetchall()\n""]",1
"[""import os\n"", ""import brightway2 as bw2\n"", ""from fixtures import *\n"", ""from lca_disclosures.brightway2.disclosure import Bw2Disclosure as DisclosureExporter\n"", ""from lca_disclosures.brightway2.importer import DisclosureImporter\n"", ""def FUNC_0():...\n"", ""VAR_0 = DisclosureExporter(TEST_BW_PROJECT_NAME, TEST_BW_DB_NAME,\n    folder_path=TEST_FOLDER, filename=TEST_FILENAME)\n"", ""assert VAR_0.foreground_flows\n"", ""assert VAR_0.background_flows\n"", ""assert VAR_0.emission_flows\n"", ""assert VAR_0.Af\n"", ""assert VAR_0.Ad\n"", ""assert VAR_0.Bf\n"", ""assert VAR_0.cutoffs\n"", ""def FUNC_1():...\n"", ""VAR_0 = DisclosureExporter(TEST_BW_PROJECT_NAME, TEST_BW_DB_NAME,\n    folder_path=TEST_FOLDER, filename=TEST_FILENAME)\n"", ""VAR_1 = VAR_0.write_json()\n"", ""print(VAR_1)\n"", ""assert os.path.isfile(VAR_1)\n"", ""def FUNC_2():...\n"", ""bw2.projects.set_current(IMPORT_PROJECT_NAME)\n"", ""VAR_2 = DisclosureImporter(os.path.join(os.path.dirname(os.path.realpath(\n    __file__)), TEST_FOLDER, '{}.json'.format(TEST_FILENAME)))\n"", ""VAR_2.apply_strategies()\n"", ""assert VAR_2.statistics()[2] == 0\n"", ""VAR_2.write_database()\n"", ""assert len(bw2.Database(VAR_2.db_name)) != 0\n""]",1
"[""@integration_synonym_api...\n"", ""FUNC_2(VAR_2)\n"", ""FUNC_3(VAR_2, 'BEAR', VAR_7='1')\n"", ""FUNC_5(VAR_4, VAR_5, VAR_11='BARE', VAR_10=[{'name': '----BARE'}, {'name':\n    'BEAR'}])\n""]",0
"[""def FUNC_7(*VAR_12):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = np.asarray(VAR_12[0])\n"", ""if VAR_1.shape[0] != VAR_1.shape[1]:\n"", ""if not np.allclose(VAR_1, VAR_1.conj().T, atol=tolerance):\n"", ""return VAR_1\n""]",0
"[""def FUNC_2(VAR_0, VAR_2):...\n"", ""return os.chmod(VAR_0, VAR_2, follow_symlinks=os.chmod not in os.\n    supports_follow_symlinks)\n""]",0
"[""def FUNC_1(self):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = 'SELECT description FROM crimes;'\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""return cursor.fetchall()\n""]",1
"[""def FUNC_9(VAR_1, VAR_8, **VAR_6):...\n"", ""import sql\n"", ""VAR_38 = '/etc/keepalived/keepalived.conf' if VAR_6.get('keepalived'\n    ) else sql.get_setting('haproxy_config_path')\n"", ""VAR_37 = FUNC_8(VAR_1)\n"", ""VAR_74 = VAR_37.open_sftp()\n"", ""VAR_37 = str(e)\n"", ""VAR_74.get(VAR_38, VAR_8)\n"", ""return VAR_37\n"", ""VAR_74.close()\n"", ""VAR_37.close()\n""]",0
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = []\n"", ""for VAR_35 in VAR_3:\n"", ""if VAR_35:\n"", ""return VAR_16\n"", ""VAR_35 = str(VAR_35).strip()\n"", ""VAR_16.append(VAR_35)\n"", ""log.info('Looking up collation for %s', VAR_35)\n"", ""VAR_36 = 'SELECT right_tag FROM tag_table WHERE wrong_tag=\""{}\""'.format(VAR_35)\n"", ""VAR_37 = db.execute_query(VAR_36)\n"", ""if not VAR_37:\n"", ""log.error(\""Can't check the tag because of the db error\"")\n"", ""if VAR_37.rowcount:\n"", ""log.warning('Tag will stay as is.')\n"", ""VAR_35 = VAR_37.fetchone()[0]\n"", ""log.info('Tag after looking up in tag_tables - %s.', VAR_35)\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""if VAR_0 < 0 or VAR_0 > 1:\n""]",0
"[""def FUNC_7(self):...\n"", ""VAR_4 = Lint.executable\n"", ""VAR_5 = 'invalid_binary_which_doesnt_exist'\n"", ""Lint.executable = VAR_5\n"", ""self.assertEqual(Lint.check_prerequisites(), \""'{}' is not installed.\"".\n    format(VAR_5))\n"", ""Lint.executable = 'echo'\n"", ""self.assertTrue(Lint.check_prerequisites())\n"", ""self.assertTrue(Lint.check_prerequisites())\n"", ""Lint.executable = VAR_4\n""]",0
"[""@memoized_method...\n"", ""VAR_14 = get_buildroot()\n"", ""return VAR_7.capture_snapshots((PathGlobsAndRoot(PathGlobs(tuple(\n    fast_relpath(a, VAR_14) for a in (self.zinc, self.compiler_bridge, self\n    .compiler_interface))), VAR_14),))[0]\n""]",0
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""if VAR_0.exception != 'None':\n"", ""return False\n"", ""VAR_2 = VAR_0.answer.split('.')[3]\n"", ""return VAR_2 in VAR_1\n""]",1
"[""def FUNC_3(self, VAR_18, VAR_19, VAR_16, VAR_17, VAR_7, VAR_8):...\n"", ""print(str(VAR_18))\n"", ""print(str(VAR_19))\n"", ""VAR_22 = 'string' + \""('%s', '%s', '%s', '%s', '%s', '%s', '%s')\"" % (VAR_18,\n    datetime.now(), VAR_19, VAR_16, VAR_17, VAR_7, VAR_8)\n"", ""self.cur.execute(VAR_22)\n"", ""self.conn.commit()\n"", ""return self.cur.lastrowid\n""]",1
"[""def __repr__(self):...\n"", ""return f'<SetEntry {self.value!r}>'\n""]",0
"[""def FUNC_12(VAR_16, VAR_19):...\n"", ""if isinstance(VAR_16, CLASS_1):\n"", ""return VAR_19 in VAR_16.flags\n"", ""return False\n""]",1
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = 'string'.format(VAR_1)\n"", ""VAR_9 = db.engine.execute(VAR_11)\n"", ""if VAR_9.rowcount == 0:\n"", ""VAR_12 = ProjectContributionsDTO()\n"", ""for row in VAR_9:\n"", ""VAR_2 = row[0] or row[3]\n"", ""return VAR_12\n"", ""VAR_26 = UserContribution()\n"", ""VAR_26.username = row[1] if row[1] else row[4]\n"", ""VAR_26.mapped = row[2] if row[2] else 0\n"", ""VAR_26.validated = row[5] if row[5] else 0\n"", ""VAR_12.user_contributions.append(VAR_26)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.six.moves.urllib.parse import unquote\n"", ""from django.utils.translation import ugettext as _, ugettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(unquote(VAR_1))\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def FUNC_32(VAR_19):...\n"", ""return dict((expr, vimsupport.VimExpressionToPythonType(expr)) for expr in\n    VAR_19)\n""]",0
"[""def FUNC_8(self, VAR_16, VAR_7, VAR_17, VAR_18, VAR_19):...\n"", ""VAR_31 = None\n"", ""VAR_32 = None\n"", ""for ln in [x.decode('utf-8').strip() for x in VAR_16]:\n"", ""if not ln and VAR_31 is not None:\n"", ""VAR_31 = None\n"", ""if not ln or ln.startswith('#'):\n"", ""VAR_32 = None\n"", ""if VAR_31 is None:\n"", ""if ln.startswith('u '):\n"", ""if VAR_31 and VAR_32 is None:\n"", ""VAR_41, VAR_43 = ln[2:].split(':', 1)\n"", ""VAR_31 = ln\n"", ""VAR_32 = ln\n"", ""VAR_37, VAR_8 = ln.split(' ')\n"", ""VAR_7[VAR_41] = VAR_43\n"", ""if not VAR_32.startswith('/'):\n"", ""if VAR_37 in 'ra':\n"", ""VAR_31 = os.path.abspath(VAR_31)\n"", ""VAR_17[VAR_32].append(VAR_8)\n"", ""if VAR_37 in 'wa':\n"", ""VAR_32 = VAR_32.strip('/')\n"", ""VAR_18[VAR_32].append(VAR_8)\n"", ""VAR_19[VAR_32] = VAR_31\n"", ""VAR_17[VAR_32] = []\n"", ""VAR_18[VAR_32] = []\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._state\n""]",0
"[""def FUNC_17(self, VAR_34):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not VAR_34:\n"", ""return True\n"", ""if self.tempfiles[VAR_34] is not None:\n"", ""VAR_70 = hashlib.sha256(FUNC_14(self.tempfiles[VAR_34], 'rb').read()\n    ).hexdigest()\n"", ""return os.close(VAR_34)\n"", ""VAR_71 = self.cfg.get('honeypot', 'download_path') + '/' + VAR_70\n"", ""if os.path.exists(VAR_71):\n"", ""os.remove(self.tempfiles[VAR_34])\n"", ""os.rename(self.tempfiles[VAR_34], VAR_71)\n"", ""self.update_realfile(self.getfile(self.filenames[VAR_34]), VAR_71)\n"", ""log.msg(format='SFTP Uploaded file \""%(filename)s\"" to %(outfile)s', eventid=\n    'cowrie.session.file_upload', VAR_32=os.path.basename(self.filenames[fd\n    ]), VAR_59=shasumfile, VAR_70=shasum)\n""]",0
"[""def FUNC_4(self, VAR_6):...\n"", ""VAR_13 = False\n"", ""if VAR_6 in self.clients:\n"", ""VAR_14 = self.clients[VAR_6]\n"", ""return VAR_13\n"", ""VAR_15 = self.register_queue[VAR_6]\n"", ""if os.environ.get('CI', False) and not os.environ.get(\n"", ""return VAR_13\n"", ""VAR_13 = VAR_14['status'] == self.RUNNING\n"", ""if VAR_14['status'] == self.STOPPED:\n"", ""VAR_16 = VAR_14['config']\n"", ""if not VAR_16['external']:\n"", ""VAR_24 = select_port(default_port=config['port'])\n"", ""VAR_14['instance'] = LSPClient(VAR_3=self, server_settings=config, VAR_17=\n    self.get_root_path(), VAR_6=language)\n"", ""VAR_16['port'] = VAR_24\n"", ""for plugin in self.lsp_plugins:\n"", ""VAR_14['instance'].register_plugin_type(plugin, self.lsp_plugins[plugin])\n"", ""VAR_0.info('Starting LSP client for {}...'.format(VAR_6))\n"", ""VAR_14['instance'].start()\n"", ""VAR_14['status'] = self.RUNNING\n"", ""for entry in VAR_15:\n"", ""VAR_14.register_file(*entry)\n"", ""self.register_queue[VAR_6] = []\n""]",1
"[""\""\""\""\nDjango settings for the Deis project.\n\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""import os.path\n"", ""import sys\n"", ""import tempfile\n"", ""VAR_0 = os.path.normpath(os.path.join(os.path.dirname(__file__), '..'))\n"", ""VAR_1 = False\n"", ""VAR_2 = VAR_1\n"", ""VAR_3 = ()\n"", ""VAR_4 = VAR_3\n"", ""VAR_5 = 60 * 3\n"", ""VAR_6 = ['localhost']\n"", ""VAR_7 = 'America/Denver'\n"", ""VAR_8 = 'en-us'\n"", ""VAR_9 = 1\n"", ""VAR_10 = True\n"", ""VAR_11 = True\n"", ""VAR_12 = True\n"", ""VAR_13 = ''\n"", ""VAR_14 = ''\n"", ""VAR_15 = os.path.abspath(os.path.join(__file__, '..', '..', 'static'))\n"", ""VAR_16 = '/static/'\n"", ""VAR_17 = ()\n"", ""VAR_18 = ('django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder')\n"", ""VAR_19 = None\n"", ""VAR_20 = ('django.template.loaders.filesystem.Loader',\n    'django.template.loaders.app_directories.Loader')\n"", ""VAR_21 = ('django.contrib.auth.context_processors.auth',\n    'django.core.context_processors.debug',\n    'django.core.context_processors.i18n',\n    'django.core.context_processors.media',\n    'django.core.context_processors.request',\n    'django.core.context_processors.static',\n    'django.core.context_processors.tz',\n    'django.contrib.messages.context_processors.messages',\n    'deis.context_processors.site')\n"", ""VAR_22 = ('django.middleware.common.CommonMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'api.middleware.VersionMiddleware')\n"", ""VAR_23 = 'deis.urls'\n"", ""VAR_24 = 'deis.wsgi.application'\n"", ""VAR_25 = VAR_0 + '/web/templates',\n"", ""VAR_26 = ('django.contrib.admin', 'django.contrib.auth',\n    'django.contrib.contenttypes', 'django.contrib.humanize',\n    'django.contrib.messages', 'django.contrib.sessions',\n    'django.contrib.sites', 'django.contrib.staticfiles', 'django_fsm',\n    'guardian', 'json_field', 'gunicorn', 'rest_framework', 'south', 'api',\n    'web')\n"", ""VAR_27 = ('django.contrib.auth.backends.ModelBackend',\n    'guardian.backends.ObjectPermissionBackend')\n"", ""VAR_28 = -1\n"", ""VAR_29 = True\n"", ""VAR_30 = 'none'\n"", ""VAR_31 = True\n"", ""VAR_32 = ['system']\n"", ""VAR_33 = '/api/auth/login/'\n"", ""VAR_34 = '/'\n"", ""VAR_35 = False\n"", ""VAR_36 = {'DEFAULT_MODEL_SERIALIZER_CLASS':\n    'rest_framework.serializers.ModelSerializer',\n    'DEFAULT_PERMISSION_CLASSES': (\n    'rest_framework.permissions.IsAuthenticated',),\n    'DEFAULT_AUTHENTICATION_CLASSES': (\n    'rest_framework.authentication.SessionAuthentication',), 'PAGINATE_BY': 100\n    }\n"", ""VAR_37 = False\n"", ""if os.path.exists('/dev/log'):\n"", ""VAR_62 = '/dev/log'\n"", ""if os.path.exists('/var/log/syslog'):\n"", ""VAR_38 = {'version': 1, 'disable_existing_loggers': False, 'formatters': {\n    'verbose': {'format':\n    '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'\n    }, 'simple': {'format': '%(levelname)s %(message)s'}}, 'filters': {\n    'require_debug_false': {'()': 'django.utils.log.RequireDebugFalse'}},\n    'handlers': {'null': {'level': 'DEBUG', 'class': 'logging.NullHandler'},\n    'console': {'level': 'DEBUG', 'class': 'logging.StreamHandler',\n    'formatter': 'simple'}, 'mail_admins': {'level': 'ERROR', 'filters': [\n    'require_debug_false'], 'class': 'django.utils.log.AdminEmailHandler'},\n    'rsyslog': {'class': 'logging.handlers.SysLogHandler', 'address':\n    VAR_62, 'facility': 'local0'}}, 'loggers': {'django': {'handlers': [\n    'null'], 'level': 'INFO', 'propagate': True}, 'django.request': {\n    'handlers': ['console', 'mail_admins'], 'level': 'WARNING', 'propagate':\n    True}, 'api': {'handlers': ['console', 'mail_admins', 'rsyslog'],\n    'level': 'INFO', 'propagate': True}}}\n"", ""VAR_62 = '/var/log/syslog'\n"", ""VAR_62 = 'localhost', 514\n"", ""VAR_39 = 'api.tests.SilentDjangoTestSuiteRunner'\n"", ""VAR_40, VAR_41 = os.environ.get('ETCD', '127.0.0.1:4001').split(',')[0].split(\n    ':')\n"", ""VAR_42 = os.path.abspath(os.path.join(__file__, '..', '..', 'logs'))\n"", ""VAR_43 = 1000\n"", ""VAR_44 = tempfile.mkdtemp(prefix='deis')\n"", ""VAR_45 = 'deis/helloworld'\n"", ""VAR_46 = 'deisapp.local'\n"", ""VAR_47 = 'mock'\n"", ""VAR_48 = ''\n"", ""VAR_49 = ''\n"", ""VAR_50 = {}\n"", ""VAR_51 = ''\n"", ""VAR_19 = os.environ.get('DEIS_SECRET_KEY',\n    'CHANGEME_sapm$s%upvsw5l_zuy_&29rkywd^78ff(qi')\n"", ""VAR_52 = os.environ.get('DEIS_BUILDER_KEY',\n    'CHANGEME_sapm$s%upvsw5l_zuy_&29rkywd^78ff(qi')\n"", ""VAR_53 = 'registry.mock'\n"", ""VAR_54 = 'http://localhost:5000'\n"", ""VAR_55 = 'localhost'\n"", ""VAR_56 = 5000\n"", ""VAR_57 = True\n"", ""VAR_58 = False\n"", ""VAR_59 = {'default': {'ENGINE': 'django.db.backends.' + os.environ.get(\n    'DATABASE_ENGINE', 'postgresql_psycopg2'), 'NAME': os.environ.get(\n    'DATABASE_NAME', 'deis')}}\n"", ""VAR_60 = '[a-z0-9-]+'\n"", ""VAR_6 = ['*']\n"", ""VAR_61 = 'HTTP_X_FORWARDED_PROTO', 'https'\n"", ""from .local_settings import *\n"", ""if os.path.exists('/templates/confd_settings.py'):\n"", ""sys.path.append('/templates')\n"", ""from confd_settings import *\n""]",1
"[""import sys\n"", ""import logging\n"", ""from django.db import connection, DatabaseError\n"", ""from reviewus.settings import DEBUG\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""VAR_1 = None\n"", ""VAR_2 = None\n"", ""def __new__(VAR_3):...\n"", ""if CLASS_0.instance is None:\n"", ""CLASS_0.instance = object.__new__(VAR_3)\n"", ""return CLASS_0.instance\n""]",0
"[""@VAR_1.assignment_tag...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = VAR_2.userprofile if VAR_2.is_authenticated() else None\n"", ""if isinstance(VAR_3, CourseInstance):\n"", ""return build_plugin_renderers(VAR_3.plugins.all(), VAR_4 or\n    'course_instance', user_profile=profile, VAR_6=some_model)\n"", ""if isinstance(VAR_3, BaseExercise):\n"", ""VAR_6 = VAR_3.course_instance\n"", ""if isinstance(VAR_3, Submission):\n"", ""return build_plugin_renderers(VAR_6.plugins.all(), VAR_4 or 'exercise',\n    user_profile=profile, exercise=some_model, VAR_6=course_instance)\n"", ""VAR_6 = VAR_3.exercise.course_instance\n"", ""VAR_0.warn('Unrecognized model type received for plugin_renderers tag: {}'.\n    format(str(type(VAR_3))))\n"", ""return build_plugin_renderers(VAR_6.plugins.all(), VAR_4 or 'submission',\n    user_profile=profile, submission=some_model, exercise=some_model.\n    exercise, VAR_6=course_instance)\n"", ""return []\n""]",1
"[""def FUNC_0(VAR_2, VAR_3=None, VAR_4=None, VAR_5=5, VAR_6=None, VAR_7='POST'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 <= 0:\n"", ""logging.error('UrlOpen(%s): Invalid number of tries: %d', VAR_2, VAR_5)\n"", ""if VAR_6 and VAR_6 < 0:\n"", ""return None\n"", ""logging.error('UrlOpen(%s): Invalid wait duration: %d', VAR_2, VAR_6)\n"", ""VAR_3 = VAR_3 or {}\n"", ""return None\n"", ""if VAR_17.COUNT_KEY in VAR_3:\n"", ""logging.error(\""UrlOpen(%s): key '%s' is duplicate.\"", VAR_2, VAR_17.COUNT_KEY)\n"", ""VAR_11 = None\n"", ""return None\n"", ""for attempt in range(VAR_5):\n"", ""VAR_3[VAR_17.COUNT_KEY] = attempt\n"", ""logging.error('UrlOpen(%s): Unable to open after %d attempts', VAR_2, VAR_5)\n"", ""for VAR_18, VAR_9 in VAR_3.iteritems():\n"", ""if e.code >= 500:\n"", ""if VAR_11 is not None:\n"", ""return None\n"", ""if isinstance(VAR_9, basestring):\n"", ""VAR_20 = urllib.urlencode(VAR_3)\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s ', VAR_2, attempt, e)\n"", ""logging.exception('UrlOpen(%s): %s', VAR_2, e)\n"", ""logging.info('UrlOpen(%s) got %d bytes.', VAR_2, len(VAR_11))\n"", ""if attempt != VAR_5 - 1:\n"", ""VAR_3[VAR_18] = VAR_9.encode('utf-8', 'xmlcharrefreplace')\n"", ""if VAR_7 == 'POSTFORM':\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s', VAR_2, attempt, e)\n"", ""return None\n"", ""return VAR_11\n"", ""if VAR_6 is None:\n"", ""VAR_16, VAR_15 = FUNC_3(VAR_10=data.iteritems(), VAR_4=files)\n"", ""if VAR_7 == 'POST':\n"", ""VAR_23 = random.random() * 3 + math.pow(1.5, attempt + 1)\n"", ""VAR_23 = VAR_6\n"", ""VAR_15 = VAR_15 or ''\n"", ""VAR_11 = urllib2.urlopen(VAR_2, VAR_20, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_22 = list(urlparse.urlparse(VAR_2))\n"", ""VAR_23 = min(10, max(0.1, VAR_23))\n"", ""time.sleep(VAR_23)\n"", ""VAR_21 = urllib2.Request(VAR_2, VAR_3=body)\n"", ""VAR_22[VAR_0] = VAR_20\n"", ""VAR_21.add_header('Content-Type', VAR_16)\n"", ""VAR_2 = urlparse.urlunparse(VAR_22)\n"", ""VAR_21.add_header('Content-Length', len(VAR_15))\n"", ""VAR_11 = urllib2.urlopen(VAR_2, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_11 = urllib2.urlopen(VAR_21, timeout=URL_OPEN_TIMEOUT).read()\n""]",1
"[""def FUNC_0(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_17 = self.pool.get('product.product').browse(VAR_1, VAR_2, VAR_3, VAR_4\n    =context)\n"", ""VAR_18 = (VAR_17.property_stock_account_input and VAR_17.\n    property_stock_account_input.id or False)\n"", ""if not VAR_18:\n"", ""VAR_18 = (VAR_17.categ_id.property_stock_account_input_categ and VAR_17.\n    categ_id.property_stock_account_input_categ.id or False)\n"", ""VAR_19 = (VAR_17.property_stock_account_output and VAR_17.\n    property_stock_account_output.id or False)\n"", ""if not VAR_19:\n"", ""VAR_19 = (VAR_17.categ_id.property_stock_account_output_categ and VAR_17.\n    categ_id.property_stock_account_output_categ.id or False)\n"", ""VAR_20 = (VAR_17.categ_id.property_stock_journal and VAR_17.categ_id.\n    property_stock_journal.id or False)\n"", ""VAR_21 = (VAR_17.categ_id.property_stock_variation and VAR_17.categ_id.\n    property_stock_variation.id or False)\n"", ""return {'stock_account_input': VAR_18, 'stock_account_output': VAR_19,\n    'stock_journal': VAR_20, 'property_stock_variation': VAR_21}\n""]",0
"[""import re\n"", ""import tornado\n"", ""from bzs import files\n"", ""from bzs import const\n"", ""from bzs import users\n"", ""from bzs import preproc\n"", ""VAR_0 = ['GET', 'HEAD']\n"", ""@tornado.web.asynchronous...\n"", ""VAR_2 = tornado.concurrent.Future()\n"", ""self.set_status(404, 'Not Found')\n"", ""self.set_status(200, 'OK')\n"", ""def FUNC_1():...\n"", ""self._headers = tornado.httputil.HTTPHeaders()\n"", ""self._headers = tornado.httputil.HTTPHeaders()\n"", ""VAR_3 = files.get_static_data('./static/home.html')\n"", ""self.add_header('Content-Length', '0')\n"", ""self.add_header('Cache-Control', 'max-age=0')\n"", ""VAR_4 = users.get_user_by_cookie(self.get_cookie('user_active_login',\n    default=''))\n"", ""self.flush()\n"", ""self.add_header('Connection', 'close')\n"", ""VAR_3 = preproc.preprocess_webpage(VAR_3, VAR_4)\n"", ""return None\n"", ""self.add_header('Content-Type', 'text/html')\n"", ""VAR_2.set_result(VAR_3)\n"", ""self.add_header('Content-Length', str(len(VAR_3)))\n"", ""tornado.ioloop.IOLoop.instance().add_callback(FUNC_1)\n"", ""self.write(VAR_3)\n"", ""VAR_3 = yield VAR_2\n"", ""self.flush()\n"", ""self.finish()\n"", ""return self\n""]",1
"[""def FUNC_1(VAR_6):...\n"", ""VAR_18 = VAR_6.result()\n"", ""if VAR_18.status_code == requests.codes.server_error:\n"", ""FUNC_4(VAR_18.json())\n"", ""VAR_18.raise_for_status()\n"", ""if VAR_18.text:\n"", ""return VAR_18.json()\n"", ""return None\n""]",0
"[""def FUNC_6(VAR_4, VAR_5=''):...\n"", ""VAR_0, VAR_10 = FUNC_0()\n"", ""VAR_18 = 'UPDATE {} SET \""options_selected\""=\\'{}\\' WHERE token=\\'{}\\''.format(\n    CFG('tokens_table_name'), VAR_5, VAR_4)\n"", ""VAR_10.execute(VAR_18)\n"", ""FUNC_1(VAR_0)\n""]",1
"[""def FUNC_0():...\n"", ""VAR_0 = 'string' % (setup_arg['name'], setup_arg['description'], cli_name,\n    cli_name, cli_name)\n"", ""VAR_1 = docopt(VAR_0, version=setup_arg['version'])\n"", ""if VAR_1['--verbose']:\n"", ""debug.verbose = True\n"", ""if VAR_1['--quiet']:\n"", ""debug.quiet = True\n"", ""debug.debug('args:', str(VAR_1).replace('\\n', ''))\n"", ""from beamr.interpreters.config import Config\n"", ""if VAR_1['--edit-config']:\n"", ""return Config.editUserConfig(VAR_1['<editor>'])\n"", ""VAR_2 = None\n"", ""if not VAR_1['--no-pdf']:\n"", ""VAR_2 = [VAR_1['--pdflatex'], '-shell-escape']\n"", ""if VAR_1['<input-file>']:\n"", ""if VAR_1['<output-file>']:\n"", ""sys.stdin = open(VAR_1['<input-file>'], 'r')\n"", ""if VAR_1['<output-file>']:\n"", ""VAR_4 = VAR_1['<output-file>']\n"", ""sys.stdout = open(VAR_1['<output-file>'], 'w')\n"", ""VAR_3 = {}\n"", ""VAR_1['<output-file>'] = None\n"", ""if VAR_1['--safe']:\n"", ""VAR_5 = VAR_4.rfind('/') + 1\n"", ""VAR_3['safe'] = True\n"", ""if VAR_1['--unsafe']:\n"", ""if VAR_5 > 0:\n"", ""Config.fromCmdline(VAR_1['--config'], **cmdlineSpecial)\n"", ""VAR_3['safe'] = False\n"", ""VAR_2.append('-output-directory=' + VAR_4[:VAR_5])\n"", ""VAR_2.append('-jobname=' + VAR_4[VAR_5:])\n"", ""from beamr.interpreters import Document\n"", ""VAR_6 = Document(sys.stdin.read())\n"", ""VAR_7 = str(VAR_6)\n"", ""if VAR_2:\n"", ""from subprocess import Popen, PIPE\n"", ""print(VAR_7)\n"", ""VAR_8 = {'stdin': PIPE}\n"", ""if debug.quiet:\n"", ""VAR_8.update({'stdout': PIPE, 'stderr': PIPE})\n"", ""VAR_9 = Popen(VAR_2, **runkwarg)\n"", ""VAR_9.communicate(bytes(VAR_7, encoding='utf-8'))\n"", ""VAR_9.communicate(bytes(VAR_7))\n"", ""VAR_9.stdin.close()\n"", ""VAR_10 = VAR_9.wait()\n"", ""if VAR_10:\n"", ""debug.err('Fatal: pdflatex exited with nonzero status', VAR_10)\n"", ""return VAR_10\n""]",1
"[""def FUNC_4(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n"", ""self.check_example('binding.py', VAR_2)\n""]",0
"[""def FUNC_38(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.cursor.execute('create table t1(a int, b varchar(10))')\n"", ""VAR_28 = [(1, 'test')]\n"", ""self.cursor.executemany('insert into t1(a, b) values (?,?)', VAR_28)\n"", ""VAR_26 = self.cursor.execute('select count(*) from t1').fetchone()[0]\n"", ""self.assertEqual(VAR_26, VAR_23(VAR_28))\n"", ""self.cursor.execute('select a, b from t1 order by a')\n"", ""VAR_29 = self.cursor.fetchall()\n"", ""self.assertEqual(VAR_26, VAR_23(VAR_29))\n"", ""for param, VAR_24 in zip(VAR_28, VAR_29):\n"", ""self.assertEqual(param[0], VAR_24[0])\n"", ""self.assertEqual(param[1], VAR_24[1])\n""]",0
"[""def FUNC_5(self, VAR_2, VAR_3, VAR_4, VAR_7={}):...\n"", ""VAR_34 = self.setActive(VAR_2, VAR_3, VAR_4, VAR_21=False, VAR_7=context)\n"", ""return VAR_34\n""]",0
"[""def FUNC_6(self, VAR_33):...\n"", ""if self.options and VAR_33 not in self.options:\n"", ""VAR_101.errors.add(errors.INVALID_OPTION)\n"", ""return VAR_33\n"", ""return self.default\n""]",0
"[""@frappe.whitelist(allow_guest=True)...\n"", ""from frappe.www.contact import send_message as website_send_message\n"", ""VAR_4 = VAR_5 = None\n"", ""website_send_message(VAR_0, VAR_1, VAR_2)\n"", ""VAR_5 = frappe.db.sql('string'.format(email_id=sender))\n"", ""if not VAR_5:\n"", ""VAR_4 = frappe.db.get_value('Lead', dict(email_id=sender))\n"", ""VAR_6 = frappe.get_doc(dict(doctype='Opportunity', enquiry_from='Customer' if\n    customer else 'Lead', VAR_3='Open', title=subject, contact_email=sender,\n    to_discuss=message))\n"", ""if not VAR_4:\n"", ""if VAR_5:\n"", ""VAR_8 = frappe.get_doc(dict(doctype='Lead', email_id=sender, lead_name=\n    sender.split('@')[0].title())).insert(ignore_permissions=True)\n"", ""VAR_6.customer = VAR_5[0][0]\n"", ""if VAR_4:\n"", ""VAR_6.insert(ignore_permissions=True)\n"", ""VAR_6.lead = VAR_4\n"", ""VAR_6.lead = VAR_8.name\n"", ""VAR_7 = frappe.get_doc({'doctype': 'Communication', 'subject': VAR_0,\n    'content': VAR_1, 'sender': VAR_2, 'sent_or_received': 'Received',\n    'reference_doctype': 'Opportunity', 'reference_name': VAR_6.name})\n"", ""VAR_7.insert(ignore_permissions=True)\n"", ""return 'okay'\n""]",1
"[""def FUNC_12(self, VAR_10=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = vars(self.parse_known_args(VAR_15=True)[0])\n"", ""VAR_13 = VAR_30.get('image_mode', None)\n"", ""if VAR_13 is not None and VAR_13 != 'none':\n"", ""self.add_image_args(VAR_13)\n"", ""VAR_12 = VAR_30.get('task', None)\n"", ""if VAR_12 is not None:\n"", ""self.add_task_args(VAR_12)\n"", ""VAR_31 = VAR_30.get('evaltask', None)\n"", ""if VAR_31 is not None:\n"", ""self.add_task_args(VAR_31)\n"", ""VAR_11 = VAR_30.get('model', None)\n"", ""if VAR_11 is not None:\n"", ""self.add_model_subargs(VAR_11)\n"", ""self.set_defaults(**self._defaults)\n""]",1
"[""@app.route('/achievements/<achievement_id>/reveal', methods=['POST'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = int(request.form.get('player_id'))\n"", ""return flask.jsonify(FUNC_12(VAR_1, VAR_2))\n""]",0
"[""def FUNC_8(VAR_0):...\n"", ""return render_form(VAR_0, False, url_for('auth_user_create'), 'Register',\n    '', True, '')\n""]",0
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_7 = {'sha': 'df1e628f2244b73f9cdf944f880a2b3470a122f4', 'fingerprint':\n    '88:25:ed:67:56:91:3d:c6:1b:7f:42:c6:9b:41:24:80', 'receive_user':\n    'autotest', 'receive_repo': '{app_id}'.format(**locals()),\n    'ssh_connection': '10.0.1.10 50337 172.17.0.143 22',\n    'ssh_original_command': \""git-receive-pack '{app_id}.git'\"".format(**\n    locals())}\n"", ""VAR_4 = '/api/hooks/push'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 403)\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json', HTTP_X_DEIS_BUILDER_AUTH=settings.BUILDER_KEY)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""for k in ('owner', 'app', 'sha', 'fingerprint', 'receive_repo',\n"", ""self.assertIn(k, VAR_5.data)\n""]",1
"[""def FUNC_18(self, VAR_16, VAR_20):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_28 = ['volume', 'select', VAR_16['name'], 'access', 'create',\n    'initiator', VAR_20['initiator']]\n"", ""VAR_0.error(_('Failed to initialize connection to volume %s'), VAR_16['name'])\n"", ""if self.configuration.eqlx_use_chap:\n"", ""VAR_28.extend(['authmethod chap', 'username', self.configuration.\n    eqlx_chap_login])\n"", ""self._eql_execute(*VAR_28)\n"", ""VAR_47 = self._get_iscsi_properties(VAR_16)\n"", ""return {'driver_volume_type': 'iscsi', 'data': VAR_47}\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.bindings\n"", ""VAR_6 = VAR_1['TEST_APP_COMPONENT_NAME']\n"", ""VAR_7 = '{0}/targetPools/{1}-tp'.format(VAR_1['TEST_GCE_REGION'], VAR_6)\n"", ""VAR_8 = {'checkIntervalSec': 9, 'healthyThreshold': 3, 'unhealthyThreshold':\n    5, 'timeoutSec': 2, 'port': 80}\n"", ""VAR_9 = self.agent.make_json_payload_from_kwargs(job=[{'cloudProvider':\n    'gce', 'provider': 'gce', 'stack': bindings['TEST_STACK'], 'detail':\n    bindings['TEST_COMPONENT_DETAIL'], 'credentials': bindings[\n    'GCE_CREDENTIALS'], 'region': bindings['TEST_GCE_REGION'], 'ipProtocol':\n    'TCP', 'portRange': spec['port'], 'loadBalancerName':\n    load_balancer_name, 'healthCheck': {'port': spec['port'], 'timeoutSec':\n    spec['timeoutSec'], 'checkIntervalSec': spec['checkIntervalSec'],\n    'healthyThreshold': spec['healthyThreshold'], 'unhealthyThreshold':\n    spec['unhealthyThreshold']}, 'type': 'upsertLoadBalancer',\n    'availabilityZones': {bindings['TEST_GCE_REGION']: []}, 'user':\n    '[anonymous]'}], description='Create Load Balancer: ' +\n    load_balancer_name, application=self.TEST_APP)\n"", ""VAR_10 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_10.new_clause_builder('Health Check Added', retryable_for_secs=30\n    ).list_resources('http-health-checks').contains_pred_list([jc.\n    PathContainsPredicate('name', '%s-hc' % VAR_6), jc.DICT_SUBSET(VAR_8)])\n"", ""VAR_10.new_clause_builder('Target Pool Added', retryable_for_secs=30\n    ).list_resources('target-pools').contains_path_value('name', '%s-tp' %\n    VAR_6)\n"", ""VAR_10.new_clause_builder('Forwarding Rules Added', retryable_for_secs=30\n    ).list_resources('forwarding-rules').contains_pred_list([jc.\n    PathContainsPredicate('name', VAR_6), jc.PathContainsPredicate('target',\n    VAR_7)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer', data=payload, path='tasks'), VAR_5=builder.build())\n""]",1
"[""def FUNC_3():...\n"", ""if VAR_2 is None:\n"", ""FUNC_2()\n"", ""return VAR_2\n""]",0
"[""def FUNC_3(VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n""]",0
"[""def FUNC_43(self, VAR_41, VAR_43):...\n"", ""self[VAR_41:VAR_41 + 1] = VAR_43\n"", ""VAR_55 = len(VAR_43) - 1\n"", ""for VAR_40, (i, j) in self._names.items():\n"", ""if i > VAR_41:\n"", ""self._names[VAR_40] = i + VAR_55, j + VAR_55\n"", ""if i == VAR_41:\n"", ""self.set_name(VAR_40, i, VAR_42=i + len(items))\n""]",0
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_10 = 'SELECT COUNT(*) FROM users'\n"", ""VAR_19 = db.execute_query(VAR_10)\n"", ""log.error(\""Can't count the total number of users!\"")\n"", ""return VAR_19.fetchone()[0]\n""]",1
"[""import io\n"", ""import os\n"", ""import json\n"", ""import zipfile\n"", ""from django.template.defaultfilters import filesizeformat\n"", ""from cuckoo.common.utils import json_default\n"", ""from cuckoo.web.controllers.analysis.analysis import AnalysisController\n"", ""from cuckoo.web.utils import get_directory_size\n"", ""\""\""\""Class for creating task exports\""\""\""\n"", ""@staticmethod...\n"", ""VAR_3 = AnalysisController.get_report(VAR_0)\n"", ""VAR_3 = VAR_3['analysis']\n"", ""VAR_5 = VAR_3['info']['analysis_path']\n"", ""VAR_6 = 0\n"", ""for directory in VAR_1:\n"", ""VAR_14 = '%s/%s' % (VAR_5, directory)\n"", ""for filename in VAR_2:\n"", ""if os.path.isdir(VAR_14):\n"", ""VAR_14 = '%s/%s' % (VAR_5, filename)\n"", ""VAR_7 = VAR_6 / 6.5\n"", ""VAR_6 += get_directory_size(VAR_14)\n"", ""if os.path.isfile(VAR_14):\n"", ""return {'size': int(VAR_7), 'size_human': filesizeformat(VAR_7)}\n"", ""VAR_6 += os.path.getsize(VAR_14)\n""]",1
"[""def FUNC_7(VAR_20, VAR_21, VAR_2, VAR_22=None, VAR_23=None, VAR_24='text',...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_27 = {}\n"", ""VAR_48 = FUNC_25(VAR_20)\n"", ""VAR_49 = FUNC_25(VAR_21)\n"", ""for VAR_77 in VAR_48:\n"", ""VAR_27[VAR_77[0].concept] = VAR_77[0].type\n"", ""for VAR_77 in VAR_48:\n"", ""VAR_27[VAR_77[0].concept] = VAR_77[0].type\n"", ""VAR_35 = FUNC_10(VAR_48, VAR_49, VAR_22, VAR_23, VAR_5, VAR_10, VAR_34=\n    output_limit)\n"", ""VAR_50 = {'text': FUNC_12, 'marcxml': FUNC_9, 'html': FUNC_13, 'dict': FUNC_11}\n"", ""VAR_51 = {}\n"", ""for VAR_88 in VAR_24:\n"", ""if VAR_88 != 'raw':\n"", ""return VAR_51\n"", ""VAR_51[VAR_88] = VAR_50[VAR_88](VAR_35, VAR_27)\n"", ""if VAR_4 > 0:\n"", ""VAR_51['raw'] = FUNC_24(FUNC_25(VAR_20, VAR_4)), FUNC_24(FUNC_25(VAR_21, VAR_4)\n    ), VAR_22, FUNC_24(FUNC_25(VAR_23, VAR_4))\n"", ""VAR_51['raw'] = VAR_48, VAR_49, VAR_22, VAR_23\n""]",0
"[""@handled_slot(bool)...\n"", ""print(f\""{'Locking' if VAR_4 else 'Unlocking'} thin etalon.\"")\n"", ""self.lock_thin_etalon_action.setChecked(not VAR_4)\n"", ""self.matisse.set_thin_etalon_lock(VAR_4)\n"", ""self.lock_thin_etalon_action.setChecked(VAR_4)\n""]",0
"[""import json, logging, requests, time, urllib\n"", ""from bisect import bisect\n"", ""from db_helper import DBHelper\n"", ""logging.basicConfig(filename='bot.log', format=\n    '%(asctime)s %(levelname)s %(message)s', level=logging.INFO)\n"", ""VAR_0 = DBHelper()\n"", ""VAR_22 = f.readline().strip()\n"", ""VAR_1 = 'https://api.telegram.org/bot{}'.format(VAR_22)\n"", ""VAR_2 = {}\n"", ""VAR_23, VAR_24 = m.readline().strip().split(' ')\n"", ""VAR_23 = int(VAR_23)\n"", ""while VAR_23:\n"", ""VAR_2[VAR_24] = []\n"", ""logging.info('Reply messages loaded into memory')\n"", ""for i in range(VAR_23):\n"", ""VAR_3 = {}\n"", ""VAR_2[VAR_24].append(m.readline().strip())\n"", ""VAR_23, VAR_24 = m.readline().strip().split(' ')\n"", ""VAR_25 = int(f.readline().strip())\n"", ""VAR_23 = int(VAR_23)\n"", ""for n in range(VAR_25):\n"", ""VAR_32 = int(f.readline().strip())\n"", ""logging.info('Blacklisted senders loaded into memory')\n"", ""if VAR_32 in VAR_3:\n"", ""VAR_4 = {}\n"", ""VAR_3[VAR_32] += 1\n"", ""VAR_3[VAR_32] = 1\n"", ""VAR_5 = {}\n"", ""VAR_6 = []\n"", ""VAR_7 = []\n"", ""logging.info('Data structures loaded into memory')\n"", ""VAR_8 = 300\n"", ""VAR_9 = 180\n"", ""logging.info('Response timeouts loaded into memory')\n"", ""VAR_10 = 70\n"", ""VAR_11 = len(VAR_2['questions'])\n"", ""VAR_12 = 1800\n"", ""logging.info('Other variables loaded into memory')\n"", ""def FUNC_0(VAR_13):...\n"", ""VAR_26 = requests.get(VAR_13)\n"", ""VAR_27 = VAR_26.content.decode('utf-8')\n"", ""logging.info('GET %s responded with %s', VAR_13, VAR_27)\n"", ""return json.loads(VAR_27)\n""]",1
"[""def FUNC_15(self, VAR_9):...\n"", ""if not self.logged_in():\n"", ""print('shrub: unauthenticated; use \""login [username] to log in first')\n"", ""VAR_20 = self.send_cmd('create_comment{} {}'.format(self.insecure_mode, VAR_9))\n"", ""return\n"", ""print(VAR_20)\n""]",0
"[""def FUNC_2():...\n"", ""super(CLASS_7, self).__init__(slideParser.parse(VAR_10, slideLexer) if\n    VAR_10 else [])\n""]",0
"[""def FUNC_2(VAR_0, VAR_6) ->Optional[CLASS_0]:...\n"", ""return FUNC_1(VAR_5, VAR_6)\n""]",0
"[""def FUNC_1(self):...\n"", ""VAR_3 = self.get_root_nodes()\n"", ""VAR_4 = VAR_3\n"", ""VAR_5 = []\n"", ""for index, n in enumerate(VAR_4):\n"", ""VAR_10 = n['node_object']\n"", ""return [n['node_object'] for n in VAR_5]\n"", ""VAR_11 = VAR_10.job\n"", ""if not VAR_11 and VAR_10.do_not_run is False:\n"", ""VAR_5.append(n)\n"", ""if VAR_11 and VAR_11.status not in ['failed', 'successful']:\n"", ""if VAR_11 and VAR_11.status == 'failed':\n"", ""VAR_13 = self.get_dependencies(VAR_10, 'failure_nodes')\n"", ""if VAR_11 and VAR_11.status == 'successful':\n"", ""VAR_14 = self.get_dependencies(VAR_10, 'always_nodes')\n"", ""VAR_12 = self.get_dependencies(VAR_10, 'success_nodes')\n"", ""VAR_16 = VAR_13 + VAR_14\n"", ""VAR_14 = self.get_dependencies(VAR_10, 'always_nodes')\n"", ""VAR_4.extend(VAR_16)\n"", ""VAR_16 = VAR_12 + VAR_14\n"", ""VAR_4.extend(VAR_16)\n""]",0
"[""def FUNC_13(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self._inspect:\n"", ""return self._inspect\n"", ""self._inspect = {}\n"", ""for filename in self.files:\n"", ""if filename is VAR_2:\n"", ""return self._inspect\n"", ""self._inspect[':memory:'] = {'hash': '000', 'file': ':memory:', 'size': 0,\n    'views': {}, 'tables': {}}\n"", ""VAR_61 = Path(filename)\n"", ""VAR_62 = VAR_61.stem\n"", ""if VAR_62 in self._inspect:\n"", ""self.prepare_connection(VAR_28)\n"", ""if e.args[0] == 'no such module: VirtualSpatialIndex':\n"", ""self._inspect[VAR_62] = {'hash': inspect_hash(VAR_61), 'file': str(VAR_61),\n    'size': VAR_61.stat().st_size, 'views': inspect_views(VAR_28), 'tables':\n    inspect_tables(VAR_28, (self.metadata('databases') or {}).get(VAR_62, {}))}\n""]",0
"[""def FUNC_3(VAR_2):...\n"", ""if not VAR_2:\n"", ""return []\n"", ""VAR_9 = []\n"", ""VAR_10 = frappe.db.get_value('Department', {'name': VAR_2}, ['lft', 'rgt'],\n    as_dict=True)\n"", ""VAR_11 = frappe.db.sql(\n    \""\""\""select name from `tabDepartment`\n\t\twhere lft >= %s and rgt <= %s order by lft desc\n\t\t\""\""\""\n    , (VAR_10.lft, VAR_10.rgt), as_list=True)\n"", ""for d in VAR_11:\n"", ""VAR_9.extend([l.leave_approver for l in frappe.db.sql('string', d, as_dict=\n    True)])\n"", ""return VAR_9\n""]",0
"[""def FUNC_4(self, VAR_5):...\n"", ""for oldg in VAR_5.get_ancestors():\n"", ""if oldg not in self.groups:\n"", ""if VAR_5 not in self.groups:\n"", ""self.add_group(oldg)\n"", ""self.groups.append(VAR_5)\n""]",1
"[""def FUNC_1(self, VAR_6, VAR_7=10):...\n"", ""if self.options.debug:\n"", ""print(colored('sending file(s)...', 'blue'), end='')\n"", ""VAR_19 = SSHClient()\n"", ""VAR_19.set_missing_host_key_policy(AutoAddPolicy())\n"", ""for attempt in range(VAR_7):\n"", ""VAR_19.connect(self.ip_address, port=self.options.dut_scp_port if not self.\n    aux else self.options.aux_scp_port, username='root', pkey=self.rsakey,\n    allow_agent=False, look_for_keys=False)\n"", ""if self.options.command != 'new':\n"", ""VAR_25 = SCPClient(VAR_19.get_transport())\n"", ""db.log_event_exception(self.result_data['id'], 'DUT' if not self.aux else\n    'AUX', 'SSH error')\n"", ""print(colored(self.serial.port + ' ' + str(self.result_data['id']) +\n    ': error sending file(s) (attempt ' + str(attempt + 1) + '/' + str(\n    VAR_7) + '): ' + str(error), 'red'))\n"", ""VAR_25.put(VAR_6)\n"", ""if self.options.command != 'new':\n"", ""VAR_25.close()\n"", ""if attempt < VAR_7 - 1:\n"", ""db.log_event_exception(self.result_data['id'], 'DUT' if not self.aux else\n    'AUX', 'SCP error')\n"", ""print(colored(self.serial.port + ' ' + str(self.result_data['id']) +\n    ': error sending file(s) (attempt ' + str(attempt + 1) + '/' + str(\n    VAR_7) + '): ' + str(error), 'red'))\n"", ""VAR_19.close()\n"", ""sleep(30)\n"", ""VAR_25.close()\n"", ""if self.options.debug:\n"", ""VAR_19.close()\n"", ""print(colored('done', 'blue'))\n"", ""if attempt < VAR_7 - 1:\n"", ""sleep(30)\n""]",1
"[""def FUNC_0(VAR_2, VAR_3=None, VAR_4=None, VAR_5=5, VAR_6=None, VAR_7='POST'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 <= 0:\n"", ""logging.error('UrlOpen(%s): Invalid number of tries: %d', VAR_2, VAR_5)\n"", ""if VAR_6 and VAR_6 < 0:\n"", ""return None\n"", ""logging.error('UrlOpen(%s): Invalid wait duration: %d', VAR_2, VAR_6)\n"", ""VAR_3 = VAR_3 or {}\n"", ""return None\n"", ""if VAR_17.COUNT_KEY in VAR_3:\n"", ""logging.error(\""UrlOpen(%s): key '%s' is duplicate.\"", VAR_2, VAR_17.COUNT_KEY)\n"", ""VAR_11 = None\n"", ""return None\n"", ""for attempt in range(VAR_5):\n"", ""VAR_3[VAR_17.COUNT_KEY] = attempt\n"", ""logging.error('UrlOpen(%s): Unable to open after %d attempts', VAR_2, VAR_5)\n"", ""for VAR_18, VAR_9 in VAR_3.iteritems():\n"", ""if e.code >= 500:\n"", ""if VAR_11 is not None:\n"", ""return None\n"", ""if isinstance(VAR_9, basestring):\n"", ""VAR_20 = urllib.urlencode(VAR_3)\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s ', VAR_2, attempt, e)\n"", ""logging.exception('UrlOpen(%s): %s', VAR_2, e)\n"", ""logging.info('UrlOpen(%s) got %d bytes.', VAR_2, len(VAR_11))\n"", ""if attempt != VAR_5 - 1:\n"", ""VAR_3[VAR_18] = VAR_9.encode('utf-8', 'xmlcharrefreplace')\n"", ""if VAR_7 == 'POSTFORM':\n"", ""logging.warning('UrlOpen(%s): attempt %d: %s', VAR_2, attempt, e)\n"", ""return None\n"", ""return VAR_11\n"", ""if VAR_6 is None:\n"", ""VAR_16, VAR_15 = FUNC_3(VAR_10=data.iteritems(), VAR_4=files)\n"", ""if VAR_7 == 'POST':\n"", ""VAR_23 = random.random() * 3 + math.pow(1.5, attempt + 1)\n"", ""VAR_23 = VAR_6\n"", ""VAR_15 = VAR_15 or ''\n"", ""VAR_11 = urllib2.urlopen(VAR_2, VAR_20, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_22 = list(urlparse.urlparse(VAR_2))\n"", ""VAR_23 = min(10, max(0.1, VAR_23))\n"", ""time.sleep(VAR_23)\n"", ""VAR_21 = urllib2.Request(VAR_2, VAR_3=body)\n"", ""VAR_22[VAR_0] = VAR_20\n"", ""VAR_21.add_header('Content-Type', VAR_16)\n"", ""VAR_2 = urlparse.urlunparse(VAR_22)\n"", ""VAR_21.add_header('Content-Length', len(VAR_15))\n"", ""VAR_11 = urllib2.urlopen(VAR_2, timeout=URL_OPEN_TIMEOUT).read()\n"", ""VAR_11 = urllib2.urlopen(VAR_21, timeout=URL_OPEN_TIMEOUT).read()\n""]",1
"[""@jwt_required...\n"", ""VAR_9 = request.get_json(force=True)\n"", ""VAR_8 = Table.save(str(VAR_3), VAR_7=post_data)\n"", ""if VAR_8:\n"", ""VAR_10 = {'status': 'success', 'message': VAR_8}\n"", ""VAR_10 = {'status': 'fail', 'message':\n    'Unknown question id. Try a different id.'}\n"", ""return make_response(jsonify(VAR_10)), 201\n"", ""return make_response(jsonify(VAR_10)), 400\n""]",1
"[""def FUNC_14(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""self.driver._eql_execute('pool', 'select', self.configuration.eqlx_pool, 'show'\n    ).AndReturn(['TotalCapacity: 111GB', 'FreeSpace: 11GB'])\n"", ""self.mox.ReplayAll()\n"", ""self.driver._update_volume_stats()\n"", ""self.assertEqual(self.driver._stats['total_capacity_gb'], 111.0)\n"", ""self.assertEqual(self.driver._stats['free_capacity_gb'], 11.0)\n""]",0
"[""def FUNC_5(self):...\n"", ""if self.get_qa_status():\n"", ""return 'QA Complete'\n"", ""if self.qa_begun:\n"", ""return 'Continue QA'\n"", ""return 'Begin QA'\n""]",0
"[""from flask import request, jsonify\n"", ""from flask_jwt_extended import create_access_token, create_refresh_token, set_access_cookies, set_refresh_cookies, jwt_refresh_token_required, get_jwt_identity\n"", ""from flask_restplus import Namespace, Resource\n"", ""from utilities import database_utilities\n"", ""VAR_0 = Namespace('login', description='Endpoint used to obtain JWT')\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = request.get_json()\n"", ""if not VAR_1['email']:\n"", ""return jsonify({'msg': 'Missing email'}), 400\n"", ""VAR_2 = database_utilities.execute_query(\n    f\""select * from admins where email = '{VAR_1['email']}'\"")\n"", ""if VAR_2:\n"", ""VAR_6 = VAR_2[0]['email']\n"", ""return jsonify({'msg': 'User is not an admin'})\n"", ""VAR_4 = create_access_token(identity=email)\n"", ""VAR_7 = create_refresh_token(identity=email)\n"", ""VAR_5 = jsonify({'login': True})\n"", ""set_access_cookies(VAR_5, VAR_4)\n"", ""set_refresh_cookies(VAR_5, VAR_7)\n"", ""return VAR_5\n""]",1
"[""def FUNC_3(self, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = self.__con.cursor()\n"", ""VAR_19.execute(\""INSERT INTO tags(name) VALUE('%s')\"" % VAR_14)\n"", ""return CLASS_0.DUPLICATE\n"", ""return CLASS_0.SUCCESS\n""]",1
"[""def FUNC_6(self):...\n"", ""VAR_1 = VAR_0.copy()\n"", ""VAR_1['SHIB_eppn'] = self.user.username.encode('utf-8')\n"", ""VAR_1['SHIB_sn'] = 'Meiklinen'\n"", ""VAR_2 = self._get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 302)\n"", ""self.assertEqual(User.objects.count(), 1)\n"", ""VAR_3 = User.objects.first()\n"", ""self.assertEqual(VAR_3.email, 'teemu.teekkari@aalto.fi')\n"", ""self.assertEqual(VAR_3.first_name, 'Matti')\n"", ""self.assertEqual(VAR_3.last_name, 'Meiklinen')\n"", ""self.assertEqual(VAR_3.userprofile.student_id, '000')\n""]",0
"[""@VAR_8.command()...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_2 is None:\n"", ""for x in VAR_13:\n"", ""if VAR_9.channel.id in VAR_2:\n"", ""print('!roll command recieved in channel ID ' + str(VAR_9.channel.id))\n"", ""for x in VAR_13:\n"", ""await VAR_9.send(vroll.roll(x))\n"", ""print('!roll command recieved in channel ID ' + str(VAR_9.channel.id) +\n    ' by user ' + str(VAR_9.author))\n"", ""await VAR_9.send(vroll.roll(x))\n""]",0
"[""def FUNC_19(self):...\n"", ""self.mock(self.bot, 'post_error', lambda *VAR_15: None)\n"", ""self.mock(bot_main, 'THIS_FILE', VAR_7.path.join(self.root_dir,\n    'swarming_bot.1.zip'))\n"", ""VAR_31 = VAR_7.path.join(self.root_dir, 'swarming_bot.2.zip')\n"", ""self.mock(time, 'time', lambda : 1400000000)\n"", ""def FUNC_27(VAR_32, VAR_3):...\n"", ""self.assertEqual('https://localhost:1/swarming/api/v1/bot/bot_code/123', VAR_3)\n"", ""self.assertEqual(VAR_31, VAR_32)\n"", ""z.writestr('__main__.py', 'print(\""hi\"")')\n"", ""return True\n""]",0
"[""@Slot()...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_14 in self.clients.values():\n"", ""if VAR_14['status'] == self.RUNNING:\n"", ""VAR_17 = self.get_root_path()\n"", ""VAR_18 = VAR_14['instance']\n"", ""VAR_18.folder = VAR_17\n"", ""VAR_18.initialize()\n""]",1
"[""from django.db import models, migrations\n"", ""VAR_0 = [('contenttypes', '0001_initial')]\n"", ""VAR_1 = [migrations.CreateModel(name='ModelWithInheritance', fields=[('id',\n    models.AutoField(verbose_name='ID', serialize=False, auto_created=True,\n    primary_key=True)), ('content_type', models.ForeignKey(editable=False,\n    to='contenttypes.ContentType', null=True))], options={'abstract': False\n    }, bases=(models.Model,))]\n""]",1
"[""def FUNC_37(self, VAR_69):...\n"", ""if not_iterable(VAR_69):\n"", ""return flag(os.path.join(self.workdir, VAR_69), 'subworkflow', self)\n"", ""return [self.target(VAR_0) for VAR_0 in VAR_69]\n""]",0
"[""def FUNC_1(self, VAR_5):...\n"", ""VAR_7 = '{0} {1}({2})'.format(VAR_5, self.model_class._meta.database.TYPES[\n    self.TYPE], self.max_length)\n"", ""if self.unique:\n"", ""VAR_7 += ' UNIQUE'\n"", ""return VAR_7\n""]",0
"[""def FUNC_6(self, VAR_11):...\n"", ""return utils.sanitize_url(VAR_11)\n""]",0
"[""def __init__(self, VAR_1, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""self.connection = mysql.connector.connect(host=connection_address, user=\n    user_name, VAR_4=password, db=database)\n"", ""self.cursor = self.connection.cursor(buffered=True)\n""]",0
"[""def FUNC_49(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'MEDIUM': 2}}\n"", ""self.check_example('paramiko_injection.py', VAR_2)\n""]",0
"[""def FUNC_4(self):...\n"", ""VAR_8 = 'test_foo.py:FooTest'\n"", ""VAR_7 = BokChoyTestSuite('', test_spec=spec)\n"", ""VAR_1 = 'tests/{}'.format(VAR_8)\n"", ""self.assertEqual(VAR_7.cmd, self._expected_command(VAR_1=name))\n""]",0
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""from openerp import api, fields, models\n"", ""VAR_0 = 'crm.lead'\n"", ""VAR_1 = fields.One2many(comodel_name='crm.phonecall', inverse_name=\n    'opportunity_id', string='Phonecalls')\n"", ""VAR_2 = fields.Integer(compute='_phonecall_count', string='Phonecalls')\n"", ""@api.multi...\n"", ""for lead in self:\n"", ""lead.phonecall_count = self.env['crm.phonecall'].search_count([(\n    'opportunity_id', '=', lead.id)])\n""]",1
"[""def __call__(self, VAR_9):...\n"", ""self.p = VAR_9\n"", ""self.p.wz_connect()\n"", ""self.p.wz_auth_requests = [(b'Router', b'auth-bind-route'), (b'Router',\n    b'auth-unbind-route'), (b'Router', b'auth-set-route-type')]\n"", ""self.p.wz_bind_methods = [(b'Evaluator', b'evaluate', self.handle_evaluate,\n    wzrpc.routetype.random)]\n"", ""self.p.auth_requests()\n"", ""self.p.bind_methods()\n"", ""self.ev = self.ev_init()\n"", ""self.bind_kt_ticker.tick()\n"", ""while self.p.running.is_set():\n"", ""VAR_14 = self.p.poll()\n"", ""if self.bind_kt_ticker.elapsed(False) > self.bind_kt:\n"", ""self.bind_kt_ticker.tick()\n"", ""self.send_keepalive()\n""]",1
"[""async def FUNC_3(self, VAR_2):...\n"", ""VAR_4 = VAR_2.server\n"", ""VAR_5 = VAR_2.author\n"", ""VAR_6 = VAR_2.channel\n"", ""VAR_7 = self.database.cursor()\n"", ""VAR_7.execute('SELECT EXISTS(SELECT 1 FROM USER WHERE id=' + str(VAR_5.id) +\n    ' collate nocase) LIMIT 1')\n"", ""if VAR_7.fetchone()[0] == 0:\n"", ""VAR_7.execute(\""INSERT INTO USER VALUES ('\"" + VAR_5.name + \""',\"" + VAR_5.id +\n    \"",'\"" + str(VAR_5.bot) + \""','\"" + VAR_5.avatar + \""','\"" + str(VAR_5.\n    created_at) + \""')\"")\n"", ""VAR_7.execute('SELECT EXISTS(SELECT 1 FROM SERVERS WHERE id=' + str(VAR_4.\n    id) + ' collate nocase) LIMIT 1')\n"", ""if VAR_7.fetchone()[0] == 0:\n"", ""VAR_7.execute(\""INSERT INTO SERVERS VALUES ('\"" + VAR_4.name + \""',\"" + VAR_4.\n    id + ',' + VAR_4.owner.id + ')')\n"", ""print(VAR_2.edited_timestamp)\n"", ""VAR_8 = VAR_2.id + \"",'\"" + str(VAR_2.edited_timestamp) + \""','\"" + str(VAR_2.\n    timestamp) + \""','\"" + str(VAR_2.tts) + \""','\"" + str(VAR_2.author.name\n    ) + \""',\"" + str(VAR_2.author.id\n    ) + \"",'\"" + VAR_2.content + \""',\"" + VAR_2.server.id + ',' + VAR_2.channel.id\n"", ""print(VAR_8)\n"", ""VAR_7.execute('INSERT INTO MESSAGE VALUES (' + VAR_8 + ')')\n"", ""self.database.commit()\n""]",1
"[""\""\""\"" Client blueprint used to handle OAuth callbacks. \""\""\""\n"", ""from __future__ import absolute_import\n"", ""from flask import Blueprint, abort, current_app, url_for, request\n"", ""from flask.ext.login import user_logged_out\n"", ""from invenio.base.globals import cfg\n"", ""from invenio.ext.sslify import ssl_required\n"", ""from ..client import oauth, handlers, disconnect_handlers, signup_handlers\n"", ""from ..handlers import authorized_default_handler, make_token_getter, make_handler, disconnect_handler, oauth_logout_handler\n"", ""VAR_0 = Blueprint('oauthclient', __name__, url_prefix='/oauth',\n    static_folder='../static', template_folder='../templates')\n"", ""@VAR_0.before_app_first_request...\n"", ""\""\""\""docstring\""\""\""\n"", ""user_logged_out.connect(oauth_logout_handler)\n"", ""oauth.init_app(current_app)\n"", ""for VAR_1, conf in cfg['OAUTHCLIENT_REMOTE_APPS'].items():\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""@VAR_0.route('/login/<remote_app>/')...\n"", ""VAR_4 = oauth.remote_app(VAR_1, **conf['params'])\n"", ""VAR_4 = oauth.remote_apps[VAR_1]\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4.tokengetter(make_token_getter(VAR_4))\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""handlers.register(VAR_1, VAR_4.authorized_handler(make_handler(conf.get(\n    'authorized_handler', authorized_default_handler), VAR_4)))\n"", ""return abort(404)\n"", ""VAR_2 = url_for('.authorized', VAR_1=remote_app, next=request.args.get(\n    'next') or request.referrer or None, _external=True)\n"", ""disconnect_handlers.register(VAR_1, make_handler(conf.get(\n    'disconnect_handler', disconnect_handler), VAR_4, with_response=False))\n"", ""return oauth.remote_apps[VAR_1].authorize(callback=callback_url)\n"", ""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", ""VAR_7 = conf.get('signup_handler', dict())\n"", ""VAR_8 = make_handler(VAR_7.get('info', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_9 = make_handler(VAR_7.get('setup', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_10 = make_handler(VAR_7.get('view', FUNC_5), VAR_4, with_response=False)\n"", ""signup_handlers.register(VAR_1, dict(info=account_info_handler, setup=\n    account_setup_handler, view=account_view_handler))\n""]",1
"[""@staticmethod...\n"", ""if not VAR_1:\n"", ""if not VAR_5:\n"", ""VAR_5 = CLASS_0.get_report(VAR_1)['analysis']\n"", ""VAR_9 = {'data': [], 'status': True}\n"", ""for VAR_17 in VAR_5.get('behavior', {}).get('generic', []):\n"", ""VAR_9['data'].append({'process_name': VAR_17['process_name'], 'pid': VAR_17\n    ['pid']})\n"", ""VAR_9['data'] = sorted(VAR_9['data'], key=lambda k: k['process_name'])\n"", ""return VAR_9\n""]",0
"[""from django.core.exceptions import ObjectDoesNotExist\n"", ""from rest_framework import exceptions\n"", ""from app import models\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=('view_project',)):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = models.Project.objects.get(pk=project_pk, deleting=False)\n"", ""return VAR_6\n"", ""for perm in VAR_2:\n"", ""if not VAR_0.user.has_perm(perm, VAR_6):\n""]",1
"[""def __init__(self, VAR_1, VAR_7, VAR_8, VAR_9, VAR_10=None, VAR_4=None):...\n"", ""GenericRequest.__init__(self, VAR_1, VAR_4)\n"", ""self.url = '%stasks/%s/test' % (self.base_url, VAR_7[1])\n"", ""self.task = VAR_7\n"", ""self.submission_format = VAR_8\n"", ""self.filenames = VAR_9\n"", ""self.data = {}\n"", ""if VAR_10 is None:\n"", ""for filename in VAR_9:\n"", ""if VAR_10 is not None:\n"", ""VAR_23 = filename_to_language(filename)\n"", ""self.data = {'language': VAR_10}\n"", ""if VAR_23 is not None:\n"", ""VAR_10 = VAR_23.name\n""]",1
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""def FUNC_3(self, VAR_1, VAR_2, VAR_5, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_30 = VAR_4.get('states', [])\n"", ""VAR_31 = VAR_4.get('what', ())\n"", ""if not VAR_5:\n"", ""VAR_5 = self.search(VAR_1, VAR_2, [])\n"", ""VAR_29 = {}.fromkeys(VAR_5, 0.0)\n"", ""if not VAR_5:\n"", ""return VAR_29\n"", ""if VAR_4.get('shop', False):\n"", ""VAR_1.execute('select warehouse_id from sale_shop where id=%s', (int(VAR_4[\n    'shop']),))\n"", ""if VAR_4.get('warehouse', False):\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""VAR_1.execute('select lot_stock_id from stock_warehouse where id=%s', (int(\n    VAR_4['warehouse']),))\n"", ""if VAR_4.get('location', False):\n"", ""if VAR_41:\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""if type(VAR_4['location']) == type(1):\n"", ""VAR_42 = []\n"", ""VAR_4['warehouse'] = VAR_41[0]\n"", ""if VAR_41:\n"", ""VAR_42 = [VAR_4['location']]\n"", ""if type(VAR_4['location']) in (type(''), type(u'')):\n"", ""VAR_43 = self.pool.get('stock.warehouse').search(VAR_1, VAR_2, [], VAR_4=\n    context)\n"", ""VAR_4['location'] = VAR_41[0]\n"", ""if VAR_4.get('compute_child', True):\n"", ""VAR_42 = self.pool.get('stock.location').search(VAR_1, VAR_2, [('name',\n    'ilike', VAR_4['location'])], VAR_4=context)\n"", ""VAR_42 = VAR_4['location']\n"", ""for w in self.pool.get('stock.warehouse').browse(VAR_1, VAR_2, VAR_43,\n"", ""VAR_44 = self.pool.get('stock.location').search(VAR_1, VAR_2, [(\n    'location_id', 'child_of', VAR_42)])\n"", ""VAR_42 = VAR_42\n"", ""VAR_42.append(w.lot_stock_id.id)\n"", ""VAR_42 = VAR_44 or VAR_42\n"", ""VAR_32 = {}\n"", ""VAR_33 = {}\n"", ""for VAR_45 in self.browse(VAR_1, VAR_2, VAR_5, VAR_4=context):\n"", ""VAR_33[VAR_45.id] = VAR_45.uom_id.id\n"", ""VAR_34 = []\n"", ""VAR_32[VAR_45.uom_id.id] = VAR_45.uom_id\n"", ""VAR_35 = []\n"", ""VAR_36 = VAR_4.get('from_date', False)\n"", ""VAR_37 = VAR_4.get('to_date', False)\n"", ""VAR_38 = False\n"", ""if VAR_36 and VAR_37:\n"", ""VAR_38 = \""date_planned>='%s' and date_planned<='%s'\"" % (VAR_36, VAR_37)\n"", ""if VAR_36:\n"", ""if 'in' in VAR_31:\n"", ""VAR_38 = \""date_planned>='%s'\"" % VAR_36\n"", ""if VAR_37:\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""if 'out' in VAR_31:\n"", ""VAR_38 = \""date_planned<='%s'\"" % VAR_37\n"", ""VAR_34 = VAR_1.fetchall()\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""VAR_39 = self.pool.get('product.uom')\n"", ""VAR_35 = VAR_1.fetchall()\n"", ""VAR_40 = map(lambda x: x[2], VAR_34) + map(lambda x: x[2], VAR_35)\n"", ""if VAR_4.get('uom', False):\n"", ""VAR_40 += [VAR_4['uom']]\n"", ""VAR_40 = filter(lambda x: x not in VAR_32.keys(), VAR_40)\n"", ""if VAR_40:\n"", ""VAR_40 = VAR_39.browse(VAR_1, VAR_2, list(set(VAR_40)), VAR_4=context)\n"", ""for VAR_46 in VAR_40:\n"", ""VAR_32[VAR_46.id] = VAR_46\n"", ""for VAR_47, prod_id, prod_uom in VAR_34:\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""for VAR_47, prod_id, prod_uom in VAR_35:\n"", ""VAR_29[prod_id] += VAR_47\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""return VAR_29\n"", ""VAR_29[prod_id] -= VAR_47\n""]",1
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""def FUNC_4(VAR_12, VAR_16, VAR_17, VAR_18, VAR_19):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_16.copy()\n"", ""if VAR_17 is not None:\n"", ""VAR_16['exit_code'] = VAR_17\n"", ""if VAR_18:\n"", ""VAR_16['output'] = base64.b64encode(VAR_18)\n"", ""VAR_35 = VAR_12.url_read_json('/swarming/api/v1/bot/task_update/%s' %\n    VAR_16['task_id'], VAR_31=params)\n"", ""VAR_16['output_chunk_start'] = VAR_19\n"", ""logging.debug('post_update() = %s', VAR_35)\n"", ""if VAR_35.get('error'):\n""]",1
"[""import datetime\n"", ""import logging\n"", ""import os\n"", ""import sys\n"", ""import time\n"", ""import unittest\n"", ""import test_env_bot_code\n"", ""test_env_bot_code.setup_test_env()\n"", ""import net_utils\n"", ""import xsrf_client\n"", ""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""self.mock(logging, 'error', lambda *_: None)\n"", ""self.mock(logging, 'exception', lambda *_: None)\n"", ""self.mock(logging, 'info', lambda *_: None)\n"", ""self.mock(logging, 'warning', lambda *_: None)\n"", ""self.mock(time, 'sleep', lambda _: None)\n"", ""def FUNC_1(self):...\n"", ""self.expected_requests([('http://localhost/a', {}, 'foo', None)])\n"", ""VAR_0 = xsrf_client.XsrfRemote('http://localhost/')\n"", ""self.assertEqual('foo', VAR_0.url_read('/a'))\n"", ""def FUNC_2(self):...\n"", ""self.expected_requests([(\n    'http://localhost/auth/api/v1/accounts/self/xsrf_token', {'data': {},\n    'headers': {'X-XSRF-Token-Request': '1'}}, {'expiration_sec': 100,\n    'xsrf_token': 'token'}), ('http://localhost/a', {'data': {'foo': 'bar'},\n    'headers': {'X-XSRF-Token': 'token'}}, 'foo', None)])\n"", ""VAR_0 = xsrf_client.XsrfRemote('http://localhost/')\n"", ""self.assertEqual('foo', VAR_0.url_read('/a', data={'foo': 'bar'}))\n"", ""def FUNC_3(self):...\n"", ""self.expected_requests([(\n    'http://localhost/auth/api/v1/accounts/self/xsrf_token', {'data': {},\n    'headers': {'X-XSRF-Token-Request': '1'}}, {'expiration_sec': 100,\n    'xsrf_token': 'token'}), ('http://localhost/a', {'data': {'foo': 'bar'},\n    'headers': {'X-XSRF-Token': 'token'}}, 'bar', None), (\n    'http://localhost/auth/api/v1/accounts/self/xsrf_token', {'data': {},\n    'headers': {'X-XSRF-Token-Request': '1'}}, {'expiration_sec': 100,\n    'xsrf_token': 'token2'}), ('http://localhost/a', {'data': {'foo': 'bar'\n    }, 'headers': {'X-XSRF-Token': 'token2'}}, 'foo', None)])\n"", ""VAR_1 = xsrf_client._utcnow()\n"", ""VAR_0 = xsrf_client.XsrfRemote('http://localhost/')\n"", ""VAR_0.url_read('/a', data={'foo': 'bar'})\n"", ""self.mock(xsrf_client, '_utcnow', lambda : VAR_1 + datetime.timedelta(\n    seconds=91))\n"", ""VAR_0.url_read('/a', data={'foo': 'bar'})\n"", ""def FUNC_4(self):...\n"", ""self.expected_requests([('http://localhost/swarming/api/v1/bot/handshake',\n    {'data': {'attributes': 'b'}, 'headers': {'X-XSRF-Token-Request': '1'}},\n    {'expiration_sec': 100, 'ignored': True, 'xsrf_token': 'token'}), (\n    'http://localhost/a', {'data': {'foo': 'bar'}, 'headers': {\n    'X-XSRF-Token': 'token'}}, 'foo', None)])\n"", ""VAR_0 = xsrf_client.XsrfRemote('http://localhost/',\n    '/swarming/api/v1/bot/handshake')\n"", ""VAR_0.xsrf_request_params = {'attributes': 'b'}\n"", ""self.assertEqual('foo', VAR_0.url_read('/a', data={'foo': 'bar'}))\n"", ""if __name__ == '__main__':\n"", ""logging.basicConfig(level=logging.ERROR)\n"", ""unittest.main()\n""]",1
"[""def FUNC_3(VAR_2):...\n"", ""if not VAR_2:\n"", ""return []\n"", ""VAR_9 = []\n"", ""VAR_10 = frappe.db.get_value('Department', {'name': VAR_2}, ['lft', 'rgt'],\n    as_dict=True)\n"", ""VAR_11 = frappe.db.sql(\n    \""\""\""select name from `tabDepartment`\n\t\twhere lft >= %s and rgt <= %s order by lft desc\n\t\t\""\""\""\n    , (VAR_10.lft, VAR_10.rgt), as_list=True)\n"", ""for d in VAR_11:\n"", ""VAR_9.extend([l.leave_approver for l in frappe.db.sql('string', d, as_dict=\n    True)])\n"", ""return VAR_9\n""]",0
"[""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/qa/extractionscript/15/', follow=True)\n"", ""VAR_1 = self.client.get('/qa/extractedtext/5/', follow=True)\n"", ""self.assertIn(b'<input type=\""text\"" name=\""rawchem-1-raw_cas\""', VAR_1.content)\n"", ""self.assertNotIn(b'<input type=\""text\"" name=\""rawchem-1-unit_type\""', VAR_1.\n    content)\n"", ""self.assertIn(b'Functional Use Chem1', VAR_1.content)\n"", ""VAR_1 = self.client.get('/qa/extractionscript/5', follow=True)\n"", ""VAR_1 = self.client.get('/qa/extractedtext/7/', follow=True)\n"", ""self.assertIn(b'rawchem-1-unit_type', VAR_1.content)\n""]",0
"[""def FUNC_13(self):...\n"", ""VAR_4 = {'r': u'not ascii  '}\n"", ""VAR_1 = 'http://my.url.com'\n"", ""VAR_2 = 'True'\n"", ""url_helper.urllib2.urlopen(mox.StrContains(VAR_1), mox.IgnoreArg(), timeout\n    =mox.IgnoreArg()).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(url_helper.UrlOpen(VAR_1, VAR_4=data), VAR_2)\n"", ""self._mox.VerifyAll()\n""]",1
"[""@click.command(help='Get information for a monitor')...\n"", ""VAR_12 = newrelic.get_monitor(VAR_0.obj['ACCOUNT'], VAR_12)\n"", ""if VAR_11:\n"", ""print(json.dumps(VAR_12))\n"", ""VAR_22 = VAR_12.get('severity', 0)\n"", ""return\n"", ""if VAR_22 == 2:\n"", ""VAR_31 = click.style(u'', fg='green')\n"", ""if VAR_22 == 1:\n"", ""VAR_12['health'] = VAR_31\n"", ""VAR_31 = click.style(u'', fg='yellow')\n"", ""VAR_31 = click.style(u'', fg='red')\n"", ""VAR_23 = VAR_12['status'].lower()\n"", ""if VAR_23 in ('muted', 'disabled'):\n"", ""VAR_23 = click.style(u' {}'.format(VAR_23), fg='yellow')\n"", ""VAR_23 = click.style(u' OK', fg='green')\n"", ""VAR_24 = [['Monitor', VAR_12['id']], ['Status', VAR_23], ['Health', VAR_31],\n    ['Name', VAR_12['name']], ['URI', VAR_12['uri']], ['Type', VAR_12[\n    'type']], ['Locations', ', '.join(VAR_12['locations'])], [\n    'slaThreshold', VAR_12['slaThreshold']], ['Emails', ', '.join(VAR_12[\n    'emails'])], ['Frequency', VAR_12['frequency']], ['Created', VAR_12[\n    'createdAt']], ['Modified', VAR_12['modifiedAt']]]\n"", ""VAR_25 = SingleTable(VAR_24)\n"", ""VAR_25.title = click.style('Monitor', fg='black')\n"", ""print(VAR_25.table)\n""]",1
"[""def FUNC_1(VAR_3, VAR_4, VAR_5):...\n"", ""return {'tilejson': '2.1.0', 'name': VAR_3, 'version': '1.0.0', 'scheme':\n    'tms', 'tiles': VAR_4, 'minzoom': 0, 'maxzoom': 22, 'bounds': VAR_5}\n""]",0
"[""@functools.wraps(VAR_3)...\n"", ""VAR_23 = VAR_5.pop('timeout', None)\n"", ""VAR_24 = eventlet.spawn(VAR_3, self, *VAR_4, **kwargs)\n"", ""if VAR_23 is None:\n"", ""return VAR_24.wait()\n"", ""VAR_36 = eventlet.spawn_after(VAR_23, VAR_24.kill)\n"", ""VAR_48 = VAR_24.wait()\n"", ""VAR_36.cancel()\n"", ""return VAR_48\n""]",0
"[""def FUNC_13(self, VAR_11, VAR_12, VAR_13, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_31 = 'createhost -iscsi -persona %s -domain %s %s %s' % (VAR_14, VAR_13,\n    VAR_11, VAR_12)\n"", ""VAR_32 = self.common._cli_run(VAR_31, None)\n"", ""if VAR_32 and len(VAR_32) > 1:\n"", ""return self.common.parse_create_host_error(VAR_11, VAR_32)\n"", ""return VAR_11\n""]",1
"[""def FUNC_3(self, VAR_10, VAR_6, VAR_11, VAR_12):...\n"", ""VAR_17 = self._binary_util.select_binary(VAR_10=supportdir, VAR_6=version,\n    name=filename)\n"", ""VAR_0.debug('Tarball for %s(%s): %s', VAR_10, VAR_6, VAR_17)\n"", ""VAR_18 = os.path.dirname(VAR_17)\n"", ""VAR_19 = os.path.join(VAR_18, 'unpacked')\n"", ""if not os.path.exists(VAR_19):\n"", ""TGZ.extract(VAR_17, tmp_dist)\n"", ""VAR_20 = os.path.join(VAR_19, VAR_12)\n"", ""os.rename(tmp_dist, VAR_19)\n"", ""return VAR_20\n""]",1
"[""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""frappe.db.sql('delete from tabEvent')\n"", ""VAR_4 = FUNC_0()\n"", ""VAR_5 = FUNC_0(VAR_1='2016-07-05 23:59:59')\n"", ""VAR_6 = FUNC_0(VAR_1='2016-07-06 00:00:00')\n"", ""VAR_7 = FUNC_0(VAR_1='2016-07-07 23:59:59')\n"", ""VAR_8 = FUNC_0(VAR_1='2016-07-08 00:00:01')\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between',\n    None]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-06', '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_6.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_4.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_6.name} not in VAR_3)\n""]",0
"[""def FUNC_22(self, VAR_55, VAR_38):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_79 = bytearray()\n"", ""for element in VAR_38:\n"", ""VAR_94 = element.keys()[0]\n"", ""return u'({})'.format(VAR_79.decode('utf8'))\n"", ""VAR_90 = getattr(self, self.WHERE_CONDITION_MAPPING.get(VAR_94))\n"", ""VAR_71 = VAR_90(element.get(VAR_94))\n"", ""if not VAR_79 and VAR_55 in [self.AND_CONDITION, self.OR_CONDITION]:\n"", ""VAR_79.extend('({})'.format(VAR_71))\n"", ""VAR_79.extend(' {0} ({1})'.format(VAR_55, VAR_71))\n""]",0
"[""def FUNC_3(self):...\n"", ""self.set_secure_cookie('username', self.get_argument('username'))\n"", ""self.redirect('/', permanent=True)\n""]",1
"[""def FUNC_5(self):...\n"", ""VAR_15 = Hunt.objects.order_by('id')\n"", ""VAR_15 = VAR_15.annotate(count=Count('events'))\n"", ""return VAR_15\n""]",0
"[""\""\""\""\nUnit tests for the Deis api app.\n\nRun the tests with \""./manage.py test api\\\""\n\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""from django.test import TestCase\n"", ""from deis import __version__\n"", ""\""\""\""Tests middleware.py's business logic\""\""\""\n"", ""VAR_0 = ['tests.json']\n"", ""def FUNC_0(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps', HTTP_X_DEIS_VERSION=__version__.rsplit\n    ('.', 1)[0])\n"", ""self.assertEqual(VAR_1.status_code, 200)\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps', HTTP_X_DEIS_VERSION='1234.5678')\n"", ""self.assertEqual(VAR_1.status_code, 405)\n"", ""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_1.status_code, 200)\n""]",1
"[""def FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10):...\n"", ""if VAR_11 == 'POST':\n"", ""return CLASS_0.session.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=\n    _HEADERS, VAR_10=timeout)\n"", ""if VAR_11 == 'GET':\n"", ""return CLASS_0.session.get(FUNC_2(VAR_7), headers=_HEADERS, VAR_10=timeout)\n""]",1
"[""from orm_cloud.database_adapters.lucene_parser.lucene_parser import LuceneParser\n"", ""def __init__(self):...\n"", ""def FUNC_0(self, VAR_0, VAR_1, VAR_2, VAR_3=None, VAR_4=None, VAR_5=None):...\n"", ""VAR_8 = self.create_select(VAR_0) + ' '\n"", ""VAR_8 += self.create_from(VAR_1) + ' '\n"", ""VAR_8 += self.create_where(VAR_2)\n"", ""if VAR_3:\n"", ""VAR_8 += ' ' + self.create_sort_by(VAR_3)\n"", ""if VAR_4 and VAR_5:\n"", ""VAR_8 += ' ' + self.create_offset(VAR_4, VAR_5)\n"", ""return VAR_8\n""]",1
"[""def FUNC_5(self):...\n"", """"]",0
"[""def FUNC_1(VAR_1, VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_2 is None:\n"", ""if 'access_token' in VAR_2:\n"", ""return FUNC_3(VAR_1, VAR_2)\n"", ""if 'oauth_token' in VAR_2 and 'oauth_token_secret' in VAR_2:\n"", ""return FUNC_2(VAR_1, VAR_2)\n"", ""if 'error' in VAR_2:\n""]",0
"[""def FUNC_3(VAR_2, VAR_0, VAR_1):...\n"", ""current_app.logger.info('Reauthenticating user {!r} for {!r}.'.format(VAR_1,\n    VAR_2))\n"", ""VAR_3['_saml2_session_name_id'] = code(VAR_0['name_id'])\n"", ""VAR_3[VAR_2] = int(time())\n"", ""VAR_3.persist()\n"", ""VAR_5 = request.form.get('RelayState', '/')\n"", ""current_app.logger.debug('Redirecting to the RelayState: ' + VAR_5)\n"", ""return redirect(location=relay_state)\n""]",0
"[""def FUNC_1(VAR_2):...\n"", ""VAR_12 = 'string' + \""AND tweets.text LIKE '%{}%' \"" * (len(VAR_2) - 1)\n"", ""VAR_12 = VAR_12.format(*VAR_2)\n"", ""VAR_6 = VAR_0.cursor()\n"", ""VAR_6.execute(VAR_12)\n"", ""VAR_11 = [None]\n"", ""VAR_13 = []\n"", ""while len(VAR_11) > 0:\n"", ""VAR_11 = VAR_6.fetchall()\n"", ""return VAR_13\n"", ""VAR_13.extend(VAR_11)\n""]",1
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = '/api/apps'\n"", ""VAR_3 = self.client.post(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 201)\n"", ""VAR_4 = VAR_3.data['id']\n"", ""self.assertIn('id', VAR_3.data)\n"", ""self.assertIn('url', VAR_3.data)\n"", ""self.assertEqual(VAR_3.data['url'], '{app_id}.deisapp.local'.format(**locals())\n    )\n"", ""VAR_3 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""self.assertEqual(len(VAR_3.data['results']), 1)\n"", ""VAR_2 = '/api/apps/{app_id}'.format(**locals())\n"", ""VAR_3 = self.client.get(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""VAR_5 = {'id': 'new'}\n"", ""VAR_3 = self.client.patch(VAR_2, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_3.status_code, 405)\n"", ""VAR_3 = self.client.delete(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 204)\n""]",1
"[""@ndb.transactional...\n"", ""VAR_10 = WfSuspectedCL.Get(VAR_0, VAR_1)\n"", ""if not VAR_10 or not VAR_10.builds:\n"", ""return False\n"", ""if not VAR_10.builds.get(VAR_2):\n"", ""return True\n"", ""VAR_10.builds[VAR_2]['status'] = VAR_3\n"", ""VAR_11 = True\n"", ""VAR_12 = True\n"", ""VAR_13 = False\n"", ""for build in VAR_10.builds.values():\n"", ""if build['status'] is None:\n"", ""if VAR_13:\n"", ""VAR_13 = True\n"", ""if build['status'] == suspected_cl_status.CORRECT:\n"", ""VAR_10.status = suspected_cl_status.PARTIALLY_TRIAGED\n"", ""if VAR_11:\n"", ""VAR_12 = False\n"", ""VAR_11 = False\n"", ""VAR_10.updated_time = VAR_4 or time_util.GetUTCNow()\n"", ""VAR_10.status = suspected_cl_status.CORRECT\n"", ""if VAR_12:\n"", ""VAR_10.put()\n"", ""VAR_10.status = suspected_cl_status.INCORRECT\n"", ""VAR_10.status = suspected_cl_status.PARTIALLY_CORRECT\n"", ""return True\n""]",0
"[""def FUNC_1(VAR_2=0, VAR_3=VAR_0, VAR_4=None, VAR_5={}, VAR_6='INBOX', VAR_7...\n"", ""VAR_13 = CLASS_0({'flags': VAR_3, 'mbox_uuid': VAR_6, 'type': 'flags',\n    'uid': VAR_2, 'chash': VAR_8})\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""if not (VAR_4.get('received') or VAR_4.get('date')):\n"", ""VAR_4.update(VAR_1)\n"", ""VAR_4['headers'] = VAR_5\n"", ""VAR_14 = CLASS_0(VAR_4)\n"", ""VAR_15 = CLASS_0({'raw': VAR_7, 'type': 'cnt'})\n"", ""return VAR_13, VAR_14, VAR_15\n""]",0
"[""@gallery.route('/gallery/benwa/')...\n"", ""return redirect(url_for('gallery.show_posts'))\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('crypto-md5.py', VAR_2)\n""]",0
"[""def FUNC_4(self, VAR_1, VAR_2, VAR_5, VAR_10=None, VAR_11=False, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not VAR_10:\n"", ""VAR_10 = []\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_29 = {}\n"", ""for VAR_48 in VAR_5:\n"", ""VAR_29[VAR_48] = {}.fromkeys(VAR_10, 0.0)\n"", ""for VAR_55 in VAR_10:\n"", ""VAR_49 = VAR_4.copy()\n"", ""return VAR_29\n"", ""if VAR_55 == 'qty_available':\n"", ""VAR_49.update({'states': ('done',), 'what': ('in', 'out')})\n"", ""if VAR_55 == 'virtual_available':\n"", ""VAR_49.update({'states': ('confirmed', 'waiting', 'assigned', 'done'),\n    'what': ('in', 'out')})\n"", ""if VAR_55 == 'incoming_qty':\n"", ""VAR_49.update({'states': ('confirmed', 'waiting', 'assigned'), 'what': ('in',)}\n    )\n"", ""if VAR_55 == 'outgoing_qty':\n"", ""VAR_49.update({'states': ('confirmed', 'waiting', 'assigned'), 'what': (\n    'out',)})\n"", ""VAR_50 = self.get_product_available(VAR_1, VAR_2, VAR_5, VAR_4=c)\n"", ""for VAR_48 in VAR_5:\n"", ""VAR_29[VAR_48][VAR_55] = VAR_50.get(VAR_48, 0.0)\n""]",0
"[""def FUNC_1(VAR_6, VAR_7, VAR_8):...\n"", ""VAR_8.debug('Running component check for %s' % VAR_6['name'])\n"", ""VAR_33 = len(VAR_6['cmd']) > 1 and 'check' in VAR_6['cmd'][1]\n"", ""VAR_9 = FUNC_6(VAR_7, VAR_6['name'])\n"", ""if VAR_9:\n"", ""VAR_56 = FUNC_2(VAR_9)\n"", ""VAR_8.debug('%s window is not running. Running custom check' % VAR_6['name'])\n"", ""VAR_8.debug('Found window pid: %s' % VAR_56)\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""VAR_57 = []\n"", ""VAR_8.debug('Component was not started by Hyperion, but the check succeeded')\n"", ""VAR_8.debug(\n    'Window not running and no check command is available or it failed: returning false'\n    )\n"", ""for entry in VAR_56:\n"", ""return CLASS_0.STARTED_BY_HAND\n"", ""return CLASS_0.STOPPED\n"", ""VAR_57.extend(Process(entry).children(recursive=True))\n"", ""VAR_58 = [p.pid for p in VAR_57]\n"", ""VAR_8.debug('Window is running %s child processes' % len(VAR_58))\n"", ""if len(VAR_58) < 3:\n"", ""VAR_8.debug(\n    'Main window process has finished. Running custom check if available')\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""VAR_8.debug('Check succeeded')\n"", ""if not VAR_33:\n"", ""VAR_8.debug('Process terminated but check was successful')\n"", ""VAR_8.debug('Check failed or no check available: returning false')\n"", ""return CLASS_0.RUNNING\n"", ""VAR_8.debug(\n    'No custom check specified and got sufficient pid amount: returning true')\n"", ""VAR_8.debug('Check failed: returning false')\n"", ""return CLASS_0.STOPPED_BUT_SUCCESSFUL\n"", ""return CLASS_0.STOPPED\n"", ""return CLASS_0.RUNNING\n"", ""return CLASS_0.STOPPED\n""]",1
"[""@property...\n"", ""if not self._is_function:\n"", ""return self._file\n""]",0
"[""@staticmethod...\n"", ""return openid.create_logout_url(VAR_3, VAR_23)\n""]",0
"[""def FUNC_6(VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = \""SELECT current_setting('%s') = '%s'\""\n"", ""VAR_3.execute(VAR_7 % (VAR_4, VAR_5))\n"", ""return VAR_3.fetchone()[0]\n""]",1
"[""def FUNC_10(self):...\n"", ""self.run_test_case(self.scenario.upsert_load_balancer())\n""]",0
"[""def FUNC_25(self, VAR_56, VAR_57):...\n"", ""\""\""\""docstring\""\""\""\n"", ""assert isinstance(VAR_56, dict)\n"", ""assert isinstance(VAR_57, str) and VAR_57\n"", ""for k, v in VAR_56.items():\n"", ""if k == VAR_57:\n"", ""yield v\n"", ""if isinstance(v, dict):\n"", ""for item in self.extract_key_from_nested_dict(v):\n"", ""yield item\n""]",0
"[""def FUNC_1(self, *VAR_10):...\n"", ""VAR_22 = self._build_url('/'.join(VAR_10))\n"", ""return self.__class__(self._conn, VAR_7=uri, VAR_8=self._default_headers,\n    VAR_9=self)\n""]",0
"[""def FUNC_16():...\n"", ""populate_test_database()\n"", ""FUNC_1('first playlist')\n"", ""VAR_11 = VAR_3.post('/videos/2/title/thumbnail')\n"", ""assert VAR_11.json['status'] == 'NOK'\n"", ""assert VAR_11.json['message'] != None\n""]",0
"[""def FUNC_1(self):...\n"", ""VAR_7 = super(CLASS_0, self).clean()\n"", ""VAR_3 = VAR_7.get('name')\n"", ""VAR_8 = api.nova.keypair_list(self.request)\n"", ""exceptions.handle(self.request, ignore=True)\n"", ""if VAR_3 in [VAR_10.name for VAR_10 in VAR_8]:\n"", ""VAR_8 = []\n"", ""VAR_9 = _('The name is already in use.')\n"", ""return VAR_7\n"", ""self._errors['name'] = self.error_class([VAR_9])\n""]",1
"[""def FUNC_24(self, VAR_17):...\n"", ""VAR_35, VAR_9, VAR_36 = sys.exc_info()\n"", ""VAR_16, VAR_37 = str(VAR_17).split(\""'\"")[-2], None\n"", ""if 'unique_' in VAR_16:\n"", ""VAR_16 = VAR_16.split('_', 1)[1]\n"", ""VAR_25 = self.meta.get_field(VAR_16)\n"", ""if VAR_25:\n"", ""VAR_37 = VAR_25.label\n"", ""VAR_54.msgprint(_('{0} must be unique'.format(VAR_37 or VAR_16)))\n""]",0
"[""def FUNC_6(VAR_2):...\n"", ""VAR_2.cursor.execute('string')\n"", ""VAR_22 = VAR_2.cursor.fetchall()\n"", ""return [VAR_0(*VAR_27) for VAR_27 in VAR_22]\n""]",0
"[""def FUNC_1(VAR_0, VAR_1):...\n"", ""VAR_2 = ''.join([chr(randint(97, 122)) for _ in range(32)])\n"", ""VAR_3 = str(uuid.uuid3(uuid.NAMESPACE_DNS, str(VAR_0 + time.time()) + VAR_2))\n"", ""VAR_1.set(VAR_3, VAR_0)\n"", ""VAR_4 = make_response(redirect('set_cookie'))\n"", ""VAR_4.set_cookie('SESSION', bytes(VAR_3, 'utf-8'))\n""]",1
"[""def FUNC_8(self):...\n"", ""VAR_15 = self.mock_nsx_clustered_api(retries=9)\n"", ""self.assertEqual(VAR_8.adapters['https://'].max_retries.total, 9)\n""]",0
"[""def FUNC_54(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 8, 'HIGH': 6}, 'CONFIDENCE': {'HIGH': 14}}\n"", ""self.check_example('weak_cryptographic_key_sizes.py', VAR_2)\n""]",0
"[""def FUNC_8(self, VAR_5=None, VAR_6=None, VAR_7=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_13 = iter(self.__entities)\n"", ""if not VAR_5 is None:\n"", ""VAR_13 = VAR_5(VAR_13)\n"", ""if not VAR_6 is None:\n"", ""VAR_13 = iter(VAR_6(VAR_13))\n"", ""if not VAR_7 is None:\n"", ""VAR_13 = islice(VAR_13, VAR_7.start, VAR_7.stop)\n"", ""return VAR_13\n""]",0
"[""def FUNC_5(self, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.bindings\n"", ""VAR_7 = VAR_1['TEST_APP_COMPONENT_NAME']\n"", ""VAR_8 = VAR_1['TEST_AWS_REGION']\n"", ""VAR_9 = [VAR_8 + 'a', VAR_8 + 'b']\n"", ""if VAR_5:\n"", ""VAR_16 = 'internal (defaultvpc)'\n"", ""VAR_16 = ''\n"", ""VAR_17 = VAR_1['TEST_AWS_VPC_ID']\n"", ""VAR_17 = None\n"", ""VAR_18 = ['default']\n"", ""VAR_18 = None\n"", ""VAR_19 = self.aws_observer.get_resource_list(root_key='Subnets',\n    aws_command='describe-subnets', aws_module='ec2', args=['--filters',\n    'Name=vpc-id,Values={vpc_id},Name=tag:Name,Values=defaultvpc.internal.{region}'\n    .format(vpc_id=vpc_id, region=region)])\n"", ""VAR_20 = VAR_9\n"", ""VAR_20 = [VAR_19[0]['AvailabilityZone']]\n"", ""VAR_10 = {'Listener': {'InstancePort': 80, 'LoadBalancerPort': 80}}\n"", ""VAR_7 += '-pub'\n"", ""VAR_11 = {'HealthyThreshold': 8, 'UnhealthyThreshold': 3, 'Interval': 12,\n    'Timeout': 6, 'Target': 'HTTP:%d/' % VAR_10['Listener']['InstancePort']}\n"", ""VAR_12 = self.agent.make_json_payload_from_kwargs(job=[{'type':\n    'upsertLoadBalancer', 'cloudProvider': 'aws', 'credentials': bindings[\n    'AWS_CREDENTIALS'], 'name': load_balancer_name, 'stack': bindings[\n    'TEST_STACK'], 'detail': '', 'region': bindings['TEST_AWS_REGION'],\n    'availabilityZones': {region: avail_zones}, 'regionZones': avail_zones,\n    'listeners': [{'internalProtocol': 'HTTP', 'internalPort': listener[\n    'Listener']['InstancePort'], 'externalProtocol': 'HTTP', 'externalPort':\n    listener['Listener']['LoadBalancerPort']}], 'healthCheck': health_check\n    ['Target'], 'healthCheckProtocol': 'HTTP', 'healthCheckPort': listener[\n    'Listener']['LoadBalancerPort'], 'healthCheckPath': '/',\n    'healthTimeout': health_check['Timeout'], 'healthInterval':\n    health_check['Interval'], 'healthyThreshold': health_check[\n    'HealthyThreshold'], 'unhealthyThreshold': health_check[\n    'UnhealthyThreshold'], 'user': '[anonymous]', 'usePreferredZones': True,\n    'vpcId': vpc_id, 'subnetType': subnet_type, 'securityGroups':\n    security_groups}], description='Create Load Balancer: ' +\n    load_balancer_name, application=self.TEST_APP)\n"", ""VAR_13 = aws.AwsContractBuilder(self.aws_observer)\n"", ""VAR_13.new_clause_builder('Load Balancer Added', retryable_for_secs=10\n    ).collect_resources(aws_module='elb', command='describe-load-balancers',\n    args=['--load-balancer-names', load_balancer_name]).contains_pred_list([\n    jc.PathContainsPredicate('LoadBalancerDescriptions/HealthCheck', VAR_11\n    ), jc.PathPredicate('LoadBalancerDescriptions/AvailabilityZones', jc.\n    LIST_SIMILAR(VAR_20)), jc.PathElementsContainPredicate(\n    'LoadBalancerDescriptions/ListenerDescriptions', VAR_10)])\n"", ""VAR_14 = '_with_vpc' if VAR_5 else '_without_vpc'\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer' + title_decorator, data=payload, path='tasks'),\n    VAR_6=builder.build())\n""]",1
"[""def FUNC_20(self, VAR_6, VAR_7, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_33 in self._cache.values():\n"", ""if VAR_6 and VAR_33.version < VAR_6:\n"", ""if VAR_7 and VAR_33.version > VAR_7:\n"", ""if VAR_8 and not VAR_33.jdk:\n"", ""return VAR_33\n""]",0
"[""def FUNC_1(VAR_0):...\n"", ""return base64.b64decode(binascii.unhexlify(VAR_0.encode('utf-8'))).decode(\n    'utf-8')\n""]",0
"[""def FUNC_2(VAR_1, VAR_2, VAR_3):...\n"", ""VAR_7 = {'create': 'CREATE TABLE {} ({})'.format(VAR_1, VAR_2)}\n"", ""VAR_7.update({'insert':\n    'INSERT INTO {} VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'.\n    format(VAR_1)})\n"", ""return VAR_7\n""]",0
"[""def FUNC_28(VAR_3):...\n"", ""VAR_0, VAR_10 = FUNC_0()\n"", ""VAR_25 = FUNC_3(VAR_10, \""SELECT options FROM {} WHERE name='{}'\"".format(CFG\n    ('poll_table_name'), VAR_3))\n"", ""if VAR_25 == None:\n"", ""return None\n"", ""VAR_24 = VAR_25.split(',')\n"", ""FUNC_1(VAR_0)\n"", ""return VAR_24\n""]",1
"[""def FUNC_4(self):...\n"", ""VAR_2 = '/api/apps'\n"", ""VAR_5 = {'id': 'autotest'}\n"", ""VAR_3 = self.client.post(VAR_2, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_3.status_code, 201)\n"", ""VAR_4 = VAR_3.data['id']\n"", ""if not os.path.exists(settings.DEIS_LOG_DIR):\n"", ""os.mkdir(settings.DEIS_LOG_DIR)\n"", ""VAR_6 = os.path.join(settings.DEIS_LOG_DIR, VAR_4 + '.log')\n"", ""if os.path.exists(VAR_6):\n"", ""os.remove(VAR_6)\n"", ""VAR_2 = '/api/apps/{app_id}/logs'.format(**locals())\n"", ""VAR_3 = self.client.get(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 204)\n"", ""self.assertEqual(VAR_3.data, 'No logs for {}'.format(VAR_4))\n"", ""f.write(VAR_0)\n"", ""VAR_3 = self.client.get(VAR_2)\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""self.assertEqual(VAR_3.data, VAR_0)\n"", ""os.remove(VAR_6)\n"", ""VAR_2 = '/api/apps/{app_id}/run'.format(**locals())\n"", ""VAR_5 = {'command': 'ls -al'}\n"", ""VAR_3 = self.client.post(VAR_2, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_3.status_code, 200)\n"", ""self.assertEqual(VAR_3.data[0], 0)\n"", ""os.remove(VAR_6)\n""]",1
"[""def FUNC_12(self, VAR_22):...\n"", ""\""\""\""docstring\""\""\""\n"", ""logging.warning(\""\""\""Authentication error.\n%s\""\""\"", VAR_22)\n"", ""self.abort(401, detail=str(error))\n""]",0
"[""def FUNC_2():...\n"", ""super(CLASS_5, self).__init__(slideParser.parse(VAR_10, slideLexer), self.\n    begin % (VAR_41, VAR_36), self.end % VAR_41)\n""]",1
"[""import geojson\n"", ""import datetime\n"", ""import dateutil.parser\n"", ""from server import db\n"", ""from sqlalchemy import desc\n"", ""from server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser\n"", ""from server.models.postgis.licenses import License, users_licenses_table\n"", ""from server.models.postgis.project_info import ProjectInfo\n"", ""from server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole\n"", ""from server.models.postgis.utils import NotFound, timestamp\n"", ""\""\""\"" Describes the history associated with a task \""\""\""\n"", ""__tablename__ = 'users'\n"", ""VAR_0 = db.Column(db.BigInteger, primary_key=True, index=True)\n"", ""VAR_1 = db.Column(db.Boolean, default=True, nullable=False)\n"", ""VAR_2 = db.Column(db.String, unique=True)\n"", ""VAR_3 = db.Column(db.Integer, default=0, nullable=False)\n"", ""VAR_4 = db.Column(db.Integer, default=1, nullable=False)\n"", ""VAR_5 = db.Column(db.Integer, default=1, nullable=False)\n"", ""VAR_6 = db.Column(db.Integer, default=0, nullable=False)\n"", ""VAR_7 = db.Column(db.Integer, default=0, nullable=False)\n"", ""VAR_8 = db.Column(db.Integer, default=0, nullable=False)\n"", ""VAR_5 = db.Column(db.ARRAY(db.Integer))\n"", ""VAR_9 = db.Column(db.String)\n"", ""VAR_10 = db.Column(db.Boolean, default=False)\n"", ""VAR_11 = db.Column(db.Boolean, default=False)\n"", ""VAR_12 = db.Column(db.String)\n"", ""VAR_13 = db.Column(db.String)\n"", ""VAR_14 = db.Column(db.String)\n"", ""VAR_15 = db.Column(db.DateTime, default=timestamp)\n"", ""VAR_16 = db.Column(db.DateTime, default=timestamp)\n"", ""VAR_17 = db.relationship('License', secondary=users_licenses_table)\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""db.session.add(self)\n"", ""db.session.commit()\n"", ""def FUNC_1(self):...\n"", ""db.session.commit()\n"", ""def FUNC_2(self, VAR_18: int):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return CLASS_0.query.get(VAR_18)\n""]",1
"[""def FUNC_1(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0.append((VAR_1, datetime.datetime.now()))\n""]",1
"[""def FUNC_5(self, VAR_0, VAR_4=None):...\n"", ""VAR_10 = []\n"", ""VAR_11 = self.find_ord(VAR_0)\n"", ""for node, dep, lbl in self.edges:\n"", ""if VAR_4:\n"", ""return VAR_10\n"", ""if node == VAR_11 and lbl == VAR_4:\n"", ""if node == VAR_11:\n"", ""VAR_10.append(self.nodes[dep])\n"", ""VAR_10.append(self.nodes[dep])\n""]",0
"[""def FUNC_17(self, VAR_16, **VAR_17):...\n"", ""VAR_24 = VAR_17.get('exception')\n"", ""if VAR_24 and hasattr(VAR_24, 'error_code'):\n"", ""VAR_40 = {}\n"", ""RequestHandler.write_error(self, VAR_16, **kw)\n"", ""VAR_40.update({'error_message': VAR_24.reason, 'error_code': VAR_24.error_code}\n    )\n"", ""if hasattr(VAR_24, 'arguments'):\n"", ""VAR_40.update({'arguments': VAR_24.arguments})\n"", ""VAR_40.update({'arguments': []})\n"", ""self.set_status(VAR_16)\n"", ""self.finish(VAR_40)\n""]",0
"[""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = VAR_2.GetVersion(VAR_3=version)\n"", ""return VAR_7 or VAR_2() if VAR_3 is None else VAR_7\n""]",0
"[""def __init__(self, VAR_0):...\n"", ""self.conn = sqlite3.connect(VAR_0)\n"", ""self.c = self.conn.cursor()\n""]",0
"[""def FUNC_1(VAR_1):...\n"", ""VAR_4 = os.path.dirname(VAR_1)\n"", ""VAR_5 = os.path.splitext(os.path.basename(VAR_1))[0]\n"", ""VAR_6 = [VAR_5] if VAR_5 != '__init__' else []\n"", ""VAR_7 = None\n"", ""while VAR_4 != VAR_7 and FUNC_0(VAR_4):\n"", ""VAR_7 = os.path.dirname(VAR_4)\n"", ""return VAR_4, '.'.join(reversed(VAR_6))\n"", ""VAR_6.append(os.path.basename(VAR_4))\n"", ""VAR_4 = VAR_7\n""]",1
"[""def FUNC_6(VAR_7):...\n"", ""@wraps(VAR_7)...\n"", ""if not app.config.get('USE_AUTH'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""if g.auth_type == 'kms':\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""if VAR_1.check_csrf_token():\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""return abort(401)\n""]",1
"[""def FUNC_2(self, VAR_5=None, VAR_6=None, VAR_7='', VAR_8=''):...\n"", ""if VAR_6:\n"", ""VAR_5 = VAR_6.apply_all(VAR_5)\n"", ""if VAR_7 != '':\n"", ""if hasattr(self.obj, VAR_7):\n"", ""return VAR_5\n"", ""if hasattr(getattr(self.obj, VAR_7), '_col_name'):\n"", ""VAR_5 = VAR_5.order_by(VAR_7 + ' ' + VAR_8)\n"", ""VAR_7 = getattr(getattr(self.obj, VAR_7), '_col_name')\n""]",1
"[""def FUNC_13(VAR_27):...\n"", ""VAR_36 = datetime.utcfromtimestamp(VAR_27.created_utc)\n"", ""FUNC_2(VAR_14=str(message.author), VAR_15='help', VAR_18='message', VAR_25=\n    message_time.strftime('%Y-%m-%d %H:%M:%S'))\n"", ""VAR_39 = VAR_1\n"", ""VAR_27.reply(VAR_39)\n""]",1
"[""def FUNC_1(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_29, VAR_30 = [], {}\n"", ""if not VAR_2:\n"", ""return VAR_29\n"", ""if VAR_3:\n"", ""for VAR_64 in VAR_3:\n"", ""for VAR_6 in VAR_2:\n"", ""VAR_63 = VAR_3[VAR_64]\n"", ""VAR_50 = True\n"", ""return VAR_29\n"", ""if not isinstance(VAR_63, (tuple, list)):\n"", ""for VAR_64, VAR_63 in iteritems(VAR_30):\n"", ""if VAR_63 is True:\n"", ""VAR_30[VAR_64] = VAR_63\n"", ""if not VAR_54.compare(getattr(VAR_6, VAR_64, None), VAR_63[0], VAR_63[1]):\n"", ""if VAR_50:\n"", ""VAR_63 = 'not None', VAR_63\n"", ""if VAR_63 is False:\n"", ""VAR_50 = False\n"", ""VAR_29.append(VAR_6)\n"", ""VAR_63 = 'None', VAR_63\n"", ""if isinstance(VAR_63, string_types) and VAR_63.startswith('^'):\n"", ""if VAR_4 and len(VAR_29) - 1 == VAR_4:\n"", ""VAR_63 = '^', VAR_63[1:]\n"", ""VAR_63 = '=', VAR_63\n""]",0
"[""\""\""\"" Client blueprint used to handle OAuth callbacks. \""\""\""\n"", ""from __future__ import absolute_import\n"", ""from flask import Blueprint, abort, current_app, url_for, request\n"", ""from flask.ext.login import user_logged_out\n"", ""from invenio.base.globals import cfg\n"", ""from invenio.ext.sslify import ssl_required\n"", ""from ..client import oauth, handlers, disconnect_handlers, signup_handlers\n"", ""from ..handlers import authorized_default_handler, make_token_getter, make_handler, disconnect_handler, oauth_logout_handler\n"", ""VAR_0 = Blueprint('oauthclient', __name__, url_prefix='/oauth',\n    static_folder='../static', template_folder='../templates')\n"", ""@VAR_0.before_app_first_request...\n"", ""\""\""\""docstring\""\""\""\n"", ""user_logged_out.connect(oauth_logout_handler)\n"", ""oauth.init_app(current_app)\n"", ""for VAR_1, conf in cfg['OAUTHCLIENT_REMOTE_APPS'].items():\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""@VAR_0.route('/login/<remote_app>/')...\n"", ""VAR_4 = oauth.remote_app(VAR_1, **conf['params'])\n"", ""VAR_4 = oauth.remote_apps[VAR_1]\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4.tokengetter(make_token_getter(VAR_4))\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""handlers.register(VAR_1, VAR_4.authorized_handler(make_handler(conf.get(\n    'authorized_handler', authorized_default_handler), VAR_4)))\n"", ""return abort(404)\n"", ""VAR_2 = url_for('.authorized', VAR_1=remote_app, next=request.args.get(\n    'next') or request.referrer or None, _external=True)\n"", ""disconnect_handlers.register(VAR_1, make_handler(conf.get(\n    'disconnect_handler', disconnect_handler), VAR_4, with_response=False))\n"", ""return oauth.remote_apps[VAR_1].authorize(callback=callback_url)\n"", ""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", ""VAR_7 = conf.get('signup_handler', dict())\n"", ""VAR_8 = make_handler(VAR_7.get('info', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_9 = make_handler(VAR_7.get('setup', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_10 = make_handler(VAR_7.get('view', FUNC_5), VAR_4, with_response=False)\n"", ""signup_handlers.register(VAR_1, dict(info=account_info_handler, setup=\n    account_setup_handler, view=account_view_handler))\n""]",1
"[""def FUNC_29(self):...\n"", ""if VAR_54.flags.in_import:\n"", ""return\n"", ""for VAR_25 in self.meta.get_select_fields():\n"", ""if VAR_25.fieldname == 'naming_series' or not (self.get(VAR_25.fieldname) and\n"", ""VAR_56 = (VAR_25.options or '').split('\\n')\n"", ""if not filter(None, VAR_56):\n"", ""self.set(VAR_25.fieldname, cstr(self.get(VAR_25.fieldname)).strip())\n"", ""VAR_9 = self.get(VAR_25.fieldname)\n"", ""if VAR_9 not in VAR_56 and not (VAR_54.flags.in_test and VAR_9.startswith(\n"", ""VAR_67 = _('Row #{0}:').format(self.idx) if self.get('parentfield') else ''\n"", ""VAR_37 = _(self.meta.get_label(VAR_25.fieldname))\n"", ""VAR_68 = '\"", \""'.join(_(each) for each in VAR_56)\n"", ""VAR_54.throw(_('{0} {1} cannot be \""{2}\"". It should be one of \""{3}\""').format\n    (VAR_67, VAR_37, VAR_9, VAR_68))\n""]",0
"[""def __init__(self, VAR_7, VAR_14=errors.NO_THING_ID, *VAR_15, **VAR_16):...\n"", ""CLASS_3.__init__(self, VAR_7, VAR_14, *VAR_15, **kw)\n""]",0
"[""def FUNC_29(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.stat(VAR_21, VAR_23=False)\n""]",0
"[""def FUNC_3(VAR_1):...\n"", ""return frappe.db.get_value('Blog Category', {'name': VAR_1}, 'title') or VAR_1\n""]",0
"[""@view_config(route_name='note-action', request_method=('GET', 'POST'),...\n"", ""\""\""\""docstring\""\""\""\n"", ""db.note.delete_note(VAR_0.db, VAR_0.params['id'])\n"", ""return HTTPNoContent()\n""]",1
"[""def FUNC_15(self, VAR_7, VAR_10):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_25 = None\n"", ""VAR_11 = self.common._safe_hostname(VAR_10['host'])\n"", ""VAR_33 = self.common.get_cpg(VAR_7, allowSnap=True)\n"", ""VAR_13 = self.common.get_domain(VAR_33)\n"", ""VAR_25 = self.common._get_3par_host(VAR_11)\n"", ""VAR_14 = self.common.get_persona_type(VAR_7)\n"", ""return VAR_25\n"", ""if not VAR_25['iSCSIPaths']:\n"", ""VAR_11 = self._create_3par_iscsi_host(VAR_11, VAR_10['initiator'], VAR_13,\n    VAR_14)\n"", ""self._modify_3par_iscsi_host(VAR_11, VAR_10['initiator'])\n"", ""VAR_25 = self.common._get_3par_host(VAR_11)\n"", ""VAR_25 = self.common._get_3par_host(VAR_11)\n""]",0
"[""from modules import sql\n"", ""def __init__(self, VAR_0):...\n"", ""self.conn = VAR_0\n"", ""def FUNC_0(self, VAR_1):...\n"", ""VAR_5 = ('select comment from comments order by date desc where userid=%d' %\n    VAR_1)\n"", ""VAR_6 = sql.queryDB(self.conn, VAR_5)\n"", ""return VAR_6\n""]",1
"[""def FUNC_0(self):...\n"", ""yield scrapy.Request(self.login_url, self.parse_login)\n""]",1
"[""def FUNC_9(VAR_26, VAR_27):...\n"", ""VAR_26['submission_count'] += VAR_27['submission_count']\n"", ""if VAR_27.get('unofficial', False):\n"", ""if VAR_27.get('unconfirmed', False):\n"", ""self._add_by_difficulty(VAR_26['unconfirmed_points_by_difficulty'], VAR_27[\n    'difficulty'], VAR_27['points'])\n"", ""VAR_26['points'] += VAR_27['points']\n"", ""self._add_by_difficulty(VAR_26['points_by_difficulty'], VAR_27['difficulty'\n    ], VAR_27['points'])\n""]",0
"[""def FUNC_10(self):...\n"", ""self.env_var_override.set('VERIFY_XSS', 'True')\n"", ""VAR_7 = BokChoyTestSuite('')\n"", ""VAR_1 = 'tests'\n"", ""self.assertEqual(VAR_7.cmd, self._expected_command(VAR_1=name, VAR_3=True))\n""]",1
"[""def FUNC_10(self, VAR_5):...\n"", ""VAR_14 = 'string' % VAR_5\n"", ""VAR_11 = sql.queryDB(self.conn, VAR_14)\n"", ""return VAR_11\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = VAR_0.copy()\n"", ""VAR_2['QUERY_STRING'] = ''\n"", ""VAR_3 = cgi.FieldStorage(fp=environ['wsgi.input'], VAR_0=data_env,\n    keep_blank_values=True)\n"", ""return VAR_3\n""]",0
"[""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_18._check_executable(VAR_0):\n"", ""if VAR_19 is None:\n"", ""return repr(VAR_0) + ' is not installed.'\n"", ""return True\n"", ""check_call(VAR_19, stdout=DEVNULL, stderr=DEVNULL)\n"", ""return VAR_20\n"", ""return True\n""]",0
"[""@commands.group(aliases=['elite', 'ed'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.invoked_subcommand is None:\n"", ""await VAR_1.send(\n    f'Invalid command passed. Try \""{self.bot.command_prefix[0]}help eddb\""')\n""]",0
"[""def FUNC_9(self, VAR_10):...\n"", ""VAR_28 = 'last_switched'\n"", ""VAR_11 = (\n    \""\""\""\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \""\""\""\n    .format(self.columns[VAR_10].select(), VAR_28, self.build_filter_string()))\n"", ""return self.query_boilerplate(VAR_11)\n""]",0
"[""def FUNC_1(self, *VAR_5, **VAR_6):...\n"", ""self.write({'countries': [{'name': c} for c in self.country_list()]})\n""]",0
"[""def FUNC_5(VAR_8, VAR_7):...\n"", ""shutil.copyfileobj(file_in, file_out)\n""]",0
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import django.core.validators\n"", ""VAR_0 = [('exercise', '0010_auto_20151214_1714')]\n"", ""VAR_1 = [migrations.CreateModel(name='CourseChapter', fields=[(\n    'learningobject_ptr', models.OneToOneField(parent_link=True,\n    primary_key=True, to='exercise.LearningObject', serialize=False,\n    auto_created=True)), ('generate_table_of_contents', models.BooleanField\n    (default=False))], options={}, bases=('exercise.learningobject',)),\n    migrations.AddField(model_name='learningobject', name='content_head',\n    field=models.TextField(blank=True), preserve_default=True), migrations.\n    AddField(model_name='learningobject', name='parent', field=models.\n    ForeignKey(related_name='children', null=True, to=\n    'exercise.LearningObject', blank=True), preserve_default=True),\n    migrations.AddField(model_name='learningobject', name='status', field=\n    models.CharField(choices=[('ready', 'Ready'), ('hidden', 'Hidden'), (\n    'maintenance', 'Maintenance')], max_length=32, default='ready'),\n    preserve_default=True), migrations.AddField(model_name='learningobject',\n    name='url', field=models.CharField(max_length=255, help_text=\n    'Input an URL identifier for this object.', validators=[django.core.\n    validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], blank=True, null=\n    True, default=None), preserve_default=True), migrations.AddField(\n    model_name='learningobject', name='use_wide_column', field=models.\n    BooleanField(help_text='Remove the third info column for more space.',\n    default=False), preserve_default=True), migrations.AlterField(\n    model_name='learningobject', name='description', field=models.TextField\n    (help_text='Internal description is not presented on site.', blank=True\n    ), preserve_default=True)]\n""]",1
"[""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""VAR_3 = os.path.join(os.getcwd(), 'bandit', 'plugins')\n"", ""VAR_4 = b_config.BanditConfig()\n"", ""self.b_mgr = b_manager.BanditManager(VAR_4, 'file')\n"", ""self.b_mgr.b_conf._settings['plugins_dir'] = VAR_3\n"", ""self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n""]",0
"[""@VAR_0.route('/upload', methods=['GET', 'POST'])...\n"", ""VAR_13 = ''\n"", ""if 'username' in VAR_19:\n"", ""return render_template('upload', VAR_13=e)\n"", ""if request.method == 'POST':\n"", ""if 'file' in request.files.keys():\n"", ""VAR_18 = []\n"", ""VAR_21 = request.files['file']\n"", ""if 'link11' in request.form.keys():\n"", ""for VAR_15 in os.listdir('static/videos'):\n"", ""VAR_21.save('static/videos/{}'.format(VAR_21.filename))\n"", ""VAR_23 = request.form['link11']\n"", ""VAR_20 = CLASS_1.query.filter_by(VAR_11=video).first()\n"", ""return render_template('upload.html', VAR_18=videos)\n"", ""VAR_14 = CLASS_0.query.filter_by(VAR_6=session['username']).first()\n"", ""VAR_24 = VAR_23.split('/')[-1]\n"", ""VAR_20 = CLASS_0.query.filter_by(VAR_5=video_uploader.UserID).first()\n"", ""VAR_22 = CLASS_1(VAR_9=None, VAR_5=data.UserID, VAR_10='local', VAR_11=f.\n    filename, VAR_12=datetime.today().strftime('%Y-%m-%d'))\n"", ""urllib.request.urlretrieve(VAR_23, 'static/videos/' + VAR_24)\n"", ""VAR_18.append((VAR_15, VAR_20.Username))\n"", ""VAR_1.session.add(VAR_22)\n"", ""VAR_14 = CLASS_0.query.filter_by(VAR_6=session['username']).first()\n"", ""VAR_1.session.commit()\n"", ""VAR_22 = CLASS_1(VAR_9=None, VAR_5=data.UserID, VAR_10='local', VAR_11=\n    filename123, VAR_12=datetime.today().strftime('%Y-%m-%d'))\n"", ""VAR_1.session.add(VAR_22)\n"", ""VAR_1.session.commit()\n""]",1
"[""from __future__ import unicode_literals\n"", ""import frappe, unittest\n"", ""from frappe.model.db_query import DatabaseQuery\n"", ""from frappe.desk.reportview import get_filters_cond\n"", ""def FUNC_1(self):...\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    limit_page_length=None))\n"", ""def FUNC_2(self):...\n"", ""self.assertTrue({'name': 'DocType', 'issingle': 0} in DatabaseQuery(\n    'DocType').execute(fields=['name', 'issingle'], limit_page_length=None))\n"", ""def FUNC_3(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[['DocType', 'name', 'like', 'J%']]))\n"", ""def FUNC_4(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[{'name': ['like', 'J%']}]))\n"", ""def FUNC_5(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['like', 'J%']}))\n"", ""def FUNC_6(self):...\n"", ""self.assertTrue({'name': 'DocField'} in DatabaseQuery('DocType').execute(\n    filters={'name': 'DocField'}))\n"", ""def FUNC_7(self):...\n"", ""self.assertFalse(DatabaseQuery('DocType').execute(filters={'name': ['in',\n    None]}))\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['not in', None]}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertTrue(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['in', 'DocType,DocField']}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertFalse(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['not in', 'DocType,DocField']}))\n"", ""def FUNC_8(self):...\n"", ""VAR_3 = DatabaseQuery('DocField').execute(filters={'parent': 'DocType'},\n    fields=['fieldname', 'fieldtype'], or_filters=[{'fieldtype': 'Table'},\n    {'fieldtype': 'Select'}])\n"", ""self.assertTrue({'fieldtype': 'Table', 'fieldname': 'fields'} in VAR_3)\n"", ""self.assertTrue({'fieldtype': 'Select', 'fieldname': 'document_type'} in VAR_3)\n"", ""self.assertFalse({'fieldtype': 'Check', 'fieldname': 'issingle'} in VAR_3)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""frappe.db.sql('delete from tabEvent')\n"", ""VAR_4 = FUNC_0()\n"", ""VAR_5 = FUNC_0(VAR_1='2016-07-05 23:59:59')\n"", ""VAR_6 = FUNC_0(VAR_1='2016-07-06 00:00:00')\n"", ""VAR_7 = FUNC_0(VAR_1='2016-07-07 23:59:59')\n"", ""VAR_8 = FUNC_0(VAR_1='2016-07-08 00:00:01')\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between',\n    None]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-06', '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_6.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_4.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_6.name} not in VAR_3)\n"", ""def FUNC_10(self):...\n"", ""frappe.set_user('test1@example.com')\n"", ""self.assertRaises(frappe.PermissionError, get_filters_cond, 'DocType', dict\n    (istable=1), [])\n"", ""self.assertTrue(get_filters_cond('DocType', dict(istable=1), [],\n    ignore_permissions=True))\n"", ""frappe.set_user('Administrator')\n"", ""def FUNC_11(self):...\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, version()'], limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (select name from tabUser), count(name))'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, (select count(*) from tabSessions)'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    \""issingle, SELECT LOCATE('', `tabUser`.`user`) AS user;\""], limit_start=\n    0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (SELECT name from tabUser), count(*))'],\n    limit_start=0, limit_page_length=1)\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'count(name)'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('count(name)' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    \""locate('', name) as _relevance\""], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('_relevance' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'date(creation) as creation'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('creation' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'datediff(modified, creation) as date_diff'], limit_start=0,\n    limit_page_length=1)\n"", ""self.assertTrue('date_diff' in VAR_3[0])\n"", ""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""def FUNC_4(self, VAR_3, **VAR_6):...\n"", ""logging.warn('url_open(%s, %s)', VAR_3[:500], str(VAR_6)[:500])\n"", ""if not self._requests:\n"", ""return None\n"", ""VAR_6.pop('stream', None)\n"", ""for i, n in enumerate(self._requests):\n"", ""if n[0] == VAR_3:\n"", ""self.fail('Unknown request %s' % VAR_3)\n"", ""VAR_9 = self._requests.pop(i)\n"", ""if len(VAR_9) != 4:\n"", ""self.fail('Expected normal request, got json data; %s' % VAR_3)\n"", ""VAR_10, VAR_11, VAR_12, VAR_4 = VAR_9\n"", ""if callable(VAR_11):\n"", ""VAR_11(VAR_6)\n"", ""self.assertEqual(VAR_11, VAR_6)\n"", ""if VAR_12 is not None:\n"", ""return FUNC_0(VAR_12, VAR_3, VAR_4)\n"", ""return None\n""]",1
"[""def __gt__(self, VAR_11):...\n"", ""return self.rule.__gt__(VAR_11.rule)\n""]",0
"[""def FUNC_7(self):...\n"", ""return self.content\n""]",0
"[""def FUNC_6(self):...\n"", ""VAR_83 = []\n"", ""if self.rate_user and VAR_101.user_is_loggedin:\n"", ""VAR_83.append('user' + VAR_100(VAR_101.user._id36))\n"", ""if self.rate_ip:\n"", ""VAR_83.append('ip' + VAR_100(VAR_102.ip))\n"", ""VAR_84 = cache.get_multi(VAR_83, self.prefix)\n"", ""if VAR_84:\n"", ""VAR_87 = VAR_55(VAR_84.values())\n"", ""VAR_99 = utils.timeuntil(VAR_87)\n"", ""VAR_101.errors.add(errors.RATELIMIT, {'time': VAR_99})\n""]",0
"[""@rest_utils.ajax()...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_10 = api.nova.list_extensions(VAR_1)\n"", ""return {'items': [e.to_dict() for e in VAR_10]}\n""]",0
"[""from setuptools import setup, find_packages\n"", ""import sys, os\n"", ""from distutils import versionpredicate\n"", ""VAR_0 = os.path.abspath(os.path.dirname(__file__))\n"", ""VAR_1 = open(os.path.join(VAR_0, 'README')).read()\n"", ""VAR_2 = '0.3.22'\n"", ""VAR_3 = ['pymongo>=2.8,<3', 'pysaml2==1.2.0beta5', 'python-memcached==1.53',\n    'cherrypy==3.2.4', 'vccs_client==0.4.1', 'eduid_am>=0.5.3']\n"", ""VAR_4 = ['nose==1.2.1', 'coverage==3.6']\n"", ""setup(name='eduid_idp', VAR_2=version, description=\n    'eduID SAML frontend IdP', long_description=README, classifiers=[],\n    keywords='eduID SAML', author='Fredrik Thulin', author_email=\n    'fredrik@thulin.net', license='BSD', packages=['eduid_idp'],\n    package_dir={'': 'src'}, zip_safe=False, VAR_3=install_requires,\n    extras_require={'testing': testing_extras}, entry_points={\n    'console_scripts': ['eduid_idp=eduid_idp.idp:main']})\n""]",1
"[""def FUNC_1(VAR_3, VAR_4, VAR_5, VAR_6, VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_0 = tormysql.ConnectionPool(max_connections=20, idle_seconds=7200,\n    wait_connection_timeout=3, host=host_addr, user=user_id, passwd=\n    password, VAR_6=db, charset='utf8')\n"", ""return VAR_7.run_until_complete(FUNC_2())\n""]",0
"[""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_21 = self.agent.type_to_payload(\n    'registerInstancesWithGoogleLoadBalancerDescription', {\n    'loadBalancerNames': [self.__use_lb_name], 'instanceIds': self.\n    use_instance_names[:2], 'region': self.bindings['TEST_GCE_REGION'],\n    'credentials': self.bindings['GCE_CREDENTIALS']})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Instances in Target Pool', retryable_for_secs=15\n    ).list_resources('target-pools').contains_pred_list([jc.\n    PathContainsPredicate('name', self.__use_lb_tp_name), jc.\n    PathEqPredicate('region', self.bindings['TEST_GCE_REGION']), jc.\n    PathElementsContainPredicate('instances', self.use_instance_names[0]),\n    jc.PathElementsContainPredicate('instances', self.use_instance_names[1])]\n    ).excludes_pred_list([jc.PathContainsPredicate('name', self.\n    __use_lb_tp_name), jc.PathElementsContainPredicate('instances', self.\n    use_instance_names[2])])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'register_load_balancer_instances', data=payload, VAR_29='ops'),\n    contract=builder.build())\n""]",1
"[""def FUNC_2():...\n"", ""VAR_39 = education_group_type.search(category=education_group_categories.\n    MINI_TRAINING).exclude(name=GROUP_TYPE_OPTION).values_list('name', flat\n    =True)\n"", ""VAR_40 = [education_group_categories.TRAINING]\n"", ""return {'parent__education_group_type__name': VAR_39,\n    'parent__education_group_type__category': VAR_40}\n""]",0
"[""def FUNC_27(VAR_6):...\n"", ""if callable(VAR_6):\n"", ""return VAR_6()\n""]",0
"[""def FUNC_0(VAR_0):...\n"", ""VAR_3 = VAR_0.lower()\n"", ""if VAR_3 in ('yes', 'true', 't', '1', 'y'):\n"", ""return True\n"", ""if VAR_3 in ('no', 'false', 'f', 'n', '0'):\n"", ""return False\n""]",0
"[""def FUNC_22(self, VAR_11):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_35 = self.common._cli_run('showvlun -a -host %s' % VAR_11, None)\n"", ""if VAR_35:\n"", ""VAR_35 = VAR_35[1:]\n"", ""for line in VAR_35:\n"", ""VAR_30 = line.split(',')\n"", ""if VAR_30 and len(VAR_30) > 4:\n"", ""return VAR_30[4]\n""]",1
"[""def FUNC_1(self, VAR_1):...\n"", ""if VAR_1.settings().get('traverse') == 'true':\n"", ""VAR_5 = VAR_1\n"", ""VAR_6 = VAR_1.window()\n"", ""VAR_7 = VAR_1.substr(VAR_1.line(VAR_1.sel()[0]))\n"", ""VAR_8 = re.findall('->\\\\s+([^\\\\|]+)', VAR_7)\n"", ""if len(VAR_8) > 0:\n"", ""VAR_9 = Urtext.get_path(VAR_1.window())\n"", ""VAR_6.focus_group(1)\n"", ""VAR_10 = VAR_6.open_file(os.path.join(VAR_9, VAR_8[0].strip()), sublime.\n    TRANSIENT)\n"", ""print('unable to open ' + VAR_8[0])\n"", ""self.return_to_left(VAR_10, VAR_5)\n"", ""VAR_10.set_scratch(True)\n""]",1
"[""@login_required...\n"", ""VAR_23 = ['extracted_text_id', 'id', 'raw_cas', 'raw_chem_name',\n    'raw_min_comp', 'raw_central_comp', 'raw_max_comp', 'unit_type__title']\n"", ""VAR_5 = DataGroup.objects.get(VAR_2=pk)\n"", ""VAR_32 = ExtractedText.objects.filter(data_document__data_group=dg).first()\n"", ""if VAR_32:\n"", ""VAR_42 = VAR_5.get_name_as_slug()\n"", ""VAR_41 = ExtractedChemical.objects.filter(extracted_text__data_document__id=pk\n    ).values(*VAR_23)\n"", ""VAR_41 = ExtractedChemical.objects.filter(\n    extracted_text__data_document__data_group_id=pk).values(*VAR_23)\n"", ""return render_to_csv_response(VAR_41, filename='raw_extracted_records.csv',\n    use_verbose_names=False)\n"", ""return render_to_csv_response(VAR_41, filename=dg_name +\n    '_raw_extracted_records.csv', field_header_map={'id':\n    'ExtractedChemical_id'}, use_verbose_names=False)\n""]",0
"[""@staticmethod...\n"", ""VAR_3 = ('SELECT jdk_entries.id, jdk_entries.title ' + 'FROM jdk_entries ' +\n    'ORDER BY date_last_modified DESC ' + 'LIMIT 30;')\n"", ""return FUNC_0(VAR_3, True)\n""]",1
"[""def FUNC_7(VAR_14: str) ->bool:...\n"", ""if not VAR_14 or not VAR_14.startswith(VAR_11):\n"", ""return False\n"", ""if VAR_14.startswith(VAR_12):\n"", ""return False\n"", ""return True\n""]",0
"[""@wraps(VAR_7)...\n"", ""if VAR_12:\n"", ""return VAR_7(VAR_8[0], VAR_1, *VAR_8[1:], **kwargs)\n"", ""return VAR_7(VAR_1, *VAR_8, **kwargs)\n""]",0
"[""def FUNC_8(self):...\n"", ""self.misc_file_checks()\n"", ""self.check_helper_consistency()\n"", ""self.check_source_management()\n"", ""self.check_manifest()\n"", ""for script in self.scripts.values():\n"", ""if script.exists:\n"", ""script.analyze()\n""]",0
"[""def FUNC_21(self, VAR_12):...\n"", ""return self.accounts[VAR_12]\n""]",0
"[""from rest_framework import serializers\n"", ""from rest_framework.validators import ValidationError\n"", ""from .models import Message\n"", ""\""\""\""\n    Message Serializer class\n    \""\""\""\n"", ""VAR_0 = Message\n"", ""VAR_1 = 'sent_by', 'room', 'text', 'attachment'\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import subprocess\n"", ""from typing import List\n"", ""from isort import SortImports\n"", ""def FUNC_0(VAR_0: str) ->bytes:...\n"", ""\""\""\""docstring\""\""\""\n"", ""return subprocess.check_output(VAR_0.split())\n""]",1
"[""@VAR_2.route('/h2h')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_28 = request.args.get('tag1', default='christmasmike')\n"", ""VAR_29 = request.args.get('tag2', default='christmasmike')\n"", ""VAR_8 = \""SELECT * FROM matches WHERE (player1 = '\"" + str(VAR_28\n    ) + \""' OR \"" + \""player2 = '\"" + str(VAR_28) + \""') AND (player1 = '\"" + str(\n    VAR_29) + \""' OR \"" + \""player2 = '\"" + str(VAR_29) + \""') ORDER BY date DESC;\""\n"", ""VAR_27 = VAR_0.exec(VAR_8)\n"", ""return json.dumps(VAR_27)\n""]",1
"[""import os\n"", ""import subprocess\n"", ""import sys\n"", ""from .crawler import find_repositories\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_2 = find_repositories(VAR_0.path)\n"", ""if VAR_0.repos:\n"", ""VAR_8 = dict((VAR_12.path, VAR_12) for VAR_12 in VAR_2)\n"", ""VAR_3 = {}\n"", ""for k in sorted(VAR_8.keys()):\n"", ""for VAR_12 in VAR_2:\n"", ""VAR_12 = VAR_8[k]\n"", ""VAR_9 = VAR_0.get_command_line(VAR_12)\n"", ""VAR_4 = VAR_3.keys()\n"", ""print('%s (%s)' % (k, VAR_12.type))\n"", ""VAR_10 = {'client': VAR_12, 'cmd': VAR_9}\n"", ""while VAR_4:\n"", ""if not VAR_9:\n"", ""if len(VAR_3) > 1:\n"", ""VAR_14, VAR_15 = os.wait()\n"", ""VAR_14, VAR_15 = os.waitpid(VAR_4[0], 0)\n"", ""if VAR_14 in VAR_4:\n"", ""VAR_9 = ['echo', '\""%s\"" is not implemented for client \""%s\""' % (VAR_0.\n    __class__.__name__, VAR_12.type)]\n"", ""if VAR_0.debug:\n"", ""print('')\n"", ""VAR_5 = {VAR_10['client'].path: VAR_14 for VAR_14, VAR_10 in VAR_3.items()}\n"", ""VAR_4.remove(VAR_14)\n"", ""print('Executing shell command \""%s\"" in \""%s\""' % (' '.join(VAR_9), VAR_12.path))\n"", ""VAR_11 = subprocess.Popen(VAR_9, shell=False, cwd=os.path.abspath(client.\n    path), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n"", ""VAR_6 = [VAR_5[path] for path in sorted(VAR_5.keys())]\n"", ""VAR_10 = VAR_3[VAR_14]\n"", ""VAR_10['process'] = VAR_11\n"", ""for VAR_14 in VAR_6:\n"", ""VAR_10['retcode'] = VAR_15\n"", ""VAR_3[VAR_11.pid] = VAR_10\n"", ""VAR_10 = VAR_3[VAR_14]\n"", ""def FUNC_1(VAR_1):...\n"", ""VAR_10['stdout'] = VAR_10['process'].stdout.read()\n"", ""VAR_12 = VAR_10['client']\n"", ""VAR_7 = {'bluef': '\\x1b[34m', 'boldon': '\\x1b[1m', 'boldoff': '\\x1b[22m',\n    'redf': '\\x1b[31m', 'reset': '\\x1b[0m', 'yellowf': '\\x1b[33m'}\n"", ""if len(VAR_3) > 1:\n"", ""print(FUNC_1('bluef') + '=== ' + FUNC_1('boldon') + VAR_12.path + FUNC_1(\n    'boldoff') + ' (' + VAR_12.type + ') ===' + FUNC_1('reset'))\n"", ""if VAR_1 in VAR_7:\n"", ""if VAR_10['cmd']:\n"", ""VAR_13 = VAR_10['stdout'].rstrip()\n"", ""return VAR_7[VAR_1]\n"", ""return ''\n"", ""if VAR_15 == 0:\n"", ""sys.stdout.write('s')\n"", ""if VAR_10['retcode'] != 0:\n"", ""sys.stdout.write('.')\n"", ""sys.stdout.write('E')\n"", ""sys.stdout.flush()\n"", ""if not VAR_13:\n"", ""if not VAR_10['cmd']:\n"", ""VAR_13 = 'Failed with retcode %d' % VAR_10['retcode']\n"", ""VAR_13 = FUNC_1('redf') + VAR_13 + FUNC_1('reset')\n"", ""VAR_13 = FUNC_1('yellowf') + VAR_13 + FUNC_1('reset')\n"", ""if VAR_13:\n"", ""print(VAR_13)\n""]",1
"[""def FUNC_1(self):...\n"", ""VAR_4 = {'username': 'firstuser', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='firstuser', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/admin/perms', content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""self.assertEqual(VAR_6.data['results'][0]['username'], 'firstuser')\n"", ""self.assertTrue(VAR_6.data['results'][0]['is_superuser'])\n"", ""VAR_4 = {'username': 'seconduser', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertFalse(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='seconduser', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/admin/perms', content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 403)\n"", ""self.assertIn('You do not have permission', VAR_6.data['detail'])\n""]",1
"[""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""return kato.new_agent(VAR_14)\n""]",0
"[""def FUNC_0(self, VAR_0):...\n"", ""if self.view.settings().has('traverse'):\n"", ""if self.view.settings().get('traverse') == 'true':\n"", ""self.view.settings().set('traverse', 'true')\n"", ""self.view.settings().set('traverse', 'false')\n"", ""self.view.set_status('traverse', 'Traverse: On')\n"", ""self.view.set_status('traverse', 'Traverse: Off')\n"", ""self.view.window().set_layout({'cols': [0, 0.4, 1], 'rows': [0, 1], 'cells':\n    [[0, 0, 1, 1], [1, 0, 2, 1]]})\n"", ""return\n"", ""VAR_3 = self.view.window().views()\n"", ""VAR_4 = 0\n"", ""for VAR_1 in VAR_3:\n"", ""if VAR_1 != self.view:\n"", ""self.view.window().focus_group(0)\n"", ""self.view.window().set_view_index(VAR_1, 1, VAR_4)\n"", ""VAR_4 += 1\n""]",0
"[""import requests\n"", ""def FUNC_0(self, VAR_0):...\n"", ""VAR_3 = VAR_0.cookies.get('XSRF-TOKEN')\n"", ""if VAR_3:\n"", ""self.xsrf_token = VAR_3\n"", ""def FUNC_1(self, VAR_1):...\n"", ""VAR_4 = {'X-XSRF-TOKEN': self.xsrf_token}\n"", ""if 'headers' in VAR_1:\n"", ""VAR_1['headers'].update(VAR_4)\n"", ""VAR_1['headers'] = VAR_4\n"", ""return VAR_1\n""]",1
"[""@contextlib.contextmanager...\n"", ""if self.closed:\n"", ""VAR_16, VAR_13 = VAR_9.command, VAR_9.seq\n"", ""VAR_16, VAR_13 = VAR_9['command'], VAR_9['seq']\n"", ""VAR_33 = {'msg': None}\n"", ""def FUNC_27(VAR_21):...\n"", ""if VAR_21.type != 'response':\n"", ""return False\n"", ""VAR_33['msg'] = VAR_21\n"", ""return VAR_21.request_seq == VAR_13\n""]",0
"[""def __init__(self, VAR_4):...\n"", ""super(CLASS_0, self).__init__()\n"", ""self._set_loader(VAR_4)\n"", ""self._banner_filename = VAR_4 or '_login_disclaimer_banner.html'\n""]",0
"[""def FUNC_2(VAR_2, VAR_0, VAR_1):...\n"", ""VAR_1.execute(\n    'SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};'\n    .format(VAR_2=id, VAR_0=playlist_id))\n"", ""VAR_9 = VAR_1.fetchone()\n"", ""return VAR_9\n""]",1
"[""def __bool__(self):...\n"", ""return bool(self.updated_input or self.missing_output or self.forced or\n    self.updated_input_run or self.noio or self.nooutput)\n""]",0
"[""@property...\n"", ""if self._snakefile is None:\n"", ""return os.path.abspath(os.path.join(self.workdir, 'Snakefile'))\n"", ""if not os.path.isabs(self._snakefile):\n"", ""return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile))\n"", ""return self._snakefile\n""]",0
"[""def FUNC_1(VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_13 = sqlite3.connect(VAR_8)\n"", ""logging.error(e)\n"", ""VAR_20 = VAR_13.cursor()\n"", ""sys.exit('No database connection could be established.')\n"", ""return VAR_13, VAR_20\n""]",0
"[""def FUNC_24(VAR_16, VAR_22):...\n"", ""VAR_53 = (\n    \""select date from matches where scene='{}' order by date desc limit 1;\""\n    .format(VAR_22))\n"", ""VAR_54 = VAR_16.exec(VAR_53)\n"", ""VAR_23 = VAR_54[0][0]\n"", ""VAR_62 = datetime.datetime.today().strftime('%Y-%m-%d')\n"", ""VAR_63, VAR_64, VAR_65 = VAR_62.split('-')\n"", ""VAR_66, VAR_67, VAR_68 = VAR_23.split('-')\n"", ""if VAR_63 > VAR_66 or VAR_64 > VAR_67:\n"", ""VAR_23 = FUNC_22(VAR_23)\n"", ""return VAR_23\n""]",1
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_1.status_code, 200)\n""]",1
"[""def FUNC_35(self, VAR_14):...\n"", ""VAR_20 = self.get_related_model(VAR_14)\n"", ""return self.session.query(VAR_20).all()\n""]",0
"[""def FUNC_3(VAR_2):...\n"", ""VAR_6 = (\n    \""\""\""SELECT user_id, content, created_at, section_id\nFROM messages\nWHERE dialog_id='%s'\""\""\""\n     % VAR_2)\n"", ""return sql_execute(VAR_6)\n""]",1
"[""def FUNC_13(VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_6, CLASS_1):\n"", ""return VAR_6.literal\n"", ""if isinstance(VAR_6, six.string_types):\n"", ""VAR_6 = VAR_6.replace(\""'\"", \""\\\\'\"")\n"", ""if isinstance(VAR_6, datetime):\n"", ""return u\""'{}'\"".format(VAR_6)\n"", ""VAR_6 = VAR_6.replace(tzinfo=None, microsecond=0)\n"", ""if isinstance(VAR_6, VAR_59):\n"", ""return \""toDateTime('{}')\"".format(VAR_6.isoformat())\n"", ""return \""toDate('{}')\"".format(VAR_6.isoformat())\n"", ""if isinstance(VAR_6, (list, tuple)):\n"", ""return u'({})'.format(', '.join(FUNC_13(v) for v in VAR_6))\n"", ""if isinstance(VAR_6, numbers.Number):\n"", ""return str(VAR_6)\n"", ""if VAR_6 is None:\n"", ""return ''\n""]",1
"[""def FUNC_1(VAR_5, VAR_6, VAR_7, VAR_8, VAR_9):...\n"", ""VAR_3.execute(\n    \""UPDATE players SET ELO = %i, Played = %i, W = %i, L = %i WHERE Name = '%s' COLLATE NOCASE\""\n     % (VAR_6, VAR_7, VAR_8, VAR_9, VAR_5))\n"", ""VAR_2.commit()\n""]",1
"[""def FUNC_5(self, VAR_3, VAR_1):...\n"", ""VAR_5 = 'insert into comment_like values(%d,%d);' % (VAR_1, VAR_3)\n"", ""VAR_6 = sql.insertDB(self.conn, VAR_5)\n"", ""return VAR_6\n""]",1
"[""def FUNC_4(self):...\n"", ""self.init()\n"", ""VAR_14 = []\n"", ""VAR_15 = [{'name': 'ID', 'value': self.params.facility_name}]\n"", ""VAR_2 = model.Report.all().ancestor(self.version).filter('facility_name =',\n    self.params.facility_name).order('-timestamp').get()\n"", ""for VAR_6 in self.facility_type.attribute_names:\n"", ""VAR_3 = self.attributes[VAR_6]\n"", ""self.render('templates/edit.html', facility=self.facility, VAR_14=fields,\n    VAR_15=readonly_fields, params=self.params, authorization=self.auth and\n    self.auth.description or 'anonymous', logout_url=users.\n    create_logout_url('/'))\n"", ""if VAR_6 in self.readonly_attribute_names:\n"", ""VAR_15.append({'name': get_message(self.version, 'attribute_name', VAR_6),\n    'value': getattr(VAR_2, VAR_6, None)})\n"", ""VAR_14.append({'name': get_message(self.version, 'attribute_name', VAR_6),\n    'type': VAR_3.type, 'input': FUNC_0(self.version, VAR_2, VAR_3)})\n""]",1
"[""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""return FUNC_0('Hent {0} fra databasen og returner som JSON'.format(VAR_5))\n""]",0
"[""def FUNC_0(self, VAR_1):...\n"", ""VAR_15 = self.session.get(VAR_1)\n"", ""for cookie in VAR_15.cookies:\n"", ""if cookie.name == '_xsrf':\n"", ""self.xsrf_token = cookie.value\n""]",1
"[""def FUNC_2(VAR_0, VAR_1, VAR_9):...\n"", ""VAR_13 = sqlite3.connect(VAR_1)\n"", ""for VAR_38 in VAR_9:\n"", ""VAR_26 = list(VAR_38.startnodes)\n"", ""VAR_13.commit()\n"", ""if len(VAR_38.startnodes) == 1:\n"", ""VAR_13.close()\n"", ""VAR_31 = VAR_26[0]\n"", ""if len(VAR_38.startnodes) == 2:\n"", ""VAR_32 = ''\n"", ""VAR_31 = VAR_26[0]\n"", ""assert False\n"", ""if VAR_38.propertytype is None:\n"", ""VAR_32 = VAR_26[1]\n"", ""VAR_42 = ''\n"", ""VAR_42 = VAR_38.propertytype\n"", ""if VAR_31 == '':\n"", ""if VAR_8 == '':\n"", ""VAR_13.execute(\""INSERT OR IGNORE INTO edge VALUES ('\"" + VAR_38.documentid +\n    \""', '\"" + VAR_38.documentclassname + \""', '\"" + VAR_38.__class__.__name__ +\n    \""', '\"" + VAR_38.edgeid + \""', \"" + \""'\"" + VAR_31 + \""', '\"" + VAR_32 +\n    \""', '\"" + VAR_38.endnode + \""', '\"" + VAR_38.propertyownerid + \""', '\"" +\n    VAR_38.propertyname + \""', '\"" + str(VAR_38.propertyvalue) + \""', '\"" +\n    VAR_42 + \""')\"")\n"", ""VAR_8 = VAR_38.edgeid\n"", ""assert VAR_7 == False or VAR_8 == VAR_38.edgeid\n"", ""VAR_7 = True\n""]",1
"[""def FUNC_21(self, VAR_14):...\n"", """"]",0
"[""from pyudev import Context\n"", ""from telnetlib import Telnet\n"", ""from termcolor import colored\n"", ""from threading import Thread\n"", ""from time import sleep, time\n"", ""from random import randrange, uniform\n"", ""from socket import AF_INET, SOCK_STREAM, socket\n"", ""from subprocess import DEVNULL, Popen\n"", ""from dut import dut\n"", ""from error import DrSEUsError\n"", ""from jtag_targets import devices\n"", ""from targets import choose_register, choose_target\n"", ""VAR_0 = {'844301CF3718': '210248585809', '8410A3D8431C': '210248657631',\n    '036801551E13': '210248691084', '036801961420': '210248691092'}\n"", ""def FUNC_0():...\n"", ""VAR_1 = Context().list_devices(ID_VENDOR_ID='0403', ID_MODEL_ID='6014')\n"", ""VAR_2 = []\n"", ""for debugger in VAR_1:\n"", ""if 'DEVLINKS' not in debugger:\n"", ""return VAR_2\n"", ""VAR_2.append(debugger['ID_SERIAL_SHORT'])\n""]",0
"[""def FUNC_5(self):...\n"", """"]",0
"[""def FUNC_5(VAR_12):...\n"", ""def FUNC_9(self, *VAR_15, **VAR_75):...\n"", ""for validator in VAR_0:\n"", ""if VAR_102.method == 'POST' and hasattr(self, 'ajax_login_redirect'):\n"", ""return FUNC_9\n"", ""validator(VAR_75)\n"", ""VAR_16 = self.build_arg_list(VAR_12, VAR_75)\n"", ""return self.ajax_login_redirect('/')\n"", ""return self.intermediate_redirect('/login')\n"", ""for VAR_110, validator in VAR_1.iteritems():\n"", ""VAR_16[VAR_110] = validator(VAR_75)\n"", ""return VAR_12(self, *VAR_15, **kw)\n""]",0
"[""from django.db import models\n"", ""from .common_info import CommonInfo\n"", ""VAR_0 = models.CharField(max_length=100, blank=False, null=False)\n"", ""VAR_1 = models.TextField(null=True, blank=True)\n"", ""VAR_2 = models.ForeignKey('Taxonomy', on_delete=models.CASCADE, null=True,\n    blank=True)\n"", ""VAR_3 = models.ForeignKey('TaxonomySource', on_delete=models.CASCADE)\n"", ""VAR_4 = models.CharField(max_length=40, null=True, blank=True)\n"", ""VAR_5 = models.ForeignKey('auth.User', on_delete=models.SET_DEFAULT, default=1)\n"", ""VAR_6 = models.ManyToManyField('PUC', through='TaxonomyToPUC')\n"", ""VAR_7 = 'Taxonomies'\n"", ""def __str__(self):...\n"", ""return str(self.title)\n""]",1
"[""from jupyterhub.auth import Authenticator\n"", ""from tornado import gen\n"", ""from traitlets import Unicode, Int\n"", ""import pymysql\n"", ""from passlib.hash import phpass\n"", ""VAR_0 = Unicode('localhost', config=True, help=\n    'URL or IP address of the database server')\n"", ""VAR_1 = Int(3306, min=1, max=65535, config=True, help=\n    'port of the database server')\n"", ""VAR_2 = Unicode(config=True, help='user name to access your wordpress database'\n    )\n"", ""VAR_3 = Unicode(config=True, help='password to access your wordpress database')\n"", ""VAR_4 = Unicode('wordpress', config=True, help=\n    'database name that your wordpress uses')\n"", ""VAR_5 = Unicode('wp_', config=True, help='table prefix for your wordpress')\n"", ""@gen.coroutine...\n"", ""VAR_8 = {}\n"", ""VAR_8['host'] = self.dbhost\n"", ""VAR_8['user'] = self.dbuser\n"", ""VAR_8['password'] = self.dbpassword\n"", ""VAR_8['db'] = self.dbname\n"", ""VAR_8['charset'] = 'utf8mb4'\n"", ""VAR_8['cursorclass'] = pymysql.cursors.Cursor\n"", ""VAR_9 = 'SELECT user_pass FROM {0}users WHERE user_login = \""{1}\""'.format(self\n    .table_prefix, VAR_7['username'])\n"", ""if cursor.execute(VAR_9) == 0:\n"", ""return None\n"", ""if phpass.verify(VAR_7['password'], cursor.fetchone()[0]) == True:\n"", ""return VAR_7['username']\n"", ""return None\n""]",1
"[""def FUNC_39(VAR_101):...\n"", ""VAR_101.params = VAR_71, VAR_72\n"", ""return VAR_101\n""]",0
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""def __new__(VAR_3):...\n"", ""if CLASS_0.instance is None:\n"", ""CLASS_0.instance = object.__new__(VAR_3)\n"", ""return CLASS_0.instance\n""]",0
"[""def FUNC_27(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.log_info('Creating archive of sosreports...')\n"", ""self.create_sos_archive()\n"", ""if self.archive:\n"", ""self.logger.info('Archive created as %s' % self.archive)\n"", ""self.cleanup()\n"", ""self.console.info(\n    \""\""\""\nThe following archive has been created. Please provide it to your support team.\""\""\""\n    )\n"", ""self.console.info('    %s' % self.archive)\n""]",0
"[""def __init__(self):...\n"", ""super(CLASS_0, self).__init__()\n"", ""self.path = ['']\n"", ""@defer.inlineCallbacks...\n"", ""self.obj_path = yield db.transact(lambda : [db.ref(db.get_root()['oms_root'])]\n    )()\n"", ""FUNC_10()\n"", ""self.tokenizer = CommandLineTokenizer()\n""]",0
"[""def FUNC_2(self, VAR_0, VAR_1):...\n"", ""if VAR_1 and self.db.check_date(VAR_1):\n"", ""return self.db.revenue(VAR_1)\n"", ""if VAR_1:\n"", ""return '    .'\n"", ""if VAR_0 == '':\n"", ""return self.db.revenue()\n"", ""return '!   .'\n""]",0
"[""\""\""\""string\""\""\""\n"", ""VAR_0 = {}\n"", ""\""\""\""Configuration of remote applications.\""\""\""\n"", ""VAR_1 = 'oauth_token'\n"", ""\""\""\""Session key prefix used when storing the access token for a remote app.\""\""\""\n""]",0
"[""def FUNC_2(self, VAR_9, VAR_10='user_db'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14, VAR_18, VAR_24, VAR_25 = VAR_9\n"", ""VAR_26 = 'string' % {'database': VAR_10, 'user_freq': VAR_25, 'mlen': len(\n    VAR_14), 'clen': len(VAR_18), 'input_phrase': VAR_14, 'phrase': VAR_18}\n"", ""self.db.execute(VAR_26)\n"", ""self.db.commit()\n""]",1
"[""def FUNC_11(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_24 = self.getfile(VAR_21)\n"", ""return False\n"", ""return VAR_24[VAR_2] == VAR_13\n""]",0
"[""from flask import abort, request\n"", ""from functools import wraps\n"", ""import cx_Oracle\n"", ""import re\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not hasattr(VAR_1, 'db'):\n"", ""VAR_13 = cx_Oracle.makedsn(VAR_0.config['DB_SERVER'], VAR_0.config[\n    'DB_PORT'], VAR_0.config['DB_SID'])\n"", ""return VAR_1.db\n"", ""VAR_1.db = cx_Oracle.connect(VAR_0.config['DB_USER'], VAR_0.config['DB_PWD'\n    ], VAR_13)\n""]",1
"[""def __len__(self):...\n"", ""return len(self._flattened)\n""]",0
"[""def FUNC_13(self, VAR_10=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = self.resource_type\n"", ""VAR_21 = self.session.query(VAR_20, count().over())\n"", ""VAR_22 = self._query_arg('limit', int)\n"", ""VAR_23 = self._query_arg('offset', int)\n"", ""VAR_24 = self._query_arg('show_deleted', bool, False)\n"", ""VAR_25 = self._query_arg('search')\n"", ""VAR_26 = self._query_arg('regex', bool, False)\n"", ""VAR_27 = self._query_arg('search_fields', FUNC_13, VAR_4=['title'])\n"", ""VAR_28 = self._query_arg('lang')\n"", ""VAR_29 = ['{}:DESC'.format(self.default_sort_column_name)]\n"", ""VAR_30 = (element.split(':') for element in self._query_arg('order_by',\n    FUNC_13, VAR_4=default_sort))\n"", ""VAR_31 = self._query_arg('type')\n"", ""if VAR_25 is not None:\n"", ""for search_field in VAR_27:\n"", ""if not VAR_24:\n"", ""VAR_21 = column_search(VAR_21, VAR_20=model_cls, column_name=search_field,\n    VAR_25=search_term, language=search_lang, VAR_26=regex)\n"", ""VAR_21 = VAR_21.filter(VAR_20.deleted == false())\n"", ""if VAR_31 is not None:\n"", ""VAR_21 = VAR_21.filter(VAR_20.type_constraint == VAR_31)\n"", ""if VAR_10 is not None:\n"", ""VAR_21 = VAR_21.filter(VAR_10)\n"", ""for attribute_name, VAR_41 in VAR_30:\n"", ""if VAR_22 is not None:\n"", ""VAR_40 = getattr(VAR_20, attribute_name)\n"", ""VAR_40 = text('{} {} NULLS LAST'.format(attribute_name, VAR_41))\n"", ""VAR_21 = VAR_21.order_by(VAR_40)\n"", ""VAR_21 = VAR_21.limit(VAR_22)\n"", ""if VAR_23 is not None:\n"", ""VAR_41 = VAR_41.lower()\n"", ""VAR_21 = VAR_21.offset(VAR_23)\n"", ""VAR_32 = VAR_21.all()\n"", ""if VAR_41 == 'asc':\n"", ""if VAR_32:\n"", ""VAR_40 = VAR_40.asc()\n"", ""if VAR_41 == 'desc':\n"", ""VAR_36 = VAR_32[0][1]\n"", ""return 0, []\n"", ""VAR_40 = VAR_40.nullslast()\n"", ""VAR_40 = VAR_40.desc()\n"", ""VAR_18 = [res[0] for res in VAR_32]\n"", ""return VAR_36, self._specific_fields(VAR_18, VAR_8=False)\n""]",0
"[""\""\""\""string\""\""\""\n"", ""from __future__ import print_function\n"", ""import sys\n"", ""import beamr.debug as debug\n"", ""from beamr import setup_arg, cli_name\n"", ""from docopt import docopt\n"", ""def FUNC_0():...\n"", ""VAR_0 = 'string' % (setup_arg['name'], setup_arg['description'], cli_name,\n    cli_name, cli_name)\n"", ""VAR_1 = docopt(VAR_0, version=setup_arg['version'])\n"", ""if VAR_1['--verbose']:\n"", ""debug.verbose = True\n"", ""if VAR_1['--quiet']:\n"", ""debug.quiet = True\n"", ""debug.debug('args:', str(VAR_1).replace('\\n', ''))\n"", ""from beamr.interpreters.config import Config\n"", ""if VAR_1['--edit-config']:\n"", ""return Config.editUserConfig(VAR_1['<editor>'])\n"", ""VAR_2 = None\n"", ""if not VAR_1['--no-pdf']:\n"", ""VAR_2 = [VAR_1['--pdflatex'], '-shell-escape']\n"", ""if VAR_1['<input-file>']:\n"", ""if VAR_1['<output-file>']:\n"", ""sys.stdin = open(VAR_1['<input-file>'], 'r')\n"", ""if VAR_1['<output-file>']:\n"", ""VAR_4 = VAR_1['<output-file>']\n"", ""sys.stdout = open(VAR_1['<output-file>'], 'w')\n"", ""VAR_3 = {}\n"", ""VAR_1['<output-file>'] = None\n"", ""if VAR_1['--safe']:\n"", ""VAR_5 = VAR_4.rfind('/') + 1\n"", ""VAR_3['safe'] = True\n"", ""if VAR_1['--unsafe']:\n"", ""if VAR_5 > 0:\n"", ""Config.fromCmdline(VAR_1['--config'], **cmdlineSpecial)\n"", ""VAR_3['safe'] = False\n"", ""VAR_2.append('-output-directory=' + VAR_4[:VAR_5])\n"", ""VAR_2.append('-jobname=' + VAR_4[VAR_5:])\n"", ""from beamr.interpreters import Document\n"", ""VAR_6 = Document(sys.stdin.read())\n"", ""VAR_7 = str(VAR_6)\n"", ""if VAR_2:\n"", ""from subprocess import Popen, PIPE\n"", ""print(VAR_7)\n"", ""VAR_8 = {'stdin': PIPE}\n"", ""if __name__ == '__main__':\n"", ""if debug.quiet:\n"", ""sys.exit(FUNC_0())\n"", ""VAR_8.update({'stdout': PIPE, 'stderr': PIPE})\n"", ""VAR_9 = Popen(VAR_2, **runkwarg)\n"", ""VAR_9.communicate(bytes(VAR_7, encoding='utf-8'))\n"", ""VAR_9.communicate(bytes(VAR_7))\n"", ""VAR_9.stdin.close()\n"", ""VAR_10 = VAR_9.wait()\n"", ""if VAR_10:\n"", ""debug.err('Fatal: pdflatex exited with nonzero status', VAR_10)\n"", ""return VAR_10\n""]",1
"[""def FUNC_0(self):...\n"", ""return self.get_serializer_class().setup_eager_loading(Locality.objects.all\n    ().order_by('-modified'))\n""]",0
"[""def FUNC_19(self):...\n"", ""VAR_56 = frappe.get_hooks('permission_query_conditions', {}).get(self.\n    doctype, [])\n"", ""if VAR_56:\n"", ""VAR_33 = []\n"", ""for method in VAR_56:\n"", ""VAR_70 = frappe.call(frappe.get_attr(method), self.user)\n"", ""return ' and '.join(VAR_33) if VAR_33 else None\n"", ""if VAR_70:\n"", ""VAR_33.append(VAR_70)\n""]",0
"[""def FUNC_7(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""VAR_3 = {'name': 'fakesnap', 'volume_name': 'fakevolume_name'}\n"", ""VAR_1 = {'name': self.volume_name}\n"", ""self.driver._eql_execute('volume', 'select', VAR_3['volume_name'],\n    'snapshot', 'select', VAR_3['name'], 'clone', VAR_1['name']).AndReturn([\n    'iSCSI target name is %s.' % self.fake_iqn])\n"", ""self.mox.ReplayAll()\n"", ""VAR_2 = self.driver.create_volume_from_snapshot(VAR_1, VAR_3)\n"", ""self.assertEqual(VAR_2, self._model_update)\n""]",0
"[""def FUNC_7(self):...\n"", ""self.__use_lb_name = 'katotest-lb-' + self.test_id\n"", ""self.__use_lb_hc_name = '%s-hc' % self.__use_lb_name\n"", ""self.__use_lb_tp_name = '%s-tp' % self.__use_lb_name\n"", ""self.__use_lb_target = '{0}/targetPools/{1}'.format(self.bindings[\n    'TEST_GCE_REGION'], self.__use_lb_tp_name)\n"", ""VAR_25 = 123\n"", ""VAR_26 = 4\n"", ""VAR_27 = 5\n"", ""VAR_28 = 78\n"", ""VAR_29 = '/' + self.__use_lb_target\n"", ""VAR_31 = {'checkIntervalSec': VAR_25, 'healthyThreshold': VAR_26,\n    'unhealthyThreshold': VAR_27, 'timeoutSec': VAR_28, 'requestPath': VAR_29}\n"", ""VAR_21 = self.agent.type_to_payload('upsertGoogleLoadBalancerDescription',\n    {'healthCheck': VAR_31, 'region': self.bindings['TEST_GCE_REGION'],\n    'credentials': self.bindings['GCE_CREDENTIALS'], 'loadBalancerName':\n    self.__use_lb_name})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Forwarding Rules Added', retryable_for_secs=30\n    ).list_resources('forwarding-rules').contains_path_value('name', self.\n    __use_lb_name).contains_path_value('target', self.__use_lb_target)\n"", ""VAR_20.new_clause_builder('Target Pool Added', retryable_for_secs=15\n    ).list_resources('target-pools').contains_path_value('name', self.\n    __use_lb_tp_name)\n"", ""VAR_20.new_clause_builder('Health Check Added', retryable_for_secs=15\n    ).list_resources('http-health-checks').contains_pred_list([jc.\n    PathContainsPredicate('name', self.__use_lb_hc_name), jc.\n    PathContainsPredicate(None, VAR_31)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer', data=payload, VAR_29='ops'), contract=builder.\n    build())\n""]",1
"[""@mock.patch('requests.post', FUNC_0)...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = self.test_release()\n"", ""VAR_15 = Release.objects.get(uuid=release3['uuid'])\n"", ""self.assertEqual(str(VAR_15), '{}-v3'.format(VAR_11['app']))\n""]",0
"[""def FUNC_9(self):...\n"", ""subprocess.call(['touch', VAR_2])\n"", ""return None\n""]",0
"[""from flask import Flask, url_for, render_template, request, make_response, jsonify, json, Response\n"", ""import requests\n"", ""from requests_oauthlib import OAuth1\n"", ""from knowyourgov import app\n"", ""from knowyourgov.models import Politician\n"", ""from knowyourgov.scripts import insert_politicians_in_db\n"", ""from knowyourgov.scripts.scraping import scrapers\n"", ""\""\""\""Home page\n\""\""\""\n"", ""@app.route('/')...\n"", ""VAR_6 = Politician.all()\n"", ""VAR_6.order('-search_count')\n"", ""VAR_7 = []\n"", ""VAR_8 = 0\n"", ""for VAR_2 in VAR_6:\n"", ""VAR_7.append(VAR_2)\n"", ""return render_template('home.html', VAR_7=politicians)\n"", ""VAR_8 = VAR_8 + 1\n"", ""if VAR_8 == 8:\n""]",1
"[""def FUNC_2(VAR_6=None):...\n"", ""VAR_10 = argparse.ArgumentParser(description=\n    'correct raut page/model import paths to webstr format')\n"", ""VAR_10.add_argument('directory', help=\n    'file path to directory with python files to be edited')\n"", ""VAR_10.add_argument('-d', '--dry-run', action='store_true')\n"", ""VAR_11 = VAR_10.parse_args()\n"", ""if not os.path.isdir(VAR_11.directory):\n"", ""print(\""error: '{0}' is not a directory\"".format(VAR_11.directory))\n"", ""for _, _, file_list in os.walk(VAR_11.directory):\n"", ""return 1\n"", ""VAR_12 = [fl for fl in file_list if FUNC_0(fl)]\n"", ""for python_file in VAR_12:\n"", ""for raut_module in VAR_0:\n"", ""FUNC_1(VAR_11.directory, raut_module, python_file, VAR_5=args.dry_run)\n""]",1
"[""@integration_solr...\n"", ""VAR_12 = VAR_2 + '/solr/possible.conflicts/admin/ping'\n"", ""VAR_13 = requests.get(VAR_12)\n"", ""assert VAR_13.status_code == 200\n""]",0
"[""def FUNC_0(VAR_2, VAR_3):...\n"", ""VAR_4 = list()\n"", ""VAR_5 = list()\n"", ""VAR_6 = list()\n"", ""def FUNC_4(VAR_2):...\n"", ""VAR_8 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) +\n    '\\\\users\\\\' + VAR_3 + '.db')\n"", ""VAR_9 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n"", ""VAR_10 = VAR_8.cursor()\n"", ""VAR_11 = VAR_9.cursor()\n"", ""VAR_11.execute('SELECT * FROM ' + VAR_2)\n"", ""VAR_18 = list()\n"", ""VAR_12 = VAR_11.fetchone()\n"", ""while VAR_12 != None:\n"", ""VAR_10.execute(\""SELECT * FROM result WHERE problem = '\"" + str(VAR_12[0]) +\n    \""' AND diff = '\"" + str(VAR_12[1]) + \""' AND NOT verdict = 'OK'\"")\n"", ""VAR_8.close()\n"", ""VAR_30 = VAR_10.fetchone()\n"", ""VAR_9.close()\n"", ""if VAR_30 != None and VAR_30 in VAR_4:\n"", ""return VAR_18\n"", ""VAR_18.append(VAR_30)\n"", ""VAR_12 = VAR_11.fetchone()\n""]",1
"[""def __init__(self, VAR_0):...\n"", ""VAR_3 = pymysql.connect(host='localhost', user='root', password='', VAR_0=\n    db, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor,\n    autocommit=True)\n"", ""self.connection = VAR_3\n""]",1
"[""VAR_0 = True\n"", ""import psycopg2 as dbi\n"", ""from MiscUtils import NoDefault\n"", ""import psycopg as dbi\n"", ""VAR_0 = False\n"", ""from psycopg2 import Warning, DatabaseError\n"", ""from MiscUtils.MixIn import MixIn\n"", ""from psycopg import Warning, DatabaseError\n"", ""import pgdb as dbi\n"", ""from psycopg2.extensions import QuotedString\n"", ""from MiddleKit.Run.ObjectKey import ObjectKey\n"", ""from psycopg.extensions import QuotedString\n"", ""from pgdb import Warning, DatabaseError\n"", ""from MiddleObject import MiddleObject\n"", ""def FUNC_12(VAR_15):...\n"", ""from SQLObjectStore import SQLObjectStore, UnknownSerialNumberError\n"", ""return \""'%s'\"" % VAR_15.replace('\\\\', '\\\\\\\\').replace(\""'\"", \""''\"")\n"", ""\""\""\""string\""\""\""\n"", ""def FUNC_0(self, VAR_1, VAR_2=False):...\n"", ""if not VAR_1.get('database'):\n"", ""VAR_1['database'] = self._model.sqlDatabaseName()\n"", ""def FUNC_1(self):...\n"", ""VAR_1 = self._dbArgs.copy()\n"", ""self.augmentDatabaseArgs(VAR_1)\n"", ""return self.dbapiModule().connect(**args)\n""]",0
"[""import io\n"", ""import time\n"", ""from cauldron.cli.threads import abort_thread\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0):...\n"", ""self.active = False\n"", ""self.bytes_buffer = io.BytesIO()\n"", ""self.redirection_source = VAR_0\n"", ""self.last_write_time = 0\n"", ""super(CLASS_0, self).__init__(buffer=self.bytes_buffer, encoding=\n    redirection_source.encoding, write_through=True)\n"", ""@property...\n"", ""if self.redirection_source.encoding:\n"", ""return self.redirection_source.encoding\n"", ""return 'utf8'\n""]",1
"[""@api.public...\n"", ""VAR_6.assertEqual(VAR_5, api.get_current_identity())\n"", ""self.response.write('OK')\n""]",0
"[""def FUNC_1(VAR_2, VAR_3):...\n"", ""VAR_10 = sqlite3.connect(VAR_1)\n"", ""VAR_11 = VAR_10.cursor()\n"", ""VAR_11.execute(\n    'SELECT user_id, password_hash, salt FROM UserData WHERE username = ?',\n    [VAR_2])\n"", ""VAR_12 = VAR_11.fetchone()\n"", ""if not VAR_12:\n"", ""return None\n"", ""VAR_13 = VAR_12[0]\n"", ""VAR_9 = VAR_12[1]\n"", ""VAR_5 = VAR_12[2]\n"", ""VAR_4 = None\n"", ""if FUNC_5(VAR_3, VAR_5) == VAR_9:\n"", ""VAR_4 = str(VAR_6.uuid4())\n"", ""VAR_10.close()\n"", ""VAR_11.execute('UPDATE UserData SET session_id = ? WHERE user_id = ?', (\n    VAR_4, VAR_13))\n"", ""return VAR_4, VAR_18\n"", ""print('SID: ' + VAR_4)\n"", ""VAR_10.commit()\n"", ""VAR_11.execute('SELECT secure_name, uuid_filename FROM Notes WHERE user_id = ?'\n    , [VAR_13])\n"", ""VAR_18 = []\n"", ""VAR_19 = VAR_11.fetchall()\n"", ""for VAR_17 in VAR_19:\n"", ""VAR_18.append({'file_id': VAR_17[1].split('.')[0], 'name': VAR_17[0]})\n""]",1
"[""from django.db import models\n"", ""from .common_info import CommonInfo\n"", ""from django.core.exceptions import ValidationError\n"", ""from .extracted_text import ExtractedText\n"", ""from .unit_type import UnitType\n"", ""from .weight_fraction_type import WeightFractionType\n"", ""from .raw_chem import RawChem\n"", ""def FUNC_0(VAR_0):...\n"", ""if VAR_0 < 1 or VAR_0 > 999:\n"", ""VAR_1 = models.CharField('Raw CAS', max_length=100, null=True, blank=True)\n"", ""VAR_2 = models.CharField('Raw chemical name', max_length=500, null=True,\n    blank=True)\n"", ""VAR_3 = models.CharField('Raw minimum composition', max_length=100, null=\n    True, blank=True)\n"", ""VAR_4 = models.CharField('Raw maximum composition', max_length=100, null=\n    True, blank=True)\n"", ""VAR_5 = models.ForeignKey(UnitType, on_delete=models.PROTECT)\n"", ""VAR_6 = models.CharField('Reported functional use', max_length=100, null=\n    True, blank=True)\n"", ""VAR_7 = models.ForeignKey(WeightFractionType, on_delete=models.PROTECT,\n    null=True, default='1')\n"", ""VAR_8 = models.PositiveIntegerField('Ingredient rank', null=True, blank=\n    True, validators=[validate_ingredient_rank])\n"", ""VAR_9 = models.CharField('Raw central composition', max_length=100, null=\n    True, blank=True)\n"", ""def __str__(self):...\n"", ""return str(self.raw_chem_name) if self.raw_chem_name else ''\n""]",1
"[""def FUNC_6(self, VAR_66, VAR_23):...\n"", ""if VAR_66:\n"", ""VAR_103 = cache.get(VAR_100(self.cache_prefix + '_' + VAR_66))\n"", ""VAR_101.errors.add(errors.EXPIRED)\n"", ""VAR_15 = Account._byID(VAR_103, data=True)\n"", ""return None\n"", ""if VAR_23 and VAR_15.name.lower() != VAR_23.lower():\n"", ""VAR_101.errors.add(errors.BAD_USERNAME)\n"", ""if VAR_15:\n"", ""return VAR_15\n""]",0
"[""def FUNC_6(self, VAR_44, VAR_50):...\n"", ""if not FUNC_2(VAR_44):\n"", ""return self.error()\n"", ""if VAR_50 != VAR_44:\n"", ""return self.error(errors.BAD_PASSWORD_MATCH)\n"", ""return VAR_44\n""]",0
"[""def FUNC_3(self, VAR_1, VAR_3, VAR_4):...\n"", ""if VAR_3['power'] > 0:\n"", ""VAR_17 = VAR_3['source']['serial_id']\n"", ""VAR_20 = 'string' % (VAR_1, VAR_17, VAR_3['power'], VAR_4 + VAR_3['energy'])\n"", ""self.c.execute(VAR_20)\n""]",1
"[""def FUNC_9(self, VAR_11, VAR_3):...\n"", ""VAR_20 = set()\n"", ""VAR_18 = VAR_11['rules']\n"", ""for VAR_37 in VAR_18:\n"", ""VAR_8 = VAR_3['rules'][VAR_37]\n"", ""return VAR_20\n"", ""VAR_20 |= FUNC_2(VAR_8, VAR_3)\n""]",0
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not self.contains('ynh_die') and not self.contains('exit'):\n"", ""return\n"", ""VAR_29 = ('cp', 'mkdir', 'rm', 'chown', 'chmod', 'apt-get', 'apt',\n    'service', 'find', 'sed', 'mysql', 'swapon', 'mount', 'dd', 'mkswap',\n    'useradd')\n"", ""VAR_30 = []\n"", ""for VAR_43 in self.lines:\n"", ""VAR_43 = ' '.join(VAR_43)\n"", ""for modifying_cmd in VAR_29:\n"", ""if 'ynh_die' in VAR_43 or 'exit' in VAR_43:\n"", ""if any(modifying_cmd in VAR_43 for VAR_43 in VAR_30):\n"", ""VAR_30.append(VAR_43)\n"", ""FUNC_4('string' % modifying_cmd, False)\n"", ""return\n""]",0
"[""def FUNC_25(VAR_21):...\n"", ""return [VAR_15._select_endpoint() for i in range(VAR_21)]\n""]",0
"[""def FUNC_0(VAR_0, VAR_1, VAR_2):...\n"", ""VAR_4 = VAR_0.cursor()\n"", ""VAR_5 = 'ALTER TABLE Presets DROP COLUMN id;'\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = (\n    'ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;'\n    )\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_6 = Table('Presets')\n"", ""VAR_7 = MySQLQuery.into(VAR_6).columns('querval', 'description').insert(VAR_1,\n    VAR_2)\n"", ""print(VAR_7)\n"", ""VAR_5 = str(VAR_7)\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = 'ALTER TABLE Presets DROP COLUMN id;'\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = (\n    'ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;'\n    )\n"", ""VAR_4.execute(VAR_5)\n""]",1
"[""def FUNC_7(self):...\n"", ""return self.content\n""]",0
"[""@route('GET', '/-test/jquery-cookie.js', VAR_1=website)...\n"", ""get_current_http_response().set_header('Content-Type',\n    'text/javascript; charset=utf-8')\n"", ""return (as_path(__file__).dirname() / 'jquery-cookie.js').text()\n""]",0
"[""def FUNC_32(VAR_19):...\n"", ""return dict((expr, vimsupport.VimExpressionToPythonType(expr)) for expr in\n    VAR_19)\n""]",0
"[""def FUNC_1(VAR_0: str) ->str:...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = shlex.split(VAR_0)\n"", ""return subprocess.check_output(VAR_6).decode('utf-8').split('\\n')[0]\n""]",1
"[""def FUNC_6(VAR_1, VAR_5=''):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_18 = VAR_17(VAR_1.name)\n"", ""return VAR_16.pop(VAR_18, None)\n""]",0
"[""def FUNC_6(self):...\n"", ""self.respond_to_github('https://api.github.com/repos/org/repo', 'metadata bits'\n    )\n"", ""self.respond_to_github('https://api.github.com/repos/org/repo/contributors',\n    '[\""a\""]')\n"", ""self.app.get(util.ingest_commit_task('org', 'repo'), params={'commit':\n    'commit-sha', 'url': 'url'})\n"", ""VAR_0 = Library.get_by_id('org/repo')\n"", ""self.assertIsNotNone(VAR_0)\n"", ""self.assertIsNone(VAR_0.error)\n"", ""self.assertFalse(VAR_0.ingest_versions)\n"", ""VAR_2 = Version.get_by_id(parent=library.key, id='commit-sha')\n"", ""self.assertEqual(VAR_2.sha, 'commit-sha')\n"", ""self.assertEqual(VAR_2.url, 'url')\n"", ""VAR_1 = self.tasks.get_filtered_tasks()\n"", ""self.assertEqual(len(VAR_1), 1)\n"", ""self.assertEqual(VAR_1[0].url, util.ingest_version_task('org', 'repo',\n    'commit-sha'))\n""]",1
"[""def __str__(self):...\n"", ""return '%s resource' % self._meta.resource_name\n""]",0
"[""def FUNC_6(VAR_10):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return '/' + VAR_10[0][1:-1]\n""]",0
"[""def FUNC_8(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = kijiji_api.KijijiApi()\n"", ""VAR_20.login(VAR_0.username, VAR_0.password)\n"", ""VAR_21 = ''\n"", ""for line in open(VAR_0.inf_file, 'rt'):\n"", ""[VAR_24, VAR_25] = line.strip().rstrip('\\n').split('=')\n"", ""VAR_20.delete_ad_using_title(VAR_21)\n"", ""print('Did not find an existing ad with matching title, skipping ad deletion')\n"", ""sleep(180)\n"", ""if VAR_24 == 'postAdForm.title':\n"", ""print('Existing ad deleted before reposting')\n"", ""FUNC_4(VAR_0)\n"", ""VAR_21 = VAR_25\n""]",1
"[""def FUNC_1(self, VAR_5=None):...\n"", ""VAR_6 = request.get_json(force=True)\n"", ""Table.delete(VAR_5, VAR_6)\n"", ""VAR_8 = {'status': 'success', 'message': 'User deleted successfully.'}\n"", ""return make_response(jsonify(VAR_8)), 200\n""]",1
"[""def FUNC_2(VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return FUNC_3(VAR_5, 'unfreeze')\n""]",0
"[""def __exit__(self, VAR_12, VAR_13, VAR_14):...\n"", ""if self._observe is None:\n"", ""CLASS_2._current_context = None\n"", ""self.execute()\n""]",0
"[""def FUNC_5(self, VAR_0):...\n"", ""VAR_5 = ['GET', 'POST', 'PUT', 'DELETE', 'HEAD']\n"", ""VAR_6 = [m for m in VAR_5 if hasattr(self, 'render_%s' % m)] + ['OPTIONS']\n"", ""VAR_0.setHeader('Allow', ', '.join(VAR_6))\n"", ""from opennode.oms.endpoint.httprest.root import EmptyResponse\n"", ""return EmptyResponse\n""]",0
"[""def FUNC_12(VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12 = VAR_3.user\n"", ""VAR_38 = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]\n"", ""VAR_31 = FUNC_9(VAR_12)\n"", ""VAR_1.exception('Error fetching order history from Otto.')\n"", ""VAR_5 = {'auth': {}, 'duplicate_provider': None, 'nav_hidden': True,\n    'fields': {'country': {'options': list(countries)}, 'gender': {\n    'options': [(choice[0], _(choice[1])) for choice in UserProfile.\n    GENDER_CHOICES]}, 'language': {'options': released_languages()},\n    'level_of_education': {'options': [(choice[0], _(choice[1])) for choice in\n    UserProfile.LEVEL_OF_EDUCATION_CHOICES]}, 'password': {'url': reverse(\n    'password_reset')}, 'year_of_birth': {'options': VAR_38},\n    'preferred_language': {'options': all_languages()}, 'time_zone': {\n    'options': TIME_ZONE_CHOICES}}, 'platform_name': configuration_helpers.\n    get_value('PLATFORM_NAME', settings.PLATFORM_NAME),\n    'password_reset_support_link': configuration_helpers.get_value(\n    'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK) or\n    settings.SUPPORT_SITE_LINK, 'user_accounts_api_url': reverse(\n    'accounts_api', VAR_28={'username': user.username}),\n    'user_preferences_api_url': reverse('preferences_api', VAR_28={\n    'username': user.username}), 'disable_courseware_js': True,\n    'show_program_listing': ProgramsApiConfig.is_enabled(), 'order_history':\n    VAR_31}\n"", ""VAR_31 = []\n"", ""if third_party_auth.is_enabled():\n"", ""VAR_5['duplicate_provider'] = pipeline.get_duplicate_provider(messages.\n    get_messages(VAR_3))\n"", ""return VAR_5\n"", ""VAR_42 = pipeline.get_provider_user_states(VAR_12)\n"", ""VAR_5['auth']['providers'] = [{'id': state.provider.provider_id, 'name':\n    state.provider.name, 'connected': state.has_account, 'connect_url':\n    pipeline.get_login_url(state.provider.provider_id, pipeline.\n    AUTH_ENTRY_ACCOUNT_SETTINGS, redirect_url=reverse('account_settings')),\n    'accepts_logins': state.provider.accepts_logins, 'disconnect_url':\n    pipeline.get_disconnect_url(state.provider.provider_id, state.\n    association_id)} for state in VAR_42 if state.provider.\n    display_for_login or state.has_account]\n""]",0
"[""import mock\n"", ""import webapp2\n"", ""from google.appengine.api import users\n"", ""from handlers.flake import analyze_regression_range\n"", ""from handlers.flake.analyze_regression_range import AnalyzeRegressionRange\n"", ""from model.flake.master_flake_analysis import MasterFlakeAnalysis\n"", ""from waterfall.test import wf_testcase\n"", ""VAR_0 = webapp2.WSGIApplication([('/waterfall/analyze_regression_range',\n    AnalyzeRegressionRange)], debug=True)\n"", ""def FUNC_0(self):...\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('2', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput(None, '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput(None, None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput('a', '1', '100'))\n"", ""def FUNC_1(self):...\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(0, 0))\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(None, 0))\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(0, None))\n"", ""self.assertEqual((None, None), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(None, None))\n"", ""self.assertEqual((1, 2), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(1, 2))\n"", ""self.assertEqual((1, 2), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(2, 1))\n"", ""@mock.patch.object(users, 'is_current_user_admin', return_value=True)...\n"", ""VAR_2 = MasterFlakeAnalysis.Create('m', 'b', 123, 's', 't')\n"", ""VAR_2.put()\n"", ""self.mock_current_user(user_email='test@google.com')\n"", ""VAR_3 = self.test_app.get('/waterfall/analyze_regression_range', params={\n    'lower_bound_commit_position': 1, 'upper_bound_commit_position': 2,\n    'iterations_to_rerun': 100, 'key': analysis.key.urlsafe()})\n"", ""self.assertEqual(200, VAR_3.status_int)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import logging\n"", ""from datetime import timedelta\n"", ""import voluptuous as vol\n"", ""from homeassistant.components.sensor import PLATFORM_SCHEMA\n"", ""from homeassistant.const import TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN\n"", ""from homeassistant.helpers.entity import Entity\n"", ""from homeassistant.util import Throttle\n"", ""import homeassistant.helpers.config_validation as cv\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""VAR_1 = 'modules'\n"", ""VAR_2 = 'station'\n"", ""VAR_3 = ['netatmo']\n"", ""VAR_4 = timedelta(seconds=600)\n"", ""VAR_5 = {'temperature': ['Temperature', TEMP_CELSIUS, None,\n    DEVICE_CLASS_TEMPERATURE], 'co2': ['CO2', 'ppm', 'mdi:cloud', None],\n    'pressure': ['Pressure', 'mbar', 'mdi:gauge', None], 'noise': ['Noise',\n    'dB', 'mdi:volume-high', None], 'humidity': ['Humidity', '%', None,\n    DEVICE_CLASS_HUMIDITY], 'rain': ['Rain', 'mm', 'mdi:weather-rainy',\n    None], 'sum_rain_1': ['sum_rain_1', 'mm', 'mdi:weather-rainy', None],\n    'sum_rain_24': ['sum_rain_24', 'mm', 'mdi:weather-rainy', None],\n    'battery_vp': ['Battery', '', 'mdi:battery', None], 'battery_lvl': [\n    'Battery_lvl', '', 'mdi:battery', None], 'min_temp': ['Min Temp.',\n    TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp': ['Max Temp.',\n    TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle': ['Angle', '',\n    'mdi:compass', None], 'windangle_value': ['Angle Value', '',\n    'mdi:compass', None], 'windstrength': ['Strength', 'km/h',\n    'mdi:weather-windy', None], 'gustangle': ['Gust Angle', '',\n    'mdi:compass', None], 'gustangle_value': ['Gust Angle Value', '',\n    'mdi:compass', None], 'guststrength': ['Gust Strength', 'km/h',\n    'mdi:weather-windy', None], 'rf_status': ['Radio', '', 'mdi:signal',\n    None], 'rf_status_lvl': ['Radio_lvl', '', 'mdi:signal', None],\n    'wifi_status': ['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl': [\n    'Wifi_lvl', 'dBm', 'mdi:wifi', None]}\n"", ""VAR_6 = vol.Schema({vol.Required(cv.string): vol.All(cv.ensure_list, [vol.\n    In(VAR_5)])})\n"", ""VAR_7 = VAR_7.extend({vol.Optional(VAR_2): cv.string, vol.Optional(VAR_1):\n    VAR_6})\n"", ""def FUNC_0(VAR_8, VAR_9, VAR_10, VAR_11=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12 = VAR_8.components.netatmo\n"", ""VAR_13 = CLASS_1(VAR_12.NETATMO_AUTH, VAR_9.get(VAR_2, None))\n"", ""VAR_14 = []\n"", ""import pyatmo\n"", ""if VAR_1 in VAR_9:\n"", ""return None\n"", ""VAR_10(VAR_14, True)\n"", ""for VAR_16, monitored_conditions in VAR_9[VAR_1].items():\n"", ""for VAR_16 in VAR_13.get_module_names():\n"", ""\""\""\""Implementation of a Netatmo sensor.\""\""\""\n"", ""if VAR_16 not in VAR_13.get_module_names():\n"", ""for variable in VAR_13.station_data.monitoredConditions(VAR_16):\n"", ""def __init__(self, VAR_15, VAR_16, VAR_17):...\n"", ""VAR_0.error('Module name: \""%s\"" not found', VAR_16)\n"", ""for variable in monitored_conditions:\n"", ""if variable in VAR_5.keys():\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14.append(CLASS_0(VAR_13, VAR_16, variable))\n"", ""VAR_14.append(CLASS_0(VAR_13, VAR_16, variable))\n"", ""VAR_0.warning('Ignoring unknown var %s for mod %s', variable, VAR_16)\n"", ""self._name = 'Netatmo {} {}'.format(VAR_16, VAR_5[VAR_17][0])\n"", ""self.netatmo_data = VAR_15\n"", ""self.module_name = VAR_16\n"", ""self.type = VAR_17\n"", ""self._state = None\n"", ""self._device_class = VAR_5[self.type][3]\n"", ""self._icon = VAR_5[self.type][2]\n"", ""self._unit_of_measurement = VAR_5[self.type][1]\n"", ""VAR_20 = self.netatmo_data.station_data.moduleByName(module=module_name)['_id']\n"", ""self.module_id = VAR_20[1]\n"", ""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._name\n""]",1
"[""def FUNC_18(self, VAR_16, VAR_20):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_28 = ['volume', 'select', VAR_16['name'], 'access', 'create',\n    'initiator', VAR_20['initiator']]\n"", ""VAR_0.error(_('Failed to initialize connection to volume %s'), VAR_16['name'])\n"", ""if self.configuration.eqlx_use_chap:\n"", ""VAR_28.extend(['authmethod chap', 'username', self.configuration.\n    eqlx_chap_login])\n"", ""self._eql_execute(*VAR_28)\n"", ""VAR_47 = self._get_iscsi_properties(VAR_16)\n"", ""return {'driver_volume_type': 'iscsi', 'data': VAR_47}\n""]",1
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""while True:\n"", ""time.sleep(1)\n"", ""self.flush_profile_data()\n""]",1
"[""def FUNC_17(VAR_16):...\n"", ""VAR_0.info('Login Error for %s' % VAR_5.args['username'][0])\n"", ""VAR_0.info('%s' % VAR_16)\n"", ""VAR_5.setResponseCode(UNAUTHORIZED)\n"", ""return self._render_template(VAR_5, 'Invalid credentials')\n""]",0
"[""def FUNC_0(self):...\n"", ""if 'submitter' in self.request.arguments:\n"", ""return list(map(to_unicode, self.request.arguments['submitter']))\n""]",0
"[""@VAR_2.route('/matches_at_date')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_5 = request.args.get('tag', default=None)\n"", ""VAR_19 = request.args.get('date', default=None)\n"", ""if VAR_5 and VAR_19:\n"", ""VAR_21, VAR_22, VAR_23 = VAR_19.split('-')\n"", ""return ''\n"", ""VAR_34 = '12' if VAR_22 == '01' else str(int(VAR_22) - 1)\n"", ""VAR_34 = VAR_34.zfill(2)\n"", ""VAR_35 = str(int(VAR_21) - 1) if VAR_22 == '01' else VAR_21\n"", ""VAR_36 = '{}-{}-{}'.format(VAR_35, VAR_34, VAR_23)\n"", ""VAR_8 = (\n    \""select * from matches where (player1='{}' or player2='{}') and date<='{}' and date>='{}'\""\n    .format(VAR_5, VAR_5, VAR_19, VAR_36))\n"", ""VAR_7 = VAR_0.exec(VAR_8)\n"", ""return json.dumps(VAR_7)\n""]",1
"[""@commands.command()...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = discord.Embed(VAR_2='Fix broken TWL', VAR_3=discord.Color(10664672))\n"", ""VAR_7.set_author(name='Plailect', url=\n    'https://3ds.guide/troubleshooting#twl_broken')\n"", ""VAR_7.set_thumbnail(url='https://3ds.guide/images/bio-photo.png')\n"", ""VAR_7.url = 'https://3ds.guide/troubleshooting#twl_broken'\n"", ""VAR_7.description = (\n    'Instructions on how to fix a broken TWL after doing the guide')\n"", ""await self.bot.say('', VAR_7=embed)\n""]",1
"[""\""\""\""\nhttps://www.w3.org/TR/shacl/#core-components-value-type\n\""\""\""\n"", ""import abc\n"", ""import pyshacl.consts\n"", ""def __init__(self, VAR_0):...\n"", ""self.shape = VAR_0\n"", ""@classmethod...\n"", ""return NotImplementedError()\n""]",1
"[""def FUNC_10():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = FUNC_3('select * from player_static_view order by wins desc')\n"", ""VAR_10 = 0\n"", ""VAR_11 = len(VAR_9)\n"", ""VAR_12 = []\n"", ""while VAR_10 < VAR_11:\n"", ""VAR_12.append((VAR_9[VAR_10][0], VAR_9[VAR_10][1], VAR_9[VAR_10 + 1][0],\n    VAR_9[VAR_10 + 1][1]))\n"", ""return VAR_12\n"", ""VAR_10 += 2\n""]",0
"[""def FUNC_1():...\n"", ""return FUNC_0(5)\n""]",0
"[""def FUNC_15(self):...\n"", ""for VAR_7 in default_fields:\n"", ""if VAR_7 not in self.__dict__:\n"", ""for VAR_7 in self.get_valid_columns():\n"", ""self.__dict__[VAR_7] = None\n"", ""if VAR_7 in ('idx', 'docstatus') and self.__dict__[VAR_7] is None:\n"", ""if VAR_7 not in self.__dict__:\n"", ""self.__dict__[VAR_7] = 0\n"", ""self.__dict__[VAR_7] = None\n""]",0
"[""def FUNC_0(VAR_0):...\n"", ""return os.stat(VAR_0, follow_symlinks=os.stat not in os.\n    supports_follow_symlinks)\n""]",0
"[""def FUNC_3(self):...\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""VAR_8 = VAR_6.data['results'][0]['id']\n"", ""VAR_5 = '/api/apps/{}/perms'.format(VAR_8)\n"", ""VAR_7 = {'username': 'autotest-2'}\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-2', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 2)\n"", ""VAR_5 = '/api/apps/{}/perms/{}'.format(VAR_8, 'autotest-2')\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 403)\n"", ""self.assertIsNone(VAR_6.data)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 204)\n"", ""self.assertIsNone(VAR_6.data)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-2', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 404)\n""]",1
"[""import json as json_module\n"", ""import logging\n"", ""import sys\n"", ""from citest.service_testing import HttpContractBuilder\n"", ""from citest.service_testing import NoOpOperation\n"", ""import citest.gcp_testing as gcp\n"", ""import citest.json_contract as jc\n"", ""import citest.service_testing as st\n"", ""import spinnaker_testing as sk\n"", ""import spinnaker_testing.kato as kato\n"", ""VAR_0 = []\n"", ""VAR_1 = []\n"", ""VAR_2 = ''\n"", ""VAR_3 = ''\n"", ""VAR_4 = ''\n"", ""VAR_5 = ''\n"", ""VAR_6 = ''\n"", ""VAR_7 = ''\n"", ""VAR_8 = ''\n"", ""VAR_9 = ''\n"", ""VAR_10 = ''\n"", ""VAR_11 = ''\n"", ""VAR_12 = ''\n"", ""@classmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""return kato.new_agent(VAR_14)\n""]",1
"[""def FUNC_0(VAR_0, VAR_1, VAR_2=('view_project',)):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = models.Project.objects.get(pk=project_pk, deleting=False)\n"", ""return VAR_6\n"", ""for perm in VAR_2:\n"", ""if not VAR_0.user.has_perm(perm, VAR_6):\n""]",0
"[""from osv import osv\n"", ""from tools.translate import _\n"", ""VAR_0 = 'pos.close.statement'\n"", ""VAR_1 = 'Close Statements'\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""def __lt__(self, VAR_11):...\n"", ""return self.rule.__lt__(VAR_11.rule)\n""]",0
"[""def FUNC_8(VAR_3, VAR_2):...\n"", ""VAR_15 = Candidate.objects.get(id=candidate_id)\n"", ""if VAR_15.person.netid != VAR_2.user.username:\n"", ""return VAR_15\n""]",0
"[""def __db_disconnect__(self):...\n"", ""self.db.close()\n""]",0
"[""def FUNC_16():...\n"", ""VAR_38 = socket(AF_INET, SOCK_STREAM)\n"", ""VAR_38.bind(('', 0))\n"", ""VAR_39 = VAR_38.getsockname()[1]\n"", ""VAR_38.close()\n"", ""return VAR_39\n""]",0
"[""def FUNC_1(self, VAR_4):...\n"", ""VAR_4 = u\""'{0}'\"".format(VAR_4)\n"", ""return VAR_4\n""]",1
"[""def FUNC_3(self):...\n"", ""self.handled_resp = 1\n"", ""self.handled_remote = 1\n"", ""self.handled_args = 1\n"", ""self.handled_kwargs = 1\n""]",0
"[""def FUNC_3(VAR_5, VAR_6=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_43 = None\n"", ""VAR_44 = None\n"", ""VAR_45 = '%Y-%m-%d %H:%M:%S.%f'\n"", ""if VAR_6:\n"", ""VAR_45 = ('%Y-%m-%d %H:%M:%S.%f' if VAR_6.fieldtype == 'Datetime' else\n    '%Y-%m-%d')\n"", ""if VAR_5 and isinstance(VAR_5, (list, tuple)):\n"", ""if len(VAR_5) >= 1:\n"", ""if not VAR_6 or VAR_6 and VAR_6.fieldtype == 'Datetime':\n"", ""VAR_43 = VAR_5[0]\n"", ""if len(VAR_5) >= 2:\n"", ""VAR_44 = add_to_date(VAR_44, days=1)\n"", ""VAR_46 = \""'%s' AND '%s'\"" % (get_datetime(VAR_43).strftime(VAR_45),\n    get_datetime(VAR_44).strftime(VAR_45))\n"", ""VAR_44 = VAR_5[1]\n"", ""return VAR_46\n""]",0
"[""def FUNC_6(self, VAR_11):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.add_phrase(VAR_11, VAR_10='user_db', VAR_13=False)\n""]",0
"[""@gen.coroutine...\n"", ""VAR_8 = {}\n"", ""VAR_8['host'] = self.dbhost\n"", ""VAR_8['user'] = self.dbuser\n"", ""VAR_8['password'] = self.dbpassword\n"", ""VAR_8['db'] = self.dbname\n"", ""VAR_8['charset'] = 'utf8mb4'\n"", ""VAR_8['cursorclass'] = pymysql.cursors.Cursor\n"", ""VAR_9 = 'SELECT user_pass FROM {0}users WHERE user_login = \""{1}\""'.format(self\n    .table_prefix, VAR_7['username'])\n"", ""if cursor.execute(VAR_9) == 0:\n"", ""return None\n"", ""if phpass.verify(VAR_7['password'], cursor.fetchone()[0]) == True:\n"", ""return VAR_7['username']\n"", ""return None\n""]",1
"[""def FUNC_0(self, VAR_4, VAR_5, VAR_6=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = []\n"", ""for VAR_43, v in VAR_5.items():\n"", ""VAR_14.append(' %s=%s' % (VAR_43, v))\n"", ""VAR_15 = VAR_4 + ''.join(VAR_14)\n"", ""return self._run_ssh(VAR_15, VAR_6)\n""]",1
"[""def FUNC_3(VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = StringIO.StringIO()\n"", ""VAR_10 = hashlib.sha1()\n"", ""for name, content in FUNC_2(VAR_2, VAR_3, VAR_4, VAR_5):\n"", ""zip_file.writestr(name, content)\n"", ""VAR_11 = VAR_9.getvalue()\n"", ""VAR_10.update(str(len(name)))\n"", ""VAR_12 = VAR_10.hexdigest()\n"", ""VAR_10.update(name)\n"", ""logging.info('get_swarming_bot_zip(%s) is %d bytes; %s', VAR_5.keys(), len(\n    VAR_11), VAR_12)\n"", ""VAR_10.update(str(len(content)))\n"", ""return VAR_11, VAR_12\n"", ""VAR_10.update(content)\n""]",0
"[""@VAR_1.route('/', methods=['POST'])...\n"", ""VAR_6 = f.name\n"", ""f.write(request.form['program'])\n"", ""f.flush()\n"", ""return check_output(['./pmlcheck', VAR_6], stderr=STDOUT).decode().replace(\n    VAR_6 + ':', 'Line ')\n"", ""return e.output.decode().replace(VAR_6 + ':', 'Line '), 400\n""]",0
"[""\""\""\""\nNetwork Path Algorithms Between Switches and Routers\n\n\""\""\""\n"", ""import re\n"", ""import sys\n"", ""import logging\n"", ""import subprocess\n"", ""import nglib\n"", ""import nglib.query.nNode\n"", ""import nglib.netdb.ip\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""def FUNC_0(VAR_1, VAR_2, VAR_3='NGTREE'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = 'CSV', 'TREE', 'JSON', 'YAML', 'NGTREE'\n"", ""if VAR_3 in VAR_11:\n"", ""VAR_0.info('Query: Finding Full Path (%s --> %s) for %s', VAR_1, VAR_2,\n    nglib.user)\n"", ""def FUNC_1(VAR_1, VAR_2, VAR_3='NGTREE', VAR_4=False):...\n"", ""VAR_8, VAR_9 = VAR_1, VAR_2\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12, VAR_13 = None, None\n"", ""VAR_11 = 'CSV', 'TREE', 'JSON', 'YAML', 'NGTREE'\n"", ""if re.search('^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', VAR_8):\n"", ""if VAR_3 in VAR_11:\n"", ""VAR_12 = nglib.query.net.get_net(VAR_8, VAR_3='NGTREE')\n"", ""if re.search('^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', VAR_9):\n"", ""VAR_21, VAR_22, VAR_19 = None, None, None\n"", ""def FUNC_2(VAR_5, VAR_6, VAR_3='NGTREE', VAR_7=True):...\n"", ""if VAR_12:\n"", ""VAR_13 = nglib.query.net.get_net(VAR_9, VAR_3='NGTREE')\n"", ""VAR_14, VAR_15, VAR_16, VAR_17 = None, None, None, None\n"", ""if re.search('^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', VAR_1):\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = VAR_12['_child001']['Name']\n"", ""if VAR_13:\n"", ""if nglib.use_netdb:\n"", ""VAR_21 = nglib.query.net.get_net(VAR_1, VAR_3='NGTREE')\n"", ""if re.search('^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', VAR_2):\n"", ""VAR_11 = 'CSV', 'TREE', 'JSON', 'YAML', 'NGTREE'\n"", ""VAR_9 = VAR_13['_child001']['Name']\n"", ""VAR_14 = nglib.netdb.ip.get_netdb_ip(VAR_1)\n"", ""if VAR_14:\n"", ""VAR_22 = nglib.query.net.get_net(VAR_2, VAR_3='NGTREE')\n"", ""if VAR_21['_child001']['VRF'] == VAR_22['_child001']['VRF']:\n"", ""if VAR_3 in VAR_11:\n"", ""VAR_15 = nglib.netdb.ip.get_netdb_ip(VAR_2)\n"", ""VAR_36 = VAR_12['_child001']['Router']\n"", ""if VAR_15:\n"", ""VAR_19 = FUNC_3(VAR_1, VAR_2, VAR_7=False)\n"", ""VAR_37 = FUNC_4(VAR_1, VAR_2, VAR_3='NGTREE')\n"", ""VAR_0.info('Query: Finding Switched Paths (%s --> %s) for %s', VAR_5, VAR_6,\n    nglib.user)\n"", ""return\n"", ""if 'StandbyRouter' in VAR_12['_child001']:\n"", ""VAR_36 = VAR_13['_child001']['Router']\n"", ""VAR_18 = True\n"", ""return VAR_19\n"", ""VAR_19 = nglib.ngtree.get_ngtree(VAR_37['Name'], tree_type='L4-PATH')\n"", ""VAR_23 = []\n"", ""VAR_36 = VAR_36 + '|' + VAR_12['_child001']['StandbyRouter']\n"", ""VAR_16 = FUNC_2(VAR_14['Switch'], VAR_36, VAR_7=False)\n"", ""if 'StandbyRouter' in VAR_13['_child001']:\n"", ""if VAR_14 and VAR_15:\n"", ""VAR_38 = True\n"", ""VAR_19 = nglib.ngtree.get_ngtree('Switched Paths', tree_type='L2-PATH')\n"", ""VAR_36 = VAR_36 + '|' + VAR_13['_child001']['StandbyRouter']\n"", ""VAR_17 = FUNC_2(VAR_36, VAR_15['Switch'], VAR_7=False)\n"", ""if VAR_14['Switch'] == VAR_15['Switch'] and VAR_14['VLAN'] == VAR_15['VLAN']:\n"", ""VAR_19 = nglib.ngtree.get_ngtree('L2-L4', tree_type='PATHs')\n"", ""VAR_26 = None\n"", ""VAR_19['Name'] = VAR_5 + ' -> ' + VAR_6\n"", ""VAR_18 = False\n"", ""if VAR_12['_child001']['Name'] != VAR_13['_child001']['Name']:\n"", ""for key in sorted(VAR_37.keys()):\n"", ""VAR_24 = dict()\n"", ""VAR_19['L3 Path'] = VAR_8 + ' -> ' + VAR_9\n"", ""if VAR_14 and VAR_15:\n"", ""if '_child' in key:\n"", ""if VAR_26:\n"", ""VAR_25 = nglib.py2neo_ses.cypher.execute('MATCH (ss:Switch), (ds:Switch), ' +\n    'sp = allShortestPaths((ss)-[:NEI*0..9]-(ds)) ' +\n    'WHERE ss.name =~ {switch1} AND ds.name =~ {switch2}' +\n    'UNWIND nodes(sp) as s1 UNWIND nodes(sp) as s2 ' +\n    'MATCH (s1)<-[nei:NEI]-(s2), plen = shortestPath((ss)-[:NEI*0..9]-(s1)) ' +\n    'RETURN DISTINCT s1.name AS csw, s2.name AS psw, ' +\n    'nei.pPort AS pport, nei.cPort as cport, nei.native AS native, ' +\n    'nei.cPc as cPc, nei.pPc AS pPc, nei.vlans AS vlans, nei.rvlans as rvlans, '\n     + 'nei._rvlans AS p_rvlans, ' +\n    'LENGTH(plen) as distance ORDER BY distance, s1.name, s2.name', {\n    'switch1': VAR_5, 'switch2': VAR_6})\n"", ""VAR_19['Lx Path'] = VAR_1 + ' -> ' + VAR_2\n"", ""VAR_19['L2 Path'] = VAR_14['Switch'] + ' (' + VAR_14['SwitchPort'\n    ] + ') -> ' + VAR_15['Switch'] + ' (' + VAR_15['SwitchPort'] + ')'\n"", ""VAR_12['_type'] = 'SRC'\n"", ""if re.search('(Network|FW)', VAR_37[key]['Name']):\n"", ""VAR_20 = FUNC_3(VAR_37[VAR_26]['gateway'], VAR_2, VAR_10=dstt['_child001'][\n    'VRF'], VAR_4=l2path)\n"", ""VAR_26 = 0\n"", ""VAR_12['Name'] = VAR_1\n"", ""if VAR_38:\n"", ""if VAR_20:\n"", ""for rec in VAR_25:\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_12)\n"", ""VAR_20 = FUNC_3(VAR_1, VAR_37[key]['gateway'], VAR_10=srct['_child001'][\n    'VRF'], VAR_4=l2path)\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_37[key])\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_20)\n"", ""VAR_39 = nglib.ngtree.get_ngtree('Link', tree_type='L2-HOP')\n"", ""if VAR_23:\n"", ""if not VAR_18 and '_child002' in VAR_13:\n"", ""if VAR_20:\n"", ""VAR_26 = key\n"", ""if rec.distance == 0:\n"", ""VAR_19['Links'] = len(VAR_23)\n"", ""if VAR_7:\n"", ""nglib.ngtree.add_child_ngtree(VAR_12, VAR_13['_child002'])\n"", ""if VAR_18 and VAR_16:\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_20)\n"", ""VAR_38 = False\n"", ""VAR_39['distance'] = rec.distance + 1\n"", ""if VAR_26:\n"", ""VAR_19['Distance'] = max([s['distance'] for s in VAR_23])\n"", ""print('No results found for path between {:} and {:}'.format(VAR_5, VAR_6))\n"", ""VAR_12['_type'] = 'L2PATH'\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_16)\n"", ""VAR_20 = FUNC_1(VAR_1, VAR_2, VAR_3='NGTREE', VAR_4=True)\n"", ""VAR_26 = 1\n"", ""if rec.distance == VAR_26:\n"", ""VAR_39['distance'] = rec.distance\n"", ""if VAR_3 == 'CSV':\n"", ""VAR_12['Name'] = VAR_1 + ' -> ' + VAR_2\n"", ""if VAR_20 and 'PATH' in VAR_20['_type']:\n"", ""VAR_39['Name'] = ('#' + str(VAR_39['distance']) + ' ' + rec.psw + '(' + rec\n    .pport + ') <-> ' + rec.csw + '(' + rec.cport + ')')\n"", ""VAR_26 += 1\n"", ""if rec.distance == VAR_26 - 1:\n"", ""nglib.query.print_dict_csv(VAR_23)\n"", ""VAR_19 = nglib.query.exp_ngtree(VAR_19, VAR_3)\n"", ""if VAR_20['_type'] == 'L4-PATH':\n"", ""if VAR_18 and VAR_17:\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_39)\n"", ""VAR_39['distance'] = rec.distance + 1\n"", ""VAR_39['distance'] = rec.distance + 1\n"", ""VAR_39['distance'] = rec.distance\n"", ""return VAR_19\n"", ""VAR_19['L4 Path'] = VAR_20['Name']\n"", ""VAR_19['L4 Path'] = 'VRF:' + VAR_12['_child001']['VRF']\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_17)\n"", ""if VAR_18:\n"", ""VAR_39['Child Switch'] = rec.csw\n"", ""VAR_26 = 0\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_20)\n"", ""VAR_13['_type'] = 'DST'\n"", ""VAR_19 = nglib.query.exp_ngtree(VAR_19, VAR_3)\n"", ""VAR_39['Child Port'] = rec.cport\n"", ""VAR_13['Name'] = VAR_2\n"", ""return VAR_19\n"", ""VAR_39['Parent Switch'] = rec.psw\n"", ""nglib.ngtree.add_child_ngtree(VAR_19, VAR_13)\n"", ""VAR_39['Parent Port'] = rec.pport\n"", ""if rec.cPc:\n"", ""VAR_39['Child Channel'] = rec.cPc\n"", ""if rec.rvlans:\n"", ""VAR_39['Parent Channel'] = rec.pPc\n"", ""VAR_39['Link VLANs'] = rec.vlans\n"", ""VAR_23.append(VAR_39)\n"", ""VAR_39['Link rVLANs'] = rec.rvlans\n"", ""VAR_39['_rvlans'] = rec.p_rvlans\n"", ""VAR_39['Native VLAN'] = rec.native\n""]",1
"[""import cgi\n"", ""import mysql.connector\n"", ""from html import beghtml, endhtml\n"", ""VAR_0 = cgi.FieldStorage()\n"", ""VAR_1 = VAR_0.getvalue('enzyme_name')\n"", ""VAR_2 = VAR_0.getvalue('process_name')\n"", ""VAR_3 = VAR_0.getvalue('enzyme_name2')\n"", ""VAR_4 = VAR_0.getvalue('process_name2')\n"", ""VAR_5 = VAR_0.getvalue('enzyme_name3')\n"", ""VAR_6 = VAR_0.getvalue('conc')\n"", ""VAR_7 = VAR_0.getvalue('compound')\n"", ""VAR_8 = VAR_0.getvalue('inter')\n"", ""VAR_9 = VAR_0.getvalue('sub')\n"", ""VAR_10 = VAR_0.getvalue('organelle')\n"", ""VAR_5 = VAR_0.getvalue('enzyme_name3')\n"", ""VAR_11 = VAR_0.getvalue('process_name3')\n"", ""VAR_12 = VAR_0.getvalue('organelle2')\n"", ""VAR_13 = VAR_0.getvalue('conc2')\n"", ""VAR_14 = VAR_0.getvalue('compound2')\n"", ""VAR_15 = mysql.connector.connect(user='eapfelba', database='eapfelba2',\n    host='localhost', password='chumash1000')\n"", ""VAR_16 = ''\n"", ""VAR_17 = VAR_15.cursor()\n"", ""if VAR_1:\n"", ""VAR_16 = \""delete from converts where enzyme_name = '%s'\"" % VAR_1\n"", ""if VAR_5:\n"", ""VAR_16 = \""delete from enzyme where enzyme_name = '%s'\"" % VAR_5\n"", ""if VAR_2:\n"", ""VAR_16 = \""delete from process where process_name = '%s'\"" % VAR_2\n"", ""if VAR_4 and VAR_3:\n"", ""VAR_16 = (\n    \""delete from uses where process_name = '%s' and enzyme_name = '%s'\"" % (\n    VAR_4, VAR_3))\n"", ""if VAR_6 and VAR_7:\n"", ""VAR_16 = \""delete from conds where concentration = '%s' and compound = '%s'\"" % (\n    VAR_6, VAR_7)\n"", ""if VAR_8:\n"", ""VAR_16 = \""delete from intermediate where intermediate_name = '%s'\"" % VAR_8\n"", ""if VAR_10 and VAR_9:\n"", ""VAR_16 = (\n    \""delete from location where organelle = '%s' and substructure = '%s'\"" %\n    (VAR_10, VAR_9))\n"", ""if VAR_5 and VAR_12:\n"", ""VAR_16 = (\n    \""delete from located_in where enzyme_name = '%s' and organelle = '%s'\"" %\n    (VAR_5, VAR_12))\n"", ""if VAR_11 and VAR_13 and VAR_14:\n"", ""VAR_16 = (\n    \""delete from operates_uner where process_name = '%s' and concentration = '%s' and compound = '%s'\""\n     % (VAR_11, VAR_13, VAR_14))\n"", ""VAR_18 = False\n"", ""if not VAR_16:\n"", ""beghtml()\n"", ""VAR_17.execute(VAR_16)\n"", ""beghtml()\n"", ""if VAR_18 == False:\n"", ""print(\""<h3>You didn't fill anything out! :/</h3>\"")\n"", ""VAR_15.commit()\n"", ""print('Something went wrong: {}'.format(err) + '<br><br>')\n"", ""beghtml()\n"", ""VAR_17.close()\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""print('<h3>Deleted!</h3>')\n"", ""VAR_15.close()\n"", ""print(\n    '<br><b><a href = \""http://ada.sterncs.net/~eapfelbaum/biobase.html\"">Home</a></b>'\n    )\n"", ""endhtm()\n"", ""print('string')\n"", ""endhtml()\n"", ""VAR_18 = True\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/biobase.html\"">Try Something Else!</a></b><br><br>'\n    )\n"", ""VAR_18 = True\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""endhtml()\n""]",1
"[""def FUNC_9(VAR_27):...\n"", ""VAR_28 = str(VAR_27.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n"", ""VAR_39 = FUNC_10(VAR_27, VAR_28, 'message')\n"", ""VAR_27.reply(VAR_39 + VAR_0)\n""]",1
"[""import os\n"", ""import vim\n"", ""import tempfile\n"", ""import json\n"", ""import signal\n"", ""from subprocess import PIPE\n"", ""from ycm import vimsupport\n"", ""from ycm import utils\n"", ""from ycm.diagnostic_interface import DiagnosticInterface\n"", ""from ycm.completers.all.omni_completer import OmniCompleter\n"", ""from ycm.completers.general import syntax_parse\n"", ""from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype\n"", ""from ycm.client.ycmd_keepalive import YcmdKeepalive\n"", ""from ycm.client.base_request import BaseRequest, BuildRequestData\n"", ""from ycm.client.command_request import SendCommandRequest\n"", ""from ycm.client.completion_request import CompletionRequest\n"", ""from ycm.client.omni_completion_request import OmniCompletionRequest\n"", ""from ycm.client.event_notification import SendEventNotificationAsync, EventNotification\n"", ""from ycm.server.responses import ServerError\n"", ""from UltiSnips import UltiSnips_Manager\n"", ""VAR_6 = False\n"", ""VAR_0.environ['no_proxy'] = '127.0.0.1,localhost'\n"", ""VAR_6 = True\n"", ""signal.signal(signal.SIGINT, signal.SIG_IGN)\n"", ""VAR_1 = 30\n"", ""VAR_2 = ('The ycmd server SHUT DOWN (restart with :YcmRestartServer). ' +\n    \""\""\""Stderr (last {0} lines):\n\n\""\""\"".format(VAR_1))\n"", ""VAR_3 = (\n    'The ycmd server SHUT DOWN (restart with :YcmRestartServer).  check console output for logs!'\n    )\n"", ""VAR_4 = 10800\n"", ""def __init__(self, VAR_7):...\n"", ""self._user_options = VAR_7\n"", ""self._user_notified_about_crash = False\n"", ""self._diag_interface = DiagnosticInterface(VAR_7)\n"", ""self._omnicomp = OmniCompleter(VAR_7)\n"", ""self._latest_completion_request = None\n"", ""self._latest_file_parse_request = None\n"", ""self._server_stdout = None\n"", ""self._server_stderr = None\n"", ""self._server_popen = None\n"", ""self._filetypes_with_keywords_loaded = set()\n"", ""self._temp_options_filename = None\n"", ""self._ycmd_keepalive = YcmdKeepalive()\n"", ""self._SetupServer()\n"", ""self._ycmd_keepalive.Start()\n"", ""def FUNC_2(self):...\n"", ""VAR_14 = utils.GetUnusedLocalhostPort()\n"", ""self._temp_options_filename = options_file.name\n"", ""json.dump(dict(self._user_options), options_file)\n"", ""options_file.flush()\n"", ""VAR_21 = [utils.PathToPythonInterpreter(), FUNC_0(), '--port={0}'.format(\n    VAR_14), '--options_file={0}'.format(options_file.name), '--log={0}'.\n    format(self._user_options['server_log_level']),\n    '--idle_suicide_seconds={0}'.format(VAR_4)]\n"", ""if not self._user_options['server_use_vim_stdout']:\n"", ""VAR_26 = VAR_0.path.join(utils.PathToTempDir(), 'server_{port}_{std}.log')\n"", ""self._server_popen = utils.SafePopen(VAR_21, stdout=PIPE, stderr=PIPE)\n"", ""self._server_stdout = VAR_26.format(port=server_port, std='stdout')\n"", ""BaseRequest.server_location = 'http://localhost:' + str(VAR_14)\n"", ""self._server_stderr = VAR_26.format(port=server_port, std='stderr')\n"", ""self._NotifyUserIfServerCrashed()\n"", ""VAR_21.append('--stdout={0}'.format(self._server_stdout))\n"", ""def FUNC_3(self):...\n"", ""VAR_21.append('--stderr={0}'.format(self._server_stderr))\n"", ""VAR_15 = self._server_popen.poll()\n"", ""if self._user_options['server_keep_logfiles']:\n"", ""return VAR_15 is None\n"", ""VAR_21.append('--keep_logfiles')\n""]",1
"[""from __future__ import absolute_import, division, print_function, unicode_literals\n"", ""import logging\n"", ""from textwrap import dedent\n"", ""from pants.backend.native.subsystems.native_toolchain import NativeToolchain\n"", ""from pants.backend.native.targets.native_library import NativeLibrary\n"", ""from pants.backend.python.python_requirement import PythonRequirement\n"", ""from pants.backend.python.subsystems import pex_build_util\n"", ""from pants.backend.python.subsystems.python_setup import PythonSetup\n"", ""from pants.backend.python.targets.python_distribution import PythonDistribution\n"", ""from pants.base.exceptions import IncompatiblePlatformsError\n"", ""from pants.binaries.executable_pex_tool import ExecutablePexTool\n"", ""from pants.subsystem.subsystem import Subsystem\n"", ""from pants.util.memo import memoized_property\n"", ""from pants.util.objects import SubclassesOf\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""A subsystem which exposes components of the native backend to the python backend.\""\""\""\n"", ""VAR_1 = 'python-native-code'\n"", ""VAR_2 = ['.c', '.cpp', '.cc']\n"", ""@classmethod...\n"", ""super(CLASS_0, VAR_3).register_options(VAR_4)\n"", ""VAR_4('--native-source-extensions', type=list, default=cls.\n    default_native_source_extensions, fingerprint=True, advanced=True, help\n    =\n    'The extensions recognized for native source files in `python_dist()` sources.'\n    )\n"", ""@classmethod...\n"", ""return super(CLASS_0, VAR_3).subsystem_dependencies() + (NativeToolchain.\n    scoped(VAR_3), PythonSetup)\n""]",1
"[""from pylons import c, request, g\n"", ""from pylons.i18n import _\n"", ""from pylons.controllers.util import abort\n"", ""from r2.lib import utils, captcha\n"", ""from r2.lib.filters import unkeep_space, websafe, _force_utf8, _force_ascii\n"", ""from r2.lib.db.operators import asc, desc\n"", ""from r2.config import cache\n"", ""from r2.lib.template_helpers import add_sr\n"", ""from r2.lib.jsonresponse import json_respond\n"", ""from r2.models import *\n"", ""from r2.controllers.errors import errors, UserRequiredException\n"", ""from copy import copy\n"", ""from datetime import datetime, timedelta\n"", ""import re\n"", ""VAR_6 = None\n"", ""def __init__(self, VAR_7=None, VAR_8=None, VAR_9=True, VAR_10=True, VAR_11=True...\n"", ""if VAR_7:\n"", ""self.param = VAR_7\n"", ""self.param = self.default_param\n"", ""self.default = VAR_8\n"", ""self.post, self.get, self.url = VAR_9, VAR_10, VAR_11\n"", ""def __call__(self, VAR_11):...\n"", ""VAR_15 = []\n"", ""if self.param:\n"", ""for p in utils.tup(self.param):\n"", ""return self.run(*VAR_15)\n"", ""if self.post and VAR_102.post.get(p):\n"", ""VAR_33 = VAR_102.post[p]\n"", ""if self.get and VAR_102.get.get(p):\n"", ""VAR_15.append(VAR_33)\n"", ""VAR_33 = VAR_102.get[p]\n"", ""if self.url and VAR_11.get(p):\n"", ""VAR_33 = VAR_11[p]\n"", ""VAR_33 = self.default\n""]",0
"[""def FUNC_0(VAR_0, VAR_1='_', VAR_2=-2, VAR_3=-1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""import pandas as pd\n"", ""VAR_15 = [int(fn.split('.')[0].split(VAR_1)[VAR_2]) for fn in VAR_0]\n"", ""VAR_16 = [int(fn.split('.')[0].split(VAR_1)[VAR_3]) for fn in VAR_0]\n"", ""VAR_17 = pd.DataFrame({'fn': VAR_0, 'month': VAR_15, 'year': VAR_16})\n"", ""VAR_18 = VAR_17.sort_values(['year', 'month'])\n"", ""return VAR_18.fn.tolist()\n""]",0
"[""def FUNC_15(VAR_1, VAR_10, VAR_11, **VAR_6):...\n"", ""VAR_51 = ''\n"", ""VAR_55 = VAR_10 + VAR_11\n"", ""if VAR_6.get('dir') == 'fullpath':\n"", ""VAR_55 = VAR_10\n"", ""VAR_37 = FUNC_8(VAR_1)\n"", ""VAR_51 = e\n"", ""VAR_74 = VAR_37.open_sftp()\n"", ""VAR_51 = e\n"", ""return VAR_51\n"", ""VAR_11 = VAR_74.put(VAR_11, VAR_55)\n"", ""VAR_74.close()\n"", ""VAR_37.close()\n""]",0
"[""def FUNC_21(self):...\n"", ""\""\""\""docstring\""\""\""\n""]",0
"[""def FUNC_4(self, VAR_5):...\n"", ""for oldg in VAR_5.get_ancestors():\n"", ""if oldg not in self.groups:\n"", ""if VAR_5 not in self.groups:\n"", ""self.add_group(oldg)\n"", ""self.groups.append(VAR_5)\n""]",1
"[""def FUNC_1(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = list(VAR_1.router.match_routes)\n"", ""VAR_30.extend(v for k, v in VAR_1.router.build_routes.iteritems() if v not in\n    VAR_1.router.match_routes)\n"", ""return [r for r in VAR_30 if issubclass(r.handler, CLASS_2)]\n""]",0
"[""@property...\n"", ""VAR_65 = '.' if self._workdir is None else self._workdir\n"", ""if not os.path.isabs(VAR_65):\n"", ""return os.path.abspath(os.path.join(self.workflow.basedir, VAR_65))\n"", ""return VAR_65\n""]",0
"[""@acs_action('login-action')...\n"", ""\""\""\""docstring\""\""\""\n"", ""current_app.logger.info('User {!r} logging in.'.format(VAR_1))\n"", ""VAR_3['_saml2_session_name_id'] = code(VAR_0['name_id'])\n"", ""VAR_3['eduPersonPrincipalName'] = VAR_1.eppn\n"", ""VAR_3['user_eppn'] = VAR_1.eppn\n"", ""VAR_4 = get_loa(current_app.config.get('AVAILABLE_LOA'), VAR_0)\n"", ""VAR_3['eduPersonAssurance'] = VAR_4\n"", ""VAR_3.persist()\n"", ""VAR_5 = request.form.get('RelayState', '/')\n"", ""current_app.logger.debug('Redirecting to the RelayState: ' + VAR_5)\n"", ""VAR_6 = redirect(location=relay_state)\n"", ""VAR_3.set_cookie(VAR_6)\n"", ""current_app.logger.info('Redirecting user {!r} to {!r}'.format(VAR_1, VAR_5))\n"", ""return VAR_6\n""]",1
"[""def FUNC_1(VAR_1):...\n"", ""VAR_7 = urlparse(VAR_1)\n"", ""VAR_8 = HTTPSConnection(VAR_7.netloc)\n"", ""VAR_8.request('HEAD', VAR_7.path)\n"", ""VAR_9 = VAR_8.getresponse()\n"", ""if VAR_9.getheader('location') == None:\n"", ""return VAR_1\n"", ""return VAR_9.getheader('location')\n""]",0
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""def FUNC_1(self):...\n"", ""return 'load page for task %s (%s)' % (self.task_id, self.url)\n""]",0
"[""def FUNC_10(VAR_12):...\n"", ""VAR_13 = binascii.hexlify(VAR_12)\n"", ""if sys.version_info >= (3, 0):\n"", ""VAR_13 = VAR_13.decode()\n"", ""return VAR_13\n""]",0
"[""def FUNC_11(self, VAR_7):...\n"", ""return self._job_exitstatus.get(VAR_7, -1)\n""]",0
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = jc.Contract()\n"", ""return st.OperationContract(self.agent.make_create_app_operation(VAR_1=self\n    .bindings, application=self.TEST_APP), VAR_6=contract)\n""]",0
"[""def FUNC_4(self, VAR_9):...\n"", ""self.cursor.execute(\n    \""SELECT upc, name, weight, description FROM product WHERE name ILIKE '%%%s%%';\""\n    , (VAR_9,))\n"", ""return self.cursor.fetchall()\n""]",1
"[""@Throttle(VAR_4)...\n"", ""\""\""\""docstring\""\""\""\n"", ""import pyatmo\n"", ""self.station_data = pyatmo.WeatherStationData(self.auth)\n"", ""if self.station is not None:\n"", ""self.data = self.station_data.lastData(VAR_19=self.station, exclude=3600)\n"", ""self.data = self.station_data.lastData(exclude=3600)\n""]",0
"[""import logger\n"", ""import datetime\n"", ""import constants\n"", ""import get_results\n"", ""import time\n"", ""import copy\n"", ""import player_web\n"", ""import bracket_utils\n"", ""from get_ranks import get_ranks\n"", ""from get_results import get_coalesced_tag, sanitize_tag\n"", ""import re\n"", ""from tweet import tweet\n"", ""VAR_0 = logger.logger(__name__)\n"", ""def __init__(self, VAR_1):...\n"", ""VAR_0.info('loading constants for process')\n"", ""self.db = VAR_1\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5=False):...\n"", ""VAR_8 = \""SELECT * FROM analyzed WHERE base_url = '\"" + str(VAR_2) + \""';\""\n"", ""VAR_9 = self.db.exec(VAR_8)\n"", ""if len(VAR_9) > 0:\n"", ""VAR_0.info('tried to analyze {}, but has already been done.'.format(VAR_2))\n"", ""if 'smash.gg' in VAR_2:\n"", ""return\n"", ""VAR_23 = get_results.process(VAR_2, VAR_3, self.db, VAR_4)\n"", ""VAR_24, VAR_25 = bracket_utils.hit_url(VAR_2)\n"", ""if VAR_23:\n"", ""if VAR_25 == 200 and bracket_utils.is_valid(VAR_24):\n"", ""self.insert_placing_data(VAR_2, VAR_5)\n"", ""VAR_0.exc('Analyzing smashgg tournament {} was not successful'.format(VAR_2))\n"", ""get_results.process(VAR_2, VAR_3, self.db, VAR_4)\n"", ""def FUNC_1(self, VAR_2, VAR_5):...\n"", ""self.insert_placing_data(VAR_2, VAR_5)\n"", ""VAR_0.info('we have called insert placing data on bracket {}'.format(VAR_2))\n"", ""VAR_10 = bracket_utils.get_tournament_placings(VAR_2)\n"", ""for VAR_26, placing in VAR_10.items():\n"", ""VAR_26 = sanitize_tag(VAR_26)\n"", ""VAR_0.info('tournament placings for {} are {}'.format(VAR_2, VAR_10))\n"", ""VAR_26 = get_coalesced_tag(VAR_26)\n"", ""def FUNC_2(self, VAR_3):...\n"", ""VAR_8 = ('INSERT INTO placings (url, player, place) VALUES ' +\n    \"" ('{}', '{}', '{}')\"".format(VAR_2, VAR_26, placing))\n"", ""VAR_0.info('About to check if ranks need updating for {}'.format(VAR_3))\n"", ""self.db.exec(VAR_8)\n"", ""VAR_8 = 'select count(*) from ranks where scene=\""{}\"";'.format(VAR_3)\n"", ""if 'christmasmike' == VAR_26 and VAR_5:\n"", ""VAR_11 = self.db.exec(VAR_8)\n"", ""if placing < 10:\n"", ""VAR_12 = VAR_11[0][0]\n"", ""VAR_40 = \""Congrats on making {} dude! You're the best.\"".format(placing)\n"", ""VAR_13 = (5 if VAR_3 == 'pro' or VAR_3 == 'pro_wiiu' else constants.\n    TOURNAMENTS_PER_RANK)\n"", ""tweet(VAR_40)\n"", ""if VAR_12 == 0:\n"", ""VAR_0.info('Detected that we need to bulk update ranks for {}'.format(VAR_3))\n"", ""VAR_8 = (\""select date from ranks where scene='{}' order by date desc limit 1;\""\n    .format(VAR_3))\n"", ""VAR_27 = bracket_utils.get_first_month(self.db, VAR_3)\n"", ""VAR_11 = self.db.exec(VAR_8)\n"", ""VAR_28 = bracket_utils.get_last_month(self.db, VAR_3)\n"", ""VAR_30 = VAR_11[0][0]\n"", ""VAR_29 = bracket_utils.iter_months(VAR_27, VAR_28, include_first=False,\n    include_last=True)\n"", ""VAR_31 = bracket_utils.has_month_passed(VAR_30)\n"", ""for month in VAR_29:\n"", ""if VAR_31:\n"", ""VAR_6, VAR_38 = bracket_utils.get_n_tournaments_before_date(self.db, VAR_3,\n    month, VAR_13)\n"", ""def FUNC_3(self, VAR_3, VAR_6, VAR_7):...\n"", ""VAR_39 = datetime.datetime.today().strftime('%Y-%m-%d')\n"", ""VAR_0.info(\n    'It has not yet been 1 month since we calculated ranks for {}. Skipping'\n    .format(VAR_3))\n"", ""self.process_ranks(VAR_3, VAR_6, month)\n"", ""VAR_14 = 0\n"", ""VAR_40 = 'Detected that we need up update monthly ranks for {}, on {}'.format(\n    VAR_3, VAR_39)\n"", ""VAR_15 = 1\n"", ""VAR_0.info(VAR_40)\n"", ""VAR_16 = 2\n"", ""if not VAR_39.split('-')[-1] == '1':\n"", ""VAR_17 = 3\n"", ""VAR_0.exc('We are calculating ranks today, {}, but it isnt the first'.\n    format(VAR_39))\n"", ""VAR_29 = bracket_utils.iter_months(VAR_30, VAR_39, include_first=False,\n    include_last=True)\n"", ""VAR_18 = 4\n"", ""for month in VAR_29:\n"", ""VAR_8 = \""SELECT * FROM ranks WHERE scene = '{}' AND date='{}';\"".format(str(\n    VAR_3), VAR_7)\n"", ""VAR_42 = bracket_utils.get_previous_month(month)\n"", ""VAR_11 = self.db.exec(VAR_8)\n"", ""VAR_43 = bracket_utils.get_tournaments_during_month(self.db, VAR_3, VAR_42)\n"", ""if len(VAR_11) > 0:\n"", ""if len(VAR_43) > 0:\n"", ""VAR_0.info('We have already calculated ranks for {} on date {}. SKipping'.\n    format(VAR_3, VAR_7))\n"", ""VAR_19 = bracket_utils.get_matches_from_urls(self.db, VAR_6)\n"", ""tweet('Calculating {} ranks for {}'.format(month, VAR_3))\n"", ""return\n"", ""VAR_0.info('About to start processing ranks for scene {} on {}'.format(\n    VAR_3, VAR_7))\n"", ""VAR_6, VAR_38 = bracket_utils.get_n_tournaments_before_date(self.db, VAR_3,\n    month, VAR_13)\n"", ""VAR_20 = {}\n"", ""self.process_ranks(VAR_3, VAR_6, month)\n"", ""for match in VAR_19:\n"", ""VAR_32 = match[VAR_14]\n"", ""VAR_21 = get_ranks(VAR_20)\n"", ""VAR_33 = match[VAR_15]\n"", ""VAR_22 = {}\n"", ""VAR_34 = match[VAR_16]\n"", ""for i, x in enumerate(VAR_21):\n"", ""VAR_35 = match[VAR_17]\n"", ""VAR_36, VAR_26 = x\n"", ""player_web.update_ranks(VAR_22)\n"", ""if VAR_32 not in VAR_20:\n"", ""VAR_37 = len(VAR_21) - i\n"", ""VAR_20[VAR_32] = {}\n"", ""if VAR_33 not in VAR_20[VAR_32]:\n"", ""VAR_8 = (\n    \""INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{}', '{}', '{}', '{}', '{}');\""\n    .format(str(VAR_3), str(VAR_26), int(VAR_37), str(VAR_36), str(VAR_7)))\n"", ""VAR_20[VAR_32][VAR_33] = []\n"", ""VAR_20[VAR_32][VAR_33].append((VAR_35, VAR_34 == VAR_32))\n"", ""self.db.exec(VAR_8)\n"", ""if VAR_33 not in VAR_20:\n"", ""VAR_8 = \""SELECT scene FROM players WHERE tag='{}';\"".format(VAR_26)\n"", ""VAR_20[VAR_33] = {}\n"", ""if VAR_32 not in VAR_20[VAR_33]:\n"", ""VAR_11 = self.db.exec(VAR_8)\n"", ""VAR_20[VAR_33][VAR_32] = []\n"", ""VAR_20[VAR_33][VAR_32].append((VAR_35, VAR_34 == VAR_33))\n"", ""if len(VAR_11) == 0 or VAR_11[0][0] == VAR_3:\n"", ""VAR_41 = {'rank': VAR_37, 'total_ranked': len(VAR_21)}\n"", ""VAR_22[VAR_26] = VAR_41\n""]",1
"[""async def FUNC_6(VAR_6):...\n"", ""import csv\n"", ""VAR_10 = {'Authorization': f'Bearer {VAR_1}'}\n"", ""VAR_11 = csv.reader(open('jogging_dataset.csv'), delimiter=',')\n"", ""for row in VAR_11:\n"", ""VAR_7 = {'date': row[0], 'location': row[1], 'distance': int(row[2]),\n    'time': int(row[3])}\n"", ""VAR_8 = await VAR_6.post('/results', VAR_10=headers, VAR_7=json.dumps(data))\n"", ""assert VAR_8.status == 201\n""]",0
"[""def FUNC_9(self, VAR_19, *VAR_20):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_26 = next(self._counter)\n"", ""VAR_27 = {'id': VAR_26, 'method': VAR_19, 'params': VAR_20}\n"", ""VAR_28 = json.dumps(VAR_27)\n"", ""self._client.write(VAR_28.encode('utf8') + b'\\n')\n"", ""self._client.flush()\n"", ""VAR_29 = self._client.readline()\n"", ""if not VAR_29:\n"", ""VAR_23 = json.loads(str(VAR_29, encoding='utf8'))\n"", ""if VAR_23['error']:\n"", ""if VAR_23['id'] != VAR_26:\n"", ""if VAR_23.get('callback') is not None:\n"", ""if self._event_client is None:\n"", ""return VAR_23['result']\n"", ""self._event_client = self._start_event_client()\n"", ""return callback_handler.CallbackHandler(callback_id=result['callback'],\n    event_client=self._event_client, ret_value=result['result'],\n    method_name=method)\n""]",0
"[""from django.db import models, migrations\n"", ""VAR_0 = [('inheritance', '0001_initial'), ('course', '0001_initial')]\n"", ""VAR_1 = [migrations.CreateModel(name='LinkService', fields=[(\n    'modelwithinheritance_ptr', models.OneToOneField(parent_link=True,\n    auto_created=True, primary_key=True, serialize=False, to=\n    'inheritance.ModelWithInheritance')), ('url', models.CharField(\n    help_text=b'The service URL', max_length=256)), ('menu_label', models.\n    CharField(help_text=b'A default label to show in the course menu.',\n    max_length=32)), ('menu_icon_class', models.CharField(default=\n    b'icon-globe', help_text=\n    b'A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs'\n    , max_length=32)), ('enabled', models.BooleanField(default=True,\n    help_text=\n    b'If not enabled, the service is disabled for all course instances.'))],\n    options={'ordering': ['menu_label']}, bases=(\n    'inheritance.modelwithinheritance',)), migrations.CreateModel(name=\n    'LTIService', fields=[('linkservice_ptr', models.OneToOneField(\n    parent_link=True, auto_created=True, primary_key=True, serialize=False,\n    to='external_services.LinkService')), ('consumer_key', models.CharField\n    (help_text=b'The consumer key provided by the LTI service.', max_length\n    =128)), ('consumer_secret', models.CharField(help_text=\n    b'The consumer secret provided by the LTI service.', max_length=128))],\n    options={}, bases=('external_services.linkservice',)), migrations.\n    CreateModel(name='MenuItem', fields=[('id', models.AutoField(\n    verbose_name='ID', serialize=False, auto_created=True, primary_key=True\n    )), ('menu_label', models.CharField(help_text=\n    b'Overrides service default label shown in the course menu.',\n    max_length=32, null=True, blank=True)), ('menu_icon_class', models.\n    CharField(help_text=\n    b'Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs'\n    , max_length=32, null=True, blank=True)), ('menu_weight', models.\n    IntegerField(default=0, help_text=\n    b'Heavier menu entries are placed after lighter ones.')), ('enabled',\n    models.BooleanField(default=True)), ('course_instance', models.\n    ForeignKey(related_name='ext_services', to='course.CourseInstance',\n    help_text=b'A course instance where the service is used.')), ('service',\n    models.ForeignKey(to='external_services.LinkService'))], options={\n    'ordering': ['course_instance', 'menu_weight', 'menu_label']}, bases=(\n    models.Model,))]\n""]",1
"[""def FUNC_1(self, VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""for f in VAR_4:\n"", ""VAR_7 = VAR_3.objects(f, RDF_type)\n"", ""if len(VAR_6) > 0:\n"", ""for ctype in iter(VAR_7):\n"", ""return False, VAR_6\n"", ""return True, None\n"", ""if ctype == self.class_rule:\n"", ""VAR_6.append(f)\n"", ""VAR_8 = VAR_3.objects(ctype, RDFS_subClassOf)\n"", ""if self.class_rule in iter(VAR_8):\n""]",1
"[""def FUNC_14(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.check_protected_output()\n"", ""VAR_20 = self.dag.reason(self).missing_output.intersection(self.existing_output\n    )\n"", ""if VAR_20:\n"", ""logger.warning(\n    \""\""\""Warning: the following output files of rule {} were not present when the DAG was created:\n{}\""\""\""\n    .format(self.rule, VAR_20))\n"", ""if self.dynamic_output:\n"", ""for VAR_28, _ in chain(*map(partial(self.expand_dynamic, VAR_13=self.\n"", ""for VAR_28, VAR_27 in zip(self.output, self.rule.output):\n"", ""os.remove(VAR_28)\n"", ""VAR_28.prepare()\n"", ""for VAR_28 in self.log:\n"", ""VAR_28.prepare()\n"", ""if self.benchmark:\n"", ""self.benchmark.prepare()\n""]",0
"[""async def FUNC_10():...\n"", ""await self.processItem(VAR_5)\n""]",0
"[""import veil_component\n"", ""from .xsrf import xsrf_token\n"", ""from .xsrf import prevent_xsrf\n"", ""from .xsrf import set_xsrf_cookie_for_page\n"", ""__all__ = [xsrf_token.__name__, prevent_xsrf.__name__,\n    set_xsrf_cookie_for_page.__name__]\n""]",1
"[""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return float(time.time())\n""]",0
"[""def FUNC_11(VAR_1, *VAR_8, **VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if current_user.is_authenticated():\n"", ""return redirect('/')\n"", ""VAR_21 = FUNC_5(VAR_1)\n"", ""if not VAR_21:\n"", ""return redirect('/')\n"", ""if not VAR_16.get(VAR_17(VAR_1.name) + '_autoregister', False):\n"", ""return redirect(url_for('.login', VAR_0=remote.name))\n"", ""VAR_22 = EmailSignUpForm(request.form)\n"", ""if VAR_22.validate_on_submit():\n"", ""VAR_27 = VAR_16.get(VAR_17(VAR_1.name) + '_account_info')\n"", ""return render_template('oauthclient/signup.html', VAR_22=form, VAR_1=remote,\n    app_title=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name].get('title', ''),\n    app_description=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name].get(\n    'description', ''), app_icon=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name\n    ].get('icon', None))\n"", ""VAR_11 = oauth_register(VAR_27, VAR_22.data)\n"", ""if VAR_11 is None:\n"", ""VAR_16.pop(VAR_17(VAR_1.name) + '_autoregister', None)\n"", ""if not oauth_authenticate(VAR_1.consumer_key, VAR_11, require_existing_link\n"", ""return current_app.login_manager.unauthorized()\n"", ""VAR_5 = FUNC_4(VAR_1, VAR_21[0], VAR_6=oauth_token[1])\n"", ""VAR_19 = signup_handlers[VAR_1.name]\n"", ""if VAR_5 is None:\n"", ""if not VAR_5.remote_account.extra_data:\n"", ""VAR_19['setup'](VAR_5)\n"", ""VAR_16.pop(VAR_17(VAR_1.name) + '_account_info', None)\n"", ""if request.args.get('next', None):\n"", ""return redirect(request.args.get('next'))\n"", ""return redirect('/')\n""]",0
"[""def FUNC_5(self, VAR_8, VAR_10):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = self.requests.get(VAR_8)\n"", ""if VAR_9:\n"", ""VAR_9.write(FUNC_0(VAR_10))\n"", ""VAR_23 = self.databuffer.get(VAR_8, [])\n"", ""VAR_9.finish()\n"", ""VAR_23.append(FUNC_0(VAR_10))\n"", ""self.databuffer[VAR_8] = VAR_23\n""]",0
"[""def FUNC_10(VAR_10):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_31 in ['cmd', 'ack', 'enq']:\n"", ""if VAR_31 in VAR_10:\n"", ""return VAR_10\n"", ""VAR_30 = VAR_10[VAR_31]\n"", ""if isinstance(VAR_30, str):\n"", ""for placeholder, replacement in [('$CR', '\\r'), ('$LF', '\\n'), ('$ACK',\n"", ""if placeholder in VAR_30:\n"", ""VAR_10[VAR_31] = VAR_30\n"", ""VAR_30 = VAR_30.replace(placeholder, replacement)\n""]",0
"[""def FUNC_13(VAR_7, VAR_1, VAR_12=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_7, six.text_type):\n"", ""VAR_7 = import_string(VAR_7)\n"", ""@wraps(VAR_7)...\n"", ""if VAR_12:\n"", ""return VAR_7(VAR_8[0], VAR_1, *VAR_8[1:], **kwargs)\n"", ""return VAR_7(VAR_1, *VAR_8, **kwargs)\n""]",0
"[""def FUNC_12(self):...\n"", ""VAR_20 = []\n"", ""for VAR_2 in self.query_order.split('.'):\n"", ""VAR_23 = VAR_2.replace('-', '')\n"", ""return self.get_url_with_query_params({self.ordering_query_param: '.'.join(\n    VAR_20)})\n"", ""if int(VAR_23) == self.column_id:\n"", ""if VAR_2.startswith('-'):\n"", ""VAR_20.append(VAR_2)\n"", ""VAR_20.append(VAR_23)\n"", ""VAR_20.append('-{}'.format(VAR_23))\n""]",0
"[""def FUNC_2(VAR_0, VAR_4):...\n"", ""VAR_7 = psycopg2.connect(dbname=pg_connection['database'], user=\n    pg_connection['user'], password=pg_connection['password'], host=\n    pg_connection['host'])\n"", ""VAR_8 = VAR_7.cursor()\n"", ""VAR_8.execute(\""\""\""\n    DELETE FROM quests\n    WHERE id = %s;\""\""\"", VAR_4)\n"", ""VAR_7.commit()\n"", ""VAR_8.close()\n"", ""VAR_7.close()\n""]",0
"[""@db.transact...\n"", ""if not self.consumed(VAR_1, VAR_2):\n"", ""VAR_8 = self.context.current_obj\n"", ""return []\n"", ""if IContainer.providedBy(VAR_8):\n"", ""return [name for name in VAR_8.listnames() if name.startswith(VAR_0)]\n""]",1
"[""def FUNC_3(self, VAR_3, VAR_4):...\n"", ""VAR_8 = self.get_all_members()\n"", ""VAR_9 = [x for x in VAR_8 if x.name == VAR_3 and x.discriminator == VAR_4][0]\n"", ""return VAR_9\n""]",0
"[""def FUNC_7(self, VAR_3):...\n"", ""VAR_3 = VAR_3.lower()\n"", ""VAR_8 = sqlite3.connect('data/ed.db').cursor()\n"", ""VAR_7 = VAR_8.execute(f\""select * from bodies where lower(name) = '{VAR_3}'\"")\n"", ""VAR_10 = VAR_7.fetchone()\n"", ""if VAR_10:\n"", ""VAR_12 = tuple(i[0] for i in VAR_7.description)\n"", ""return 'No bodies found.'\n"", ""return '\\n'.join(f\""{key.replace('_', ' ').title()}: {field}\"" for key, field in\n    zip(VAR_12[2:], VAR_10[2:]) if field)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import argparse\n"", ""import time\n"", ""import csv\n"", ""import logging\n"", ""import sys\n"", ""import shutil\n"", ""from benchmark import config, data_service\n"", ""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""logging.debug('Getting cli arguments')\n"", ""VAR_0 = argparse.ArgumentParser(description=\n    'A benchmark for genomics routines in Python.')\n"", ""VAR_1 = VAR_0.add_subparsers(title='commands', dest='command')\n"", ""VAR_1.required = True\n"", ""VAR_2 = VAR_1.add_parser('config', help=\n    'Setting up the default configuration of the benchmark. It creates the default configuration file.'\n    )\n"", ""VAR_2.add_argument('--output_config', type=str, required=True, help=\n    'Specify the output path to a configuration file.', metavar='FILEPATH')\n"", ""VAR_2.add_argument('-f', action='store_true', help=\n    'Overwrite the destination file if it already exists.')\n"", ""VAR_3 = VAR_1.add_parser('setup', help=\n    'Preparation and setting up of the data for the benchmark. It requires a configuration file.'\n    )\n"", ""VAR_3.add_argument('--config_file', required=True, help=\n    'Location of the configuration file', metavar='FILEPATH')\n"", ""VAR_4 = VAR_1.add_parser('exec', help=\n    'Execution of the benchmark modes. It requires a configuration file.')\n"", ""VAR_4.add_argument('--label', type=str, default='run', metavar='RUN_LABEL',\n    help='Label for the benchmark run.')\n"", ""VAR_4.add_argument('--config_file', type=str, required=True, help=\n    'Specify the path to a configuration file.', metavar='FILEPATH')\n"", ""VAR_5 = vars(VAR_0.parse_args())\n"", ""return VAR_5\n""]",1
"[""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return database_utilities.execute_query('select * from users')\n""]",0
"[""def FUNC_6(self, VAR_6, VAR_7):...\n"", ""self.vars[VAR_6] = VAR_7\n""]",0
"[""@VAR_0.route('/register', methods=['GET', 'POST'])...\n"", ""VAR_11 = registerForm(request.form)\n"", ""if request.method == 'POST' and VAR_11.validate():\n"", ""VAR_8 = VAR_3.connection\n"", ""return render_template('register.html', VAR_11=form)\n"", ""VAR_9 = VAR_8.cursor()\n"", ""VAR_15 = VAR_11.username.data\n"", ""VAR_18 = VAR_11.firstname.data\n"", ""VAR_19 = VAR_11.lastname.data\n"", ""VAR_20 = VAR_11.email.data\n"", ""VAR_21 = sha256_crypt.hash(VAR_11.password.data)\n"", ""VAR_10 = VAR_9.execute(\n    'INSERT INTO users (first_name, last_name, username, password, email) VALUES (%s, %s, %s, %s, %s)'\n    , (VAR_18, VAR_19, VAR_15, VAR_21, VAR_20))\n"", ""VAR_8.commit()\n"", ""if str(VAR_10):\n"", ""return redirect(url_for('login'))\n""]",1
"[""def FUNC_4(self, VAR_2, VAR_3):...\n"", ""VAR_6 = psutil.Popen(['ssh', VAR_2, 'ls', '-Fa', VAR_3.as_posix()], stdout=\n    PIPE, stderr=PIPE)\n"", ""VAR_7, VAR_8 = VAR_6.communicate()\n"", ""VAR_9 = VAR_8.decode(encoding='UTF-8')\n"", ""VAR_10 = re.search('No such file or directory', VAR_9)\n"", ""if VAR_10 is not None:\n"", ""logging.debug('Path not found')\n"", ""return True\n"", ""return False\n""]",1
"[""@app.route('/api/script_update', methods=['POST'])...\n"", ""if not app.config['FIREBASE']:\n"", ""abort(400)\n"", ""if request.json is None:\n"", ""abort(400)\n"", ""if request.json['auth_token'] != app.config['API_KEY']:\n"", ""abort(403)\n"", ""VAR_0 = request.json['session_id']\n"", ""abort(400)\n"", ""VAR_2 = {'progress': VAR_5, 'text': VAR_6}\n"", ""VAR_5 = int(request.json['progress'])\n"", ""fbdb.child('sessions').child(VAR_0).set(VAR_2)\n"", ""VAR_6 = request.json['text']\n"", ""return '', 200\n""]",1
"[""def FUNC_1(VAR_4, VAR_5):...\n"", ""VAR_7 = zipfile.ZipFile('%s' % VAR_5, 'w')\n"", ""VAR_8 = os.path.abspath(VAR_4)\n"", ""for dirname, subdirs, files in os.walk(VAR_4):\n"", ""for filename in files:\n"", ""VAR_7.close()\n"", ""if filename != VAR_0:\n"", ""VAR_16 = os.path.abspath(os.path.join(dirname, filename))\n"", ""VAR_17 = VAR_16[len(VAR_8) + 1:]\n"", ""VAR_7.write(VAR_16, VAR_17)\n""]",0
"[""def FUNC_6(self):...\n"", ""if self._IsServerAlive():\n"", ""self._server_popen.terminate()\n"", ""utils.RemoveIfExists(self._temp_options_filename)\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_14 = {'username': 'autotest', 'app': VAR_6}\n"", ""VAR_4 = '/api/hooks/builds'.format(**locals())\n"", ""VAR_15 = {'web': 'node server.js', 'worker': 'node worker.js'}\n"", ""VAR_16 = 'ecdff91c57a0b9ab82e89634df87e293d259a3aa'\n"", ""VAR_7 = {'receive_user': 'autotest', 'receive_repo': VAR_6, 'image':\n    '{app_id}:v2'.format(**locals()), 'sha': VAR_16, 'procfile': VAR_15}\n"", ""self.assertIsNone(self.client.logout())\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 403)\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json', HTTP_X_DEIS_BUILDER_AUTH=settings.BUILDER_KEY)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertIn('release', VAR_5.data)\n"", ""self.assertIn('version', VAR_5.data['release'])\n"", ""self.assertIn('domains', VAR_5.data)\n"", ""self.assertTrue(self.client.login(VAR_8='autotest', VAR_9='password'))\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertIn('results', VAR_5.data)\n"", ""VAR_14 = VAR_5.data['results'][0]\n"", ""self.assertEqual(VAR_14['sha'], VAR_16)\n"", ""self.assertEqual(VAR_14['procfile'], VAR_15)\n"", ""VAR_4 = '/api/apps/{app_id}/containers/web'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(len(VAR_5.data['results']), 1)\n"", ""VAR_17 = VAR_5.data['results'][0]\n"", ""self.assertEqual(VAR_17['type'], 'web')\n"", ""self.assertEqual(VAR_17['num'], 1)\n""]",1
"[""def __init__(self):...\n"", ""VAR_5 = [('/', CLASS_5), ('/login', CLASS_2), ('/logout', CLASS_3), (\n    '/config', CLASS_4), ('/(\\\\w+)', CLASS_5)]\n"", ""VAR_6 = os.path.dirname(__file__)\n"", ""VAR_7 = dict(xsrf_cookie=True, cookie_secret=\n    'bls9+x7PT5GIbaBuKzsGOecL9SG7KUmEh6rNbMYTpfk=', login_url='/login',\n    template_path=os.path.join(mainDir, 'templates/myStyle'), static_path=\n    os.path.join(mainDir, 'templates/myStyle/static'))\n"", ""tornado.web.Application.__init__(self, VAR_5, **settings)\n""]",1
"[""def FUNC_0(self):...\n"", ""super(CLASS_0, self).setUp()\n"", ""VAR_7.environ.pop('SWARMING_LOAD_TEST', None)\n"", ""self.root_dir = tempfile.mkdtemp(prefix='bot_main')\n"", ""self.old_cwd = VAR_7.getcwd()\n"", ""VAR_7.chdir(self.root_dir)\n"", ""VAR_7.mkdir('logs')\n"", ""self.server = xsrf_client.XsrfRemote('https://localhost:1/')\n"", ""self.attributes = {'dimensions': {'foo': ['bar'], 'id': ['localhost'],\n    'pool': ['default']}, 'state': {'cost_usd_hour': 3600.0}, 'version': '123'}\n"", ""self.mock(zip_package, 'generate_version', lambda : '123')\n"", ""self.bot = bot.Bot(self.server, self.attributes, 'https://localhost:1/',\n    'version1', self.root_dir, self.fail)\n"", ""self.mock(self.bot, 'post_error', self.fail)\n"", ""self.mock(self.bot, 'restart', self.fail)\n"", ""self.mock(subprocess42, 'call', self.fail)\n"", ""self.mock(time, 'time', lambda : 100.0)\n"", ""VAR_4 = VAR_7.path.join(test_env_bot_code.BOT_DIR, 'config', 'config.json')\n"", ""VAR_36 = json.load(VAR_32)\n"", ""self.mock(bot_main, 'get_config', lambda : VAR_36)\n"", ""self.mock(bot_main, 'THIS_FILE', VAR_7.path.join(test_env_bot_code.BOT_DIR,\n    'swarming_bot.zip'))\n""]",1
"[""@pytest.fixture(scope='session', autouse=True)...\n"", ""VAR_13 = FUNC_6()\n"", ""conn.execute(f'DROP DATABASE IF EXISTS {VAR_13}')\n"", ""conn.execute(f'CREATE DATABASE {VAR_13}')\n"", ""FUNC_10()\n"", ""VAR_0.addfinalizer(lambda : FUNC_5(VAR_4))\n""]",1
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""VAR_5 = {constraint for target_adaptor in VAR_1 for constraint in VAR_0.\n    compatibility_or_constraints(getattr(target_adaptor, 'compatibility',\n    None))}\n"", ""VAR_6 = []\n"", ""for constraint in sorted(VAR_5):\n"", ""VAR_6.extend(['--interpreter-constraint', text_type(constraint)])\n"", ""return VAR_6\n""]",0
"[""def FUNC_1(VAR_2):...\n"", ""return CLASS_0.all().filter('email =', VAR_2).get()\n""]",0
"[""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.nodes.pop()\n""]",1
"[""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_22 = 0.1\n"", ""VAR_23 = self.metrics['time_coeff'] * random.expovariate(self.metrics[\n    'time_lambda'])\n"", ""VAR_24 = int(VAR_23 / VAR_22)\n"", ""VAR_25 = VAR_23 - VAR_24 * VAR_22\n"", ""for i in xrange(VAR_24):\n"", ""time.sleep(VAR_22)\n"", ""time.sleep(VAR_25)\n"", ""if self.die:\n"", ""if self.die:\n""]",1
"[""def FUNC_4(self, VAR_3, **VAR_6):...\n"", ""logging.warn('url_open(%s, %s)', VAR_3[:500], str(VAR_6)[:500])\n"", ""if not self._requests:\n"", ""return None\n"", ""VAR_6.pop('stream', None)\n"", ""for i, n in enumerate(self._requests):\n"", ""if n[0] == VAR_3:\n"", ""self.fail('Unknown request %s' % VAR_3)\n"", ""VAR_9 = self._requests.pop(i)\n"", ""if len(VAR_9) != 4:\n"", ""self.fail('Expected normal request, got json data; %s' % VAR_3)\n"", ""VAR_10, VAR_11, VAR_12, VAR_4 = VAR_9\n"", ""if callable(VAR_11):\n"", ""VAR_11(VAR_6)\n"", ""self.assertEqual(VAR_11, VAR_6)\n"", ""if VAR_12 is not None:\n"", ""return FUNC_0(VAR_12, VAR_3, VAR_4)\n"", ""return None\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_4 = {'username': 'first', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(VAR_6.data['is_superuser'])\n"", ""VAR_4 = {'username': 'second', 'password': 'password', 'email':\n    'autotest@deis.io'}\n"", ""VAR_5 = '/api/auth/register'\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertFalse(VAR_6.data['is_superuser'])\n"", ""self.assertTrue(self.client.login(VAR_1='first', VAR_2='password'))\n"", ""VAR_5 = '/api/admin/perms'\n"", ""VAR_7 = {'username': 'second'}\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""VAR_6 = self.client.get(VAR_5)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 2)\n"", ""self.assertIn('second', str(VAR_6.data['results']))\n""]",1
"[""from __future__ import unicode_literals\n"", ""import frappe, unittest\n"", ""from frappe.model.db_query import DatabaseQuery\n"", ""from frappe.desk.reportview import get_filters_cond\n"", ""def FUNC_1(self):...\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    limit_page_length=None))\n"", ""def FUNC_2(self):...\n"", ""self.assertTrue({'name': 'DocType', 'issingle': 0} in DatabaseQuery(\n    'DocType').execute(fields=['name', 'issingle'], limit_page_length=None))\n"", ""def FUNC_3(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[['DocType', 'name', 'like', 'J%']]))\n"", ""def FUNC_4(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[{'name': ['like', 'J%']}]))\n"", ""def FUNC_5(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['like', 'J%']}))\n"", ""def FUNC_6(self):...\n"", ""self.assertTrue({'name': 'DocField'} in DatabaseQuery('DocType').execute(\n    filters={'name': 'DocField'}))\n"", ""def FUNC_7(self):...\n"", ""self.assertFalse(DatabaseQuery('DocType').execute(filters={'name': ['in',\n    None]}))\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['not in', None]}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertTrue(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['in', 'DocType,DocField']}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertFalse(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['not in', 'DocType,DocField']}))\n"", ""def FUNC_8(self):...\n"", ""VAR_3 = DatabaseQuery('DocField').execute(filters={'parent': 'DocType'},\n    fields=['fieldname', 'fieldtype'], or_filters=[{'fieldtype': 'Table'},\n    {'fieldtype': 'Select'}])\n"", ""self.assertTrue({'fieldtype': 'Table', 'fieldname': 'fields'} in VAR_3)\n"", ""self.assertTrue({'fieldtype': 'Select', 'fieldname': 'document_type'} in VAR_3)\n"", ""self.assertFalse({'fieldtype': 'Check', 'fieldname': 'issingle'} in VAR_3)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""frappe.db.sql('delete from tabEvent')\n"", ""VAR_4 = FUNC_0()\n"", ""VAR_5 = FUNC_0(VAR_1='2016-07-05 23:59:59')\n"", ""VAR_6 = FUNC_0(VAR_1='2016-07-06 00:00:00')\n"", ""VAR_7 = FUNC_0(VAR_1='2016-07-07 23:59:59')\n"", ""VAR_8 = FUNC_0(VAR_1='2016-07-08 00:00:01')\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between',\n    None]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-06', '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_6.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_4.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_6.name} not in VAR_3)\n"", ""def FUNC_10(self):...\n"", ""frappe.set_user('test1@example.com')\n"", ""self.assertRaises(frappe.PermissionError, get_filters_cond, 'DocType', dict\n    (istable=1), [])\n"", ""self.assertTrue(get_filters_cond('DocType', dict(istable=1), [],\n    ignore_permissions=True))\n"", ""frappe.set_user('Administrator')\n"", ""def FUNC_11(self):...\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, version()'], limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (select name from tabUser), count(name))'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, (select count(*) from tabSessions)'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    \""issingle, SELECT LOCATE('', `tabUser`.`user`) AS user;\""], limit_start=\n    0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (SELECT name from tabUser), count(*))'],\n    limit_start=0, limit_page_length=1)\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'count(name)'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('count(name)' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    \""locate('', name) as _relevance\""], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('_relevance' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'date(creation) as creation'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('creation' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'datediff(modified, creation) as date_diff'], limit_start=0,\n    limit_page_length=1)\n"", ""self.assertTrue('date_diff' in VAR_3[0])\n"", ""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""def FUNC_2(VAR_1, VAR_4, VAR_2, VAR_5=0):...\n"", ""VAR_6 = 'string' % (VAR_2, VAR_4, VAR_1, VAR_5)\n"", ""return {'status': 1}\n""]",1
"[""from __future__ import unicode_literals\n"", ""from six import iteritems, string_types\n"", ""\""\""\""build query for doclistview and return results\""\""\""\n"", ""import frappe, json, copy, re\n"", ""import frappe.defaults\n"", ""import frappe.share\n"", ""import frappe.permissions\n"", ""from frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date\n"", ""from frappe import _\n"", ""from frappe.model import optional_fields\n"", ""from frappe.client import check_parent_permission\n"", ""from frappe.model.utils.user_settings import get_user_settings, update_user_settings\n"", ""from datetime import datetime\n"", ""def __init__(self, VAR_0):...\n"", ""self.doctype = VAR_0\n"", ""self.tables = []\n"", ""self.conditions = []\n"", ""self.or_conditions = []\n"", ""self.fields = None\n"", ""self.user = None\n"", ""self.ignore_ifnull = False\n"", ""self.flags = frappe._dict()\n"", ""def FUNC_4(self, VAR_7=None, VAR_8=None, VAR_4=None, VAR_9=None, VAR_10=...\n"", ""if not VAR_18 and not frappe.has_permission(self.doctype, 'read', VAR_19=user):\n"", ""frappe.flags.error_message = _('Insufficient Permission for {0}').format(frappe\n    .bold(self.doctype))\n"", ""if isinstance(VAR_8, dict) or isinstance(VAR_8, list) and VAR_8 and isinstance(\n"", ""VAR_4, VAR_8 = VAR_8, VAR_4\n"", ""if VAR_8 and isinstance(VAR_4, list) and len(VAR_4) > 1 and isinstance(VAR_4\n"", ""if VAR_8:\n"", ""VAR_4, VAR_8 = VAR_8, VAR_4\n"", ""self.fields = VAR_8\n"", ""self.fields = ['`tab{0}`.`name`'.format(self.doctype)]\n"", ""if VAR_23:\n"", ""VAR_13 = VAR_23\n"", ""if VAR_24:\n"", ""VAR_14 = VAR_24\n"", ""if VAR_25:\n"", ""VAR_14 = VAR_25\n"", ""self.filters = VAR_4 or []\n"", ""self.or_filters = VAR_9 or []\n"", ""self.docstatus = VAR_10 or []\n"", ""self.group_by = VAR_11\n"", ""self.order_by = VAR_12\n"", ""self.limit_start = 0 if VAR_13 is False else cint(VAR_13)\n"", ""self.limit_page_length = cint(VAR_14) if VAR_14 else None\n"", ""self.with_childnames = VAR_16\n"", ""self.debug = VAR_17\n"", ""self.join = VAR_21\n"", ""self.distinct = VAR_22\n"", ""self.as_list = VAR_15\n"", ""self.ignore_ifnull = VAR_26\n"", ""self.flags.ignore_permissions = VAR_18\n"", ""self.user = VAR_19 or frappe.session.user\n"", ""self.update = VAR_29\n"", ""self.user_settings_fields = copy.deepcopy(self.fields)\n"", ""if VAR_31:\n"", ""self.user_settings = json.loads(VAR_31)\n"", ""if VAR_7:\n"", ""VAR_39 = self.run_custom_query(VAR_7)\n"", ""VAR_39 = self.build_and_run()\n"", ""if VAR_20 and not VAR_15 and self.doctype:\n"", ""self.add_comment_count(VAR_39)\n"", ""if VAR_27:\n"", ""self.save_user_settings_fields = VAR_28\n"", ""return VAR_39\n"", ""self.update_user_settings()\n""]",0
"[""def FUNC_12(VAR_15):...\n"", ""VAR_61 = VAR_0.format(list_root_ids=','.join(str(root_id) for root_id in\n    root_ids))\n"", ""cursor.execute(VAR_61)\n"", ""return [{'id': row[0], 'child_branch_id': row[1], 'child_leaf_id': row[2],\n    'parent_id': row[3], 'level': row[4]} for row in cursor.fetchall()]\n""]",1
"[""def FUNC_17(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_3='X-Some')\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', VAR_20={'X-Some': token})\n"", ""self.assertEqual([('POST', True)], VAR_12)\n""]",0
"[""def FUNC_13(self):...\n"", ""self.compilation_ok(\n    \""\""\""\nif header :contains :comparator \""i;octet\"" \""Subject\"" \""MAKE MONEY FAST\"" {\n  discard;\n}\n\""\""\""\n    )\n"", ""self.representation_is('string')\n""]",0
"[""@api.model_cr...\n"", ""tools.drop_view_if_exists(self.env.cr, self._table)\n"", ""self.env.cr.execute(\n    \""\""\""CREATE or REPLACE VIEW %s as (\n            %s\n            FROM ( %s )\n            %s\n            )\""\""\""\n     % (self._table, self._select(), self._from(), self._group_by()))\n""]",1
"[""@auth.before_request...\n"", ""g.user = current_user\n""]",0
"[""@classmethod...\n"", ""return VAR_4._create_jardep('scala-library', VAR_6)\n""]",1
"[""def FUNC_3(self, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = self._cliq_get_cluster_info(VAR_8)\n"", ""VAR_20 = []\n"", ""for vip in VAR_19.findall('response/cluster/vip'):\n"", ""VAR_20.append(vip.attrib.get('ipAddress'))\n"", ""if len(VAR_20) == 1:\n"", ""return VAR_20[0]\n"", ""VAR_21 = etree.tostring(VAR_19)\n"", ""VAR_22 = _(\n    'Unexpected number of virtual ips for cluster  %(cluster_name)s. Result=%(_xml)s'\n    ) % {'cluster_name': VAR_8, '_xml': VAR_21}\n""]",0
"[""def FUNC_29(VAR_16, VAR_22, VAR_28):...\n"", ""VAR_53 = (\""SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\"".\n    format(VAR_22, VAR_28))\n"", ""VAR_54 = VAR_16.exec(VAR_53)\n"", ""VAR_54 = [VAR_41 for VAR_41 in VAR_54 if FUNC_34(VAR_16, VAR_22, VAR_28,\n    FUNC_23(VAR_41[0]))]\n"", ""VAR_78 = {}\n"", ""for VAR_41 in VAR_54:\n"", ""VAR_78[VAR_41[0]] = VAR_41[1]\n"", ""return VAR_78\n""]",1
"[""def FUNC_1(self):...\n"", ""VAR_1 = 'cmd'\n"", ""self.assertEqual(escape_path_argument('C:\\\\Windows\\\\has-a-weird-shell.txt',\n    VAR_1), '\""C:\\\\Windows\\\\has-a-weird-shell.txt\""')\n"", ""self.assertEqual(escape_path_argument('C:\\\\Windows\\\\lolrofl\\\\dirs\\\\', VAR_1\n    ), '\""C:\\\\Windows\\\\lolrofl\\\\dirs\\\\\""')\n"", ""self.assertEqual(escape_path_argument('X:\\\\Users\\\\Maito Gai\\\\fi le.exe',\n    VAR_1), '\""X:\\\\Users\\\\Maito Gai\\\\fi le.exe\""')\n"", ""self.assertEqual(escape_path_argument('X:\\\\Users\\\\Mai to Gai\\\\director y\\\\',\n    VAR_1), '\""X:\\\\Users\\\\Mai to Gai\\\\director y\\\\\""')\n"", ""self.assertEqual(escape_path_argument(\n    'X:\\\\Users\\\\Maito Gai\\\\\""seven-gates\"".y', VAR_1),\n    '\""X:\\\\Users\\\\Maito Gai\\\\^\""seven-gates^\"".y\""')\n"", ""self.assertEqual(escape_path_argument('System32\\\\my-custom relative tool\\\\',\n    VAR_1), '\""System32\\\\my-custom relative tool\\\\\""')\n"", ""self.assertEqual(escape_path_argument('System32\\\\illegal\"" name \""\"".curd',\n    VAR_1), '\""System32\\\\illegal^\"" name ^\""^\"".curd\""')\n""]",0
"[""def FUNC_5(*VAR_17):...\n"", ""VAR_18 = VAR_8.replace('_', '-')\n"", ""VAR_9 = ' '.join(str(elem) for elem in VAR_17)\n"", ""return self._exec_adb_cmd(VAR_18, VAR_9)\n""]",1
"[""def FUNC_12(self, VAR_20, VAR_21):...\n"", ""return VAR_21 in self.inspect().get(VAR_20, {}).get('tables')\n""]",0
"[""\""\""\""Test admin interface.\""\""\""\n"", ""from __future__ import absolute_import, print_function\n"", ""import uuid\n"", ""from flask import url_for\n"", ""from flask_admin import Admin, menu\n"", ""from mock import patch\n"", ""from sqlalchemy.exc import SQLAlchemyError\n"", ""from invenio_records.admin import record_adminview\n"", ""from invenio_records.api import Record\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = Admin(VAR_0, name='Test')\n"", ""assert 'model' in record_adminview\n"", ""assert 'modelview' in record_adminview\n"", ""VAR_3 = record_adminview.pop('model')\n"", ""VAR_4 = record_adminview.pop('modelview')\n"", ""VAR_2.add_view(VAR_4(VAR_3, VAR_1.session, **record_adminview))\n"", ""VAR_5 = {str(item.name): item for item in VAR_2.menu()}\n"", ""assert 'Records' in VAR_5\n"", ""assert VAR_5['Records'].is_category()\n"", ""VAR_6 = {str(item.name): item for item in VAR_5['Records'].get_children()}\n"", ""assert 'Record Metadata' in VAR_6\n"", ""assert isinstance(VAR_6['Record Metadata'], menu.MenuView)\n"", ""VAR_7 = str(uuid.uuid4())\n"", ""Record.create({'title': 'test'}, id_=rec_uuid)\n"", ""VAR_1.session.commit()\n"", ""VAR_8 = url_for('recordmetadata.index_view')\n"", ""VAR_9 = url_for('recordmetadata.delete_view')\n"", ""VAR_10 = url_for('recordmetadata.details_view', id=rec_uuid)\n"", ""VAR_11 = client.get(VAR_8)\n"", ""assert VAR_11.status_code == 200\n"", ""db_mock.side_effect = SQLAlchemyError()\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n"", ""VAR_11 = client.get(VAR_10)\n"", ""assert VAR_11.status_code == 200\n"", ""assert '<pre>null</pre>' in VAR_11.get_data(as_text=True)\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n""]",1
"[""def FUNC_0(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n"", ""chaos.CREATE_ERROR_RATE = 0\n"", ""chaos.DESTROY_ERROR_RATE = 0\n"", ""chaos.START_ERROR_RATE = 0\n"", ""chaos.STOP_ERROR_RATE = 0\n"", ""settings.SCHEDULER_MODULE = 'chaos'\n"", ""settings.SSH_PRIVATE_KEY = '<some-ssh-private-key>'\n""]",1
"[""def FUNC_24(self, VAR_7, VAR_17):...\n"", ""self.common.extend_volume(VAR_7, VAR_17)\n""]",0
"[""import collections\n"", ""import os\n"", ""import pymongo\n"", ""from django.http import Http404\n"", ""from cuckoo.core.database import Database, TASK_PENDING\n"", ""from cuckoo.common.mongo import mongo\n"", ""VAR_0 = Database()\n"", ""@staticmethod...\n"", ""if not isinstance(VAR_1, int):\n"", ""VAR_9 = {}\n"", ""VAR_10 = VAR_0.view_task(VAR_1, details=True)\n"", ""if VAR_10:\n"", ""VAR_19 = VAR_10.to_dict()\n"", ""return Exception('Task not found')\n"", ""VAR_19['guest'] = {}\n"", ""if VAR_10.guest:\n"", ""VAR_19['guest'] = VAR_10.guest.to_dict()\n"", ""VAR_19['errors'] = []\n"", ""for error in VAR_10.errors:\n"", ""VAR_19['errors'].append(error.message)\n"", ""VAR_19['sample'] = {}\n"", ""if VAR_10.sample_id:\n"", ""VAR_26 = VAR_0.view_sample(VAR_10.sample_id)\n"", ""VAR_9['task'] = VAR_19\n"", ""VAR_19['sample'] = VAR_26.to_dict()\n"", ""return VAR_9\n""]",1
"[""def FUNC_24(VAR_10, VAR_3):...\n"", ""VAR_6 = FUNC_21()\n"", ""VAR_28 = VAR_6, VAR_3\n"", ""VAR_18 = 'INSERT INTO {} VALUES (?, ?)'.format(CFG('admintoken_table_name'))\n"", ""VAR_10.execute(VAR_18, VAR_28)\n""]",0
"[""def FUNC_15(VAR_6):...\n"", ""VAR_21 = re.compile('\\\\d+.\\\\d+')\n"", ""if 'Server' not in VAR_6.headers:\n"", ""return True\n"", ""VAR_28 = VAR_21.search(VAR_6.headers['Server'])\n"", ""if not VAR_28:\n"", ""return True\n"", ""if len(VAR_28.group()) > 1:\n"", ""return False\n"", ""return True\n""]",0
"[""def FUNC_19(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.cursor.execute('select storeid, storename from store')\n""]",0
"[""def FUNC_10(VAR_32=None, VAR_33=None, VAR_22=None, VAR_23=None, VAR_5=False,...\n"", ""if VAR_34:\n"", ""VAR_78 = VAR_32[0:VAR_34]\n"", ""VAR_78 = VAR_32\n"", ""VAR_79 = VAR_33[0:VAR_34]\n"", ""VAR_79 = VAR_33\n"", ""VAR_57 = {'Core keywords': FUNC_19(VAR_32, VAR_33, VAR_5=spires)}\n"", ""if not VAR_10:\n"", ""VAR_57['Author keywords'] = FUNC_17(VAR_22, VAR_5=spires)\n"", ""return VAR_57\n"", ""VAR_57['Composite keywords'] = FUNC_15(VAR_79, VAR_5=spires)\n"", ""VAR_57['Single keywords'] = FUNC_14(VAR_78, VAR_5=spires)\n"", ""VAR_57['Field codes'] = FUNC_18(VAR_78, VAR_79, VAR_5=spires)\n"", ""VAR_57['Acronyms'] = FUNC_16(VAR_23)\n""]",0
"[""def FUNC_4(self, VAR_5):...\n"", ""VAR_20 = 'string' % VAR_5\n"", ""self.c.execute(VAR_20)\n"", ""VAR_3 = self.c.fetchone()\n"", ""return VAR_3[0], VAR_3[1], VAR_3[2]\n""]",1
"[""def FUNC_1(self):...\n"", ""VAR_1 = bot.Bot(None, {}, 'https://localhost:1/',\n    '1234-1a2b3c4-tainted-joe', 'base_dir', None)\n"", ""VAR_2 = threading.Event()\n"", ""VAR_1.call_later(0.001, VAR_2.set)\n"", ""self.assertTrue(VAR_2.wait(1))\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_15 = time.time()\n"", ""print('=' * 25)\n"", ""print(\""\""\""\n[*]Target: {}\n[*]Date: {}\""\""\"".format(VAR_6.get(), datetime.now().\n    strftime('%d/%m/%Y %H:%M:%S')))\n"", ""VAR_16 = [VAR_6.get()]\n"", ""if VAR_14.get() == 'On':\n"", ""VAR_16 += bane.crawl(VAR_6.get(), bypass=True)\n"", ""VAR_17 = VAR_12.get()\n"", ""if len(VAR_17) == 0:\n"", ""VAR_17 = None\n"", ""if VAR_8.get() == 'GET':\n"", ""VAR_21 = True\n"", ""if VAR_8.get() == 'POST':\n"", ""VAR_22 = False\n"", ""VAR_21 = False\n"", ""VAR_21 = True\n"", ""VAR_18 = False\n"", ""VAR_22 = True\n"", ""VAR_22 = True\n"", ""if VAR_13.get() == 'On':\n"", ""VAR_18 = True\n"", ""VAR_19 = None\n"", ""VAR_20 = VAR_7.get()\n"", ""if len(VAR_20) > 0:\n"", ""VAR_19 = VAR_20\n"", ""for x in VAR_16:\n"", ""if VAR_0 == True:\n"", ""print(\""\""\""[*]Test was finished at: {}\n[*]Duration: {} seconds\n\""\""\"".format(\n    datetime.now().strftime('%d/%m/%Y %H:%M:%S'), int(time.time() - VAR_15)))\n"", ""print('[*]URL: {}'.format(x))\n"", ""print('=' * 25)\n"", ""bane.xss(x, VAR_11=payload.get(), VAR_12=pr, VAR_21=get, VAR_22=post,\n    VAR_10=user_agent.get(), VAR_18=fresh, VAR_7=ck)\n""]",0
"[""def FUNC_12(self, VAR_16=None):...\n"", ""if not VAR_16:\n"", ""VAR_16 = self.path[-1:][0]\n"", ""return {'directories': VAR_0.select('directory', 'parent_directory_id = ' +\n    str(VAR_16) + ' AND user_id = ' + str(self.user_id)), 'files': VAR_0.\n    select('file', 'directory_id = ' + str(VAR_16) + ' AND user_id = ' +\n    str(self.user_id))}\n""]",1
"[""def FUNC_20(self):...\n"", ""if self.child:\n"", ""return False\n"", ""return True\n""]",0
"[""def FUNC_6():...\n"", ""VAR_13.throw(_('Invalid Search Field'), VAR_13.DataError)\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""VAR_10 = [(\""(RCLONE_CONFIG_\\\\S*_ACCESS_KEY_ID=')(\\\\S*)(\\\\S\\\\S\\\\S\\\\S')\"",\n    '\\\\1***\\\\3'), (\""(RCLONE_CONFIG_\\\\S*_SECRET_ACCESS_KEY=')(\\\\S*)(')\"",\n    '\\\\1***\\\\3'), (\""(RCLONE_CONFIG_\\\\S*_KEY=')(\\\\S*)(')\"", '\\\\1***\\\\3'), (\n    \""(RCLONE_CONFIG_\\\\S*_KEY=')(\\\\S*)(')\"", '\\\\1***\\\\3'), (\n    \""(RCLONE_CONFIG_\\\\S*_CLIENT_ID=')(\\\\S*)(\\\\S\\\\S\\\\S\\\\S')\"", '\\\\1***\\\\3'),\n    (\""(RCLONE_CONFIG_\\\\S*_SERVICE_ACCOUNT_CREDENTIALS=')([^']*)(')\"",\n    '\\\\1{***}\\\\3')]\n"", ""for regex, replace in VAR_10:\n"", ""VAR_0 = re.sub(regex, replace, VAR_0)\n"", ""return VAR_0\n""]",0
"[""def FUNC_25(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.set('modified', now())\n"", ""VAR_54.db.set_value(self.doctype, self.name, 'modified', self.modified,\n    update_modified=False)\n""]",0
"[""def FUNC_6(self):...\n"", ""for i, step in enumerate(self._r_steps_, 1):\n"", ""VAR_31, VAR_3 = step\n"", ""return None, None, None\n"", ""if VAR_3 == VAR_0:\n"", ""return i, VAR_31, VAR_3\n""]",0
"[""def FUNC_0(self, VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = os.path.join(VAR_1, 'saml2_settings.py')\n"", ""VAR_2.update({'SAML2_LOGIN_REDIRECT_URL': '/', 'SAML2_LOGOUT_REDIRECT_URL':\n    '/logged-out', 'SAML2_SETTINGS_MODULE': VAR_9, 'TOKEN_LOGIN_SHARED_KEY':\n    'shared_secret', 'TOKEN_LOGIN_SUCCESS_REDIRECT_URL':\n    'http://test.localhost/success', 'TOKEN_LOGIN_FAILURE_REDIRECT_URL':\n    'http://test.localhost/failure'})\n"", ""return VAR_2\n""]",1
"[""def __eq__(self, VAR_22):...\n"", ""if isinstance(VAR_22, CLASS_3):\n"", ""return VAR_22._r_item_ == self._r_item_\n"", ""return VAR_22 == self._r_item_\n""]",1
"[""__author__ = 'vladimir'\n"", ""import ujson\n"", ""from flask import Blueprint\n"", ""VAR_0 = '/post'\n"", ""VAR_1 = Blueprint('post', __name__)\n"", ""@VAR_1.route(VAR_0 + '/create', methods=['GET'])...\n"", ""return ujson.dumps({'success': True})\n""]",1
"[""def FUNC_16(self):...\n"", ""VAR_6 = None\n"", ""VAR_6 = tempfile.NamedTemporaryFile(delete=False)\n"", ""if VAR_6:\n"", ""VAR_6.close()\n"", ""os.remove(VAR_6.name)\n"", ""os.chmod(VAR_6.name, stat.S_IREAD)\n"", ""self._mox.StubOutWithMock(url_helper, 'UrlOpen')\n"", ""url_helper.UrlOpen(mox.IgnoreArg(), method='GET').AndReturn('data')\n"", ""self._mox.ReplayAll()\n"", ""self.assertFalse(url_helper.DownloadFile(VAR_6.name, 'http://www.fakeurl.com'))\n"", ""self._mox.VerifyAll()\n""]",0
"[""def FUNC_11(VAR_5):...\n"", ""return '.' in VAR_5 and VAR_5.rsplit('.', 1)[1].lower() in VAR_2\n""]",1
"[""async def FUNC_3(VAR_8: str, VAR_5: str):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_15 = -1\n"", ""await cursor.execute(\n    \""INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\""\n     % (VAR_8, VAR_5))\n"", ""await conn.rollback()\n"", ""await conn.commit()\n"", ""VAR_15 = conn.insert_id()\n"", ""FUNC_10(ex)\n"", ""return True, VAR_15\n"", ""return False, -1\n""]",1
"[""def FUNC_23(self):...\n"", ""VAR_14 = self.new_mocked_client(client.NSX3Client)\n"", ""VAR_14.delete('ports/11')\n"", ""FUNC_2('delete', VAR_14, 'https://1.2.3.4/api/v1/ports/11')\n""]",0
"[""def __init__(self, VAR_0):...\n"", ""super(CLASS_4, self).__init__('\\\\url{' + VAR_0 + '}')\n""]",1
"[""def FUNC_4(self, VAR_10, VAR_11, VAR_12):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_12.lower()\n"", ""return [VAR_0 for VAR_0 in VAR_11 if VAR_16 in VAR_0.ud.lower()]\n""]",0
"[""def __init__(self, VAR_19):...\n"", ""self._store = VAR_19\n""]",0
"[""def FUNC_9(VAR_9):...\n"", ""if not isinstance(VAR_9, six.text_type):\n"", ""VAR_9 = six.text_type(VAR_9, 'utf-8', 'ignore')\n"", ""VAR_9 = six.text_type(unidecode(VAR_9))\n"", ""VAR_24 = []\n"", ""for item in VAR_9.split():\n"", ""VAR_24.append(item.lower() if item not in ('AND', 'OR', 'NOT') else item)\n"", ""return ' '.join(VAR_24)\n""]",0
"[""def FUNC_1(VAR_2):...\n"", ""if not app.config.get('USE_AUTH'):\n"", ""return True\n"", ""if VAR_2 == g.user_type:\n"", ""return True\n"", ""return False\n""]",0
"[""def FUNC_24(self):...\n"", ""return self.finish()\n""]",0
"[""@property...\n"", ""return FUNC_0(self.file).st_mtime\n""]",0
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""def FUNC_20(self, VAR_13):...\n"", ""self.copy_database_file()\n"", ""VAR_15 = self.create_tab_title_from_filepath(self.\n    filechooser_creation_dialog.get_current_name())\n"", ""self.start_database_creation_routine(VAR_15)\n"", ""self.override_dialog.destroy()\n""]",0
"[""def FUNC_3(self):...\n"", ""GenericRequest._prepare(self)\n"", ""VAR_15, VAR_16 = tempfile.mkstemp()\n"", ""self.files = list(zip(self.submission_format, self.filenames)) + [('input',\n    VAR_16)]\n""]",0
"[""import random\n"", ""import string\n"", ""from urllib import quote\n"", ""from saker.fuzzers.fuzzer import Fuzzer\n"", ""\""\""\""Code Payload\""\""\""\n"", ""VAR_0 = {'a': '', 'c': '', 'd': '', 'e': '', 'h': '', 'i': '', 'j':\n    '', 'l': '', 'o': '', 'p': '', 'r': '', 'q': '', 's': '', 'w':\n    '', 'x': '', 'y': ''}\n"", ""def __init__(self):...\n"", ""super(CLASS_0, self).__init__()\n"", ""@staticmethod...\n"", ""for i in xrange(256):\n"", ""yield chr(i)\n"", ""@staticmethod...\n"", ""for i in xrange(VAR_1):\n"", ""yield unichr(random.randint(0, 65535))\n"", ""@staticmethod...\n"", ""VAR_2 = VAR_2.replace('A', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('A', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('A', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('a', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('e', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('a', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('e', '', VAR_1)\n"", ""VAR_2 = VAR_2.replace('o', '', VAR_1)\n"", ""return VAR_2\n""]",1
"[""@app.route('/nominal')...\n"", ""return redirect('https://soundcloud.com/iamnominal')\n""]",0
"[""def FUNC_9(self):...\n"", ""VAR_7 = BokChoyTestSuite('', VAR_3=True)\n"", ""VAR_1 = 'tests'\n"", ""self.assertEqual(VAR_7.cmd, self._expected_command(VAR_1=name, VAR_3=True))\n""]",1
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self._prepare()\n"", ""self._execute()\n""]",0
"[""def FUNC_23(VAR_33, VAR_13, VAR_20, VAR_21, VAR_12):...\n"", ""if VAR_21 == wzrpc.status.success:\n"", ""self.log.debug('Successfull auth for (%s, %s)', VAR_16, VAR_17)\n"", ""if VAR_21 == wzrpc.status.e_auth_wrong_hash:\n"", ""if wzrpc.status.e_timeout:\n"", ""self.log.warn('Timeout {0}, retrying'.format(VAR_12[0]))\n"", ""self.log.warning('Recvd unknown reply for (%s, %s) %s: %s', VAR_16, VAR_17,\n    wzrpc.name_status(VAR_21), repr(VAR_12))\n"", ""VAR_33.retry = True\n""]",0
"[""def FUNC_1(self, VAR_2, VAR_5):...\n"", ""VAR_0.info('we have called insert placing data on bracket {}'.format(VAR_2))\n"", ""VAR_10 = bracket_utils.get_tournament_placings(VAR_2)\n"", ""for VAR_26, placing in VAR_10.items():\n"", ""VAR_26 = sanitize_tag(VAR_26)\n"", ""VAR_0.info('tournament placings for {} are {}'.format(VAR_2, VAR_10))\n"", ""VAR_26 = get_coalesced_tag(VAR_26)\n"", ""VAR_8 = ('INSERT INTO placings (url, player, place) VALUES ' +\n    \"" ('{}', '{}', '{}')\"".format(VAR_2, VAR_26, placing))\n"", ""self.db.exec(VAR_8)\n"", ""if 'christmasmike' == VAR_26 and VAR_5:\n"", ""if placing < 10:\n"", ""VAR_40 = \""Congrats on making {} dude! You're the best.\"".format(placing)\n"", ""tweet(VAR_40)\n""]",1
"[""\""\""\""\nTest core utility functions.\n\""\""\""\n"", ""import mock\n"", ""from unittest import skip\n"", ""from ddt import ddt, data, unpack\n"", ""from django.conf import settings\n"", ""from django.contrib.sites.models import Site\n"", ""from django.core import mail\n"", ""from django.test import TestCase\n"", ""from core.common.utils import send_email, get_onboarding_percentage\n"", ""from core.common import onboarding\n"", ""from core.common.utils import get_onboarding_setting, ONBOARDING_STEPS_DEFAULT_TEMPLATE, get_onboarding_status_with_settings\n"", ""\""\""\""\n    Test auxiliary functions.\n    \""\""\""\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""send_email(context_data={'milestone': 'first', 'students_number': 2,\n    'course_title': 'Test Course', 'lesson_title': 'Test Lesson',\n    'current_site': Site.objects.get_current(), 'course_id': 1,\n    'unit_lesson_id': 1, 'courselet_pk': 1}, from_email=settings.EMAIL_FROM,\n    to_email=['test@example.com'], template_subject=\n    'ct/email/milestone_ortc_notify_subject', template_text=\n    'ct/email/milestone_ortc_notify_text')\n"", ""self.assertEqual(len(mail.outbox), 1)\n"", ""@VAR_2.patch('core.common.utils.c_onboarding_status')...\n"", ""VAR_5 = VAR_2.return_value\n"", ""VAR_5.find_one.return_value = VAR_0\n"", ""self.assertEqual(get_onboarding_percentage(1), VAR_1)\n"", ""@VAR_2.patch('core.common.utils.c_onboarding_status')...\n"", ""self.assertEqual(get_onboarding_setting(VAR_3), VAR_4)\n"", ""@skip...\n"", ""def FUNC_4(VAR_3):...\n"", ""VAR_10 = {onboarding.INTRODUCTION_INTRO: {'html': '<p>instructor_intro</p>',\n    'description': 'instructor_intro desc', 'title': 'instructor_intro'},\n    onboarding.CREATE_COURSE: {'html': '<p>create_course</p>',\n    'description': 'create_course desc', 'title': 'create_course'},\n    onboarding.CREATE_COURSELET: {'html': '<p>create_courselet</p>',\n    'description': 'create_courselet desc', 'title': 'create_courselet'},\n    onboarding.NEXT_STEPS: {'html': '<p>next_steps</p>', 'description':\n    'next_steps desc', 'title': 'next_steps'}, onboarding.INVITE_SOMEBODY:\n    {'html': '<p>invite_somebody</p>', 'description':\n    'invite_somebody desc', 'title': 'invite_somebody'}, onboarding.\n    CREATE_THREAD: {'html': '<p>create_thread</p>', 'description':\n    'create_thread desc', 'title': 'create_thread'}, onboarding.\n    VIEW_INTRODUCTION: {'html': '<p>view_introduction</p>', 'description':\n    'view_introduction desc', 'title': 'view_introduction'}, onboarding.\n    PREVIEW_COURSELET: {'html': '<p>preview_courselet</p>', 'description':\n    'preview_courselet desc', 'title': 'preview_courselet'}}\n"", ""return VAR_10[VAR_3]\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""from pages.models import Post\n"", ""VAR_1 = Post.objects.filter(published_date__lte=timezone.now())\n"", ""VAR_2 = Post.objects.values('subject').annotate(newest_published_date=Max(\n    'published_date'))\n"", ""VAR_3 = Post.objects.filter(subject__in=[b.get('subject') for b in pb],\n    published_date__in=[b.get('newest_published_date') for b in pb])\n"", ""return {'navbarMain': VAR_3}\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import os\n"", ""from datetime import timedelta\n"", ""from django.utils.translation import gettext_lazy as _\n"", ""VAR_0 = os.path.dirname(os.path.abspath(__file__))\n"", ""VAR_1 = os.path.normpath(os.path.dirname(__file__))\n"", ""VAR_2 = '_dzlo^9d#ox6!7c9rju@=u8+4^sprqocy3s*l*ejc2yr34@&98'\n"", ""VAR_3 = True\n"", ""VAR_4 = []\n"", ""VAR_5 = ['constance', 'constance.backends.database', 'jet.dashboard', 'jet',\n    'import_export', 'django.contrib.admin', 'django.contrib.auth',\n    'django.contrib.contenttypes', 'django.contrib.sessions',\n    'django.contrib.messages', 'django.contrib.staticfiles',\n    'django.contrib.humanize', 'django_celery_beat', 'compressor',\n    'websecmap.app', 'websecmap.organizations', 'websecmap.scanners',\n    'websecmap.reporting', 'websecmap.map', 'websecmap.pro',\n    'dashboard.internet_nl_dashboard', 'django_otp',\n    'django_otp.plugins.otp_static', 'django_otp.plugins.otp_totp',\n    'two_factor']\n"", ""if not os.environ.get('COMPRESS', False):\n"", ""VAR_6 = ['django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django_otp.middleware.OTPMiddleware']\n"", ""import django_uwsgi\n"", ""VAR_7 = 'dashboard.urls'\n"", ""VAR_5 += ['django_uwsgi']\n"", ""VAR_8 = [{'BACKEND': 'django.template.backends.django.DjangoTemplates',\n    'DIRS': [VAR_0 + '/'], 'APP_DIRS': True, 'OPTIONS': {\n    'context_processors': ['constance.context_processors.config',\n    'django.template.context_processors.debug',\n    'django.template.context_processors.request',\n    'django.contrib.auth.context_processors.auth',\n    'django.contrib.messages.context_processors.messages']}}]\n"", ""VAR_9 = 'dashboard.wsgi.application'\n"", ""VAR_10 = {'mysql': {'init_command': 'string'}}\n"", ""VAR_11 = os.environ.get('DB_ENGINE', 'mysql')\n"", ""VAR_12 = {'mysql': 'dashboard.app.backends.mysql'}\n"", ""VAR_13 = {'dev': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.\n    environ.get('DB_NAME', 'db.sqlite3')}, 'test': {'ENGINE':\n    'django.db.backends.sqlite3', 'NAME': os.environ.get('DB_NAME',\n    'db.sqlite3')}, 'production': {'ENGINE': VAR_12.get(VAR_11, \n    'django.db.backends.' + VAR_11), 'NAME': os.environ.get('DB_NAME',\n    'dashboard'), 'USER': os.environ.get('DB_USER', 'dashboard'),\n    'PASSWORD': os.environ.get('DB_PASSWORD', 'dashboard'), 'HOST': os.\n    environ.get('DB_HOST', 'mysql'), 'OPTIONS': VAR_10.get(os.environ.get(\n    'DB_ENGINE', 'mysql'), {})}}\n"", ""VAR_14 = os.environ.get('DJANGO_DATABASE', 'dev')\n"", ""VAR_15 = {'default': VAR_13[VAR_14]}\n"", ""VAR_16 = [{'NAME':\n    'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'\n    }, {'NAME':\n    'django.contrib.auth.password_validation.MinimumLengthValidator'}, {\n    'NAME':\n    'django.contrib.auth.password_validation.CommonPasswordValidator'}, {\n    'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator'}\n    ]\n"", ""VAR_17 = 'en-us'\n"", ""VAR_18 = 'UTC'\n"", ""VAR_19 = True\n"", ""VAR_20 = True\n"", ""VAR_21 = True\n"", ""VAR_22 = ['locale']\n"", ""VAR_23 = 'dashboard_language'\n"", ""VAR_24 = '/static/'\n"", ""if VAR_3:\n"", ""VAR_59 = 'static'\n"", ""VAR_59 = '/srv/dashboard/static/'\n"", ""VAR_25 = [{'label': _(' Configuration'), 'items': [{'name': 'auth.user'},\n    {'name': 'auth.group'}, {'name': 'constance.config', 'label': _(\n    'Configuration')}]}, {'label': _('Dashboard'), 'items': [{'name':\n    'internet_nl_dashboard.account'}, {'name':\n    'internet_nl_dashboard.urllist'}, {'name':\n    'internet_nl_dashboard.uploadlog'}]}, {'label': _(' Periodic Tasks'),\n    'items': [{'name': 'app.job'}, {'name':\n    'django_celery_beat.periodictask'}, {'name':\n    'django_celery_beat.crontabschedule'}]}]\n"", ""VAR_26 = os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(\n    __file__)) + '/uploads/')\n"", ""VAR_27 = os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(\n    __file__)) + '/uploads/')\n"", ""VAR_28 = 'two_factor:login'\n"", ""VAR_29 = '/dashboard/'\n"", ""VAR_30 = VAR_28\n"", ""VAR_31 = 'qrcode.image.pil.PilImage'\n"", ""VAR_32 = 6\n"", ""VAR_33 = True\n"", ""VAR_34 = os.environ.get('FIELD_ENCRYPTION_KEY',\n    b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=')\n"", ""if not VAR_3 and VAR_34 == b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=':\n"", ""VAR_35 = {'version': 1, 'disable_existing_loggers': False, 'handlers': {\n    'console': {'class': 'logging.StreamHandler', 'formatter': 'color'}},\n    'formatters': {'debug': {'format':\n    '%(asctime)s\\t%(levelname)-8s - %(filename)-20s:%(lineno)-4s - %(funcName)20s() - %(message)s'\n    }, 'color': {'()': 'colorlog.ColoredFormatter', 'format':\n    '%(log_color)s%(asctime)s\\t%(levelname)-8s - %(message)s', 'datefmt':\n    '%Y-%m-%d %H:%M', 'log_colors': {'DEBUG': 'green', 'INFO': 'white',\n    'WARNING': 'yellow', 'ERROR': 'red', 'CRITICAL': 'bold_red'}}},\n    'loggers': {'django': {'handlers': ['console'], 'level': os.getenv(\n    'DJANGO_LOG_LEVEL', 'INFO')}, 'dashboard': {'handlers': ['console'],\n    'level': os.getenv('DJANGO_LOG_LEVEL', 'DEBUG')}}}\n"", ""VAR_36 = ['pickle', 'yaml']\n"", ""VAR_37 = 'pickle'\n"", ""VAR_38 = 'pickle'\n"", ""VAR_39 = os.environ.get('BROKER', 'redis://localhost:6379/0')\n"", ""VAR_40 = True\n"", ""VAR_41 = ['pickle']\n"", ""VAR_42 = 'pickle'\n"", ""VAR_43 = 'pickle'\n"", ""VAR_44 = 'UTC'\n"", ""VAR_45 = 'django_celery_beat.schedulers:DatabaseScheduler'\n"", ""VAR_46 = 1\n"", ""VAR_47 = False\n"", ""VAR_48 = timedelta(hours=4)\n"", ""VAR_49 = 2\n"", ""VAR_50 = 10\n"", ""VAR_51 = True\n"", ""VAR_52 = {'organizations': {'import_data_dir': ''}}\n"", ""VAR_53 = os.environ.get('OUTPUT_DIR', os.path.abspath(os.path.dirname(\n    __file__)) + '/')\n"", ""VAR_54 = os.environ.get('VENDOR_DIR', os.path.abspath(os.path.dirname(\n    __file__) + '/../vendor/') + '/')\n"", ""if VAR_3:\n"", ""VAR_60 = 10000\n"", ""VAR_55 = ('django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n    'compressor.finders.CompressorFinder')\n"", ""VAR_56 = ['compressor.filters.cssmin.CSSCompressorFilter']\n"", ""VAR_57 = 'compressor.storage.GzipCompressorFileStorage'\n"", ""VAR_58 = not VAR_3\n""]",1
"[""def FUNC_23(self):...\n"", ""self.log.info('Initializing interprocess signal socket %s', self.pr_sa)\n"", ""self.pr_sock = self.p.ctx.socket(zmq.PUB)\n"", ""self.pr_sock.bind(self.pr_sa)\n""]",0
"[""@classmethod...\n"", ""if not os.path.isfile(VAR_6.userConfigPath):\n"", ""if VAR_11:\n"", ""if not VAR_11:\n"", ""cf.write(VAR_6.userConfigTemplate % VAR_11)\n"", ""err('Editor not given. Cannot edit.')\n"", ""for VAR_15 in yaml.load_all(cf):\n"", ""if not VAR_11:\n"", ""subprocess.call([VAR_11, VAR_6.userConfigPath])\n"", ""return 2\n"", ""if 'editor' in VAR_15:\n"", ""err('Editor not given. Cannot edit.')\n"", ""return 0\n"", ""VAR_11 = VAR_15['editor']\n"", ""return 3\n""]",1
"[""def FUNC_21():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return 'bibclassify v%s' % (bconfig.VERSION,)\n""]",0
"[""def FUNC_0(VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_11(VAR_9):...\n"", ""@functools.wraps(VAR_9)...\n"", ""VAR_19 = {'$schema': 'http://json-schema.org/draft-07/schema#',\n    'definitions': {'tag': {'type': 'object', 'required': ['namespace',\n    'predicate', 'value'], 'properties': {'namespace': {'type': 'string'},\n    'predicate': {'type': 'string'}, 'value': {'type': ['number', 'string']\n    }}}, 'issue': {'type': 'object', 'required': ['title'], 'properties': {\n    'title': {'type': 'string'}, 'description': {'type': 'string'}, 'tags':\n    {'type': 'array', 'default': [], 'minItems': 0, 'items': {'$ref':\n    '#/definitions/tag'}}}}}}\n"", ""if VAR_3:\n"", ""VAR_19['definitions']['issue']['required'].append('id')\n"", ""VAR_19 = {**VAR_19, **{'type': 'object', 'properties': {'data': {'type':\n    'array', 'minItems': 1, 'items': {'$ref': '#/definitions/issue'}}}}}\n"", ""VAR_19['definitions']['issue']['properties']['id'] = {'type': ['integer',\n    'string']}\n"", ""VAR_20 = request.get_json()\n"", ""validate(instance=request_payload, schema=request_schema)\n"", ""return jsonify({'data': [], 'errors': [\n    'failed to validate payload against json schema']}), 400\n"", ""return VAR_9(*VAR_17, **kwargs)\n""]",1
"[""def FUNC_17(self, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not self.is_mine(VAR_14):\n"", ""VAR_11 = VAR_14.user\n"", ""VAR_11.message_set.create(message=self.message_template % self.created_at)\n""]",0
"[""def FUNC_12(self, VAR_15):...\n"", ""VAR_30 = FUNC_4()\n"", ""VAR_31 = VAR_51.getSettingsFilename()\n"", ""self.write('string'.format('<p><b>Settings updated</b></p>' if VAR_15 else\n    '', VAR_31, VAR_30))\n""]",1
"[""def FUNC_3(self):...\n"", ""assert self.initialised, 'Initialise the map from a file first!'\n"", ""self.turningNodes = []\n"", ""for VAR_23 in range(self.mapHeight):\n"", ""for VAR_22 in range(self.mapWidth):\n"", ""if self.stateMap[VAR_22][VAR_23].isTraversable():\n"", ""self.stateMap[VAR_22][VAR_23].identifyTurning()\n"", ""if self.stateMap[VAR_22][VAR_23].isTurning():\n"", ""self.turningNodes.append([VAR_22, VAR_23])\n""]",0
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""if VAR_0.exception != 'None':\n"", ""return False\n"", ""VAR_2 = VAR_0.answer.split('.')[3]\n"", ""return VAR_2 in VAR_1\n""]",1
"[""def FUNC_13(self, VAR_11, VAR_12, VAR_13, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_31 = 'createhost -iscsi -persona %s -domain %s %s %s' % (VAR_14, VAR_13,\n    VAR_11, VAR_12)\n"", ""VAR_32 = self.common._cli_run(VAR_31, None)\n"", ""if VAR_32 and len(VAR_32) > 1:\n"", ""return self.common.parse_create_host_error(VAR_11, VAR_32)\n"", ""return VAR_11\n""]",1
"[""\""\""\""\nController classes, handling actions required for archival\n\""\""\""\n"", ""import time, tempfile, asyncio, json, os, shutil, signal\n"", ""from itertools import islice\n"", ""from datetime import datetime\n"", ""from operator import attrgetter\n"", ""from abc import ABC, abstractmethod\n"", ""from yarl import URL\n"", ""from . import behavior as cbehavior\n"", ""from .browser import SiteLoader, RequestResponsePair, PageIdle, FrameNavigated\n"", ""from .util import getFormattedViewportMetrics, getSoftwareInfo\n"", ""from .behavior import ExtractLinksEvent\n"", ""__slots__ = 'idleTimeout', 'timeout', 'insecure'\n"", ""def __init__(self, VAR_2=2, VAR_3=10, VAR_4=False):...\n"", ""self.idleTimeout = VAR_2\n"", ""self.timeout = VAR_3\n"", ""self.insecure = VAR_4\n"", ""def FUNC_1(self):...\n"", ""return dict(VAR_2=self.idleTimeout, VAR_3=self.timeout, VAR_4=self.insecure)\n""]",1
"[""def FUNC_1():...\n"", ""VAR_0 = DisclosureExporter(TEST_BW_PROJECT_NAME, TEST_BW_DB_NAME,\n    folder_path=TEST_FOLDER, filename=TEST_FILENAME)\n"", ""VAR_1 = VAR_0.write_json()\n"", ""print(VAR_1)\n"", ""assert os.path.isfile(VAR_1)\n""]",1
"[""@eqlx.with_timeout...\n"", ""return 'no timeout'\n""]",0
"[""@rest_utils.ajax()...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_1.DATA.get('console_type', 'AUTO')\n"", ""VAR_17 = OrderedDict([('VNC', api.nova.server_vnc_console), ('SPICE', api.\n    nova.server_spice_console), ('RDP', api.nova.server_rdp_console), (\n    'SERIAL', api.nova.server_serial_console)])\n"", ""\""\""\""Get a tuple of console url and console type.\""\""\""\n"", ""if VAR_16 == 'AUTO':\n"", ""VAR_40 = VAR_17\n"", ""VAR_40 = {VAR_16: VAR_17[VAR_16]}\n"", ""VAR_51 = _('Console type \""%s\"" not supported.') % VAR_16\n"", ""VAR_41 = exceptions.HttpNotImplemented\n"", ""VAR_41 = exceptions.HTTPNotImplemented\n"", ""for con_type, api_call in VAR_40.items():\n"", ""VAR_49 = api_call(VAR_1, VAR_3)\n"", ""if con_type == 'SERIAL':\n"", ""VAR_50 = VAR_49.url\n"", ""VAR_50 = '%s&%s(%s)' % (VAR_49.url, utils_http.urlencode({'title': _(\n    'Console')}), VAR_3)\n"", ""return {'type': con_type, 'url': VAR_50}\n""]",0
"[""def FUNC_21(self, VAR_14):...\n"", """"]",0
